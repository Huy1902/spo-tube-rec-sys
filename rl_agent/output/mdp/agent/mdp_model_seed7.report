step: 0 @ episode report: {'average_total_reward': 0.0, 'reward_variance': 0.0, 'max_total_reward': 0.0, 'min_total_reward': 0.0, 'average_n_step': 0.0, 'max_n_step': 0.0, 'min_n_step': 0.0, 'buffer_size': 2048} @ step loss: {'critic_loss': 0.42131301760673523, 'actor_loss': 18.772924423217773, 'hyper_actor_loss': 0.07274796813726425, 'behavior_loss': 1.4574223756790161, 'mean_batch': 0.7031083106994629, 'min_batch': -0.3301869034767151, 'max_batch': 1.600395679473877}
step: 10 @ episode report: {'average_total_reward': 0.9639999, 'reward_variance': 1.6530441, 'max_total_reward': 4.57, 'min_total_reward': -0.2, 'average_n_step': 2.9, 'max_n_step': 6.0, 'min_n_step': 2.0, 'buffer_size': 2368} @ step loss: {'critic_loss': 0.330619153380394, 'actor_loss': 23.47763900756836, 'hyper_actor_loss': 0.07379715591669082, 'behavior_loss': 1.6126721501350403, 'mean_batch': 0.20790783874690533, 'min_batch': -0.5084813058376312, 'max_batch': 0.8472534656524658}
step: 20 @ episode report: {'average_total_reward': 1.019, 'reward_variance': 0.64508903, 'max_total_reward': 2.4600003, 'min_total_reward': -0.09, 'average_n_step': 2.9, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 2688} @ step loss: {'critic_loss': 0.19115401059389114, 'actor_loss': 17.87513859272003, 'hyper_actor_loss': 0.07597508504986764, 'behavior_loss': 1.846106493473053, 'mean_batch': 0.3079272866249084, 'min_batch': -0.11776060983538628, 'max_batch': 0.7243722677230835}
step: 30 @ episode report: {'average_total_reward': 0.654, 'reward_variance': 0.594844, 'max_total_reward': 2.24, 'min_total_reward': -0.2, 'average_n_step': 2.7, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 3008} @ step loss: {'critic_loss': 0.13794860392808914, 'actor_loss': 19.848693656921387, 'hyper_actor_loss': 0.07807903960347176, 'behavior_loss': 1.9008562564849854, 'mean_batch': 0.24424911439418792, 'min_batch': -0.12824396342039107, 'max_batch': 0.5326614052057266}
step: 40 @ episode report: {'average_total_reward': 0.475, 'reward_variance': 0.23752499, 'max_total_reward': 1.35, 'min_total_reward': -0.09, 'average_n_step': 2.4, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 3328} @ step loss: {'critic_loss': 0.12235555276274682, 'actor_loss': 14.428477311134339, 'hyper_actor_loss': 0.0800648495554924, 'behavior_loss': 1.9126953721046447, 'mean_batch': 0.318913197517395, 'min_batch': -0.05871965177357197, 'max_batch': 0.6000370383262634}
step: 50 @ episode report: {'average_total_reward': 0.78599995, 'reward_variance': 0.59860396, 'max_total_reward': 2.24, 'min_total_reward': -0.09, 'average_n_step': 2.7, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 3648} @ step loss: {'critic_loss': 0.10592697486281395, 'actor_loss': 18.222722625732423, 'hyper_actor_loss': 0.08272483348846435, 'behavior_loss': 1.8468517780303955, 'mean_batch': 0.2558977484703064, 'min_batch': -0.10062829405069351, 'max_batch': 0.5445438534021377}
step: 60 @ episode report: {'average_total_reward': 0.609, 'reward_variance': 0.266169, 'max_total_reward': 1.24, 'min_total_reward': -0.2, 'average_n_step': 2.6, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 3968} @ step loss: {'critic_loss': 0.1105201631784439, 'actor_loss': 19.82543315887451, 'hyper_actor_loss': 0.0848262757062912, 'behavior_loss': 1.7895408034324647, 'mean_batch': 0.24616552740335465, 'min_batch': -0.17057298570871354, 'max_batch': 0.5246217638254166}
step: 70 @ episode report: {'average_total_reward': 0.94200003, 'reward_variance': 0.129996, 'max_total_reward': 1.35, 'min_total_reward': 0.13, 'average_n_step': 2.9, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 4288} @ step loss: {'critic_loss': 0.0921077124774456, 'actor_loss': 19.91146926879883, 'hyper_actor_loss': 0.0870666302740574, 'behavior_loss': 1.620094633102417, 'mean_batch': 0.22599388062953948, 'min_batch': -0.15472155585885047, 'max_batch': 0.4974666774272919}
step: 80 @ episode report: {'average_total_reward': 0.565, 'reward_variance': 0.28614503, 'max_total_reward': 1.3500001, 'min_total_reward': -0.2, 'average_n_step': 2.6, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 4608} @ step loss: {'critic_loss': 0.09493596479296684, 'actor_loss': 19.892423820495605, 'hyper_actor_loss': 0.08887626826763154, 'behavior_loss': 1.5320064544677734, 'mean_batch': 0.23029690682888032, 'min_batch': -0.17278464883565903, 'max_batch': 0.5051864236593246}
step: 90 @ episode report: {'average_total_reward': 0.309, 'reward_variance': 0.22230902, 'max_total_reward': 1.24, 'min_total_reward': -0.2, 'average_n_step': 2.3, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 4928} @ step loss: {'critic_loss': 0.08430934771895408, 'actor_loss': 20.14874153137207, 'hyper_actor_loss': 0.09046533480286598, 'behavior_loss': 1.423060989379883, 'mean_batch': 0.17835280448198318, 'min_batch': -0.15485098138451575, 'max_batch': 0.44650637209415434}
step: 100 @ episode report: {'average_total_reward': 0.16600001, 'reward_variance': 0.16340402, 'max_total_reward': 0.91, 'min_total_reward': -0.2, 'average_n_step': 2.3, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 5248} @ step loss: {'critic_loss': 0.08476101383566856, 'actor_loss': 20.129603004455568, 'hyper_actor_loss': 0.0917625866830349, 'behavior_loss': 1.2957525610923768, 'mean_batch': 0.1827913776040077, 'min_batch': -0.21467176377773284, 'max_batch': 0.4886313498020172}
step: 110 @ episode report: {'average_total_reward': 0.39800003, 'reward_variance': 0.47383603, 'max_total_reward': 2.24, 'min_total_reward': -0.09, 'average_n_step': 2.4, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 5568} @ step loss: {'critic_loss': 0.0891686238348484, 'actor_loss': 20.691822052001953, 'hyper_actor_loss': 0.09269045293331146, 'behavior_loss': 1.1573005318641663, 'mean_batch': 0.10571682527661323, 'min_batch': -0.3782760813832283, 'max_batch': 0.45647302865982053}
step: 120 @ episode report: {'average_total_reward': 0.031, 'reward_variance': 0.032549, 'max_total_reward': 0.24000001, 'min_total_reward': -0.2, 'average_n_step': 2.0, 'max_n_step': 2.0, 'min_n_step': 2.0, 'buffer_size': 5888} @ step loss: {'critic_loss': 0.0814518854022026, 'actor_loss': 21.495687103271486, 'hyper_actor_loss': 0.09393381923437119, 'behavior_loss': 1.0866333425045014, 'mean_batch': 0.05091671925038099, 'min_batch': -0.37614481151103973, 'max_batch': 0.40757554173469546}
step: 130 @ episode report: {'average_total_reward': -0.07900001, 'reward_variance': 0.018029, 'max_total_reward': 0.24, 'min_total_reward': -0.2, 'average_n_step': 2.0, 'max_n_step': 2.0, 'min_n_step': 2.0, 'buffer_size': 6208} @ step loss: {'critic_loss': 0.08010551184415818, 'actor_loss': 34.04581871032715, 'hyper_actor_loss': 0.09463662430644035, 'behavior_loss': 1.0386054992675782, 'mean_batch': -0.041943841613829136, 'min_batch': -0.5570540368556977, 'max_batch': 0.32504674345254897}
step: 140 @ episode report: {'average_total_reward': -0.10100001, 'reward_variance': 0.015609001, 'max_total_reward': 0.24, 'min_total_reward': -0.2, 'average_n_step': 2.0, 'max_n_step': 2.0, 'min_n_step': 2.0, 'buffer_size': 6528} @ step loss: {'critic_loss': 0.0719148650765419, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.09560541808605194, 'behavior_loss': 1.0079493284225465, 'mean_batch': -0.08021716214716434, 'min_batch': -0.6083247423171997, 'max_batch': 0.33005785644054414}
step: 150 @ episode report: {'average_total_reward': -0.057000004, 'reward_variance': 0.019481001, 'max_total_reward': 0.24000001, 'min_total_reward': -0.2, 'average_n_step': 2.0, 'max_n_step': 2.0, 'min_n_step': 2.0, 'buffer_size': 6848} @ step loss: {'critic_loss': 0.07482080683112144, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.09645436629652977, 'behavior_loss': 0.96446413397789, 'mean_batch': -0.13215411826968193, 'min_batch': -0.7126259565353393, 'max_batch': 0.2793607026338577}
step: 160 @ episode report: {'average_total_reward': 1.086, 'reward_variance': 4.529064, 'max_total_reward': 5.79, 'min_total_reward': -0.2, 'average_n_step': 3.0, 'max_n_step': 7.0, 'min_n_step': 2.0, 'buffer_size': 7168} @ step loss: {'critic_loss': 0.07972973398864269, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.09722798317670822, 'behavior_loss': 0.9372344374656677, 'mean_batch': -0.09846532717347145, 'min_batch': -0.629619711637497, 'max_batch': 0.2815266758203506}
step: 170 @ episode report: {'average_total_reward': 0.065, 'reward_variance': 0.17222498, 'max_total_reward': 1.24, 'min_total_reward': -0.2, 'average_n_step': 2.1, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 7488} @ step loss: {'critic_loss': 0.08365375623106956, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.0979230374097824, 'behavior_loss': 0.9173677861690521, 'mean_batch': -0.08022592738270759, 'min_batch': -0.4992560625076294, 'max_batch': 0.2500301331281662}
step: 180 @ episode report: {'average_total_reward': -0.12300001, 'reward_variance': 0.012221001, 'max_total_reward': 0.13, 'min_total_reward': -0.2, 'average_n_step': 2.0, 'max_n_step': 2.0, 'min_n_step': 2.0, 'buffer_size': 7808} @ step loss: {'critic_loss': 0.07519588619470596, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.09882891625165939, 'behavior_loss': 0.8870839893817901, 'mean_batch': -0.11532572656869888, 'min_batch': -0.5493077129125595, 'max_batch': 0.2680757582187653}
step: 190 @ episode report: {'average_total_reward': -0.024000004, 'reward_variance': 0.024684, 'max_total_reward': 0.24, 'min_total_reward': -0.2, 'average_n_step': 2.0, 'max_n_step': 2.0, 'min_n_step': 2.0, 'buffer_size': 8128} @ step loss: {'critic_loss': 0.07048654481768608, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.09927533939480782, 'behavior_loss': 0.8683761119842529, 'mean_batch': -0.11227562949061394, 'min_batch': -0.5717340856790543, 'max_batch': 0.23260640054941178}
step: 200 @ episode report: {'average_total_reward': -0.024000004, 'reward_variance': 0.022264, 'max_total_reward': 0.24, 'min_total_reward': -0.2, 'average_n_step': 2.0, 'max_n_step': 2.0, 'min_n_step': 2.0, 'buffer_size': 8448} @ step loss: {'critic_loss': 0.06671690531075, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.0999353714287281, 'behavior_loss': 0.8504867732524872, 'mean_batch': -0.24533603638410567, 'min_batch': -0.6955511152744294, 'max_batch': 0.12726261802017688}
step: 210 @ episode report: {'average_total_reward': -0.057000004, 'reward_variance': 0.014641002, 'max_total_reward': 0.13, 'min_total_reward': -0.2, 'average_n_step': 2.0, 'max_n_step': 2.0, 'min_n_step': 2.0, 'buffer_size': 8768} @ step loss: {'critic_loss': 0.0774307731539011, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.1007661372423172, 'behavior_loss': 0.8525951027870178, 'mean_batch': -0.1908086732029915, 'min_batch': -0.5825916856527329, 'max_batch': 0.14639077484607696}
step: 220 @ episode report: {'average_total_reward': 0.076, 'reward_variance': 0.077064, 'max_total_reward': 0.8, 'min_total_reward': -0.2, 'average_n_step': 2.1, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 9088} @ step loss: {'critic_loss': 0.05837616100907326, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10133761689066886, 'behavior_loss': 0.8308950304985047, 'mean_batch': -0.18818770349025726, 'min_batch': -0.6004720509052277, 'max_batch': 0.1245430950075388}
step: 230 @ episode report: {'average_total_reward': 0.30900002, 'reward_variance': 0.42472905, 'max_total_reward': 2.13, 'min_total_reward': -0.2, 'average_n_step': 2.3, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 9408} @ step loss: {'critic_loss': 0.06588977724313735, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10167163237929344, 'behavior_loss': 0.7791643857955932, 'mean_batch': -0.25504191070795057, 'min_batch': -0.6637638688087464, 'max_batch': 0.08742186948657035}
step: 240 @ episode report: {'average_total_reward': 0.275, 'reward_variance': 0.22154501, 'max_total_reward': 1.35, 'min_total_reward': -0.09, 'average_n_step': 2.2, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 9728} @ step loss: {'critic_loss': 0.062169095128774644, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10235317721962929, 'behavior_loss': 0.7548052847385407, 'mean_batch': -0.2331576406955719, 'min_batch': -0.5813026785850525, 'max_batch': 0.10809699185192585}
step: 250 @ episode report: {'average_total_reward': 0.365, 'reward_variance': 0.164045, 'max_total_reward': 1.24, 'min_total_reward': -0.2, 'average_n_step': 2.4, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 10048} @ step loss: {'critic_loss': 0.060307396948337554, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10333923101425171, 'behavior_loss': 0.781772643327713, 'mean_batch': -0.19648125916719436, 'min_batch': -0.5605189234018326, 'max_batch': 0.1383383184671402}
step: 260 @ episode report: {'average_total_reward': 0.44300002, 'reward_variance': 0.599721, 'max_total_reward': 2.24, 'min_total_reward': -0.2, 'average_n_step': 2.5, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 10368} @ step loss: {'critic_loss': 0.06418565176427364, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10370695069432259, 'behavior_loss': 0.7354193568229676, 'mean_batch': -0.23590664863586425, 'min_batch': -0.5497114717960357, 'max_batch': 0.04349149614572525}
step: 270 @ episode report: {'average_total_reward': 0.266, 'reward_variance': 0.16986401, 'max_total_reward': 1.13, 'min_total_reward': -0.2, 'average_n_step': 2.4, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 10688} @ step loss: {'critic_loss': 0.06411089561879635, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10409318059682846, 'behavior_loss': 0.7477652549743652, 'mean_batch': -0.2636853739619255, 'min_batch': -0.6440195620059967, 'max_batch': 0.07377891354262829}
step: 280 @ episode report: {'average_total_reward': 0.27499998, 'reward_variance': 0.121224985, 'max_total_reward': 1.13, 'min_total_reward': -0.09, 'average_n_step': 2.2, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 11008} @ step loss: {'critic_loss': 0.06087093986570835, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10462519824504853, 'behavior_loss': 0.7271001875400543, 'mean_batch': -0.2714563250541687, 'min_batch': -0.6336594700813294, 'max_batch': 0.021755876392126082}
step: 290 @ episode report: {'average_total_reward': 0.179, 'reward_variance': 0.087629005, 'max_total_reward': 0.8000001, 'min_total_reward': -0.2, 'average_n_step': 2.5, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 11328} @ step loss: {'critic_loss': 0.060878222435712816, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10496428608894348, 'behavior_loss': 0.7105173289775848, 'mean_batch': -0.26561464965343473, 'min_batch': -0.5813246130943298, 'max_batch': 0.07865599542856216}
step: 300 @ episode report: {'average_total_reward': 0.9080001, 'reward_variance': 2.6659565, 'max_total_reward': 5.6800003, 'min_total_reward': 0.019999996, 'average_n_step': 2.8, 'max_n_step': 7.0, 'min_n_step': 2.0, 'buffer_size': 11648} @ step loss: {'critic_loss': 0.0611633587628603, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10559537336230278, 'behavior_loss': 0.6979988396167756, 'mean_batch': -0.2636132135987282, 'min_batch': -0.6161754488945007, 'max_batch': 0.05810967311263084}
step: 310 @ episode report: {'average_total_reward': 0.589, 'reward_variance': 0.09992901, 'max_total_reward': 0.91, 'min_total_reward': -0.09, 'average_n_step': 2.8, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 11968} @ step loss: {'critic_loss': 0.06233206987380981, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10588098838925361, 'behavior_loss': 0.7012796580791474, 'mean_batch': -0.27352271378040316, 'min_batch': -0.5826761364936829, 'max_batch': 0.027364885807037352}
step: 320 @ episode report: {'average_total_reward': 0.531, 'reward_variance': 0.24668899, 'max_total_reward': 1.35, 'min_total_reward': -0.2, 'average_n_step': 2.5, 'max_n_step': 3.0, 'min_n_step': 2.0, 'buffer_size': 12288} @ step loss: {'critic_loss': 0.06157188601791859, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.1061437413096428, 'behavior_loss': 0.699472290277481, 'mean_batch': -0.2879586488008499, 'min_batch': -0.5968235850334167, 'max_batch': 0.046292911469936374}
step: 330 @ episode report: {'average_total_reward': 0.86300004, 'reward_variance': 0.46886104, 'max_total_reward': 2.02, 'min_total_reward': -0.09, 'average_n_step': 2.7, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 12608} @ step loss: {'critic_loss': 0.06320025622844697, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10664825290441513, 'behavior_loss': 0.671880567073822, 'mean_batch': -0.30139514803886414, 'min_batch': -0.6338022768497467, 'max_batch': 0.018411893397569656}
step: 340 @ episode report: {'average_total_reward': 1.4420002, 'reward_variance': 1.4634563, 'max_total_reward': 4.6800003, 'min_total_reward': 0.24000001, 'average_n_step': 3.4, 'max_n_step': 6.0, 'min_n_step': 2.0, 'buffer_size': 12928} @ step loss: {'critic_loss': 0.054617589339613914, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10692712813615798, 'behavior_loss': 0.6796814024448394, 'mean_batch': -0.3021091729402542, 'min_batch': -0.6831175208091735, 'max_batch': 0.09568328149616719}
step: 350 @ episode report: {'average_total_reward': 1.054, 'reward_variance': 0.31050405, 'max_total_reward': 2.13, 'min_total_reward': -0.09, 'average_n_step': 3.1, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 13248} @ step loss: {'critic_loss': 0.06484692730009556, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10737903714179993, 'behavior_loss': 0.6710906565189362, 'mean_batch': -0.2928663492202759, 'min_batch': -0.5979002892971039, 'max_batch': 0.03401389829814434}
step: 360 @ episode report: {'average_total_reward': 1.187, 'reward_variance': 0.43866104, 'max_total_reward': 2.3500001, 'min_total_reward': 0.13, 'average_n_step': 3.2, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 13568} @ step loss: {'critic_loss': 0.06036893390119076, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.1076525829732418, 'behavior_loss': 0.6570985615253448, 'mean_batch': -0.2846602097153664, 'min_batch': -0.6151922345161438, 'max_batch': 0.06896462813019752}
step: 370 @ episode report: {'average_total_reward': 1.098, 'reward_variance': 0.87167585, 'max_total_reward': 3.35, 'min_total_reward': 0.019999996, 'average_n_step': 3.1, 'max_n_step': 5.0, 'min_n_step': 2.0, 'buffer_size': 13888} @ step loss: {'critic_loss': 0.06421948671340942, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10809536799788474, 'behavior_loss': 0.6470093667507172, 'mean_batch': -0.2712091043591499, 'min_batch': -0.5820852965116501, 'max_batch': 0.06312717087566852}
step: 380 @ episode report: {'average_total_reward': 1.42, 'reward_variance': 0.97156, 'max_total_reward': 3.13, 'min_total_reward': 0.019999996, 'average_n_step': 3.4, 'max_n_step': 5.0, 'min_n_step': 2.0, 'buffer_size': 14208} @ step loss: {'critic_loss': 0.060252011939883235, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10853521376848221, 'behavior_loss': 0.6289823293685913, 'mean_batch': -0.2767431244254112, 'min_batch': -0.6171920657157898, 'max_batch': 0.10439681373536587}
step: 390 @ episode report: {'average_total_reward': 1.32, 'reward_variance': 1.8048998, 'max_total_reward': 4.46, 'min_total_reward': 0.02, 'average_n_step': 3.3, 'max_n_step': 6.0, 'min_n_step': 2.0, 'buffer_size': 14528} @ step loss: {'critic_loss': 0.059157198667526244, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10876314714550972, 'behavior_loss': 0.621898227930069, 'mean_batch': -0.274178621172905, 'min_batch': -0.6149577319622039, 'max_batch': 0.10797947384417057}
step: 400 @ episode report: {'average_total_reward': 1.7850001, 'reward_variance': 0.24522504, 'max_total_reward': 2.3500001, 'min_total_reward': 1.13, 'average_n_step': 3.6, 'max_n_step': 4.0, 'min_n_step': 3.0, 'buffer_size': 14848} @ step loss: {'critic_loss': 0.0641044870018959, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10870907977223396, 'behavior_loss': 0.6343733668327332, 'mean_batch': -0.2611765146255493, 'min_batch': -0.6351267755031585, 'max_batch': 0.1815123215317726}
step: 410 @ episode report: {'average_total_reward': 0.96400005, 'reward_variance': 0.41368398, 'max_total_reward': 2.46, 'min_total_reward': -0.09, 'average_n_step': 2.9, 'max_n_step': 4.0, 'min_n_step': 2.0, 'buffer_size': 15168} @ step loss: {'critic_loss': 0.059651829302310944, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10905240550637245, 'behavior_loss': 0.6444295287132263, 'mean_batch': -0.2643130883574486, 'min_batch': -0.6222070336341858, 'max_batch': 0.16847467720508574}
step: 420 @ episode report: {'average_total_reward': 1.952, 'reward_variance': 0.48029596, 'max_total_reward': 3.35, 'min_total_reward': 0.8, 'average_n_step': 3.8, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 15488} @ step loss: {'critic_loss': 0.06452197656035423, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10904882550239563, 'behavior_loss': 0.6482976078987122, 'mean_batch': -0.24370194971561432, 'min_batch': -0.6093883335590362, 'max_batch': 0.13542310446500777}
step: 430 @ episode report: {'average_total_reward': 1.9529998, 'reward_variance': 0.50860095, 'max_total_reward': 3.02, 'min_total_reward': 0.8, 'average_n_step': 3.9, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 15808} @ step loss: {'critic_loss': 0.0652127679437399, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10901885628700256, 'behavior_loss': 0.6357502222061158, 'mean_batch': -0.19868568181991578, 'min_batch': -0.5900269746780396, 'max_batch': 0.1881693810224533}
step: 440 @ episode report: {'average_total_reward': 2.152, 'reward_variance': 0.89939606, 'max_total_reward': 3.3500001, 'min_total_reward': 0.90999997, 'average_n_step': 4.0, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 16128} @ step loss: {'critic_loss': 0.056280316412448884, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10906190201640129, 'behavior_loss': 0.6239206850528717, 'mean_batch': -0.17020729631185533, 'min_batch': -0.535886013507843, 'max_batch': 0.28134740591049195}
step: 450 @ episode report: {'average_total_reward': 2.0960002, 'reward_variance': 1.2596639, 'max_total_reward': 4.35, 'min_total_reward': 0.24, 'average_n_step': 3.9, 'max_n_step': 6.0, 'min_n_step': 2.0, 'buffer_size': 16448} @ step loss: {'critic_loss': 0.06279931068420411, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10931076034903527, 'behavior_loss': 0.6418878555297851, 'mean_batch': -0.15385086536407472, 'min_batch': -0.5502945721149445, 'max_batch': 0.42706080675125124}
step: 460 @ episode report: {'average_total_reward': 2.263, 'reward_variance': 0.717821, 'max_total_reward': 4.46, 'min_total_reward': 0.8, 'average_n_step': 4.1, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 16768} @ step loss: {'critic_loss': 0.05919613502919674, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10908635035157203, 'behavior_loss': 0.6405147314071655, 'mean_batch': -0.1572953447699547, 'min_batch': -0.6168069779872895, 'max_batch': 0.3658489719033241}
step: 470 @ episode report: {'average_total_reward': 2.418, 'reward_variance': 1.029456, 'max_total_reward': 4.35, 'min_total_reward': 0.9100001, 'average_n_step': 4.2, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 17088} @ step loss: {'critic_loss': 0.06460744366049767, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10893724486231804, 'behavior_loss': 0.6161278069019318, 'mean_batch': -0.09988698670640588, 'min_batch': -0.5589723765850068, 'max_batch': 0.40221128463745115}
step: 480 @ episode report: {'average_total_reward': 2.007, 'reward_variance': 0.45406103, 'max_total_reward': 3.5700002, 'min_total_reward': 1.02, 'average_n_step': 3.8, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 17408} @ step loss: {'critic_loss': 0.06144145280122757, 'actor_loss': 36.84136199951172, 'hyper_actor_loss': 0.10881795361638069, 'behavior_loss': 0.6351932108402252, 'mean_batch': -0.07452451251447201, 'min_batch': -0.4897324800491333, 'max_batch': 0.3627021640539169}
step: 490 @ episode report: {'average_total_reward': 2.0960002, 'reward_variance': 0.7157641, 'max_total_reward': 3.3500001, 'min_total_reward': 0.69, 'average_n_step': 3.9, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 17728} @ step loss: {'critic_loss': 0.06261210478842258, 'actor_loss': 33.84314804077148, 'hyper_actor_loss': 0.1086316503584385, 'behavior_loss': 0.6337701439857483, 'mean_batch': -0.03703339453786612, 'min_batch': -0.43803219199180604, 'max_batch': 0.533137995004654}
step: 500 @ episode report: {'average_total_reward': 2.3400002, 'reward_variance': 0.7533601, 'max_total_reward': 3.4600003, 'min_total_reward': 1.24, 'average_n_step': 4.1, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 18048} @ step loss: {'critic_loss': 0.051238921284675595, 'actor_loss': 25.233665657043456, 'hyper_actor_loss': 0.10842855051159858, 'behavior_loss': 0.6251136779785156, 'mean_batch': 0.04216027418151498, 'min_batch': -0.36458793431520464, 'max_batch': 0.4872261732816696}
step: 510 @ episode report: {'average_total_reward': 2.2619998, 'reward_variance': 0.743176, 'max_total_reward': 3.46, 'min_total_reward': 0.91, 'average_n_step': 4.0, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 18368} @ step loss: {'critic_loss': 0.0598956935107708, 'actor_loss': 20.68743133544922, 'hyper_actor_loss': 0.1084645852446556, 'behavior_loss': 0.6346112668514252, 'mean_batch': 0.10718664266169071, 'min_batch': -0.3882926642894745, 'max_batch': 0.6465258479118348}
step: 520 @ episode report: {'average_total_reward': 2.573, 'reward_variance': 0.7658811, 'max_total_reward': 3.5700002, 'min_total_reward': 1.02, 'average_n_step': 4.3, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 18688} @ step loss: {'critic_loss': 0.06573307253420353, 'actor_loss': 20.422234535217285, 'hyper_actor_loss': 0.10875913649797439, 'behavior_loss': 0.6370851933956146, 'mean_batch': 0.140410615503788, 'min_batch': -0.34042427837848666, 'max_batch': 0.6675211668014527}
step: 530 @ episode report: {'average_total_reward': 2.352, 'reward_variance': 0.22111598, 'max_total_reward': 3.24, 'min_total_reward': 1.69, 'average_n_step': 4.2, 'max_n_step': 5.0, 'min_n_step': 4.0, 'buffer_size': 19008} @ step loss: {'critic_loss': 0.06182275637984276, 'actor_loss': 19.9910680770874, 'hyper_actor_loss': 0.10904362723231316, 'behavior_loss': 0.6258942186832428, 'mean_batch': 0.2122684270143509, 'min_batch': -0.2622933268547058, 'max_batch': 0.7320262551307678}
step: 540 @ episode report: {'average_total_reward': 2.5279999, 'reward_variance': 0.9709361, 'max_total_reward': 4.57, 'min_total_reward': 1.13, 'average_n_step': 4.2, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 19328} @ step loss: {'critic_loss': 0.056302303448319435, 'actor_loss': 19.785042572021485, 'hyper_actor_loss': 0.1090819150209427, 'behavior_loss': 0.620872950553894, 'mean_batch': 0.25867891162633894, 'min_batch': -0.3069483257830143, 'max_batch': 0.8100691616535187}
step: 550 @ episode report: {'average_total_reward': 2.628, 'reward_variance': 1.1230161, 'max_total_reward': 4.6800003, 'min_total_reward': 1.02, 'average_n_step': 4.3, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 19648} @ step loss: {'critic_loss': 0.058576063439249995, 'actor_loss': 19.669089126586915, 'hyper_actor_loss': 0.10918857008218766, 'behavior_loss': 0.6274131536483765, 'mean_batch': 0.288641183078289, 'min_batch': -0.22231625393033028, 'max_batch': 0.7877881407737732}
step: 560 @ episode report: {'average_total_reward': 1.8840002, 'reward_variance': 0.73662406, 'max_total_reward': 3.3500001, 'min_total_reward': 1.02, 'average_n_step': 3.6, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 19968} @ step loss: {'critic_loss': 0.057748456671833995, 'actor_loss': 19.52717533111572, 'hyper_actor_loss': 0.10913418084383011, 'behavior_loss': 0.6315330326557159, 'mean_batch': 0.33197048008441926, 'min_batch': -0.22870297133922576, 'max_batch': 0.7947126865386963}
step: 570 @ episode report: {'average_total_reward': 3.2610002, 'reward_variance': 0.94452906, 'max_total_reward': 4.57, 'min_total_reward': 1.13, 'average_n_step': 4.9, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 20288} @ step loss: {'critic_loss': 0.06433625742793084, 'actor_loss': 19.323544311523438, 'hyper_actor_loss': 0.10922851786017418, 'behavior_loss': 0.6141778886318207, 'mean_batch': 0.4122687578201294, 'min_batch': -0.12768713235855103, 'max_batch': 0.8964060068130493}
step: 580 @ episode report: {'average_total_reward': 3.006, 'reward_variance': 0.82322407, 'max_total_reward': 4.46, 'min_total_reward': 0.90999997, 'average_n_step': 4.7, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 20608} @ step loss: {'critic_loss': 0.06893201507627963, 'actor_loss': 12.876911294460296, 'hyper_actor_loss': 0.1091429702937603, 'behavior_loss': 0.6163666844367981, 'mean_batch': 0.3885198384523392, 'min_batch': -0.038148824125528336, 'max_batch': 0.8787130773067474}
step: 590 @ episode report: {'average_total_reward': 2.5170002, 'reward_variance': 0.24594107, 'max_total_reward': 3.2400002, 'min_total_reward': 1.35, 'average_n_step': 4.2, 'max_n_step': 5.0, 'min_n_step': 3.0, 'buffer_size': 20928} @ step loss: {'critic_loss': 0.06299744211137295, 'actor_loss': 17.61960895061493, 'hyper_actor_loss': 0.10911067575216293, 'behavior_loss': 0.6209263026714325, 'mean_batch': 0.4785649210214615, 'min_batch': -0.10286776833236218, 'max_batch': 0.9873612344264984}
step: 600 @ episode report: {'average_total_reward': 3.117, 'reward_variance': 0.96386087, 'max_total_reward': 4.35, 'min_total_reward': 1.35, 'average_n_step': 4.8, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 21248} @ step loss: {'critic_loss': 0.06736351661384106, 'actor_loss': 13.883416533470154, 'hyper_actor_loss': 0.10921494737267494, 'behavior_loss': 0.6224905252456665, 'mean_batch': 0.5302023410797119, 'min_batch': -0.031172266602516173, 'max_batch': 0.9587216198444366}
step: 610 @ episode report: {'average_total_reward': 3.172, 'reward_variance': 0.37293595, 'max_total_reward': 4.46, 'min_total_reward': 2.3500001, 'average_n_step': 4.8, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 21568} @ step loss: {'critic_loss': 0.06820178106427192, 'actor_loss': 11.723160862922668, 'hyper_actor_loss': 0.10921884477138519, 'behavior_loss': 0.6086808025836945, 'mean_batch': 0.618961751461029, 'min_batch': -0.006292987614870071, 'max_batch': 1.0508866429328918}
step: 620 @ episode report: {'average_total_reward': 3.4720001, 'reward_variance': 1.3775163, 'max_total_reward': 5.5700006, 'min_total_reward': 2.24, 'average_n_step': 5.1, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 21888} @ step loss: {'critic_loss': 0.07181832902133464, 'actor_loss': 9.939937940239906, 'hyper_actor_loss': 0.10966258719563485, 'behavior_loss': 0.6178003907203674, 'mean_batch': 0.660216498374939, 'min_batch': 0.029448223114013673, 'max_batch': 1.1124587833881379}
step: 630 @ episode report: {'average_total_reward': 2.639, 'reward_variance': 0.6275689, 'max_total_reward': 4.68, 'min_total_reward': 2.1299999, 'average_n_step': 4.3, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 22208} @ step loss: {'critic_loss': 0.07165766321122646, 'actor_loss': 0.8058627128601075, 'hyper_actor_loss': 0.10949114933609963, 'behavior_loss': 0.5828548431396484, 'mean_batch': 0.6969439744949341, 'min_batch': 0.1582418128848076, 'max_batch': 1.1672173976898192}
step: 640 @ episode report: {'average_total_reward': 3.161, 'reward_variance': 1.2262089, 'max_total_reward': 5.24, 'min_total_reward': 1.3500001, 'average_n_step': 4.8, 'max_n_step': 7.0, 'min_n_step': 3.0, 'buffer_size': 22528} @ step loss: {'critic_loss': 0.08413884714245796, 'actor_loss': 0.32063978910446167, 'hyper_actor_loss': 0.10924209356307983, 'behavior_loss': 0.6108791530132294, 'mean_batch': 0.7994135081768036, 'min_batch': 0.19122957140207292, 'max_batch': 1.2463699102401733}
step: 650 @ episode report: {'average_total_reward': 2.928, 'reward_variance': 0.46327585, 'max_total_reward': 4.4599996, 'min_total_reward': 2.24, 'average_n_step': 4.6, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 22848} @ step loss: {'critic_loss': 0.080000014975667, 'actor_loss': 3.8413422763347627, 'hyper_actor_loss': 0.10932935997843743, 'behavior_loss': 0.6169622600078583, 'mean_batch': 0.8164570212364197, 'min_batch': 0.15859265252947807, 'max_batch': 1.2488531112670898}
step: 660 @ episode report: {'average_total_reward': 2.894, 'reward_variance': 0.5090038, 'max_total_reward': 4.5699997, 'min_total_reward': 2.2400002, 'average_n_step': 4.5, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 23168} @ step loss: {'critic_loss': 0.09924185872077942, 'actor_loss': -0.34786006808280945, 'hyper_actor_loss': 0.10928708091378211, 'behavior_loss': 0.6225076854228974, 'mean_batch': 0.8931781589984894, 'min_batch': 0.33231701552867887, 'max_batch': 1.2665504217147827}
step: 670 @ episode report: {'average_total_reward': 3.194, 'reward_variance': 1.9956446, 'max_total_reward': 5.680001, 'min_total_reward': 1.35, 'average_n_step': 4.8, 'max_n_step': 7.0, 'min_n_step': 3.0, 'buffer_size': 23488} @ step loss: {'critic_loss': 0.10546542853116989, 'actor_loss': -0.6528208665549755, 'hyper_actor_loss': 0.10916493386030197, 'behavior_loss': 0.6270861983299255, 'mean_batch': 0.977624386548996, 'min_batch': 0.42001187056303024, 'max_batch': 1.3167941331863404}
step: 680 @ episode report: {'average_total_reward': 3.338, 'reward_variance': 0.6120559, 'max_total_reward': 4.57, 'min_total_reward': 2.24, 'average_n_step': 4.9, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 23808} @ step loss: {'critic_loss': 0.11824500858783722, 'actor_loss': -0.4281682685017586, 'hyper_actor_loss': 0.10879599899053574, 'behavior_loss': 0.6257560670375824, 'mean_batch': 1.0006093859672547, 'min_batch': 0.3252791196107864, 'max_batch': 1.3886279463768005}
step: 690 @ episode report: {'average_total_reward': 3.2160003, 'reward_variance': 0.989504, 'max_total_reward': 4.57, 'min_total_reward': 1.1300001, 'average_n_step': 4.8, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 24128} @ step loss: {'critic_loss': 0.12421251833438873, 'actor_loss': -0.9784366935491562, 'hyper_actor_loss': 0.10895842909812928, 'behavior_loss': 0.6225753784179687, 'mean_batch': 1.1259429931640625, 'min_batch': 0.49312331080436705, 'max_batch': 1.499372136592865}
step: 700 @ episode report: {'average_total_reward': 3.4720001, 'reward_variance': 0.9537361, 'max_total_reward': 5.6800003, 'min_total_reward': 2.13, 'average_n_step': 5.1, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 24448} @ step loss: {'critic_loss': 0.14306597858667375, 'actor_loss': -1.1119301319122314, 'hyper_actor_loss': 0.10898793935775757, 'behavior_loss': 0.6199069023132324, 'mean_batch': 1.156966245174408, 'min_batch': 0.5392122954130173, 'max_batch': 1.4827117800712586}
step: 710 @ episode report: {'average_total_reward': 2.883, 'reward_variance': 1.2197411, 'max_total_reward': 4.57, 'min_total_reward': 1.35, 'average_n_step': 4.5, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 24768} @ step loss: {'critic_loss': 0.15533080399036409, 'actor_loss': -1.059597335755825, 'hyper_actor_loss': 0.10899083986878395, 'behavior_loss': 0.6193847417831421, 'mean_batch': 1.194192373752594, 'min_batch': 0.5308837324380875, 'max_batch': 1.4965237498283386}
step: 720 @ episode report: {'average_total_reward': 3.4380002, 'reward_variance': 1.3022361, 'max_total_reward': 5.6800003, 'min_total_reward': 2.0200002, 'average_n_step': 5.0, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 25088} @ step loss: {'critic_loss': 0.15415154695510863, 'actor_loss': -1.1128327190876006, 'hyper_actor_loss': 0.10901258066296578, 'behavior_loss': 0.6149044990539551, 'mean_batch': 1.188658392429352, 'min_batch': 0.5608304187655448, 'max_batch': 1.499548077583313}
step: 730 @ episode report: {'average_total_reward': 3.616, 'reward_variance': 1.746604, 'max_total_reward': 5.57, 'min_total_reward': 1.35, 'average_n_step': 5.2, 'max_n_step': 7.0, 'min_n_step': 3.0, 'buffer_size': 25408} @ step loss: {'critic_loss': 0.18021444976329803, 'actor_loss': -1.4354042291641236, 'hyper_actor_loss': 0.10901873335242271, 'behavior_loss': 0.5999809801578522, 'mean_batch': 1.271185028553009, 'min_batch': 0.6750515282154084, 'max_batch': 1.5663181304931642}
step: 740 @ episode report: {'average_total_reward': 3.8490002, 'reward_variance': 1.0962889, 'max_total_reward': 5.35, 'min_total_reward': 1.9100002, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 25728} @ step loss: {'critic_loss': 0.1881377875804901, 'actor_loss': -1.6358333289623261, 'hyper_actor_loss': 0.10903198793530464, 'behavior_loss': 0.600949364900589, 'mean_batch': 1.343326735496521, 'min_batch': 0.8118020117282867, 'max_batch': 1.659673261642456}
step: 750 @ episode report: {'average_total_reward': 2.9610002, 'reward_variance': 0.6109291, 'max_total_reward': 4.57, 'min_total_reward': 1.9100001, 'average_n_step': 4.6, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 26048} @ step loss: {'critic_loss': 0.20843398571014404, 'actor_loss': -1.6946967005729676, 'hyper_actor_loss': 0.10893841162323951, 'behavior_loss': 0.6213594198226928, 'mean_batch': 1.3969552874565125, 'min_batch': 0.804067748785019, 'max_batch': 1.7028801321983338}
step: 760 @ episode report: {'average_total_reward': 3.5940003, 'reward_variance': 1.4478244, 'max_total_reward': 5.5700006, 'min_total_reward': 2.24, 'average_n_step': 5.2, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 26368} @ step loss: {'critic_loss': 0.22520213276147844, 'actor_loss': -1.9058164596557616, 'hyper_actor_loss': 0.10881236419081688, 'behavior_loss': 0.6128827571868897, 'mean_batch': 1.4383485674858094, 'min_batch': 0.9520575404167175, 'max_batch': 1.6969778776168822}
step: 770 @ episode report: {'average_total_reward': 3.4170003, 'reward_variance': 1.9336411, 'max_total_reward': 6.79, 'min_total_reward': 2.13, 'average_n_step': 5.1, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 26688} @ step loss: {'critic_loss': 0.23560479134321213, 'actor_loss': -1.8686885595321656, 'hyper_actor_loss': 0.10886553674936295, 'behavior_loss': 0.5956411838531495, 'mean_batch': 1.4462738990783692, 'min_batch': 0.9050596594810486, 'max_batch': 1.7324169158935547}
step: 780 @ episode report: {'average_total_reward': 3.3170002, 'reward_variance': 1.1490409, 'max_total_reward': 4.6800003, 'min_total_reward': 1.69, 'average_n_step': 5.0, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 27008} @ step loss: {'critic_loss': 0.23674551099538804, 'actor_loss': -1.8600911974906922, 'hyper_actor_loss': 0.10871691703796386, 'behavior_loss': 0.6042578220367432, 'mean_batch': 1.4711621522903442, 'min_batch': 0.8900191307067871, 'max_batch': 1.7475247621536254}
step: 790 @ episode report: {'average_total_reward': 4.116, 'reward_variance': 0.576584, 'max_total_reward': 4.6800003, 'min_total_reward': 2.46, 'average_n_step': 5.7, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 27328} @ step loss: {'critic_loss': 0.2782369554042816, 'actor_loss': -1.9852497696876525, 'hyper_actor_loss': 0.10859697237610817, 'behavior_loss': 0.6048974335193634, 'mean_batch': 1.4828428506851197, 'min_batch': 0.9995052933692932, 'max_batch': 1.7772855162620544}
step: 800 @ episode report: {'average_total_reward': 3.6710002, 'reward_variance': 1.154469, 'max_total_reward': 5.68, 'min_total_reward': 2.13, 'average_n_step': 5.2, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 27648} @ step loss: {'critic_loss': 0.29713125228881837, 'actor_loss': -1.9722561717033387, 'hyper_actor_loss': 0.10877254158258438, 'behavior_loss': 0.6110869646072388, 'mean_batch': 1.545074725151062, 'min_batch': 0.9446338832378387, 'max_batch': 1.8375590443611145}
step: 810 @ episode report: {'average_total_reward': 3.316, 'reward_variance': 0.72304404, 'max_total_reward': 4.46, 'min_total_reward': 2.1299999, 'average_n_step': 4.9, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 27968} @ step loss: {'critic_loss': 0.30750170797109605, 'actor_loss': -2.11177773475647, 'hyper_actor_loss': 0.10882988721132278, 'behavior_loss': 0.6054190814495086, 'mean_batch': 1.5574225544929505, 'min_batch': 1.0787590146064758, 'max_batch': 1.8340730547904969}
step: 820 @ episode report: {'average_total_reward': 3.449, 'reward_variance': 0.425289, 'max_total_reward': 4.6800003, 'min_total_reward': 2.46, 'average_n_step': 5.0, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 28288} @ step loss: {'critic_loss': 0.3347620666027069, 'actor_loss': -2.1878710269927977, 'hyper_actor_loss': 0.10890326201915741, 'behavior_loss': 0.6070545732975006, 'mean_batch': 1.5719849348068238, 'min_batch': 1.1365350008010864, 'max_batch': 1.8648937582969665}
step: 830 @ episode report: {'average_total_reward': 3.65, 'reward_variance': 1.32746, 'max_total_reward': 5.6800003, 'min_total_reward': 2.02, 'average_n_step': 5.3, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 28608} @ step loss: {'critic_loss': 0.35037530660629274, 'actor_loss': -2.3344635248184202, 'hyper_actor_loss': 0.10847850143909454, 'behavior_loss': 0.6217131197452546, 'mean_batch': 1.7266615867614745, 'min_batch': 1.2276803255081177, 'max_batch': 2.011630725860596}
step: 840 @ episode report: {'average_total_reward': 4.037, 'reward_variance': 0.6344811, 'max_total_reward': 5.79, 'min_total_reward': 3.35, 'average_n_step': 5.5, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 28928} @ step loss: {'critic_loss': 0.3372711181640625, 'actor_loss': -2.1606356501579285, 'hyper_actor_loss': 0.10850768014788628, 'behavior_loss': 0.5986255884170533, 'mean_batch': 1.5745776772499085, 'min_batch': 1.1208369255065918, 'max_batch': 1.8270940780639648}
step: 850 @ episode report: {'average_total_reward': 3.9490001, 'reward_variance': 0.93270904, 'max_total_reward': 5.57, 'min_total_reward': 2.35, 'average_n_step': 5.5, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 29248} @ step loss: {'critic_loss': 0.38837063908576963, 'actor_loss': -2.422189998626709, 'hyper_actor_loss': 0.10856515616178512, 'behavior_loss': 0.6245441675186157, 'mean_batch': 1.7461142063140869, 'min_batch': 1.2985156297683715, 'max_batch': 2.0365405797958376}
step: 860 @ episode report: {'average_total_reward': 3.338, 'reward_variance': 0.64373606, 'max_total_reward': 4.6800003, 'min_total_reward': 2.24, 'average_n_step': 4.9, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 29568} @ step loss: {'critic_loss': 0.389461150765419, 'actor_loss': -2.380945348739624, 'hyper_actor_loss': 0.10882113575935363, 'behavior_loss': 0.6085329473018646, 'mean_batch': 1.7221426844596863, 'min_batch': 1.278881573677063, 'max_batch': 1.9785526394844055}
step: 870 @ episode report: {'average_total_reward': 3.0619998, 'reward_variance': 1.331776, 'max_total_reward': 4.57, 'min_total_reward': 1.3500001, 'average_n_step': 4.8, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 29888} @ step loss: {'critic_loss': 0.41535813808441163, 'actor_loss': -2.4207592010498047, 'hyper_actor_loss': 0.10874143093824387, 'behavior_loss': 0.6157058775424957, 'mean_batch': 1.7352054715156555, 'min_batch': 1.302950417995453, 'max_batch': 1.998890256881714}
step: 880 @ episode report: {'average_total_reward': 3.4940002, 'reward_variance': 0.915984, 'max_total_reward': 5.79, 'min_total_reward': 2.24, 'average_n_step': 5.1, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 30208} @ step loss: {'critic_loss': 0.4294618934392929, 'actor_loss': -2.526457333564758, 'hyper_actor_loss': 0.10881215631961823, 'behavior_loss': 0.6211531102657318, 'mean_batch': 1.7777662873268127, 'min_batch': 1.4093810677528382, 'max_batch': 2.030552661418915}
step: 890 @ episode report: {'average_total_reward': 3.2940001, 'reward_variance': 0.89948404, 'max_total_reward': 4.68, 'min_total_reward': 2.13, 'average_n_step': 4.9, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 30528} @ step loss: {'critic_loss': 0.41014536619186404, 'actor_loss': -2.4347676038742065, 'hyper_actor_loss': 0.10835644826292992, 'behavior_loss': 0.6239707350730896, 'mean_batch': 1.7749663472175599, 'min_batch': 1.3002872586250305, 'max_batch': 2.0447447061538697}
step: 900 @ episode report: {'average_total_reward': 3.4380002, 'reward_variance': 0.65319604, 'max_total_reward': 4.57, 'min_total_reward': 2.3500001, 'average_n_step': 5.0, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 30848} @ step loss: {'critic_loss': 0.42428078055381774, 'actor_loss': -2.6266202449798586, 'hyper_actor_loss': 0.10796342566609382, 'behavior_loss': 0.5994454264640808, 'mean_batch': 1.885578453540802, 'min_batch': 1.472599697113037, 'max_batch': 2.1485743284225465}
step: 910 @ episode report: {'average_total_reward': 3.4830003, 'reward_variance': 1.0348809, 'max_total_reward': 4.5699997, 'min_total_reward': 1.13, 'average_n_step': 5.1, 'max_n_step': 6.0, 'min_n_step': 3.0, 'buffer_size': 31168} @ step loss: {'critic_loss': 0.5201044410467148, 'actor_loss': -2.5135929584503174, 'hyper_actor_loss': 0.10785887390375137, 'behavior_loss': 0.6163354754447937, 'mean_batch': 1.8865557074546815, 'min_batch': 1.3278084337711333, 'max_batch': 2.179668164253235}
step: 920 @ episode report: {'average_total_reward': 3.8930001, 'reward_variance': 1.0431811, 'max_total_reward': 5.79, 'min_total_reward': 2.3500001, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 31488} @ step loss: {'critic_loss': 0.4977491170167923, 'actor_loss': -2.655219221115112, 'hyper_actor_loss': 0.10801864862442016, 'behavior_loss': 0.6082603693008423, 'mean_batch': 1.9350423336029052, 'min_batch': 1.4846672356128692, 'max_batch': 2.231026864051819}
step: 930 @ episode report: {'average_total_reward': 3.8709998, 'reward_variance': 1.449649, 'max_total_reward': 6.68, 'min_total_reward': 2.24, 'average_n_step': 5.4, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 31808} @ step loss: {'critic_loss': 0.5031474113464356, 'actor_loss': -2.673397397994995, 'hyper_actor_loss': 0.1083524078130722, 'behavior_loss': 0.5958936214447021, 'mean_batch': 1.8705435156822205, 'min_batch': 1.5553565502166748, 'max_batch': 2.1501494526863096}
step: 940 @ episode report: {'average_total_reward': 3.926, 'reward_variance': 1.027044, 'max_total_reward': 5.79, 'min_total_reward': 2.46, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 32128} @ step loss: {'critic_loss': 0.4443426549434662, 'actor_loss': -2.802471327781677, 'hyper_actor_loss': 0.10848580747842788, 'behavior_loss': 0.5864995360374451, 'mean_batch': 2.031688559055328, 'min_batch': 1.623564076423645, 'max_batch': 2.3333593606948853}
step: 950 @ episode report: {'average_total_reward': 4.4820004, 'reward_variance': 2.2194963, 'max_total_reward': 7.6800003, 'min_total_reward': 2.2400002, 'average_n_step': 6.0, 'max_n_step': 9.0, 'min_n_step': 4.0, 'buffer_size': 32448} @ step loss: {'critic_loss': 0.5294299274682999, 'actor_loss': -2.785508370399475, 'hyper_actor_loss': 0.10841978341341019, 'behavior_loss': 0.5801122963428498, 'mean_batch': 1.9828984022140503, 'min_batch': 1.636945903301239, 'max_batch': 2.2690353870391844}
step: 960 @ episode report: {'average_total_reward': 3.816, 'reward_variance': 0.368304, 'max_total_reward': 4.6800003, 'min_total_reward': 3.2400002, 'average_n_step': 5.4, 'max_n_step': 6.0, 'min_n_step': 5.0, 'buffer_size': 32768} @ step loss: {'critic_loss': 0.5388603895902634, 'actor_loss': -2.756324315071106, 'hyper_actor_loss': 0.10832252353429794, 'behavior_loss': 0.6131735146045685, 'mean_batch': 1.9908848643302917, 'min_batch': 1.5848921179771422, 'max_batch': 2.267898678779602}
step: 970 @ episode report: {'average_total_reward': 3.294, 'reward_variance': 1.0869639, 'max_total_reward': 5.4599996, 'min_total_reward': 1.35, 'average_n_step': 4.9, 'max_n_step': 7.0, 'min_n_step': 3.0, 'buffer_size': 33088} @ step loss: {'critic_loss': 0.5474416106939316, 'actor_loss': -2.667593240737915, 'hyper_actor_loss': 0.10839310884475709, 'behavior_loss': 0.6066641390323639, 'mean_batch': 1.9049911975860596, 'min_batch': 1.5211174845695496, 'max_batch': 2.164383959770203}
step: 980 @ episode report: {'average_total_reward': 3.8379998, 'reward_variance': 1.7233158, 'max_total_reward': 5.68, 'min_total_reward': 2.13, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 33408} @ step loss: {'critic_loss': 0.5216933101415634, 'actor_loss': -2.78534836769104, 'hyper_actor_loss': 0.10823483243584633, 'behavior_loss': 0.6018626868724823, 'mean_batch': 1.9976413607597352, 'min_batch': 1.6292558073997498, 'max_batch': 2.2766069889068605}
step: 990 @ episode report: {'average_total_reward': 3.9599998, 'reward_variance': 0.9841998, 'max_total_reward': 5.68, 'min_total_reward': 2.46, 'average_n_step': 5.5, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 33728} @ step loss: {'critic_loss': 0.585031047463417, 'actor_loss': -2.845504403114319, 'hyper_actor_loss': 0.10822585597634315, 'behavior_loss': 0.6084355473518371, 'mean_batch': 2.081824254989624, 'min_batch': 1.6575921177864075, 'max_batch': 2.376806402206421}
step: 1000 @ episode report: {'average_total_reward': 3.605, 'reward_variance': 0.45806497, 'max_total_reward': 4.6800003, 'min_total_reward': 2.46, 'average_n_step': 5.2, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 34048} @ step loss: {'critic_loss': 0.6073357284069061, 'actor_loss': -2.7968608379364013, 'hyper_actor_loss': 0.1081726647913456, 'behavior_loss': 0.6017705917358398, 'mean_batch': 2.00973858833313, 'min_batch': 1.6325659513473512, 'max_batch': 2.252461051940918}
step: 1010 @ episode report: {'average_total_reward': 3.5489998, 'reward_variance': 0.5322288, 'max_total_reward': 4.57, 'min_total_reward': 2.3500001, 'average_n_step': 5.1, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 34368} @ step loss: {'critic_loss': 0.6125393897294998, 'actor_loss': -2.7358307123184202, 'hyper_actor_loss': 0.10821407958865166, 'behavior_loss': 0.5987663507461548, 'mean_batch': 1.9901987075805665, 'min_batch': 1.5530311465263367, 'max_batch': 2.2746017932891847}
step: 1020 @ episode report: {'average_total_reward': 3.4819999, 'reward_variance': 1.9585559, 'max_total_reward': 6.9, 'min_total_reward': 1.3500001, 'average_n_step': 5.0, 'max_n_step': 8.0, 'min_n_step': 3.0, 'buffer_size': 34688} @ step loss: {'critic_loss': 0.632201200723648, 'actor_loss': -2.923172616958618, 'hyper_actor_loss': 0.10804549008607864, 'behavior_loss': 0.5977838277816773, 'mean_batch': 2.157603883743286, 'min_batch': 1.728181505203247, 'max_batch': 2.4758654832839966}
step: 1030 @ episode report: {'average_total_reward': 3.8159995, 'reward_variance': 0.8780837, 'max_total_reward': 5.68, 'min_total_reward': 2.4600003, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 35008} @ step loss: {'critic_loss': 0.6640990793704986, 'actor_loss': -2.7994426012039186, 'hyper_actor_loss': 0.10838237628340722, 'behavior_loss': 0.5920258104801178, 'mean_batch': 2.0104735016822817, 'min_batch': 1.6367018938064575, 'max_batch': 2.2944262504577635}
step: 1040 @ episode report: {'average_total_reward': 3.8820004, 'reward_variance': 0.951276, 'max_total_reward': 5.79, 'min_total_reward': 2.46, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 35328} @ step loss: {'critic_loss': 0.6429857552051544, 'actor_loss': -2.8794338941574096, 'hyper_actor_loss': 0.10828589349985122, 'behavior_loss': 0.60321044921875, 'mean_batch': 2.0909231901168823, 'min_batch': 1.7047882437705995, 'max_batch': 2.3667963266372682}
step: 1050 @ episode report: {'average_total_reward': 3.9600003, 'reward_variance': 1.0719799, 'max_total_reward': 5.79, 'min_total_reward': 2.46, 'average_n_step': 5.5, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 35648} @ step loss: {'critic_loss': 0.6425186812877655, 'actor_loss': -2.936543655395508, 'hyper_actor_loss': 0.10811193957924843, 'behavior_loss': 0.5956172108650207, 'mean_batch': 2.1464011907577514, 'min_batch': 1.7609192728996277, 'max_batch': 2.4347058296203614}
step: 1060 @ episode report: {'average_total_reward': 4.0039997, 'reward_variance': 1.194584, 'max_total_reward': 5.68, 'min_total_reward': 2.35, 'average_n_step': 5.5, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 35968} @ step loss: {'critic_loss': 0.6816343903541565, 'actor_loss': -2.844897723197937, 'hyper_actor_loss': 0.10796070992946624, 'behavior_loss': 0.6001160442829132, 'mean_batch': 2.0767228841781615, 'min_batch': 1.6589839100837707, 'max_batch': 2.370434617996216}
step: 1070 @ episode report: {'average_total_reward': 4.0270004, 'reward_variance': 0.92350084, 'max_total_reward': 6.4599996, 'min_total_reward': 3.1299999, 'average_n_step': 5.6, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 36288} @ step loss: {'critic_loss': 0.6775331795215607, 'actor_loss': -2.9096724510192873, 'hyper_actor_loss': 0.10758032649755478, 'behavior_loss': 0.5902659296989441, 'mean_batch': 2.1103312253952025, 'min_batch': 1.7418678760528565, 'max_batch': 2.4192665338516237}
step: 1080 @ episode report: {'average_total_reward': 3.771, 'reward_variance': 0.48016906, 'max_total_reward': 4.6800003, 'min_total_reward': 2.3500001, 'average_n_step': 5.3, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 36608} @ step loss: {'critic_loss': 0.6718652248382568, 'actor_loss': -2.9256163120269774, 'hyper_actor_loss': 0.1079814687371254, 'behavior_loss': 0.603446227312088, 'mean_batch': 2.1287057638168334, 'min_batch': 1.755481493473053, 'max_batch': 2.4229008197784423}
step: 1090 @ episode report: {'average_total_reward': 3.9269996, 'reward_variance': 0.9880409, 'max_total_reward': 5.6800003, 'min_total_reward': 2.02, 'average_n_step': 5.5, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 36928} @ step loss: {'critic_loss': 0.709606260061264, 'actor_loss': -2.962496113777161, 'hyper_actor_loss': 0.10800460502505302, 'behavior_loss': 0.5880574882030487, 'mean_batch': 2.180827522277832, 'min_batch': 1.7787321925163269, 'max_batch': 2.492586374282837}
step: 1100 @ episode report: {'average_total_reward': 3.4830003, 'reward_variance': 1.4861411, 'max_total_reward': 5.6800003, 'min_total_reward': 2.13, 'average_n_step': 5.1, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 37248} @ step loss: {'critic_loss': 0.6992766976356506, 'actor_loss': -2.9664062023162843, 'hyper_actor_loss': 0.10816496908664704, 'behavior_loss': 0.5833951532840729, 'mean_batch': 2.21420841217041, 'min_batch': 1.7566964745521545, 'max_batch': 2.5297078132629394}
step: 1110 @ episode report: {'average_total_reward': 3.9490001, 'reward_variance': 2.6360695, 'max_total_reward': 7.9000006, 'min_total_reward': 2.13, 'average_n_step': 5.5, 'max_n_step': 9.0, 'min_n_step': 4.0, 'buffer_size': 37568} @ step loss: {'critic_loss': 0.7207986235618591, 'actor_loss': -2.978894591331482, 'hyper_actor_loss': 0.10769039317965508, 'behavior_loss': 0.5897953987121582, 'mean_batch': 2.1942524194717405, 'min_batch': 1.794938588142395, 'max_batch': 2.4808329343795776}
step: 1120 @ episode report: {'average_total_reward': 3.205, 'reward_variance': 0.74848497, 'max_total_reward': 4.68, 'min_total_reward': 2.02, 'average_n_step': 4.8, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 37888} @ step loss: {'critic_loss': 0.7082515299320221, 'actor_loss': -3.0284178495407104, 'hyper_actor_loss': 0.10784763023257256, 'behavior_loss': 0.5721106827259064, 'mean_batch': 2.2326645374298097, 'min_batch': 1.8526403307914734, 'max_batch': 2.520216679573059}
step: 1130 @ episode report: {'average_total_reward': 4.3710003, 'reward_variance': 1.4886491, 'max_total_reward': 6.57, 'min_total_reward': 2.13, 'average_n_step': 5.9, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 38208} @ step loss: {'critic_loss': 0.7400122284889221, 'actor_loss': -3.1243889808654783, 'hyper_actor_loss': 0.10770967453718186, 'behavior_loss': 0.5915096700191498, 'mean_batch': 2.335792064666748, 'min_batch': 1.948819923400879, 'max_batch': 2.668459677696228}
step: 1140 @ episode report: {'average_total_reward': 3.439, 'reward_variance': 0.939689, 'max_total_reward': 4.6800003, 'min_total_reward': 1.8000001, 'average_n_step': 5.1, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 38528} @ step loss: {'critic_loss': 0.731497174501419, 'actor_loss': -3.1579639673233033, 'hyper_actor_loss': 0.10750933811068535, 'behavior_loss': 0.5940771579742432, 'mean_batch': 2.4400074958801268, 'min_batch': 1.9401716113090515, 'max_batch': 2.7715184688568115}
step: 1150 @ episode report: {'average_total_reward': 3.95, 'reward_variance': 1.7255598, 'max_total_reward': 6.79, 'min_total_reward': 2.46, 'average_n_step': 5.6, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 38848} @ step loss: {'critic_loss': 0.7601797103881835, 'actor_loss': -3.040193033218384, 'hyper_actor_loss': 0.10773342996835708, 'behavior_loss': 0.6032312214374542, 'mean_batch': 2.258192205429077, 'min_batch': 1.8534619808197021, 'max_batch': 2.5646027088165284}
step: 1160 @ episode report: {'average_total_reward': 4.5930004, 'reward_variance': 0.407821, 'max_total_reward': 5.6800003, 'min_total_reward': 3.46, 'average_n_step': 6.1, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 39168} @ step loss: {'critic_loss': 0.7540002703666687, 'actor_loss': -3.1286022663116455, 'hyper_actor_loss': 0.10784014016389847, 'behavior_loss': 0.6006405353546143, 'mean_batch': 2.3362547636032103, 'min_batch': 1.9565172791481018, 'max_batch': 2.6545979499816896}
step: 1170 @ episode report: {'average_total_reward': 3.794, 'reward_variance': 1.393364, 'max_total_reward': 5.57, 'min_total_reward': 1.8000001, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 39488} @ step loss: {'critic_loss': 0.8067622721195221, 'actor_loss': -3.242688012123108, 'hyper_actor_loss': 0.10799892097711564, 'behavior_loss': 0.6029727756977081, 'mean_batch': 2.471132445335388, 'min_batch': 2.073811745643616, 'max_batch': 2.7909366607666017}
step: 1180 @ episode report: {'average_total_reward': 3.9599998, 'reward_variance': 0.59388006, 'max_total_reward': 4.6800003, 'min_total_reward': 2.24, 'average_n_step': 5.5, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 39808} @ step loss: {'critic_loss': 0.7950345337390899, 'actor_loss': -3.1931351900100706, 'hyper_actor_loss': 0.10800356715917588, 'behavior_loss': 0.5840599715709687, 'mean_batch': 2.40325186252594, 'min_batch': 2.0289787888526916, 'max_batch': 2.728421211242676}
step: 1190 @ episode report: {'average_total_reward': 3.7829998, 'reward_variance': 0.996761, 'max_total_reward': 5.46, 'min_total_reward': 2.02, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 40128} @ step loss: {'critic_loss': 0.8082292020320893, 'actor_loss': -3.1495944023132325, 'hyper_actor_loss': 0.10774085372686386, 'behavior_loss': 0.5807464063167572, 'mean_batch': 2.396928381919861, 'min_batch': 1.9509009003639222, 'max_batch': 2.7288312196731566}
step: 1200 @ episode report: {'average_total_reward': 3.8269997, 'reward_variance': 1.4667206, 'max_total_reward': 5.68, 'min_total_reward': 2.13, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 40448} @ step loss: {'critic_loss': 0.7991109728813172, 'actor_loss': -3.2230697154998778, 'hyper_actor_loss': 0.10713077411055565, 'behavior_loss': 0.5972267746925354, 'mean_batch': 2.455521845817566, 'min_batch': 2.045503294467926, 'max_batch': 2.7775394439697267}
step: 1210 @ episode report: {'average_total_reward': 3.705, 'reward_variance': 1.2413851, 'max_total_reward': 5.46, 'min_total_reward': 1.02, 'average_n_step': 5.3, 'max_n_step': 7.0, 'min_n_step': 3.0, 'buffer_size': 40768} @ step loss: {'critic_loss': 0.7965488433837891, 'actor_loss': -3.191240358352661, 'hyper_actor_loss': 0.10716438964009285, 'behavior_loss': 0.5848548471927643, 'mean_batch': 2.421736741065979, 'min_batch': 2.0113667964935305, 'max_batch': 2.7244574785232545}
step: 1220 @ episode report: {'average_total_reward': 4.1260004, 'reward_variance': 1.0030639, 'max_total_reward': 5.7899995, 'min_total_reward': 2.46, 'average_n_step': 5.6, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 41088} @ step loss: {'critic_loss': 0.862797212600708, 'actor_loss': -3.235115146636963, 'hyper_actor_loss': 0.10744340121746063, 'behavior_loss': 0.5889487266540527, 'mean_batch': 2.4428418636322022, 'min_batch': 2.0821727871894837, 'max_batch': 2.7515059232711794}
step: 1230 @ episode report: {'average_total_reward': 4.737, 'reward_variance': 1.580581, 'max_total_reward': 7.46, 'min_total_reward': 3.3500001, 'average_n_step': 6.2, 'max_n_step': 9.0, 'min_n_step': 5.0, 'buffer_size': 41408} @ step loss: {'critic_loss': 0.8556312143802642, 'actor_loss': -3.1202173233032227, 'hyper_actor_loss': 0.10728569030761718, 'behavior_loss': 0.5904755234718323, 'mean_batch': 2.4095441102981567, 'min_batch': 1.9039239168167115, 'max_batch': 2.7311511039733887}
step: 1240 @ episode report: {'average_total_reward': 4.2489996, 'reward_variance': 1.0860488, 'max_total_reward': 5.79, 'min_total_reward': 2.35, 'average_n_step': 5.8, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 41728} @ step loss: {'critic_loss': 0.8549884617328644, 'actor_loss': -3.2413835287094117, 'hyper_actor_loss': 0.10754793211817741, 'behavior_loss': 0.6063800692558289, 'mean_batch': 2.466217875480652, 'min_batch': 2.0755234360694885, 'max_batch': 2.783180999755859}
step: 1250 @ episode report: {'average_total_reward': 4.082, 'reward_variance': 1.0278356, 'max_total_reward': 6.7899995, 'min_total_reward': 3.3500001, 'average_n_step': 5.6, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 42048} @ step loss: {'critic_loss': 0.9596902251243591, 'actor_loss': -3.0706280708312987, 'hyper_actor_loss': 0.10783690512180329, 'behavior_loss': 0.6024249374866486, 'mean_batch': 2.2710222005844116, 'min_batch': 1.8995417714118958, 'max_batch': 2.556861400604248}
step: 1260 @ episode report: {'average_total_reward': 3.5829997, 'reward_variance': 0.983641, 'max_total_reward': 4.6800003, 'min_total_reward': 1.9100001, 'average_n_step': 5.2, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 42368} @ step loss: {'critic_loss': 0.806374317407608, 'actor_loss': -3.247997522354126, 'hyper_actor_loss': 0.10757657960057258, 'behavior_loss': 0.6005256354808808, 'mean_batch': 2.4656715631484984, 'min_batch': 2.0906226992607118, 'max_batch': 2.771078372001648}
step: 1270 @ episode report: {'average_total_reward': 4.2260003, 'reward_variance': 0.92818415, 'max_total_reward': 5.6800003, 'min_total_reward': 2.35, 'average_n_step': 5.7, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 42688} @ step loss: {'critic_loss': 0.9155908167362213, 'actor_loss': -3.2596329927444456, 'hyper_actor_loss': 0.1077124036848545, 'behavior_loss': 0.5931726932525635, 'mean_batch': 2.4952916622161867, 'min_batch': 2.0887909054756166, 'max_batch': 2.8049400568008425}
step: 1280 @ episode report: {'average_total_reward': 3.8489997, 'reward_variance': 1.630709, 'max_total_reward': 6.79, 'min_total_reward': 2.46, 'average_n_step': 5.4, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 43008} @ step loss: {'critic_loss': 0.8710610449314118, 'actor_loss': -3.269867181777954, 'hyper_actor_loss': 0.10743537917733192, 'behavior_loss': 0.5997338235378266, 'mean_batch': 2.514704132080078, 'min_batch': 2.094696044921875, 'max_batch': 2.861801099777222}
step: 1290 @ episode report: {'average_total_reward': 4.3149996, 'reward_variance': 1.2512248, 'max_total_reward': 5.79, 'min_total_reward': 2.24, 'average_n_step': 5.8, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 43328} @ step loss: {'critic_loss': 0.9338658571243286, 'actor_loss': -3.2988219022750855, 'hyper_actor_loss': 0.10717606842517853, 'behavior_loss': 0.5907561361789704, 'mean_batch': 2.527457070350647, 'min_batch': 2.14424786567688, 'max_batch': 2.8338361740112306}
step: 1300 @ episode report: {'average_total_reward': 4.382, 'reward_variance': 1.316116, 'max_total_reward': 5.6800003, 'min_total_reward': 2.13, 'average_n_step': 5.9, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 43648} @ step loss: {'critic_loss': 0.8865519821643829, 'actor_loss': -3.288839864730835, 'hyper_actor_loss': 0.10704455450177193, 'behavior_loss': 0.595407372713089, 'mean_batch': 2.5097885847091677, 'min_batch': 2.138267731666565, 'max_batch': 2.8170663356781005}
step: 1310 @ episode report: {'average_total_reward': 4.571, 'reward_variance': 1.6796091, 'max_total_reward': 6.9, 'min_total_reward': 3.13, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 43968} @ step loss: {'critic_loss': 0.8484864592552185, 'actor_loss': -3.252578067779541, 'hyper_actor_loss': 0.10705055072903633, 'behavior_loss': 0.5860771417617798, 'mean_batch': 2.5183616399765016, 'min_batch': 2.056210958957672, 'max_batch': 2.8067003965377806}
step: 1320 @ episode report: {'average_total_reward': 3.8489997, 'reward_variance': 0.92092896, 'max_total_reward': 4.68, 'min_total_reward': 2.13, 'average_n_step': 5.4, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 44288} @ step loss: {'critic_loss': 0.8141355454921723, 'actor_loss': -3.331199073791504, 'hyper_actor_loss': 0.10694023966789246, 'behavior_loss': 0.5958035349845886, 'mean_batch': 2.580190825462341, 'min_batch': 2.1729239225387573, 'max_batch': 2.8950807809829713}
step: 1330 @ episode report: {'average_total_reward': 3.782, 'reward_variance': 0.6719959, 'max_total_reward': 4.57, 'min_total_reward': 2.3500001, 'average_n_step': 5.3, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 44608} @ step loss: {'critic_loss': 0.9151325941085815, 'actor_loss': -3.3196763038635253, 'hyper_actor_loss': 0.10697488710284234, 'behavior_loss': 0.596977561712265, 'mean_batch': 2.550169563293457, 'min_batch': 2.1703018665313722, 'max_batch': 2.8691744804382324}
step: 1340 @ episode report: {'average_total_reward': 4.4259996, 'reward_variance': 1.5551441, 'max_total_reward': 5.7900004, 'min_total_reward': 2.35, 'average_n_step': 5.9, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 44928} @ step loss: {'critic_loss': 0.9551683604717255, 'actor_loss': -3.3101452827453612, 'hyper_actor_loss': 0.10707604736089707, 'behavior_loss': 0.5845062136650085, 'mean_batch': 2.5470009803771974, 'min_batch': 2.151452398300171, 'max_batch': 2.8622536182403566}
step: 1350 @ episode report: {'average_total_reward': 4.2039995, 'reward_variance': 0.93698406, 'max_total_reward': 5.68, 'min_total_reward': 2.35, 'average_n_step': 5.7, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 45248} @ step loss: {'critic_loss': 0.9191017389297486, 'actor_loss': -3.2817414522171022, 'hyper_actor_loss': 0.10695977956056595, 'behavior_loss': 0.5896106243133545, 'mean_batch': 2.5395894289016723, 'min_batch': 2.097910749912262, 'max_batch': 2.8582058906555177}
step: 1360 @ episode report: {'average_total_reward': 3.494, 'reward_variance': 0.99146384, 'max_total_reward': 4.68, 'min_total_reward': 2.13, 'average_n_step': 5.1, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 45568} @ step loss: {'critic_loss': 0.9383552849292756, 'actor_loss': -3.2837684631347654, 'hyper_actor_loss': 0.106913261115551, 'behavior_loss': 0.602018541097641, 'mean_batch': 2.502639985084534, 'min_batch': 2.1341278195381164, 'max_batch': 2.7902645826339723}
step: 1370 @ episode report: {'average_total_reward': 4.127, 'reward_variance': 0.848841, 'max_total_reward': 5.6800003, 'min_total_reward': 2.46, 'average_n_step': 5.7, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 45888} @ step loss: {'critic_loss': 0.950406140089035, 'actor_loss': -3.345273494720459, 'hyper_actor_loss': 0.10710804313421249, 'behavior_loss': 0.5944059908390045, 'mean_batch': 2.6133447647094727, 'min_batch': 2.172866177558899, 'max_batch': 2.9352407217025758}
step: 1380 @ episode report: {'average_total_reward': 3.949, 'reward_variance': 2.1478689, 'max_total_reward': 6.68, 'min_total_reward': 2.13, 'average_n_step': 5.5, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 46208} @ step loss: {'critic_loss': 0.8658337354660034, 'actor_loss': -3.358161282539368, 'hyper_actor_loss': 0.10703718140721322, 'behavior_loss': 0.588149219751358, 'mean_batch': 2.596586275100708, 'min_batch': 2.2152329444885255, 'max_batch': 2.9081069231033325}
step: 1390 @ episode report: {'average_total_reward': 4.204, 'reward_variance': 0.44898397, 'max_total_reward': 5.46, 'min_total_reward': 3.2400002, 'average_n_step': 5.7, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 46528} @ step loss: {'critic_loss': 0.9281859815120697, 'actor_loss': -3.412090706825256, 'hyper_actor_loss': 0.10733483582735062, 'behavior_loss': 0.5895449936389923, 'mean_batch': 2.676409912109375, 'min_batch': 2.26842885017395, 'max_batch': 3.014987063407898}
step: 1400 @ episode report: {'average_total_reward': 4.1600003, 'reward_variance': 1.1052401, 'max_total_reward': 5.7900004, 'min_total_reward': 2.46, 'average_n_step': 5.7, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 46848} @ step loss: {'critic_loss': 0.9779082775115967, 'actor_loss': -3.36808443069458, 'hyper_actor_loss': 0.10701106488704681, 'behavior_loss': 0.5806914091110229, 'mean_batch': 2.6337808847427366, 'min_batch': 2.205658721923828, 'max_batch': 2.9355254888534548}
step: 1410 @ episode report: {'average_total_reward': 4.748, 'reward_variance': 0.62925607, 'max_total_reward': 5.6800003, 'min_total_reward': 3.3500001, 'average_n_step': 6.2, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 47168} @ step loss: {'critic_loss': 0.9798051357269287, 'actor_loss': -3.383601260185242, 'hyper_actor_loss': 0.10664001852273941, 'behavior_loss': 0.581257826089859, 'mean_batch': 2.656972885131836, 'min_batch': 2.2201151609420777, 'max_batch': 2.987202835083008}
step: 1420 @ episode report: {'average_total_reward': 4.238, 'reward_variance': 0.9044962, 'max_total_reward': 5.57, 'min_total_reward': 3.13, 'average_n_step': 5.8, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 47488} @ step loss: {'critic_loss': 1.0304597616195679, 'actor_loss': -3.399552321434021, 'hyper_actor_loss': 0.1065957322716713, 'behavior_loss': 0.6061665773391723, 'mean_batch': 2.673762583732605, 'min_batch': 2.243263578414917, 'max_batch': 3.0065805673599244}
step: 1430 @ episode report: {'average_total_reward': 4.4590006, 'reward_variance': 0.552249, 'max_total_reward': 5.68, 'min_total_reward': 3.2399998, 'average_n_step': 5.9, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 47808} @ step loss: {'critic_loss': 0.9656204640865326, 'actor_loss': -3.363164258003235, 'hyper_actor_loss': 0.10689047276973725, 'behavior_loss': 0.5886410355567933, 'mean_batch': 2.616436409950256, 'min_batch': 2.209284019470215, 'max_batch': 2.944376230239868}
step: 1440 @ episode report: {'average_total_reward': 4.9370003, 'reward_variance': 0.89598083, 'max_total_reward': 6.68, 'min_total_reward': 3.2400002, 'average_n_step': 6.4, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 48128} @ step loss: {'critic_loss': 1.0477734684944153, 'actor_loss': -3.3198745965957643, 'hyper_actor_loss': 0.10687039718031884, 'behavior_loss': 0.5932149827480316, 'mean_batch': 2.589804530143738, 'min_batch': 2.1398430109024047, 'max_batch': 2.886932063102722}
step: 1450 @ episode report: {'average_total_reward': 4.382, 'reward_variance': 1.1403162, 'max_total_reward': 5.6800003, 'min_total_reward': 2.35, 'average_n_step': 5.9, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 48448} @ step loss: {'critic_loss': 0.9947063088417053, 'actor_loss': -3.4019906759262084, 'hyper_actor_loss': 0.10701665803790092, 'behavior_loss': 0.5875398516654968, 'mean_batch': 2.6555841684341432, 'min_batch': 2.2624815464019776, 'max_batch': 2.9810349225997923}
step: 1460 @ episode report: {'average_total_reward': 4.0379996, 'reward_variance': 1.9512761, 'max_total_reward': 6.6800003, 'min_total_reward': 2.24, 'average_n_step': 5.6, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 48768} @ step loss: {'critic_loss': 1.040386039018631, 'actor_loss': -3.419947552680969, 'hyper_actor_loss': 0.10658423155546189, 'behavior_loss': 0.5781220614910125, 'mean_batch': 2.732479119300842, 'min_batch': 2.23880455493927, 'max_batch': 3.0857558965682985}
step: 1470 @ episode report: {'average_total_reward': 4.571, 'reward_variance': 1.5526688, 'max_total_reward': 6.68, 'min_total_reward': 2.24, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 49088} @ step loss: {'critic_loss': 0.995533674955368, 'actor_loss': -3.46019606590271, 'hyper_actor_loss': 0.10682679563760758, 'behavior_loss': 0.5770812153816223, 'mean_batch': 2.7425507307052612, 'min_batch': 2.322779417037964, 'max_batch': 3.0918073654174805}
step: 1480 @ episode report: {'average_total_reward': 4.682, 'reward_variance': 1.2776558, 'max_total_reward': 7.57, 'min_total_reward': 3.3500001, 'average_n_step': 6.2, 'max_n_step': 9.0, 'min_n_step': 5.0, 'buffer_size': 49408} @ step loss: {'critic_loss': 1.2311276137828826, 'actor_loss': -3.395805263519287, 'hyper_actor_loss': 0.10672971159219742, 'behavior_loss': 0.59420605301857, 'mean_batch': 2.6605026721954346, 'min_batch': 2.251449799537659, 'max_batch': 2.968275284767151}
step: 1490 @ episode report: {'average_total_reward': 4.371, 'reward_variance': 0.7566491, 'max_total_reward': 5.57, 'min_total_reward': 3.13, 'average_n_step': 5.9, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 49728} @ step loss: {'critic_loss': 1.0219322204589845, 'actor_loss': -3.3316849946975706, 'hyper_actor_loss': 0.10668892115354538, 'behavior_loss': 0.596523892879486, 'mean_batch': 2.548582887649536, 'min_batch': 2.1997752666473387, 'max_batch': 2.8634631872177123}
step: 1500 @ episode report: {'average_total_reward': 4.481, 'reward_variance': 2.4624288, 'max_total_reward': 6.79, 'min_total_reward': 2.24, 'average_n_step': 5.9, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 50048} @ step loss: {'critic_loss': 1.1294923007488251, 'actor_loss': -3.4264440536499023, 'hyper_actor_loss': 0.10689451619982719, 'behavior_loss': 0.5762612998485566, 'mean_batch': 2.7118064165115356, 'min_batch': 2.2710835695266725, 'max_batch': 3.042553997039795}
step: 1510 @ episode report: {'average_total_reward': 4.393, 'reward_variance': 0.9526011, 'max_total_reward': 6.57, 'min_total_reward': 2.46, 'average_n_step': 5.9, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 50368} @ step loss: {'critic_loss': 1.0093571543693542, 'actor_loss': -3.3617263317108153, 'hyper_actor_loss': 0.10667000338435173, 'behavior_loss': 0.5728114783763886, 'mean_batch': 2.6097700595855713, 'min_batch': 2.212545895576477, 'max_batch': 2.943979358673096}
step: 1520 @ episode report: {'average_total_reward': 4.659, 'reward_variance': 0.83980894, 'max_total_reward': 6.79, 'min_total_reward': 3.35, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 50688} @ step loss: {'critic_loss': 1.0207768619060515, 'actor_loss': -3.418146181106567, 'hyper_actor_loss': 0.10675330758094788, 'behavior_loss': 0.5998687267303466, 'mean_batch': 2.67109272480011, 'min_batch': 2.2869678020477293, 'max_batch': 3.005740761756897}
step: 1530 @ episode report: {'average_total_reward': 3.5709999, 'reward_variance': 1.2087691, 'max_total_reward': 5.79, 'min_total_reward': 2.24, 'average_n_step': 5.1, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 51008} @ step loss: {'critic_loss': 1.1321478724479674, 'actor_loss': -3.4542638301849364, 'hyper_actor_loss': 0.10675296932458878, 'behavior_loss': 0.5914194524288178, 'mean_batch': 2.731574463844299, 'min_batch': 2.318483901023865, 'max_batch': 3.0734424114227297}
step: 1540 @ episode report: {'average_total_reward': 4.57, 'reward_variance': 1.0930399, 'max_total_reward': 5.79, 'min_total_reward': 3.35, 'average_n_step': 6.0, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 51328} @ step loss: {'critic_loss': 1.0955211699008942, 'actor_loss': -3.3877138614654543, 'hyper_actor_loss': 0.10666823834180832, 'behavior_loss': 0.5991837203502655, 'mean_batch': 2.6372814178466797, 'min_batch': 2.246225094795227, 'max_batch': 2.942844271659851}
step: 1550 @ episode report: {'average_total_reward': 4.681, 'reward_variance': 1.177089, 'max_total_reward': 5.79, 'min_total_reward': 2.24, 'average_n_step': 6.1, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 51648} @ step loss: {'critic_loss': 0.962071669101715, 'actor_loss': -3.504623007774353, 'hyper_actor_loss': 0.10639857724308968, 'behavior_loss': 0.5927189826965332, 'mean_batch': 2.783472752571106, 'min_batch': 2.391810178756714, 'max_batch': 3.1033832311630247}
step: 1560 @ episode report: {'average_total_reward': 4.437, 'reward_variance': 0.8617212, 'max_total_reward': 6.7900004, 'min_total_reward': 3.35, 'average_n_step': 5.9, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 51968} @ step loss: {'critic_loss': 1.011478316783905, 'actor_loss': -3.3966480255126954, 'hyper_actor_loss': 0.10659172609448433, 'behavior_loss': 0.5840360879898071, 'mean_batch': 2.666246271133423, 'min_batch': 2.24333119392395, 'max_batch': 2.965603828430176}
step: 1570 @ episode report: {'average_total_reward': 4.5590005, 'reward_variance': 1.7893889, 'max_total_reward': 6.8999996, 'min_total_reward': 2.24, 'average_n_step': 6.0, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 52288} @ step loss: {'critic_loss': 1.115237718820572, 'actor_loss': -3.4169929027557373, 'hyper_actor_loss': 0.10653098970651627, 'behavior_loss': 0.5988752663135528, 'mean_batch': 2.6681150436401366, 'min_batch': 2.286073637008667, 'max_batch': 3.0001188039779665}
step: 1580 @ episode report: {'average_total_reward': 4.3599997, 'reward_variance': 0.90471995, 'max_total_reward': 5.7900004, 'min_total_reward': 2.3500001, 'average_n_step': 5.9, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 52608} @ step loss: {'critic_loss': 1.0972949385643005, 'actor_loss': -3.4347240686416627, 'hyper_actor_loss': 0.10654585137963295, 'behavior_loss': 0.5760465502738953, 'mean_batch': 2.6751052379608153, 'min_batch': 2.3199110984802247, 'max_batch': 2.9821667432785035}
step: 1590 @ episode report: {'average_total_reward': 4.6040006, 'reward_variance': 2.4334645, 'max_total_reward': 7.680001, 'min_total_reward': 2.13, 'average_n_step': 6.1, 'max_n_step': 9.0, 'min_n_step': 4.0, 'buffer_size': 52928} @ step loss: {'critic_loss': 1.080154925584793, 'actor_loss': -3.4654979944229125, 'hyper_actor_loss': 0.10651113092899323, 'behavior_loss': 0.5732667684555054, 'mean_batch': 2.72303991317749, 'min_batch': 2.3509899854660032, 'max_batch': 3.034920883178711}
step: 1600 @ episode report: {'average_total_reward': 3.926, 'reward_variance': 1.539464, 'max_total_reward': 5.79, 'min_total_reward': 2.24, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 53248} @ step loss: {'critic_loss': 1.0978002965450286, 'actor_loss': -3.4492058515548707, 'hyper_actor_loss': 0.10629058852791787, 'behavior_loss': 0.5844323813915253, 'mean_batch': 2.7084946155548097, 'min_batch': 2.3253236055374145, 'max_batch': 3.030908942222595}
step: 1610 @ episode report: {'average_total_reward': 3.8270001, 'reward_variance': 0.607761, 'max_total_reward': 4.6800003, 'min_total_reward': 2.1299999, 'average_n_step': 5.4, 'max_n_step': 6.0, 'min_n_step': 4.0, 'buffer_size': 53568} @ step loss: {'critic_loss': 1.0998229265213013, 'actor_loss': -3.3798136949539184, 'hyper_actor_loss': 0.10654639378190041, 'behavior_loss': 0.5881343901157379, 'mean_batch': 2.6406988143920898, 'min_batch': 2.2263291835784913, 'max_batch': 2.9382239103317263}
step: 1620 @ episode report: {'average_total_reward': 4.8810005, 'reward_variance': 1.7950093, 'max_total_reward': 7.6800003, 'min_total_reward': 2.46, 'average_n_step': 6.3, 'max_n_step': 9.0, 'min_n_step': 4.0, 'buffer_size': 53888} @ step loss: {'critic_loss': 1.0945569038391114, 'actor_loss': -3.397059679031372, 'hyper_actor_loss': 0.10642949864268303, 'behavior_loss': 0.5797217011451721, 'mean_batch': 2.6778804779052736, 'min_batch': 2.234452724456787, 'max_batch': 2.9766281604766847}
step: 1630 @ episode report: {'average_total_reward': 4.471, 'reward_variance': 1.1451688, 'max_total_reward': 6.68, 'min_total_reward': 3.13, 'average_n_step': 6.0, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 54208} @ step loss: {'critic_loss': 1.0817662954330445, 'actor_loss': -3.474298095703125, 'hyper_actor_loss': 0.106341752409935, 'behavior_loss': 0.5851589202880859, 'mean_batch': 2.7458290338516234, 'min_batch': 2.352943181991577, 'max_batch': 3.071356248855591}
step: 1640 @ episode report: {'average_total_reward': 4.3589997, 'reward_variance': 1.429949, 'max_total_reward': 5.68, 'min_total_reward': 2.46, 'average_n_step': 5.8, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 54528} @ step loss: {'critic_loss': 1.1344393491744995, 'actor_loss': -3.492328977584839, 'hyper_actor_loss': 0.10644844323396682, 'behavior_loss': 0.5833234846591949, 'mean_batch': 2.7872493505477904, 'min_batch': 2.360597825050354, 'max_batch': 3.1295809984207152}
step: 1650 @ episode report: {'average_total_reward': 4.482, 'reward_variance': 0.55065596, 'max_total_reward': 5.79, 'min_total_reward': 3.2400002, 'average_n_step': 6.0, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 54848} @ step loss: {'critic_loss': 1.0732605278491973, 'actor_loss': -3.5045949459075927, 'hyper_actor_loss': 0.1061231590807438, 'behavior_loss': 0.5716037511825561, 'mean_batch': 2.796342706680298, 'min_batch': 2.3815054655075074, 'max_batch': 3.1430118083953857}
step: 1660 @ episode report: {'average_total_reward': 4.0379996, 'reward_variance': 0.9902159, 'max_total_reward': 5.6800003, 'min_total_reward': 2.46, 'average_n_step': 5.6, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 55168} @ step loss: {'critic_loss': 1.1139482080936431, 'actor_loss': -3.510995388031006, 'hyper_actor_loss': 0.10605302825570107, 'behavior_loss': 0.5775022149085999, 'mean_batch': 2.832511305809021, 'min_batch': 2.3670262813568117, 'max_batch': 3.161197471618652}
step: 1670 @ episode report: {'average_total_reward': 4.87, 'reward_variance': 2.80578, 'max_total_reward': 7.6800003, 'min_total_reward': 2.2400002, 'average_n_step': 6.3, 'max_n_step': 9.0, 'min_n_step': 4.0, 'buffer_size': 55488} @ step loss: {'critic_loss': 1.0640618205070496, 'actor_loss': -3.513284134864807, 'hyper_actor_loss': 0.10586019158363343, 'behavior_loss': 0.5727276086807251, 'mean_batch': 2.786764407157898, 'min_batch': 2.4100602149963377, 'max_batch': 3.1109378814697264}
step: 1680 @ episode report: {'average_total_reward': 4.559, 'reward_variance': 1.0767691, 'max_total_reward': 6.57, 'min_total_reward': 2.46, 'average_n_step': 6.0, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 55808} @ step loss: {'critic_loss': 1.2141320168972016, 'actor_loss': -3.500893807411194, 'hyper_actor_loss': 0.10599813833832741, 'behavior_loss': 0.5816707015037537, 'mean_batch': 2.788227105140686, 'min_batch': 2.379286861419678, 'max_batch': 3.132772374153137}
step: 1690 @ episode report: {'average_total_reward': 4.5590005, 'reward_variance': 0.61076915, 'max_total_reward': 5.57, 'min_total_reward': 3.35, 'average_n_step': 6.0, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 56128} @ step loss: {'critic_loss': 1.1154937028884888, 'actor_loss': -3.4511318683624266, 'hyper_actor_loss': 0.10639678984880448, 'behavior_loss': 0.5810351014137268, 'mean_batch': 2.729523754119873, 'min_batch': 2.312617468833923, 'max_batch': 3.0683109760284424}
step: 1700 @ episode report: {'average_total_reward': 4.6150002, 'reward_variance': 1.3554848, 'max_total_reward': 6.68, 'min_total_reward': 2.13, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 56448} @ step loss: {'critic_loss': 1.0729586243629456, 'actor_loss': -3.5400457859039305, 'hyper_actor_loss': 0.10660188123583794, 'behavior_loss': 0.5722046315670013, 'mean_batch': 2.8594236612319945, 'min_batch': 2.4136154890060424, 'max_batch': 3.1804245948791503}
step: 1710 @ episode report: {'average_total_reward': 3.882, 'reward_variance': 1.1002159, 'max_total_reward': 5.79, 'min_total_reward': 2.13, 'average_n_step': 5.4, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 56768} @ step loss: {'critic_loss': 1.1941558122634888, 'actor_loss': -3.5237250089645387, 'hyper_actor_loss': 0.10646260008215905, 'behavior_loss': 0.5806007802486419, 'mean_batch': 2.8040823221206663, 'min_batch': 2.4199724435806274, 'max_batch': 3.1215485095977784}
step: 1720 @ episode report: {'average_total_reward': 4.416, 'reward_variance': 0.87130386, 'max_total_reward': 5.7900004, 'min_total_reward': 3.24, 'average_n_step': 6.0, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 57088} @ step loss: {'critic_loss': 1.096254551410675, 'actor_loss': -3.5129496097564696, 'hyper_actor_loss': 0.10620988979935646, 'behavior_loss': 0.5786966919898987, 'mean_batch': 2.7792641639709474, 'min_batch': 2.4146035432815554, 'max_batch': 3.133433437347412}
step: 1730 @ episode report: {'average_total_reward': 4.482, 'reward_variance': 0.758136, 'max_total_reward': 5.79, 'min_total_reward': 2.3500001, 'average_n_step': 6.0, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 57408} @ step loss: {'critic_loss': 1.192039155960083, 'actor_loss': -3.472600317001343, 'hyper_actor_loss': 0.10612682327628135, 'behavior_loss': 0.575641292333603, 'mean_batch': 2.7604792594909666, 'min_batch': 2.336317467689514, 'max_batch': 3.0920399904251097}
step: 1740 @ episode report: {'average_total_reward': 4.903, 'reward_variance': 2.5299811, 'max_total_reward': 6.9, 'min_total_reward': 2.46, 'average_n_step': 6.3, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 57728} @ step loss: {'critic_loss': 1.165143710374832, 'actor_loss': -3.478980541229248, 'hyper_actor_loss': 0.10617218539118767, 'behavior_loss': 0.584917026758194, 'mean_batch': 2.7695937156677246, 'min_batch': 2.3428087711334227, 'max_batch': 3.111684060096741}
step: 1750 @ episode report: {'average_total_reward': 4.415, 'reward_variance': 1.5042251, 'max_total_reward': 6.680001, 'min_total_reward': 2.4600003, 'average_n_step': 5.9, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 58048} @ step loss: {'critic_loss': 1.1461354672908783, 'actor_loss': -3.458872938156128, 'hyper_actor_loss': 0.10619587153196335, 'behavior_loss': 0.5797314465045929, 'mean_batch': 2.7386085033416747, 'min_batch': 2.3225353717803956, 'max_batch': 3.0839307069778443}
step: 1760 @ episode report: {'average_total_reward': 4.57, 'reward_variance': 1.4708402, 'max_total_reward': 7.6800003, 'min_total_reward': 3.46, 'average_n_step': 6.0, 'max_n_step': 9.0, 'min_n_step': 5.0, 'buffer_size': 58368} @ step loss: {'critic_loss': 1.2173800110816955, 'actor_loss': -3.51743323802948, 'hyper_actor_loss': 0.10622716322541237, 'behavior_loss': 0.5692989826202393, 'mean_batch': 2.8440876483917235, 'min_batch': 2.3745352745056154, 'max_batch': 3.177066421508789}
step: 1770 @ episode report: {'average_total_reward': 4.714, 'reward_variance': 1.4966239, 'max_total_reward': 6.8999996, 'min_total_reward': 3.46, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 58688} @ step loss: {'critic_loss': 1.1168780326843262, 'actor_loss': -3.5615705013275147, 'hyper_actor_loss': 0.10600747615098953, 'behavior_loss': 0.5767241358757019, 'mean_batch': 2.8846709966659545, 'min_batch': 2.4446571111679076, 'max_batch': 3.2382311105728148}
step: 1780 @ episode report: {'average_total_reward': 4.1600003, 'reward_variance': 0.78093994, 'max_total_reward': 5.68, 'min_total_reward': 2.24, 'average_n_step': 5.7, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 59008} @ step loss: {'critic_loss': 1.1807677388191222, 'actor_loss': -3.4847140550613402, 'hyper_actor_loss': 0.10615554973483085, 'behavior_loss': 0.5766970038414001, 'mean_batch': 2.772663688659668, 'min_batch': 2.3535618782043457, 'max_batch': 3.1151925802230833}
step: 1790 @ episode report: {'average_total_reward': 4.6699996, 'reward_variance': 1.10736, 'max_total_reward': 6.9, 'min_total_reward': 3.3500001, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 59328} @ step loss: {'critic_loss': 1.0680709898471832, 'actor_loss': -3.522148036956787, 'hyper_actor_loss': 0.10623757019639016, 'behavior_loss': 0.5682841777801514, 'mean_batch': 2.8321945905685424, 'min_batch': 2.393317770957947, 'max_batch': 3.164142441749573}
step: 1800 @ episode report: {'average_total_reward': 4.338, 'reward_variance': 0.502056, 'max_total_reward': 5.46, 'min_total_reward': 3.3500001, 'average_n_step': 5.9, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 59648} @ step loss: {'critic_loss': 1.1426434576511384, 'actor_loss': -3.5603123903274536, 'hyper_actor_loss': 0.10637239143252372, 'behavior_loss': 0.5741811990737915, 'mean_batch': 2.875021982192993, 'min_batch': 2.44856276512146, 'max_batch': 3.2109824895858763}
step: 1810 @ episode report: {'average_total_reward': 4.759, 'reward_variance': 0.43610898, 'max_total_reward': 5.79, 'min_total_reward': 3.5700002, 'average_n_step': 6.2, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 59968} @ step loss: {'critic_loss': 1.1424511909484862, 'actor_loss': -3.554053783416748, 'hyper_actor_loss': 0.10619715601205826, 'behavior_loss': 0.5612246692180634, 'mean_batch': 2.875948357582092, 'min_batch': 2.4337562084198, 'max_batch': 3.2198214769363402}
step: 1820 @ episode report: {'average_total_reward': 4.394, 'reward_variance': 3.1571045, 'max_total_reward': 7.5700006, 'min_total_reward': 2.24, 'average_n_step': 6.0, 'max_n_step': 9.0, 'min_n_step': 4.0, 'buffer_size': 60288} @ step loss: {'critic_loss': 1.24083468914032, 'actor_loss': -3.523646283149719, 'hyper_actor_loss': 0.10610311031341553, 'behavior_loss': 0.5763899564743042, 'mean_batch': 2.841511034965515, 'min_batch': 2.389614200592041, 'max_batch': 3.16213059425354}
step: 1830 @ episode report: {'average_total_reward': 4.1710005, 'reward_variance': 0.34198898, 'max_total_reward': 4.6800003, 'min_total_reward': 3.24, 'average_n_step': 5.7, 'max_n_step': 6.0, 'min_n_step': 5.0, 'buffer_size': 60608} @ step loss: {'critic_loss': 1.1928096175193788, 'actor_loss': -3.493017864227295, 'hyper_actor_loss': 0.10605568289756775, 'behavior_loss': 0.5837277710437775, 'mean_batch': 2.7640021800994874, 'min_batch': 2.3811636447906492, 'max_batch': 3.0991029024124144}
step: 1840 @ episode report: {'average_total_reward': 4.6700006, 'reward_variance': 0.64377975, 'max_total_reward': 5.79, 'min_total_reward': 3.4600003, 'average_n_step': 6.1, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 60928} @ step loss: {'critic_loss': 1.0342572510242463, 'actor_loss': -3.6714946031570435, 'hyper_actor_loss': 0.10590574443340302, 'behavior_loss': 0.5725731015205383, 'mean_batch': 3.015851855278015, 'min_batch': 2.609835124015808, 'max_batch': 3.3989476919174195}
step: 1850 @ episode report: {'average_total_reward': 4.4369993, 'reward_variance': 1.132561, 'max_total_reward': 5.79, 'min_total_reward': 2.3500001, 'average_n_step': 5.9, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 61248} @ step loss: {'critic_loss': 1.1261768519878388, 'actor_loss': -3.699608874320984, 'hyper_actor_loss': 0.10586845278739929, 'behavior_loss': 0.5765835762023925, 'mean_batch': 3.0503393173217774, 'min_batch': 2.6523277282714846, 'max_batch': 3.447123074531555}
step: 1860 @ episode report: {'average_total_reward': 5.414, 'reward_variance': 2.0198643, 'max_total_reward': 7.6800003, 'min_total_reward': 3.57, 'average_n_step': 6.8, 'max_n_step': 9.0, 'min_n_step': 5.0, 'buffer_size': 61568} @ step loss: {'critic_loss': 1.0911922395229339, 'actor_loss': -3.678559994697571, 'hyper_actor_loss': 0.10576907470822335, 'behavior_loss': 0.5723882913589478, 'mean_batch': 3.0364678382873533, 'min_batch': 2.6096667528152464, 'max_batch': 3.407243275642395}
step: 1870 @ episode report: {'average_total_reward': 4.7809997, 'reward_variance': 0.84204894, 'max_total_reward': 5.79, 'min_total_reward': 3.4600003, 'average_n_step': 6.2, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 61888} @ step loss: {'critic_loss': 1.2888917207717896, 'actor_loss': -3.646706461906433, 'hyper_actor_loss': 0.10571845099329949, 'behavior_loss': 0.588264274597168, 'mean_batch': 3.0129639148712157, 'min_batch': 2.5485400676727297, 'max_batch': 3.3663525342941285}
step: 1880 @ episode report: {'average_total_reward': 4.8589997, 'reward_variance': 1.1958891, 'max_total_reward': 6.79, 'min_total_reward': 3.46, 'average_n_step': 6.3, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 62208} @ step loss: {'critic_loss': 1.3430118203163146, 'actor_loss': -3.6189526557922362, 'hyper_actor_loss': 0.10578726530075074, 'behavior_loss': 0.5725094497203826, 'mean_batch': 2.9576984882354735, 'min_batch': 2.5243892908096313, 'max_batch': 3.318738031387329}
step: 1890 @ episode report: {'average_total_reward': 4.803, 'reward_variance': 0.7103809, 'max_total_reward': 5.79, 'min_total_reward': 3.35, 'average_n_step': 6.2, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 62528} @ step loss: {'critic_loss': 1.034101551771164, 'actor_loss': -3.607665991783142, 'hyper_actor_loss': 0.10576346144080162, 'behavior_loss': 0.5657629132270813, 'mean_batch': 2.9571954250335692, 'min_batch': 2.4963359594345094, 'max_batch': 3.3044784307479858}
step: 1900 @ episode report: {'average_total_reward': 5.237, 'reward_variance': 1.1342008, 'max_total_reward': 6.57, 'min_total_reward': 3.13, 'average_n_step': 6.7, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 62848} @ step loss: {'critic_loss': 1.197113674879074, 'actor_loss': -3.6962424755096435, 'hyper_actor_loss': 0.1058097593486309, 'behavior_loss': 0.5620716691017151, 'mean_batch': 3.070155072212219, 'min_batch': 2.6280312299728394, 'max_batch': 3.4211113929748533}
step: 1910 @ episode report: {'average_total_reward': 5.247, 'reward_variance': 1.9774004, 'max_total_reward': 8.679999, 'min_total_reward': 3.5700002, 'average_n_step': 6.6, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 63168} @ step loss: {'critic_loss': 1.2651287913322449, 'actor_loss': -3.5787448406219484, 'hyper_actor_loss': 0.10548687726259232, 'behavior_loss': 0.5762161016464233, 'mean_batch': 2.9061108112335203, 'min_batch': 2.46697313785553, 'max_batch': 3.251146149635315}
step: 1920 @ episode report: {'average_total_reward': 4.6260004, 'reward_variance': 2.1483238, 'max_total_reward': 6.79, 'min_total_reward': 2.46, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 63488} @ step loss: {'critic_loss': 1.237250703573227, 'actor_loss': -3.5781293869018556, 'hyper_actor_loss': 0.10556331798434257, 'behavior_loss': 0.5638218700885773, 'mean_batch': 2.9286841630935667, 'min_batch': 2.4492676496505736, 'max_batch': 3.266726922988892}
step: 1930 @ episode report: {'average_total_reward': 5.003, 'reward_variance': 0.716241, 'max_total_reward': 6.57, 'min_total_reward': 3.4600003, 'average_n_step': 6.4, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 63808} @ step loss: {'critic_loss': 1.3509108662605285, 'actor_loss': -3.561526918411255, 'hyper_actor_loss': 0.10568332746624946, 'behavior_loss': 0.5686158120632172, 'mean_batch': 2.877148985862732, 'min_batch': 2.449801969528198, 'max_batch': 3.2061691284179688}
step: 1940 @ episode report: {'average_total_reward': 4.548, 'reward_variance': 0.23845601, 'max_total_reward': 5.57, 'min_total_reward': 3.46, 'average_n_step': 6.0, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 64128} @ step loss: {'critic_loss': 1.3444907903671264, 'actor_loss': -3.5987826347351075, 'hyper_actor_loss': 0.1059736154973507, 'behavior_loss': 0.5724021196365356, 'mean_batch': 2.9417311191558837, 'min_batch': 2.487328791618347, 'max_batch': 3.2782976150512697}
step: 1950 @ episode report: {'average_total_reward': 4.748, 'reward_variance': 0.74409604, 'max_total_reward': 5.7900004, 'min_total_reward': 3.3500001, 'average_n_step': 6.2, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 64448} @ step loss: {'critic_loss': 1.218917727470398, 'actor_loss': -3.645686626434326, 'hyper_actor_loss': 0.10622691512107849, 'behavior_loss': 0.5735415697097779, 'mean_batch': 2.9881340980529787, 'min_batch': 2.565737175941467, 'max_batch': 3.3368570804595947}
step: 1960 @ episode report: {'average_total_reward': 5.4469995, 'reward_variance': 2.2542808, 'max_total_reward': 7.9, 'min_total_reward': 3.57, 'average_n_step': 6.8, 'max_n_step': 9.0, 'min_n_step': 5.0, 'buffer_size': 64768} @ step loss: {'critic_loss': 1.2810091018676757, 'actor_loss': -3.6562799215316772, 'hyper_actor_loss': 0.10555918589234352, 'behavior_loss': 0.5657885849475861, 'mean_batch': 3.0222633361816404, 'min_batch': 2.5656876087188722, 'max_batch': 3.3668221950531008}
step: 1970 @ episode report: {'average_total_reward': 5.203, 'reward_variance': 0.7958807, 'max_total_reward': 6.7899995, 'min_total_reward': 3.4600003, 'average_n_step': 6.6, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 65088} @ step loss: {'critic_loss': 1.2388648986816406, 'actor_loss': -3.651005506515503, 'hyper_actor_loss': 0.10547069236636161, 'behavior_loss': 0.5627328395843506, 'mean_batch': 3.0101797103881838, 'min_batch': 2.559174084663391, 'max_batch': 3.3630725383758544}
step: 1980 @ episode report: {'average_total_reward': 4.6150002, 'reward_variance': 2.245905, 'max_total_reward': 6.57, 'min_total_reward': 2.13, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 65408} @ step loss: {'critic_loss': 1.2430669128894807, 'actor_loss': -3.7123801469802857, 'hyper_actor_loss': 0.10526682585477828, 'behavior_loss': 0.5618198633193969, 'mean_batch': 3.10923318862915, 'min_batch': 2.636765646934509, 'max_batch': 3.4852991819381716}
step: 1990 @ episode report: {'average_total_reward': 4.6480002, 'reward_variance': 1.9649563, 'max_total_reward': 7.79, 'min_total_reward': 2.46, 'average_n_step': 6.1, 'max_n_step': 9.0, 'min_n_step': 4.0, 'buffer_size': 65728} @ step loss: {'critic_loss': 1.2656830549240112, 'actor_loss': -3.682508707046509, 'hyper_actor_loss': 0.10545095279812813, 'behavior_loss': 0.5739856660366058, 'mean_batch': 3.033337211608887, 'min_batch': 2.6211082458496096, 'max_batch': 3.394932413101196}
step: 2000 @ episode report: {'average_total_reward': 5.181, 'reward_variance': 0.91324884, 'max_total_reward': 6.79, 'min_total_reward': 3.46, 'average_n_step': 6.6, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 66048} @ step loss: {'critic_loss': 1.2319094657897949, 'actor_loss': -3.616415572166443, 'hyper_actor_loss': 0.10564874932169914, 'behavior_loss': 0.5592552065849304, 'mean_batch': 2.9508026361465456, 'min_batch': 2.522239089012146, 'max_batch': 3.305216932296753}
step: 2010 @ episode report: {'average_total_reward': 4.9040003, 'reward_variance': 0.62222415, 'max_total_reward': 6.57, 'min_total_reward': 3.46, 'average_n_step': 6.4, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 66368} @ step loss: {'critic_loss': 1.20595640540123, 'actor_loss': -3.7069546461105345, 'hyper_actor_loss': 0.10561947077512741, 'behavior_loss': 0.5700449466705322, 'mean_batch': 3.084699845314026, 'min_batch': 2.6419958591461183, 'max_batch': 3.462305951118469}
step: 2020 @ episode report: {'average_total_reward': 4.9370003, 'reward_variance': 1.2447212, 'max_total_reward': 6.680001, 'min_total_reward': 3.3500001, 'average_n_step': 6.4, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 66688} @ step loss: {'critic_loss': 1.1631292700767517, 'actor_loss': -3.7104098081588743, 'hyper_actor_loss': 0.10537260174751281, 'behavior_loss': 0.5557218074798584, 'mean_batch': 3.1114460468292235, 'min_batch': 2.6285680770874023, 'max_batch': 3.48124213218689}
step: 2030 @ episode report: {'average_total_reward': 4.926, 'reward_variance': 0.92188394, 'max_total_reward': 6.6800003, 'min_total_reward': 3.5700002, 'average_n_step': 6.4, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 67008} @ step loss: {'critic_loss': 1.277917629480362, 'actor_loss': -3.6937007188796995, 'hyper_actor_loss': 0.10547876358032227, 'behavior_loss': 0.5626406610012055, 'mean_batch': 3.0793901920318603, 'min_batch': 2.612671136856079, 'max_batch': 3.452187442779541}
step: 2040 @ episode report: {'average_total_reward': 4.5379996, 'reward_variance': 1.6747363, 'max_total_reward': 6.79, 'min_total_reward': 2.02, 'average_n_step': 6.1, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 67328} @ step loss: {'critic_loss': 1.2346198201179504, 'actor_loss': -3.714031291007996, 'hyper_actor_loss': 0.10531605631113053, 'behavior_loss': 0.5470794796943664, 'mean_batch': 3.0941248893737794, 'min_batch': 2.6541900873184203, 'max_batch': 3.4460336446762083}
step: 2050 @ episode report: {'average_total_reward': 4.9479995, 'reward_variance': 2.5380359, 'max_total_reward': 9.01, 'min_total_reward': 3.35, 'average_n_step': 6.4, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 67648} @ step loss: {'critic_loss': 1.3431928873062133, 'actor_loss': -3.69645357131958, 'hyper_actor_loss': 0.10523947551846505, 'behavior_loss': 0.5647264540195465, 'mean_batch': 3.0546070337295532, 'min_batch': 2.64170618057251, 'max_batch': 3.396172285079956}
step: 2060 @ episode report: {'average_total_reward': 5.158, 'reward_variance': 0.9691957, 'max_total_reward': 6.8999996, 'min_total_reward': 3.57, 'average_n_step': 6.5, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 67968} @ step loss: {'critic_loss': 1.2433081150054932, 'actor_loss': -3.693102812767029, 'hyper_actor_loss': 0.10538347661495209, 'behavior_loss': 0.5723806381225586, 'mean_batch': 3.079716610908508, 'min_batch': 2.610024333000183, 'max_batch': 3.4476051330566406}
step: 2070 @ episode report: {'average_total_reward': 4.8370004, 'reward_variance': 0.92254084, 'max_total_reward': 5.79, 'min_total_reward': 2.3500001, 'average_n_step': 6.3, 'max_n_step': 7.0, 'min_n_step': 4.0, 'buffer_size': 68288} @ step loss: {'critic_loss': 1.340815019607544, 'actor_loss': -3.7171681404113768, 'hyper_actor_loss': 0.10556395277380944, 'behavior_loss': 0.562505716085434, 'mean_batch': 3.0948637247085573, 'min_batch': 2.659855771064758, 'max_batch': 3.4705560922622682}
step: 2080 @ episode report: {'average_total_reward': 4.57, 'reward_variance': 3.0910404, 'max_total_reward': 8.900001, 'min_total_reward': 3.35, 'average_n_step': 6.0, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 68608} @ step loss: {'critic_loss': 1.33296639919281, 'actor_loss': -3.661131978034973, 'hyper_actor_loss': 0.10527589991688728, 'behavior_loss': 0.5804831862449646, 'mean_batch': 3.0278422594070435, 'min_batch': 2.5709614038467405, 'max_batch': 3.3623531103134154}
step: 2090 @ episode report: {'average_total_reward': 5.037, 'reward_variance': 2.666581, 'max_total_reward': 7.9, 'min_total_reward': 2.46, 'average_n_step': 6.5, 'max_n_step': 9.0, 'min_n_step': 4.0, 'buffer_size': 68928} @ step loss: {'critic_loss': 1.2780401468276978, 'actor_loss': -3.7408143997192385, 'hyper_actor_loss': 0.10530909672379493, 'behavior_loss': 0.5617450118064881, 'mean_batch': 3.15583655834198, 'min_batch': 2.6736153602600097, 'max_batch': 3.52475905418396}
step: 2100 @ episode report: {'average_total_reward': 4.915, 'reward_variance': 1.0478649, 'max_total_reward': 6.5699997, 'min_total_reward': 3.4600003, 'average_n_step': 6.4, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 69248} @ step loss: {'critic_loss': 1.1596291542053223, 'actor_loss': -3.786147356033325, 'hyper_actor_loss': 0.1054881252348423, 'behavior_loss': 0.5568687379360199, 'mean_batch': 3.193660855293274, 'min_batch': 2.7626220703125, 'max_batch': 3.546732783317566}
step: 2110 @ episode report: {'average_total_reward': 4.903, 'reward_variance': 0.8904212, 'max_total_reward': 6.6800003, 'min_total_reward': 3.57, 'average_n_step': 6.3, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 69568} @ step loss: {'critic_loss': 1.3556641459465026, 'actor_loss': -3.7589061975479128, 'hyper_actor_loss': 0.10549143999814987, 'behavior_loss': 0.5822908163070679, 'mean_batch': 3.1746501207351683, 'min_batch': 2.707597279548645, 'max_batch': 3.511782717704773}
step: 2120 @ episode report: {'average_total_reward': 5.0810003, 'reward_variance': 0.63280916, 'max_total_reward': 6.6800003, 'min_total_reward': 4.13, 'average_n_step': 6.5, 'max_n_step': 8.0, 'min_n_step': 6.0, 'buffer_size': 69888} @ step loss: {'critic_loss': 1.2715837359428406, 'actor_loss': -3.768621063232422, 'hyper_actor_loss': 0.10561437308788299, 'behavior_loss': 0.5723936915397644, 'mean_batch': 3.2109826803207397, 'min_batch': 2.7043620586395263, 'max_batch': 3.5778057098388674}
step: 2130 @ episode report: {'average_total_reward': 5.9800005, 'reward_variance': 0.98094004, 'max_total_reward': 7.7900004, 'min_total_reward': 4.46, 'average_n_step': 7.3, 'max_n_step': 9.0, 'min_n_step': 6.0, 'buffer_size': 70208} @ step loss: {'critic_loss': 1.4129438400268555, 'actor_loss': -3.7717639446258544, 'hyper_actor_loss': 0.10548185110092163, 'behavior_loss': 0.5706634640693664, 'mean_batch': 3.1694141149520876, 'min_batch': 2.7451095819473266, 'max_batch': 3.5232996940612793}
step: 2140 @ episode report: {'average_total_reward': 4.803, 'reward_variance': 1.4107014, 'max_total_reward': 6.680001, 'min_total_reward': 2.3500001, 'average_n_step': 6.2, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 70528} @ step loss: {'critic_loss': 1.1882624208927155, 'actor_loss': -3.6904979228973387, 'hyper_actor_loss': 0.10527379289269448, 'behavior_loss': 0.554043459892273, 'mean_batch': 3.0551039457321165, 'min_batch': 2.6251810789108276, 'max_batch': 3.40662567615509}
step: 2150 @ episode report: {'average_total_reward': 4.792, 'reward_variance': 0.455656, 'max_total_reward': 5.7900004, 'min_total_reward': 3.5700002, 'average_n_step': 6.2, 'max_n_step': 7.0, 'min_n_step': 5.0, 'buffer_size': 70848} @ step loss: {'critic_loss': 1.4137583136558534, 'actor_loss': -3.7634042501449585, 'hyper_actor_loss': 0.10526997894048691, 'behavior_loss': 0.567822253704071, 'mean_batch': 3.166795182228088, 'min_batch': 2.723290038108826, 'max_batch': 3.505164361000061}
step: 2160 @ episode report: {'average_total_reward': 4.781, 'reward_variance': 2.8281493, 'max_total_reward': 7.7900004, 'min_total_reward': 1.35, 'average_n_step': 6.2, 'max_n_step': 9.0, 'min_n_step': 3.0, 'buffer_size': 71168} @ step loss: {'critic_loss': 1.4078782796859741, 'actor_loss': -3.6608991861343383, 'hyper_actor_loss': 0.10536376386880875, 'behavior_loss': 0.5623245418071747, 'mean_batch': 3.0529558420181275, 'min_batch': 2.549938941001892, 'max_batch': 3.410291838645935}
step: 2170 @ episode report: {'average_total_reward': 4.87, 'reward_variance': 0.98094, 'max_total_reward': 6.79, 'min_total_reward': 3.46, 'average_n_step': 6.3, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 71488} @ step loss: {'critic_loss': 1.3905528664588929, 'actor_loss': -3.715915393829346, 'hyper_actor_loss': 0.10531445443630219, 'behavior_loss': 0.5564850389957428, 'mean_batch': 3.096782422065735, 'min_batch': 2.658357334136963, 'max_batch': 3.4438281059265137}
step: 2180 @ episode report: {'average_total_reward': 5.814, 'reward_variance': 2.4117045, 'max_total_reward': 9.01, 'min_total_reward': 3.46, 'average_n_step': 7.2, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 71808} @ step loss: {'critic_loss': 1.3287567853927613, 'actor_loss': -3.7652081489562987, 'hyper_actor_loss': 0.1049889400601387, 'behavior_loss': 0.5755132257938385, 'mean_batch': 3.178078603744507, 'min_batch': 2.7192190885543823, 'max_batch': 3.5101504802703856}
step: 2190 @ episode report: {'average_total_reward': 5.2139997, 'reward_variance': 1.6466242, 'max_total_reward': 6.680001, 'min_total_reward': 2.3500001, 'average_n_step': 6.6, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 72128} @ step loss: {'critic_loss': 1.4061150431632996, 'actor_loss': -3.695555233955383, 'hyper_actor_loss': 0.10526353195309639, 'behavior_loss': 0.5562537431716919, 'mean_batch': 3.0707062244415284, 'min_batch': 2.6249151468276977, 'max_batch': 3.4120479345321657}
step: 2200 @ episode report: {'average_total_reward': 5.8030005, 'reward_variance': 4.3285804, 'max_total_reward': 8.789999, 'min_total_reward': 2.13, 'average_n_step': 7.2, 'max_n_step': 10.0, 'min_n_step': 4.0, 'buffer_size': 72448} @ step loss: {'critic_loss': 1.49389306306839, 'actor_loss': -3.681322193145752, 'hyper_actor_loss': 0.10524826869368553, 'behavior_loss': 0.5631213545799255, 'mean_batch': 3.0656511068344114, 'min_batch': 2.5908740758895874, 'max_batch': 3.414164662361145}
step: 2210 @ episode report: {'average_total_reward': 5.7139997, 'reward_variance': 2.9164042, 'max_total_reward': 9.01, 'min_total_reward': 3.5700002, 'average_n_step': 7.1, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 72768} @ step loss: {'critic_loss': 1.252251660823822, 'actor_loss': -3.7141083240509034, 'hyper_actor_loss': 0.10523058325052262, 'behavior_loss': 0.5562496602535247, 'mean_batch': 3.0950515985488893, 'min_batch': 2.6533788681030273, 'max_batch': 3.433721923828125}
step: 2220 @ episode report: {'average_total_reward': 5.5360003, 'reward_variance': 1.2647241, 'max_total_reward': 7.79, 'min_total_reward': 3.57, 'average_n_step': 6.9, 'max_n_step': 9.0, 'min_n_step': 5.0, 'buffer_size': 73088} @ step loss: {'critic_loss': 1.1891696095466613, 'actor_loss': -3.80776104927063, 'hyper_actor_loss': 0.10506666824221611, 'behavior_loss': 0.5720710098743439, 'mean_batch': 3.243877577781677, 'min_batch': 2.7807884931564333, 'max_batch': 3.614172840118408}
step: 2230 @ episode report: {'average_total_reward': 5.925, 'reward_variance': 2.883585, 'max_total_reward': 9.01, 'min_total_reward': 3.3500001, 'average_n_step': 7.3, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 73408} @ step loss: {'critic_loss': 1.3470984101295471, 'actor_loss': -3.740546631813049, 'hyper_actor_loss': 0.10525159910321236, 'behavior_loss': 0.5621822595596313, 'mean_batch': 3.132918095588684, 'min_batch': 2.6916614532470704, 'max_batch': 3.5010207653045655}
step: 2240 @ episode report: {'average_total_reward': 5.125, 'reward_variance': 2.320745, 'max_total_reward': 6.9, 'min_total_reward': 1.35, 'average_n_step': 6.5, 'max_n_step': 8.0, 'min_n_step': 3.0, 'buffer_size': 73728} @ step loss: {'critic_loss': 1.3354914903640747, 'actor_loss': -3.7713780641555785, 'hyper_actor_loss': 0.10512711554765701, 'behavior_loss': 0.5564978003501893, 'mean_batch': 3.1645074605941774, 'min_batch': 2.747372579574585, 'max_batch': 3.5112026929855347}
step: 2250 @ episode report: {'average_total_reward': 4.9140005, 'reward_variance': 1.303964, 'max_total_reward': 6.9, 'min_total_reward': 3.24, 'average_n_step': 6.3, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 74048} @ step loss: {'critic_loss': 1.437531018257141, 'actor_loss': -3.76344473361969, 'hyper_actor_loss': 0.10504257529973984, 'behavior_loss': 0.5610196053981781, 'mean_batch': 3.1590532302856444, 'min_batch': 2.730224275588989, 'max_batch': 3.5115621089935303}
step: 2260 @ episode report: {'average_total_reward': 5.9800005, 'reward_variance': 1.4517802, 'max_total_reward': 7.9000006, 'min_total_reward': 4.35, 'average_n_step': 7.3, 'max_n_step': 9.0, 'min_n_step': 6.0, 'buffer_size': 74368} @ step loss: {'critic_loss': 1.3164932370185851, 'actor_loss': -3.7589001417160035, 'hyper_actor_loss': 0.10483354553580285, 'behavior_loss': 0.5636327743530274, 'mean_batch': 3.162243103981018, 'min_batch': 2.7143987655639648, 'max_batch': 3.5370281457901003}
step: 2270 @ episode report: {'average_total_reward': 5.525, 'reward_variance': 0.9845449, 'max_total_reward': 6.79, 'min_total_reward': 3.57, 'average_n_step': 6.9, 'max_n_step': 8.0, 'min_n_step': 5.0, 'buffer_size': 74688} @ step loss: {'critic_loss': 1.283937966823578, 'actor_loss': -3.791199040412903, 'hyper_actor_loss': 0.10512467175722122, 'behavior_loss': 0.544855785369873, 'mean_batch': 3.230489182472229, 'min_batch': 2.746164870262146, 'max_batch': 3.5813342332839966}
step: 2280 @ episode report: {'average_total_reward': 6.336, 'reward_variance': 2.2331243, 'max_total_reward': 8.900001, 'min_total_reward': 4.6800003, 'average_n_step': 7.7, 'max_n_step': 10.0, 'min_n_step': 6.0, 'buffer_size': 75008} @ step loss: {'critic_loss': 1.3648155629634857, 'actor_loss': -3.767670154571533, 'hyper_actor_loss': 0.1049488514661789, 'behavior_loss': 0.5589368402957916, 'mean_batch': 3.15736243724823, 'min_batch': 2.7422762155532836, 'max_batch': 3.4950732707977297}
step: 2290 @ episode report: {'average_total_reward': 6.4460006, 'reward_variance': 2.7750247, 'max_total_reward': 8.900001, 'min_total_reward': 3.57, 'average_n_step': 7.7, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 75328} @ step loss: {'critic_loss': 1.4595486760139464, 'actor_loss': -3.6770204305648804, 'hyper_actor_loss': 0.10467609167098998, 'behavior_loss': 0.5689074635505676, 'mean_batch': 3.0260462284088137, 'min_batch': 2.6138638496398925, 'max_batch': 3.3365026712417603}
step: 2300 @ episode report: {'average_total_reward': 6.269, 'reward_variance': 3.593549, 'max_total_reward': 9.79, 'min_total_reward': 3.57, 'average_n_step': 7.6, 'max_n_step': 11.0, 'min_n_step': 5.0, 'buffer_size': 75648} @ step loss: {'critic_loss': 1.4131828010082246, 'actor_loss': -3.729573965072632, 'hyper_actor_loss': 0.10472689941525459, 'behavior_loss': 0.5579870581626892, 'mean_batch': 3.102494549751282, 'min_batch': 2.6868114709854125, 'max_batch': 3.424552345275879}
step: 2310 @ episode report: {'average_total_reward': 5.6029997, 'reward_variance': 0.6659009, 'max_total_reward': 6.79, 'min_total_reward': 4.35, 'average_n_step': 7.0, 'max_n_step': 8.0, 'min_n_step': 6.0, 'buffer_size': 75968} @ step loss: {'critic_loss': 1.3763856410980224, 'actor_loss': -3.752475214004517, 'hyper_actor_loss': 0.1046103946864605, 'behavior_loss': 0.5444340169429779, 'mean_batch': 3.135710620880127, 'min_batch': 2.7223844051361086, 'max_batch': 3.477078890800476}
step: 2320 @ episode report: {'average_total_reward': 5.503, 'reward_variance': 2.526181, 'max_total_reward': 8.68, 'min_total_reward': 3.46, 'average_n_step': 6.9, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 76288} @ step loss: {'critic_loss': 1.380567765235901, 'actor_loss': -3.75796320438385, 'hyper_actor_loss': 0.10460488945245743, 'behavior_loss': 0.5459408760070801, 'mean_batch': 3.1593008995056153, 'min_batch': 2.7149125814437864, 'max_batch': 3.5363494634628294}
step: 2330 @ episode report: {'average_total_reward': 5.88, 'reward_variance': 3.087361, 'max_total_reward': 10.010001, 'min_total_reward': 3.57, 'average_n_step': 7.2, 'max_n_step': 11.0, 'min_n_step': 5.0, 'buffer_size': 76608} @ step loss: {'critic_loss': 1.3274190783500672, 'actor_loss': -3.824246907234192, 'hyper_actor_loss': 0.10457481145858764, 'behavior_loss': 0.5443244814872742, 'mean_batch': 3.2797369718551637, 'min_batch': 2.7943989992141725, 'max_batch': 3.666636919975281}
step: 2340 @ episode report: {'average_total_reward': 6.224, 'reward_variance': 1.238584, 'max_total_reward': 7.9, 'min_total_reward': 3.46, 'average_n_step': 7.5, 'max_n_step': 9.0, 'min_n_step': 5.0, 'buffer_size': 76928} @ step loss: {'critic_loss': 1.3632357239723205, 'actor_loss': -3.810802459716797, 'hyper_actor_loss': 0.10481470227241516, 'behavior_loss': 0.566708117723465, 'mean_batch': 3.2195951461791994, 'min_batch': 2.8083497047424317, 'max_batch': 3.5608646869659424}
step: 2350 @ episode report: {'average_total_reward': 6.6800003, 'reward_variance': 1.3511403, 'max_total_reward': 9.01, 'min_total_reward': 4.57, 'average_n_step': 8.0, 'max_n_step': 10.0, 'min_n_step': 6.0, 'buffer_size': 77248} @ step loss: {'critic_loss': 1.338403683900833, 'actor_loss': -3.8111699342727663, 'hyper_actor_loss': 0.10521052852272987, 'behavior_loss': 0.5488976180553437, 'mean_batch': 3.2849053144454956, 'min_batch': 2.7548001766204835, 'max_batch': 3.672677826881409}
step: 2360 @ episode report: {'average_total_reward': 7.1470003, 'reward_variance': 1.5339411, 'max_total_reward': 10.01, 'min_total_reward': 5.79, 'average_n_step': 8.5, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 77568} @ step loss: {'critic_loss': 1.3551354467868806, 'actor_loss': -3.8390215635299683, 'hyper_actor_loss': 0.10464862883090972, 'behavior_loss': 0.5580966651439667, 'mean_batch': 3.2976041793823243, 'min_batch': 2.8206889629364014, 'max_batch': 3.6767379522323607}
step: 2370 @ episode report: {'average_total_reward': 6.224, 'reward_variance': 2.9485834, 'max_total_reward': 9.9, 'min_total_reward': 3.5700002, 'average_n_step': 7.5, 'max_n_step': 11.0, 'min_n_step': 5.0, 'buffer_size': 77888} @ step loss: {'critic_loss': 1.4004907727241516, 'actor_loss': -3.8043256282806395, 'hyper_actor_loss': 0.1042917400598526, 'behavior_loss': 0.5487028807401657, 'mean_batch': 3.224265766143799, 'min_batch': 2.786438012123108, 'max_batch': 3.5975110054016115}
step: 2380 @ episode report: {'average_total_reward': 6.979, 'reward_variance': 1.9780089, 'max_total_reward': 9.79, 'min_total_reward': 4.46, 'average_n_step': 8.2, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 78208} @ step loss: {'critic_loss': 1.4402204155921936, 'actor_loss': -3.7662371158599854, 'hyper_actor_loss': 0.10424854382872581, 'behavior_loss': 0.5517060071229934, 'mean_batch': 3.176286244392395, 'min_batch': 2.7235734939575194, 'max_batch': 3.5234609842300415}
step: 2390 @ episode report: {'average_total_reward': 6.8459997, 'reward_variance': 2.0290637, 'max_total_reward': 9.01, 'min_total_reward': 4.46, 'average_n_step': 8.1, 'max_n_step': 10.0, 'min_n_step': 6.0, 'buffer_size': 78528} @ step loss: {'critic_loss': 1.3609863877296449, 'actor_loss': -3.802879476547241, 'hyper_actor_loss': 0.10408437699079513, 'behavior_loss': 0.5480627596378327, 'mean_batch': 3.2587087631225584, 'min_batch': 2.7550058364868164, 'max_batch': 3.6365227460861207}
step: 2400 @ episode report: {'average_total_reward': 6.8130007, 'reward_variance': 5.0214014, 'max_total_reward': 11.01, 'min_total_reward': 3.46, 'average_n_step': 8.1, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 78848} @ step loss: {'critic_loss': 1.401735496520996, 'actor_loss': -3.8201135873794554, 'hyper_actor_loss': 0.10420218333601952, 'behavior_loss': 0.5544199228286744, 'mean_batch': 3.2479116678237916, 'min_batch': 2.809996819496155, 'max_batch': 3.6338467359542848}
step: 2410 @ episode report: {'average_total_reward': 6.679, 'reward_variance': 4.3121285, 'max_total_reward': 11.23, 'min_total_reward': 3.3500001, 'average_n_step': 7.9, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 79168} @ step loss: {'critic_loss': 1.408014166355133, 'actor_loss': -3.755302333831787, 'hyper_actor_loss': 0.10420213416218757, 'behavior_loss': 0.5533859968185425, 'mean_batch': 3.17135694026947, 'min_batch': 2.700084114074707, 'max_batch': 3.5441136360168457}
step: 2420 @ episode report: {'average_total_reward': 6.468, 'reward_variance': 1.1575756, 'max_total_reward': 7.9, 'min_total_reward': 4.6800003, 'average_n_step': 7.7, 'max_n_step': 9.0, 'min_n_step': 6.0, 'buffer_size': 79488} @ step loss: {'critic_loss': 1.5575258135795593, 'actor_loss': -3.8298723220825197, 'hyper_actor_loss': 0.10406179130077362, 'behavior_loss': 0.5513531506061554, 'mean_batch': 3.245713639259338, 'min_batch': 2.8389344930648805, 'max_batch': 3.5995219945907593}
step: 2430 @ episode report: {'average_total_reward': 7.102, 'reward_variance': 2.097796, 'max_total_reward': 9.9, 'min_total_reward': 5.46, 'average_n_step': 8.4, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 79808} @ step loss: {'critic_loss': 1.4305641651153564, 'actor_loss': -3.8259490728378296, 'hyper_actor_loss': 0.10412391871213914, 'behavior_loss': 0.5436020910739898, 'mean_batch': 3.26688129901886, 'min_batch': 2.8109795808792115, 'max_batch': 3.625108337402344}
step: 2440 @ episode report: {'average_total_reward': 6.7910004, 'reward_variance': 2.5189688, 'max_total_reward': 10.12, 'min_total_reward': 4.2400002, 'average_n_step': 8.1, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 80128} @ step loss: {'critic_loss': 1.4981191396713256, 'actor_loss': -3.8606508493423464, 'hyper_actor_loss': 0.1041842371225357, 'behavior_loss': 0.5575043082237243, 'mean_batch': 3.3027703285217287, 'min_batch': 2.8782173871994017, 'max_batch': 3.6402128458023073}
step: 2450 @ episode report: {'average_total_reward': 6.924, 'reward_variance': 2.501924, 'max_total_reward': 9.9, 'min_total_reward': 4.68, 'average_n_step': 8.2, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 80448} @ step loss: {'critic_loss': 1.4299198150634767, 'actor_loss': -3.8257310152053834, 'hyper_actor_loss': 0.10407946109771729, 'behavior_loss': 0.5519822359085083, 'mean_batch': 3.239060091972351, 'min_batch': 2.833412218093872, 'max_batch': 3.592630887031555}
step: 2460 @ episode report: {'average_total_reward': 6.1239996, 'reward_variance': 1.7374847, 'max_total_reward': 9.010001, 'min_total_reward': 4.46, 'average_n_step': 7.4, 'max_n_step': 10.0, 'min_n_step': 6.0, 'buffer_size': 80768} @ step loss: {'critic_loss': 1.475970309972763, 'actor_loss': -3.8290510177612305, 'hyper_actor_loss': 0.10390729829668999, 'behavior_loss': 0.5593699306249619, 'mean_batch': 3.2623661279678347, 'min_batch': 2.8237999439239503, 'max_batch': 3.627861833572388}
step: 2470 @ episode report: {'average_total_reward': 6.7019997, 'reward_variance': 2.2538157, 'max_total_reward': 9.01, 'min_total_reward': 4.46, 'average_n_step': 8.0, 'max_n_step': 10.0, 'min_n_step': 6.0, 'buffer_size': 81088} @ step loss: {'critic_loss': 1.4458743989467622, 'actor_loss': -3.841076922416687, 'hyper_actor_loss': 0.10386854410171509, 'behavior_loss': 0.5487270295619965, 'mean_batch': 3.2769471645355224, 'min_batch': 2.843428206443787, 'max_batch': 3.6637133359909058}
step: 2480 @ episode report: {'average_total_reward': 6.8129997, 'reward_variance': 1.2788813, 'max_total_reward': 8.900001, 'min_total_reward': 5.46, 'average_n_step': 8.1, 'max_n_step': 10.0, 'min_n_step': 7.0, 'buffer_size': 81408} @ step loss: {'critic_loss': 1.4088210582733154, 'actor_loss': -3.868420362472534, 'hyper_actor_loss': 0.10383227169513702, 'behavior_loss': 0.5316391348838806, 'mean_batch': 3.3300791501998903, 'min_batch': 2.8768967628479003, 'max_batch': 3.6973758935928345}
step: 2490 @ episode report: {'average_total_reward': 7.757, 'reward_variance': 2.3712618, 'max_total_reward': 10.120001, 'min_total_reward': 4.6800003, 'average_n_step': 9.0, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 81728} @ step loss: {'critic_loss': 1.365735912322998, 'actor_loss': -3.870985412597656, 'hyper_actor_loss': 0.10370981171727181, 'behavior_loss': 0.5396658837795257, 'mean_batch': 3.3568482637405395, 'min_batch': 2.8621962308883666, 'max_batch': 3.743661665916443}
step: 2500 @ episode report: {'average_total_reward': 6.8459997, 'reward_variance': 1.7142241, 'max_total_reward': 8.900001, 'min_total_reward': 4.57, 'average_n_step': 8.1, 'max_n_step': 10.0, 'min_n_step': 6.0, 'buffer_size': 82048} @ step loss: {'critic_loss': 1.4802178740501404, 'actor_loss': -3.883656311035156, 'hyper_actor_loss': 0.10359462052583694, 'behavior_loss': 0.5407981693744659, 'mean_batch': 3.345351791381836, 'min_batch': 2.907564377784729, 'max_batch': 3.709359908103943}
step: 2510 @ episode report: {'average_total_reward': 7.268, 'reward_variance': 4.2727575, 'max_total_reward': 12.340001, 'min_total_reward': 4.5699997, 'average_n_step': 8.5, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 82368} @ step loss: {'critic_loss': 1.3753339409828187, 'actor_loss': -3.8417300462722777, 'hyper_actor_loss': 0.10351064503192901, 'behavior_loss': 0.5292439639568329, 'mean_batch': 3.341768407821655, 'min_batch': 2.791739344596863, 'max_batch': 3.7435444355010987}
step: 2520 @ episode report: {'average_total_reward': 7.4900002, 'reward_variance': 2.77146, 'max_total_reward': 10.12, 'min_total_reward': 4.5699997, 'average_n_step': 8.7, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 82688} @ step loss: {'critic_loss': 1.526454496383667, 'actor_loss': -3.9264837503433228, 'hyper_actor_loss': 0.10341317132115364, 'behavior_loss': 0.554307609796524, 'mean_batch': 3.470526432991028, 'min_batch': 2.9244009017944337, 'max_batch': 3.883496809005737}
step: 2530 @ episode report: {'average_total_reward': 7.6120005, 'reward_variance': 4.8910365, 'max_total_reward': 11.010001, 'min_total_reward': 4.68, 'average_n_step': 8.8, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 83008} @ step loss: {'critic_loss': 1.411642611026764, 'actor_loss': -3.9105623960494995, 'hyper_actor_loss': 0.10354478806257247, 'behavior_loss': 0.546931779384613, 'mean_batch': 3.430098795890808, 'min_batch': 2.9126631736755373, 'max_batch': 3.836232590675354}
step: 2540 @ episode report: {'average_total_reward': 8.023001, 'reward_variance': 3.2742805, 'max_total_reward': 10.9, 'min_total_reward': 4.68, 'average_n_step': 9.2, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 83328} @ step loss: {'critic_loss': 1.3727124810218811, 'actor_loss': -3.9879064083099367, 'hyper_actor_loss': 0.10346519872546196, 'behavior_loss': 0.5312488108873368, 'mean_batch': 3.5484934091567992, 'min_batch': 3.041503596305847, 'max_batch': 3.9563074111938477}
step: 2550 @ episode report: {'average_total_reward': 8.2, 'reward_variance': 1.5101001, 'max_total_reward': 10.12, 'min_total_reward': 6.79, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 83648} @ step loss: {'critic_loss': 1.4803051948547363, 'actor_loss': -3.9403965711593627, 'hyper_actor_loss': 0.10308571606874466, 'behavior_loss': 0.5483256638050079, 'mean_batch': 3.4765625953674317, 'min_batch': 2.96062433719635, 'max_batch': 3.8614387273788453}
step: 2560 @ episode report: {'average_total_reward': 6.857, 'reward_variance': 2.2485013, 'max_total_reward': 9.01, 'min_total_reward': 3.5700002, 'average_n_step': 8.1, 'max_n_step': 10.0, 'min_n_step': 5.0, 'buffer_size': 83968} @ step loss: {'critic_loss': 1.6126261115074159, 'actor_loss': -3.9113324165344237, 'hyper_actor_loss': 0.10309764891862869, 'behavior_loss': 0.5324826180934906, 'mean_batch': 3.404506278038025, 'min_batch': 2.936865735054016, 'max_batch': 3.785986542701721}
step: 2570 @ episode report: {'average_total_reward': 8.323, 'reward_variance': 3.8450005, 'max_total_reward': 11.01, 'min_total_reward': 4.3500004, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 84288} @ step loss: {'critic_loss': 1.4887420654296875, 'actor_loss': -3.989512395858765, 'hyper_actor_loss': 0.10302337482571602, 'behavior_loss': 0.5356591045856476, 'mean_batch': 3.5692528963088987, 'min_batch': 3.033934497833252, 'max_batch': 3.9960270643234255}
step: 2580 @ episode report: {'average_total_reward': 8.311, 'reward_variance': 3.1429088, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 9.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 84608} @ step loss: {'critic_loss': 1.5457707047462463, 'actor_loss': -3.957933950424194, 'hyper_actor_loss': 0.1031802661716938, 'behavior_loss': 0.5504604637622833, 'mean_batch': 3.484018349647522, 'min_batch': 3.00719678401947, 'max_batch': 3.9147571563720702}
step: 2590 @ episode report: {'average_total_reward': 8.167001, 'reward_variance': 4.1869597, 'max_total_reward': 11.12, 'min_total_reward': 5.57, 'average_n_step': 9.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 84928} @ step loss: {'critic_loss': 1.4705342173576355, 'actor_loss': -4.038158106803894, 'hyper_actor_loss': 0.10306713953614235, 'behavior_loss': 0.529299134016037, 'mean_batch': 3.6621047496795653, 'min_batch': 3.100226807594299, 'max_batch': 4.109491014480591}
step: 2600 @ episode report: {'average_total_reward': 8.6779995, 'reward_variance': 1.7680762, 'max_total_reward': 11.12, 'min_total_reward': 6.9000006, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 85248} @ step loss: {'critic_loss': 1.3808369517326355, 'actor_loss': -4.031805562973022, 'hyper_actor_loss': 0.1027901291847229, 'behavior_loss': 0.5407042026519775, 'mean_batch': 3.6321877956390383, 'min_batch': 3.106156921386719, 'max_batch': 4.0395094633102415}
step: 2610 @ episode report: {'average_total_reward': 7.201, 'reward_variance': 3.391529, 'max_total_reward': 11.12, 'min_total_reward': 3.5700002, 'average_n_step': 8.4, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 85568} @ step loss: {'critic_loss': 1.6167622804641724, 'actor_loss': -4.013850235939026, 'hyper_actor_loss': 0.10268461853265762, 'behavior_loss': 0.5411046862602233, 'mean_batch': 3.5614177942276, 'min_batch': 3.1097795009613036, 'max_batch': 3.9773168563842773}
step: 2620 @ episode report: {'average_total_reward': 7.7560005, 'reward_variance': 2.730724, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 8.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 85888} @ step loss: {'critic_loss': 1.680891180038452, 'actor_loss': -3.9874345541000364, 'hyper_actor_loss': 0.10274126529693603, 'behavior_loss': 0.5436124920845031, 'mean_batch': 3.533097195625305, 'min_batch': 3.0540388584136964, 'max_batch': 3.9324495077133177}
step: 2630 @ episode report: {'average_total_reward': 7.5239997, 'reward_variance': 3.4594238, 'max_total_reward': 11.23, 'min_total_reward': 4.46, 'average_n_step': 8.8, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 86208} @ step loss: {'critic_loss': 1.49363112449646, 'actor_loss': -3.9728620529174803, 'hyper_actor_loss': 0.10283277630805969, 'behavior_loss': 0.5320187509059906, 'mean_batch': 3.543789005279541, 'min_batch': 3.000756025314331, 'max_batch': 3.9145965337753297}
step: 2640 @ episode report: {'average_total_reward': 8.234001, 'reward_variance': 1.8127444, 'max_total_reward': 10.010001, 'min_total_reward': 5.6800003, 'average_n_step': 9.4, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 86528} @ step loss: {'critic_loss': 1.7053953766822816, 'actor_loss': -3.9814971446990968, 'hyper_actor_loss': 0.10281903743743896, 'behavior_loss': 0.5546789646148682, 'mean_batch': 3.528106713294983, 'min_batch': 3.039806604385376, 'max_batch': 3.929755163192749}
step: 2650 @ episode report: {'average_total_reward': 8.1449995, 'reward_variance': 1.3681253, 'max_total_reward': 9.900001, 'min_total_reward': 6.5699997, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 86848} @ step loss: {'critic_loss': 1.5608213543891907, 'actor_loss': -3.9540895223617554, 'hyper_actor_loss': 0.10260205566883088, 'behavior_loss': 0.5260529190301895, 'mean_batch': 3.4835827112197877, 'min_batch': 2.9949114084243775, 'max_batch': 3.8848793745040893}
step: 2660 @ episode report: {'average_total_reward': 8.134, 'reward_variance': 2.342924, 'max_total_reward': 9.79, 'min_total_reward': 4.6800003, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 87168} @ step loss: {'critic_loss': 1.5730245232582092, 'actor_loss': -4.059088706970215, 'hyper_actor_loss': 0.10254930779337883, 'behavior_loss': 0.5307268053293228, 'mean_batch': 3.628278636932373, 'min_batch': 3.193866562843323, 'max_batch': 4.049650120735168}
step: 2670 @ episode report: {'average_total_reward': 8.267, 'reward_variance': 2.4059808, 'max_total_reward': 11.009999, 'min_total_reward': 5.46, 'average_n_step': 9.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 87488} @ step loss: {'critic_loss': 1.745011830329895, 'actor_loss': -3.954308009147644, 'hyper_actor_loss': 0.10275735855102539, 'behavior_loss': 0.534317484498024, 'mean_batch': 3.4872085571289064, 'min_batch': 2.9936336517333983, 'max_batch': 3.9241103410720823}
step: 2680 @ episode report: {'average_total_reward': 7.5340004, 'reward_variance': 2.3154042, 'max_total_reward': 10.01, 'min_total_reward': 5.68, 'average_n_step': 8.7, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 87808} @ step loss: {'critic_loss': 1.7529921531677246, 'actor_loss': -4.011744570732117, 'hyper_actor_loss': 0.10248365998268127, 'behavior_loss': 0.5274582922458648, 'mean_batch': 3.5691231727600097, 'min_batch': 3.097106671333313, 'max_batch': 3.9851276159286497}
step: 2690 @ episode report: {'average_total_reward': 7.3230004, 'reward_variance': 1.3563808, 'max_total_reward': 9.01, 'min_total_reward': 5.79, 'average_n_step': 8.5, 'max_n_step': 10.0, 'min_n_step': 7.0, 'buffer_size': 88128} @ step loss: {'critic_loss': 1.5890315055847168, 'actor_loss': -3.9780531406402586, 'hyper_actor_loss': 0.1020820014178753, 'behavior_loss': 0.5359298884868622, 'mean_batch': 3.508100461959839, 'min_batch': 3.047333073616028, 'max_batch': 3.918154764175415}
step: 2700 @ episode report: {'average_total_reward': 8.001, 'reward_variance': 1.8668888, 'max_total_reward': 9.9, 'min_total_reward': 5.57, 'average_n_step': 9.2, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 88448} @ step loss: {'critic_loss': 1.5825130939483643, 'actor_loss': -4.037180614471436, 'hyper_actor_loss': 0.10203515440225601, 'behavior_loss': 0.5200234591960907, 'mean_batch': 3.607153558731079, 'min_batch': 3.1431385278701782, 'max_batch': 4.023386073112488}
step: 2710 @ episode report: {'average_total_reward': 7.7450004, 'reward_variance': 2.6267457, 'max_total_reward': 10.120001, 'min_total_reward': 5.4599996, 'average_n_step': 8.9, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 88768} @ step loss: {'critic_loss': 1.63881556391716, 'actor_loss': -4.0465433359146115, 'hyper_actor_loss': 0.10200621262192726, 'behavior_loss': 0.5299059331417084, 'mean_batch': 3.6405300855636598, 'min_batch': 3.1453050136566163, 'max_batch': 4.070964026451111}
step: 2720 @ episode report: {'average_total_reward': 8.089001, 'reward_variance': 2.3828492, 'max_total_reward': 11.12, 'min_total_reward': 5.7900004, 'average_n_step': 9.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 89088} @ step loss: {'critic_loss': 1.7133652687072753, 'actor_loss': -4.051040172576904, 'hyper_actor_loss': 0.10205486789345741, 'behavior_loss': 0.5301768213510514, 'mean_batch': 3.623237156867981, 'min_batch': 3.1730087280273436, 'max_batch': 4.012089824676513}
step: 2730 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 3.0827205, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 89408} @ step loss: {'critic_loss': 1.8344610571861266, 'actor_loss': -4.066542625427246, 'hyper_actor_loss': 0.10205978602170944, 'behavior_loss': 0.5269155532121659, 'mean_batch': 3.678484296798706, 'min_batch': 3.1742350339889525, 'max_batch': 4.09011025428772}
step: 2740 @ episode report: {'average_total_reward': 9.2, 'reward_variance': 2.5837798, 'max_total_reward': 11.009999, 'min_total_reward': 5.57, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 89728} @ step loss: {'critic_loss': 1.694322109222412, 'actor_loss': -3.994916534423828, 'hyper_actor_loss': 0.10202408283948898, 'behavior_loss': 0.5255821466445922, 'mean_batch': 3.5226746082305906, 'min_batch': 3.0851046800613404, 'max_batch': 3.9364466428756715}
step: 2750 @ episode report: {'average_total_reward': 7.6229997, 'reward_variance': 1.544261, 'max_total_reward': 9.01, 'min_total_reward': 5.68, 'average_n_step': 8.8, 'max_n_step': 10.0, 'min_n_step': 7.0, 'buffer_size': 90048} @ step loss: {'critic_loss': 1.7420599937438965, 'actor_loss': -4.089168500900269, 'hyper_actor_loss': 0.10183576866984367, 'behavior_loss': 0.5346502184867858, 'mean_batch': 3.7083101749420164, 'min_batch': 3.219973397254944, 'max_batch': 4.105510592460632}
step: 2760 @ episode report: {'average_total_reward': 8.788, 'reward_variance': 3.3636556, 'max_total_reward': 11.009999, 'min_total_reward': 5.7900004, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 90368} @ step loss: {'critic_loss': 1.56880441904068, 'actor_loss': -4.011837768554687, 'hyper_actor_loss': 0.10182179808616638, 'behavior_loss': 0.5184317469596863, 'mean_batch': 3.5655710220336916, 'min_batch': 3.100818228721619, 'max_batch': 3.9906592845916746}
step: 2770 @ episode report: {'average_total_reward': 8.733, 'reward_variance': 3.551941, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 90688} @ step loss: {'critic_loss': 1.7071050643920898, 'actor_loss': -4.077958011627198, 'hyper_actor_loss': 0.10189585536718368, 'behavior_loss': 0.5397052973508835, 'mean_batch': 3.6709856033325194, 'min_batch': 3.216353011131287, 'max_batch': 4.142105770111084}
step: 2780 @ episode report: {'average_total_reward': 7.6559997, 'reward_variance': 1.2357242, 'max_total_reward': 9.01, 'min_total_reward': 5.79, 'average_n_step': 8.8, 'max_n_step': 10.0, 'min_n_step': 7.0, 'buffer_size': 91008} @ step loss: {'critic_loss': 1.6973917603492736, 'actor_loss': -4.0939940214157104, 'hyper_actor_loss': 0.10176905393600463, 'behavior_loss': 0.5102527052164078, 'mean_batch': 3.756489109992981, 'min_batch': 3.196011471748352, 'max_batch': 4.138970899581909}
step: 2790 @ episode report: {'average_total_reward': 8.289, 'reward_variance': 1.2379893, 'max_total_reward': 10.12, 'min_total_reward': 6.79, 'average_n_step': 9.4, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 91328} @ step loss: {'critic_loss': 1.737790584564209, 'actor_loss': -4.026919174194336, 'hyper_actor_loss': 0.10143939405679703, 'behavior_loss': 0.5260655552148819, 'mean_batch': 3.59665961265564, 'min_batch': 3.1205487728118895, 'max_batch': 3.99272825717926}
step: 2800 @ episode report: {'average_total_reward': 8.123, 'reward_variance': 3.9009411, 'max_total_reward': 12.12, 'min_total_reward': 4.6800003, 'average_n_step': 9.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 91648} @ step loss: {'critic_loss': 1.4981219172477722, 'actor_loss': -4.112227487564087, 'hyper_actor_loss': 0.10154582858085633, 'behavior_loss': 0.5287913084030151, 'mean_batch': 3.7631750106811523, 'min_batch': 3.2481340646743773, 'max_batch': 4.175342106819153}
step: 2810 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 1.0257841, 'max_total_reward': 10.12, 'min_total_reward': 6.7899995, 'average_n_step': 10.1, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 91968} @ step loss: {'critic_loss': 1.91139714717865, 'actor_loss': -4.0967953443527225, 'hyper_actor_loss': 0.10167602524161339, 'behavior_loss': 0.5373151242733002, 'mean_batch': 3.7143277406692503, 'min_batch': 3.24293258190155, 'max_batch': 4.111992955207825}
step: 2820 @ episode report: {'average_total_reward': 8.778, 'reward_variance': 3.8274162, 'max_total_reward': 13.12, 'min_total_reward': 5.46, 'average_n_step': 9.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 92288} @ step loss: {'critic_loss': 1.7080529570579528, 'actor_loss': -4.064050149917603, 'hyper_actor_loss': 0.10170754864811897, 'behavior_loss': 0.5286330729722977, 'mean_batch': 3.6425639629364013, 'min_batch': 3.1987088918685913, 'max_batch': 4.016212344169617}
step: 2830 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 4.0923357, 'max_total_reward': 11.2300005, 'min_total_reward': 4.46, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 92608} @ step loss: {'critic_loss': 1.5738092422485352, 'actor_loss': -4.106189107894897, 'hyper_actor_loss': 0.10144811794161797, 'behavior_loss': 0.5219274014234543, 'mean_batch': 3.7726516723632812, 'min_batch': 3.2212348222732543, 'max_batch': 4.176915121078491}
step: 2840 @ episode report: {'average_total_reward': 8.433001, 'reward_variance': 3.596161, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 92928} @ step loss: {'critic_loss': 1.7564272165298462, 'actor_loss': -4.045853471755981, 'hyper_actor_loss': 0.10132695585489274, 'behavior_loss': 0.528472313284874, 'mean_batch': 3.6327676296234133, 'min_batch': 3.148389983177185, 'max_batch': 4.031481862068176}
step: 2850 @ episode report: {'average_total_reward': 8.544001, 'reward_variance': 3.0958846, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 9.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 93248} @ step loss: {'critic_loss': 1.6236673712730407, 'actor_loss': -4.0787880420684814, 'hyper_actor_loss': 0.10133111327886582, 'behavior_loss': 0.49852344393730164, 'mean_batch': 3.6864887714385985, 'min_batch': 3.206435751914978, 'max_batch': 4.075682473182678}
step: 2860 @ episode report: {'average_total_reward': 8.478, 'reward_variance': 2.1052759, 'max_total_reward': 10.010001, 'min_total_reward': 5.79, 'average_n_step': 9.6, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 93568} @ step loss: {'critic_loss': 1.6097479164600372, 'actor_loss': -4.109302806854248, 'hyper_actor_loss': 0.10137010142207145, 'behavior_loss': 0.5131244450807572, 'mean_batch': 3.728165054321289, 'min_batch': 3.2693817615509033, 'max_batch': 4.115052700042725}
step: 2870 @ episode report: {'average_total_reward': 9.521, 'reward_variance': 4.970909, 'max_total_reward': 14.56, 'min_total_reward': 5.68, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 93888} @ step loss: {'critic_loss': 1.8967860102653504, 'actor_loss': -4.077178859710694, 'hyper_actor_loss': 0.10107043385505676, 'behavior_loss': 0.5184914410114289, 'mean_batch': 3.6970956802368162, 'min_batch': 3.194541573524475, 'max_batch': 4.086646366119385}
step: 2880 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 2.8188696, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 94208} @ step loss: {'critic_loss': 1.7408432483673095, 'actor_loss': -4.034595060348511, 'hyper_actor_loss': 0.10065136700868607, 'behavior_loss': 0.5199339777231217, 'mean_batch': 3.64196035861969, 'min_batch': 3.1092754125595095, 'max_batch': 4.056657457351685}
step: 2890 @ episode report: {'average_total_reward': 8.644, 'reward_variance': 6.218764, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 9.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 94528} @ step loss: {'critic_loss': 1.7515660405158997, 'actor_loss': -4.079944086074829, 'hyper_actor_loss': 0.10073887780308724, 'behavior_loss': 0.5148824661970138, 'mean_batch': 3.6851173639297485, 'min_batch': 3.211356544494629, 'max_batch': 4.106337547302246}
step: 2900 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 0.8169651, 'max_total_reward': 11.2300005, 'min_total_reward': 7.68, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 94848} @ step loss: {'critic_loss': 1.851041603088379, 'actor_loss': -4.126043081283569, 'hyper_actor_loss': 0.10104488506913185, 'behavior_loss': 0.5211082965135574, 'mean_batch': 3.802955389022827, 'min_batch': 3.259234142303467, 'max_batch': 4.2434775829315186}
step: 2910 @ episode report: {'average_total_reward': 8.711, 'reward_variance': 1.775589, 'max_total_reward': 11.12, 'min_total_reward': 6.79, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 95168} @ step loss: {'critic_loss': 1.8118919372558593, 'actor_loss': -4.062625360488892, 'hyper_actor_loss': 0.10105068907141686, 'behavior_loss': 0.5250691056251526, 'mean_batch': 3.6577097892761232, 'min_batch': 3.1798778057098387, 'max_batch': 4.061352205276489}
step: 2920 @ episode report: {'average_total_reward': 8.300001, 'reward_variance': 4.90018, 'max_total_reward': 11.2300005, 'min_total_reward': 3.2400002, 'average_n_step': 9.4, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 95488} @ step loss: {'critic_loss': 1.7971746444702148, 'actor_loss': -4.118208646774292, 'hyper_actor_loss': 0.10109982267022133, 'behavior_loss': 0.5156779438257217, 'mean_batch': 3.7594529151916505, 'min_batch': 3.2708604097366334, 'max_batch': 4.171196842193604}
step: 2930 @ episode report: {'average_total_reward': 8.7, 'reward_variance': 2.8046207, 'max_total_reward': 12.2300005, 'min_total_reward': 6.68, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 95808} @ step loss: {'critic_loss': 1.8992175936698914, 'actor_loss': -4.091511583328247, 'hyper_actor_loss': 0.1007075086236, 'behavior_loss': 0.5183221191167832, 'mean_batch': 3.722617268562317, 'min_batch': 3.215990424156189, 'max_batch': 4.1346040725708}
step: 2940 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 3.5601354, 'max_total_reward': 12.339999, 'min_total_reward': 5.7900004, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 96128} @ step loss: {'critic_loss': 1.8340712547302247, 'actor_loss': -4.080238223075867, 'hyper_actor_loss': 0.10055474787950516, 'behavior_loss': 0.4963123768568039, 'mean_batch': 3.6924665689468386, 'min_batch': 3.2086169958114623, 'max_batch': 4.1031496047973635}
step: 2950 @ episode report: {'average_total_reward': 9.332001, 'reward_variance': 5.2538757, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 96448} @ step loss: {'critic_loss': 1.6139949798583983, 'actor_loss': -4.220055866241455, 'hyper_actor_loss': 0.10037301778793335, 'behavior_loss': 0.5048564463853836, 'mean_batch': 3.9408071756362917, 'min_batch': 3.4542497634887694, 'max_batch': 4.372123098373413}
step: 2960 @ episode report: {'average_total_reward': 9.222, 'reward_variance': 1.7529361, 'max_total_reward': 11.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 96768} @ step loss: {'critic_loss': 1.6126630187034607, 'actor_loss': -4.125162506103516, 'hyper_actor_loss': 0.1003965675830841, 'behavior_loss': 0.5211789965629577, 'mean_batch': 3.7949601650238036, 'min_batch': 3.262440395355225, 'max_batch': 4.210435295104981}
step: 2970 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 4.4510965, 'max_total_reward': 12.2300005, 'min_total_reward': 5.6800003, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 97088} @ step loss: {'critic_loss': 1.7651267051696777, 'actor_loss': -4.127305126190185, 'hyper_actor_loss': 0.10047465190291405, 'behavior_loss': 0.5125806510448456, 'mean_batch': 3.7586929321289064, 'min_batch': 3.300294542312622, 'max_batch': 4.163705444335937}
step: 2980 @ episode report: {'average_total_reward': 8.233, 'reward_variance': 4.1306205, 'max_total_reward': 10.12, 'min_total_reward': 4.5699997, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 97408} @ step loss: {'critic_loss': 1.6756062626838684, 'actor_loss': -4.192310237884522, 'hyper_actor_loss': 0.10056787878274917, 'behavior_loss': 0.5176775485277176, 'mean_batch': 3.90379114151001, 'min_batch': 3.3943262815475466, 'max_batch': 4.326032972335815}
step: 2990 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.9423037, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 97728} @ step loss: {'critic_loss': 1.8209784507751465, 'actor_loss': -4.191875648498535, 'hyper_actor_loss': 0.10042869523167611, 'behavior_loss': 0.5078949570655823, 'mean_batch': 3.9020934104919434, 'min_batch': 3.3920876502990724, 'max_batch': 4.314831924438477}
step: 3000 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 3.429689, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 98048} @ step loss: {'critic_loss': 1.5487372636795045, 'actor_loss': -4.214226388931275, 'hyper_actor_loss': 0.10021703988313675, 'behavior_loss': 0.5012542486190796, 'mean_batch': 3.979313611984253, 'min_batch': 3.402085876464844, 'max_batch': 4.409568023681641}
step: 3010 @ episode report: {'average_total_reward': 8.755, 'reward_variance': 2.5051255, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 98368} @ step loss: {'critic_loss': 1.9964945912361145, 'actor_loss': -4.201925611495971, 'hyper_actor_loss': 0.10016499012708664, 'behavior_loss': 0.507175600528717, 'mean_batch': 3.9205383539199827, 'min_batch': 3.4164036989212034, 'max_batch': 4.357136201858521}
step: 3020 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 2.7351842, 'max_total_reward': 13.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 98688} @ step loss: {'critic_loss': 1.8855561137199401, 'actor_loss': -4.184125995635986, 'hyper_actor_loss': 0.10023942813277245, 'behavior_loss': 0.5030745804309845, 'mean_batch': 3.8802509784698485, 'min_batch': 3.3842230796813966, 'max_batch': 4.331180238723755}
step: 3030 @ episode report: {'average_total_reward': 8.933001, 'reward_variance': 1.7567409, 'max_total_reward': 11.2300005, 'min_total_reward': 6.68, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 99008} @ step loss: {'critic_loss': 1.9959255814552308, 'actor_loss': -4.218220567703247, 'hyper_actor_loss': 0.10037615820765496, 'behavior_loss': 0.4923405945301056, 'mean_batch': 3.9322105646133423, 'min_batch': 3.4555421829223634, 'max_batch': 4.323385524749756}
step: 3040 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 1.785764, 'max_total_reward': 11.12, 'min_total_reward': 5.7900004, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 99328} @ step loss: {'critic_loss': 1.7803476691246032, 'actor_loss': -4.149205589294434, 'hyper_actor_loss': 0.0998558096587658, 'behavior_loss': 0.49885722398757937, 'mean_batch': 3.8153576135635374, 'min_batch': 3.3244953870773317, 'max_batch': 4.233987045288086}
step: 3050 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 4.0969057, 'max_total_reward': 13.340001, 'min_total_reward': 5.68, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 99648} @ step loss: {'critic_loss': 1.7067464232444762, 'actor_loss': -4.2368556499481205, 'hyper_actor_loss': 0.09986574575304985, 'behavior_loss': 0.4795851081609726, 'mean_batch': 4.003690958023071, 'min_batch': 3.4576550006866453, 'max_batch': 4.474525260925293}
step: 3060 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 1.5137806, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 99968} @ step loss: {'critic_loss': 2.00795259475708, 'actor_loss': -4.180881786346435, 'hyper_actor_loss': 0.09972248449921609, 'behavior_loss': 0.5067936778068542, 'mean_batch': 3.911612558364868, 'min_batch': 3.3498724699020386, 'max_batch': 4.3550739765167235}
step: 3070 @ episode report: {'average_total_reward': 9.599, 'reward_variance': 3.674689, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9516831278800963, 'actor_loss': -4.244020223617554, 'hyper_actor_loss': 0.09999048113822936, 'behavior_loss': 0.49755534827709197, 'mean_batch': 4.0231029987335205, 'min_batch': 3.4658902883529663, 'max_batch': 4.502554607391358}
step: 3080 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 2.6085413, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9764614701271057, 'actor_loss': -4.225882053375244, 'hyper_actor_loss': 0.09973313212394715, 'behavior_loss': 0.5037081509828567, 'mean_batch': 3.9785265207290648, 'min_batch': 3.443184757232666, 'max_batch': 4.4285424709320065}
step: 3090 @ episode report: {'average_total_reward': 8.078001, 'reward_variance': 5.862817, 'max_total_reward': 11.2300005, 'min_total_reward': 2.35, 'average_n_step': 9.2, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9082125425338745, 'actor_loss': -4.251876544952393, 'hyper_actor_loss': 0.09965636283159256, 'behavior_loss': 0.4961770325899124, 'mean_batch': 4.013468384742737, 'min_batch': 3.501108455657959, 'max_batch': 4.481334018707275}
step: 3100 @ episode report: {'average_total_reward': 9.411, 'reward_variance': 2.904489, 'max_total_reward': 12.34, 'min_total_reward': 7.5699997, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7768383026123047, 'actor_loss': -4.265550518035889, 'hyper_actor_loss': 0.0998379684984684, 'behavior_loss': 0.502597838640213, 'mean_batch': 4.0731117725372314, 'min_batch': 3.4994218349456787, 'max_batch': 4.54273829460144}
step: 3110 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 7.93669, 'max_total_reward': 14.45, 'min_total_reward': 4.68, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.954236924648285, 'actor_loss': -4.240627574920654, 'hyper_actor_loss': 0.10004019513726234, 'behavior_loss': 0.5129619240760803, 'mean_batch': 3.9892850637435915, 'min_batch': 3.482993316650391, 'max_batch': 4.451386117935181}
step: 3120 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.7947242, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0365508913993837, 'actor_loss': -4.204529428482056, 'hyper_actor_loss': 0.09999484941363335, 'behavior_loss': 0.5020483136177063, 'mean_batch': 3.9442647457122804, 'min_batch': 3.4002476215362547, 'max_batch': 4.374377965927124}
step: 3130 @ episode report: {'average_total_reward': 9.133, 'reward_variance': 1.3642814, 'max_total_reward': 11.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8739232897758484, 'actor_loss': -4.234474754333496, 'hyper_actor_loss': 0.09987878054380417, 'behavior_loss': 0.5020210593938828, 'mean_batch': 4.023349142074585, 'min_batch': 3.4335748672485353, 'max_batch': 4.500914907455444}
step: 3140 @ episode report: {'average_total_reward': 10.164999, 'reward_variance': 2.1510653, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.739732563495636, 'actor_loss': -4.276723957061767, 'hyper_actor_loss': 0.09981806129217148, 'behavior_loss': 0.47789621651172637, 'mean_batch': 4.113798141479492, 'min_batch': 3.505277919769287, 'max_batch': 4.59619631767273}
step: 3150 @ episode report: {'average_total_reward': 9.91, 'reward_variance': 3.7691388, 'max_total_reward': 13.339999, 'min_total_reward': 5.57, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.727747118473053, 'actor_loss': -4.296825551986695, 'hyper_actor_loss': 0.09978295713663102, 'behavior_loss': 0.5059271961450577, 'mean_batch': 4.142195510864258, 'min_batch': 3.548987627029419, 'max_batch': 4.627232694625855}
step: 3160 @ episode report: {'average_total_reward': 9.098999, 'reward_variance': 1.552229, 'max_total_reward': 11.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8251366853713988, 'actor_loss': -4.296820640563965, 'hyper_actor_loss': 0.09967532157897949, 'behavior_loss': 0.49683550000190735, 'mean_batch': 4.104541206359864, 'min_batch': 3.58160138130188, 'max_batch': 4.577192878723144}
step: 3170 @ episode report: {'average_total_reward': 9.033, 'reward_variance': 2.2621405, 'max_total_reward': 11.12, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7902680039405823, 'actor_loss': -4.261850786209107, 'hyper_actor_loss': 0.0996023803949356, 'behavior_loss': 0.48263726830482484, 'mean_batch': 4.072795510292053, 'min_batch': 3.4871670246124267, 'max_batch': 4.539925861358642}
step: 3180 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 1.7249362, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0056697130203247, 'actor_loss': -4.3304825782775875, 'hyper_actor_loss': 0.09930630773305893, 'behavior_loss': 0.4974167585372925, 'mean_batch': 4.1524882316589355, 'min_batch': 3.661603808403015, 'max_batch': 4.620451545715332}
step: 3190 @ episode report: {'average_total_reward': 8.844, 'reward_variance': 8.647686, 'max_total_reward': 12.2300005, 'min_total_reward': 2.46, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7564786911010741, 'actor_loss': -4.332827949523926, 'hyper_actor_loss': 0.09920598715543746, 'behavior_loss': 0.48901793658733367, 'mean_batch': 4.186299133300781, 'min_batch': 3.6393850088119506, 'max_batch': 4.657788419723511}
step: 3200 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 2.0860996, 'max_total_reward': 11.12, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.091519033908844, 'actor_loss': -4.361424255371094, 'hyper_actor_loss': 0.09922652989625931, 'behavior_loss': 0.4962016254663467, 'mean_batch': 4.270540189743042, 'min_batch': 3.6714598417282103, 'max_batch': 4.80865159034729}
step: 3210 @ episode report: {'average_total_reward': 9.099001, 'reward_variance': 2.9306493, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8175019860267638, 'actor_loss': -4.346957111358643, 'hyper_actor_loss': 0.09930461794137954, 'behavior_loss': 0.47988603711128236, 'mean_batch': 4.260384225845337, 'min_batch': 3.6293015480041504, 'max_batch': 4.739003610610962}
step: 3220 @ episode report: {'average_total_reward': 10.642001, 'reward_variance': 4.0993967, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.079474425315857, 'actor_loss': -4.327710390090942, 'hyper_actor_loss': 0.09937945678830147, 'behavior_loss': 0.48953844606876373, 'mean_batch': 4.18378849029541, 'min_batch': 3.624154233932495, 'max_batch': 4.673353052139282}
step: 3230 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 8.383928, 'max_total_reward': 13.450001, 'min_total_reward': 2.24, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0255269765853883, 'actor_loss': -4.359687471389771, 'hyper_actor_loss': 0.09937874153256417, 'behavior_loss': 0.4847773164510727, 'mean_batch': 4.223550128936767, 'min_batch': 3.7059212923049927, 'max_batch': 4.686325263977051}
step: 3240 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.5588486, 'max_total_reward': 13.23, 'min_total_reward': 7.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9798101305961608, 'actor_loss': -4.340506601333618, 'hyper_actor_loss': 0.09917966946959496, 'behavior_loss': 0.49706498682498934, 'mean_batch': 4.172969675064087, 'min_batch': 3.678827691078186, 'max_batch': 4.686830043792725}
step: 3250 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 2.9177957, 'max_total_reward': 12.23, 'min_total_reward': 6.57, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.073272907733917, 'actor_loss': -4.344304418563842, 'hyper_actor_loss': 0.09900215044617652, 'behavior_loss': 0.4832052022218704, 'mean_batch': 4.17678747177124, 'min_batch': 3.6898680686950684, 'max_batch': 4.653570365905762}
step: 3260 @ episode report: {'average_total_reward': 9.455, 'reward_variance': 1.0129644, 'max_total_reward': 12.119999, 'min_total_reward': 8.68, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.031528663635254, 'actor_loss': -4.341201972961426, 'hyper_actor_loss': 0.09879781678318977, 'behavior_loss': 0.4893853098154068, 'mean_batch': 4.1799530506134035, 'min_batch': 3.675524616241455, 'max_batch': 4.6575674533844}
step: 3270 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 0.991125, 'max_total_reward': 10.12, 'min_total_reward': 6.79, 'average_n_step': 10.0, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9179362893104552, 'actor_loss': -4.415547227859497, 'hyper_actor_loss': 0.09871826320886612, 'behavior_loss': 0.48405699133872987, 'mean_batch': 4.360541582107544, 'min_batch': 3.7968260288238525, 'max_batch': 4.844660806655884}
step: 3280 @ episode report: {'average_total_reward': 8.2, 'reward_variance': 3.1718795, 'max_total_reward': 12.339999, 'min_total_reward': 5.6800003, 'average_n_step': 9.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9534650802612306, 'actor_loss': -4.4222142696380615, 'hyper_actor_loss': 0.09845535084605217, 'behavior_loss': 0.4784581422805786, 'mean_batch': 4.388708782196045, 'min_batch': 3.7975480794906615, 'max_batch': 4.8571204662323}
step: 3290 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 3.073305, 'max_total_reward': 13.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.053717815876007, 'actor_loss': -4.401305532455444, 'hyper_actor_loss': 0.09867697581648827, 'behavior_loss': 0.4968288689851761, 'mean_batch': 4.316257905960083, 'min_batch': 3.780494236946106, 'max_batch': 4.752334690093994}
step: 3300 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 1.1686046, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8479444980621338, 'actor_loss': -4.442302274703979, 'hyper_actor_loss': 0.09889672845602035, 'behavior_loss': 0.46990989744663236, 'mean_batch': 4.418591833114624, 'min_batch': 3.8493239879608154, 'max_batch': 4.878573036193847}
step: 3310 @ episode report: {'average_total_reward': 10.099001, 'reward_variance': 1.8791687, 'max_total_reward': 12.23, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.635334861278534, 'actor_loss': -4.475771379470825, 'hyper_actor_loss': 0.09882740080356597, 'behavior_loss': 0.4761894911527634, 'mean_batch': 4.486288452148438, 'min_batch': 3.919992184638977, 'max_batch': 5.030706787109375}
step: 3320 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 2.1027892, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0860363006591798, 'actor_loss': -4.4097075939178465, 'hyper_actor_loss': 0.09872687458992005, 'behavior_loss': 0.4797653377056122, 'mean_batch': 4.35981125831604, 'min_batch': 3.7750035524368286, 'max_batch': 4.795399713516235}
step: 3330 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 2.1500049, 'max_total_reward': 13.45, 'min_total_reward': 8.570001, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9684038043022156, 'actor_loss': -4.452663898468018, 'hyper_actor_loss': 0.09839965701103211, 'behavior_loss': 0.47581154108047485, 'mean_batch': 4.384183931350708, 'min_batch': 3.9169371366500854, 'max_batch': 4.86036229133606}
step: 3340 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 2.8771613, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0986037850379944, 'actor_loss': -4.455565595626831, 'hyper_actor_loss': 0.09831321761012077, 'behavior_loss': 0.47113862037658694, 'mean_batch': 4.4552477359771725, 'min_batch': 3.86766037940979, 'max_batch': 4.929106426239014}
step: 3350 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 1.7601964, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.115551006793976, 'actor_loss': -4.453785181045532, 'hyper_actor_loss': 0.0984156847000122, 'behavior_loss': 0.4897242605686188, 'mean_batch': 4.462529611587525, 'min_batch': 3.853550386428833, 'max_batch': 4.917558193206787}
step: 3360 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 2.4090292, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9536121606826782, 'actor_loss': -4.4739158153533936, 'hyper_actor_loss': 0.0984136663377285, 'behavior_loss': 0.47205028831958773, 'mean_batch': 4.447659969329834, 'min_batch': 3.945466494560242, 'max_batch': 4.9103649139404295}
step: 3370 @ episode report: {'average_total_reward': 8.522, 'reward_variance': 4.8212166, 'max_total_reward': 13.010001, 'min_total_reward': 5.79, 'average_n_step': 9.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1998207807540893, 'actor_loss': -4.4357274055480955, 'hyper_actor_loss': 0.09831888154149056, 'behavior_loss': 0.47868883013725283, 'mean_batch': 4.407302522659302, 'min_batch': 3.8333736181259157, 'max_batch': 4.838491630554199}
step: 3380 @ episode report: {'average_total_reward': 8.811, 'reward_variance': 1.6349691, 'max_total_reward': 10.12, 'min_total_reward': 5.79, 'average_n_step': 9.9, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2235265970230103, 'actor_loss': -4.4603941440582275, 'hyper_actor_loss': 0.09819134697318077, 'behavior_loss': 0.47081215381622316, 'mean_batch': 4.432228088378906, 'min_batch': 3.906367635726929, 'max_batch': 4.933016681671143}
step: 3390 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.2494643, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0137709856033323, 'actor_loss': -4.510471248626709, 'hyper_actor_loss': 0.09810145646333694, 'behavior_loss': 0.4658845871686935, 'mean_batch': 4.5602028369903564, 'min_batch': 3.9914724349975588, 'max_batch': 5.018578672409058}
step: 3400 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 1.2390096, 'max_total_reward': 12.230001, 'min_total_reward': 7.9000006, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.171177351474762, 'actor_loss': -4.527100133895874, 'hyper_actor_loss': 0.09800053983926774, 'behavior_loss': 0.4764876484870911, 'mean_batch': 4.588204574584961, 'min_batch': 4.032729387283325, 'max_batch': 5.132346773147583}
step: 3410 @ episode report: {'average_total_reward': 8.467, 'reward_variance': 2.3166611, 'max_total_reward': 10.010001, 'min_total_reward': 5.57, 'average_n_step': 9.6, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9971741557121276, 'actor_loss': -4.523209190368652, 'hyper_actor_loss': 0.09806182608008385, 'behavior_loss': 0.4751063287258148, 'mean_batch': 4.598801851272583, 'min_batch': 4.0079961061477665, 'max_batch': 5.121964597702027}
step: 3420 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 1.5547206, 'max_total_reward': 12.23, 'min_total_reward': 7.680001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.242773377895355, 'actor_loss': -4.522605085372925, 'hyper_actor_loss': 0.09806831553578377, 'behavior_loss': 0.4854952931404114, 'mean_batch': 4.606574249267578, 'min_batch': 4.000351786613464, 'max_batch': 5.118606901168823}
step: 3430 @ episode report: {'average_total_reward': 9.244, 'reward_variance': 2.8920636, 'max_total_reward': 12.23, 'min_total_reward': 5.7900004, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3208049297332765, 'actor_loss': -4.53446478843689, 'hyper_actor_loss': 0.0979081854224205, 'behavior_loss': 0.47664855420589447, 'mean_batch': 4.598508644104004, 'min_batch': 4.054927110671997, 'max_batch': 5.082306528091431}
step: 3440 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 0.67786485, 'max_total_reward': 11.2300005, 'min_total_reward': 8.900001, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.105857241153717, 'actor_loss': -4.55753903388977, 'hyper_actor_loss': 0.09806012362241745, 'behavior_loss': 0.47031676173210146, 'mean_batch': 4.661103010177612, 'min_batch': 4.092918848991394, 'max_batch': 5.15124101638794}
step: 3450 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 3.2207649, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9633845508098602, 'actor_loss': -4.565629291534424, 'hyper_actor_loss': 0.09799301102757454, 'behavior_loss': 0.4599844217300415, 'mean_batch': 4.689664459228515, 'min_batch': 4.10106098651886, 'max_batch': 5.201336288452149}
step: 3460 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 2.7274446, 'max_total_reward': 13.120001, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.019326937198639, 'actor_loss': -4.586324548721313, 'hyper_actor_loss': 0.09780088290572167, 'behavior_loss': 0.466645160317421, 'mean_batch': 4.775958919525147, 'min_batch': 4.11317663192749, 'max_batch': 5.270682716369629}
step: 3470 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 5.898856, 'max_total_reward': 12.34, 'min_total_reward': 4.46, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.477668857574463, 'actor_loss': -4.526698017120362, 'hyper_actor_loss': 0.09761258587241173, 'behavior_loss': 0.46810880303382874, 'mean_batch': 4.638400650024414, 'min_batch': 3.990821957588196, 'max_batch': 5.129516983032227}
step: 3480 @ episode report: {'average_total_reward': 8.933001, 'reward_variance': 3.6816802, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2738608360290526, 'actor_loss': -4.544572353363037, 'hyper_actor_loss': 0.09770230278372764, 'behavior_loss': 0.47378671169281006, 'mean_batch': 4.654496097564698, 'min_batch': 4.046909666061401, 'max_batch': 5.119498300552368}
step: 3490 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 3.561842, 'max_total_reward': 13.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.186234641075134, 'actor_loss': -4.575535631179809, 'hyper_actor_loss': 0.09794349372386932, 'behavior_loss': 0.4736603647470474, 'mean_batch': 4.715408229827881, 'min_batch': 4.12016544342041, 'max_batch': 5.2027098655700685}
step: 3500 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 1.9064087, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1817518353462217, 'actor_loss': -4.563486814498901, 'hyper_actor_loss': 0.09765497222542763, 'behavior_loss': 0.4540013521909714, 'mean_batch': 4.676999902725219, 'min_batch': 4.1034475564956665, 'max_batch': 5.163969278335571}
step: 3510 @ episode report: {'average_total_reward': 10.798001, 'reward_variance': 2.2506173, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2667515754699705, 'actor_loss': -4.561449003219605, 'hyper_actor_loss': 0.09759285673499107, 'behavior_loss': 0.4796581596136093, 'mean_batch': 4.700241184234619, 'min_batch': 4.0752222537994385, 'max_batch': 5.223849058151245}
step: 3520 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 4.8218365, 'max_total_reward': 12.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.236796474456787, 'actor_loss': -4.605502414703369, 'hyper_actor_loss': 0.09768420681357384, 'behavior_loss': 0.46632138192653655, 'mean_batch': 4.749937677383423, 'min_batch': 4.214501261711121, 'max_batch': 5.217642402648925}
step: 3530 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 1.5470836, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.301407504081726, 'actor_loss': -4.592910671234131, 'hyper_actor_loss': 0.09766944497823715, 'behavior_loss': 0.45935171842575073, 'mean_batch': 4.7654541492462155, 'min_batch': 4.1481647968292235, 'max_batch': 5.277502012252808}
step: 3540 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 2.8326638, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3696640133857727, 'actor_loss': -4.633914375305176, 'hyper_actor_loss': 0.09749330803751946, 'behavior_loss': 0.4613502353429794, 'mean_batch': 4.825879859924316, 'min_batch': 4.2665245056152346, 'max_batch': 5.333385181427002}
step: 3550 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 4.346345, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.515158224105835, 'actor_loss': -4.5687903881073, 'hyper_actor_loss': 0.09747122600674629, 'behavior_loss': 0.47508834302425385, 'mean_batch': 4.699872827529907, 'min_batch': 4.104764127731324, 'max_batch': 5.193396520614624}
step: 3560 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 1.8909401, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.12593936920166, 'actor_loss': -4.661403465270996, 'hyper_actor_loss': 0.0973277971148491, 'behavior_loss': 0.45591818988323213, 'mean_batch': 4.912473869323731, 'min_batch': 4.30973494052887, 'max_batch': 5.385776662826538}
step: 3570 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 5.1557236, 'max_total_reward': 15.67, 'min_total_reward': 7.7900004, 'average_n_step': 11.0, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6578577160835266, 'actor_loss': -4.5685618877410885, 'hyper_actor_loss': 0.09727315530180931, 'behavior_loss': 0.48826696276664733, 'mean_batch': 4.669481515884399, 'min_batch': 4.132553601264954, 'max_batch': 5.1647546768188475}
step: 3580 @ episode report: {'average_total_reward': 9.666, 'reward_variance': 0.55502385, 'max_total_reward': 11.12, 'min_total_reward': 8.68, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1912507891654966, 'actor_loss': -4.628316164016724, 'hyper_actor_loss': 0.09756571650505066, 'behavior_loss': 0.4563485771417618, 'mean_batch': 4.810611295700073, 'min_batch': 4.2616605997085575, 'max_batch': 5.284776210784912}
step: 3590 @ episode report: {'average_total_reward': 9.021001, 'reward_variance': 1.6307694, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.202324163913727, 'actor_loss': -4.643793249130249, 'hyper_actor_loss': 0.09722086861729622, 'behavior_loss': 0.44731121957302095, 'mean_batch': 4.881223917007446, 'min_batch': 4.262145972251892, 'max_batch': 5.398754453659057}
step: 3600 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 3.6036212, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3645341277122496, 'actor_loss': -4.588811779022217, 'hyper_actor_loss': 0.09685190692543984, 'behavior_loss': 0.45901860296726227, 'mean_batch': 4.754824256896972, 'min_batch': 4.14106137752533, 'max_batch': 5.249447870254516}
step: 3610 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 1.6494051, 'max_total_reward': 12.230001, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.304144024848938, 'actor_loss': -4.618539905548095, 'hyper_actor_loss': 0.0970305934548378, 'behavior_loss': 0.44781449139118196, 'mean_batch': 4.842960500717163, 'min_batch': 4.187364912033081, 'max_batch': 5.306792688369751}
step: 3620 @ episode report: {'average_total_reward': 9.876, 'reward_variance': 1.1774037, 'max_total_reward': 11.23, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.445912706851959, 'actor_loss': -4.605473804473877, 'hyper_actor_loss': 0.09692435562610627, 'behavior_loss': 0.450537782907486, 'mean_batch': 4.790203332901001, 'min_batch': 4.1785176515579225, 'max_batch': 5.290435361862182}
step: 3630 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 0.6085697, 'max_total_reward': 11.120001, 'min_total_reward': 8.789999, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4771158933639525, 'actor_loss': -4.575466918945312, 'hyper_actor_loss': 0.09702048748731613, 'behavior_loss': 0.4589915663003922, 'mean_batch': 4.7116029262542725, 'min_batch': 4.122594666481018, 'max_batch': 5.210735654830932}
step: 3640 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 4.8559694, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6067753791809083, 'actor_loss': -4.661871767044067, 'hyper_actor_loss': 0.09711986631155015, 'behavior_loss': 0.44410336315631865, 'mean_batch': 4.8757692813873295, 'min_batch': 4.342358779907227, 'max_batch': 5.329420900344848}
step: 3650 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 3.1352015, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3266874313354493, 'actor_loss': -4.624926424026489, 'hyper_actor_loss': 0.0970255509018898, 'behavior_loss': 0.4517690598964691, 'mean_batch': 4.817670249938965, 'min_batch': 4.236443996429443, 'max_batch': 5.323039531707764}
step: 3660 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 3.3327408, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1827045917510985, 'actor_loss': -4.654564476013183, 'hyper_actor_loss': 0.09692274704575539, 'behavior_loss': 0.4604430735111237, 'mean_batch': 4.881343984603882, 'min_batch': 4.3068585872650145, 'max_batch': 5.363133716583252}
step: 3670 @ episode report: {'average_total_reward': 8.554999, 'reward_variance': 6.0374255, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 9.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0427401065826416, 'actor_loss': -4.610716676712036, 'hyper_actor_loss': 0.09702822118997574, 'behavior_loss': 0.45654820203781127, 'mean_batch': 4.780250167846679, 'min_batch': 4.2090383768081665, 'max_batch': 5.253720712661743}
step: 3680 @ episode report: {'average_total_reward': 10.564001, 'reward_variance': 4.809165, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4361414432525637, 'actor_loss': -4.564715242385864, 'hyper_actor_loss': 0.09720297306776046, 'behavior_loss': 0.45569256246089934, 'mean_batch': 4.681872987747193, 'min_batch': 4.104907703399658, 'max_batch': 5.132669496536255}
step: 3690 @ episode report: {'average_total_reward': 10.654001, 'reward_variance': 1.8884041, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.351688301563263, 'actor_loss': -4.566697835922241, 'hyper_actor_loss': 0.09723134562373162, 'behavior_loss': 0.4390278935432434, 'mean_batch': 4.686521434783936, 'min_batch': 4.1079092741012575, 'max_batch': 5.155325126647949}
step: 3700 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 2.0798852, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1189841747283937, 'actor_loss': -4.614831972122192, 'hyper_actor_loss': 0.09700992777943611, 'behavior_loss': 0.4435220628976822, 'mean_batch': 4.772307968139648, 'min_batch': 4.2331305027008055, 'max_batch': 5.249496650695801}
step: 3710 @ episode report: {'average_total_reward': 8.8550005, 'reward_variance': 0.7944453, 'max_total_reward': 10.010001, 'min_total_reward': 6.79, 'average_n_step': 9.9, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1095284938812258, 'actor_loss': -4.6669830799102785, 'hyper_actor_loss': 0.09677910953760147, 'behavior_loss': 0.45504869520664215, 'mean_batch': 4.854463529586792, 'min_batch': 4.383998394012451, 'max_batch': 5.294435214996338}
step: 3720 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 2.9626088, 'max_total_reward': 12.12, 'min_total_reward': 6.9000006, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5479259967803953, 'actor_loss': -4.629478979110718, 'hyper_actor_loss': 0.09681562408804893, 'behavior_loss': 0.4436129152774811, 'mean_batch': 4.769305753707886, 'min_batch': 4.30000102519989, 'max_batch': 5.268988847732544}
step: 3730 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 3.2452812, 'max_total_reward': 12.34, 'min_total_reward': 5.7899995, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3617624163627626, 'actor_loss': -4.579702949523925, 'hyper_actor_loss': 0.09682978317141533, 'behavior_loss': 0.4557911157608032, 'mean_batch': 4.691088724136352, 'min_batch': 4.159362173080444, 'max_batch': 5.175331974029541}
step: 3740 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 0.96384096, 'max_total_reward': 10.12, 'min_total_reward': 7.79, 'average_n_step': 10.2, 'max_n_step': 11.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4427521944046022, 'actor_loss': -4.6598528861999515, 'hyper_actor_loss': 0.09686754047870635, 'behavior_loss': 0.4425980091094971, 'mean_batch': 4.943867349624634, 'min_batch': 4.2789939641952515, 'max_batch': 5.435765409469605}
step: 3750 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 4.097665, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4162646293640138, 'actor_loss': -4.592807817459106, 'hyper_actor_loss': 0.0968727171421051, 'behavior_loss': 0.4538458436727524, 'mean_batch': 4.689799833297729, 'min_batch': 4.212603521347046, 'max_batch': 5.145527601242065}
step: 3760 @ episode report: {'average_total_reward': 9.466001, 'reward_variance': 2.6291041, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.214193332195282, 'actor_loss': -4.638625001907348, 'hyper_actor_loss': 0.09659828245639801, 'behavior_loss': 0.4296847105026245, 'mean_batch': 4.871832418441772, 'min_batch': 4.246349716186524, 'max_batch': 5.375287199020386}
step: 3770 @ episode report: {'average_total_reward': 8.655001, 'reward_variance': 5.0666447, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 9.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.100561809539795, 'actor_loss': -4.645815420150757, 'hyper_actor_loss': 0.09640366584062576, 'behavior_loss': 0.44290090203285215, 'mean_batch': 4.868739128112793, 'min_batch': 4.280362939834594, 'max_batch': 5.358205699920655}
step: 3780 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 2.2010636, 'max_total_reward': 13.339999, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4217382073402405, 'actor_loss': -4.646597576141358, 'hyper_actor_loss': 0.09662110581994057, 'behavior_loss': 0.448543456196785, 'mean_batch': 4.8667223930358885, 'min_batch': 4.284568834304809, 'max_batch': 5.34987244606018}
step: 3790 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 5.451655, 'max_total_reward': 13.45, 'min_total_reward': 5.5700006, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4174013257026674, 'actor_loss': -4.627695322036743, 'hyper_actor_loss': 0.09673307836055756, 'behavior_loss': 0.4318964868783951, 'mean_batch': 4.792516851425171, 'min_batch': 4.26905369758606, 'max_batch': 5.282957267761231}
step: 3800 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 2.53549, 'max_total_reward': 13.340001, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.130009377002716, 'actor_loss': -4.656277751922607, 'hyper_actor_loss': 0.09662285596132278, 'behavior_loss': 0.41901772618293764, 'mean_batch': 4.888967132568359, 'min_batch': 4.308225870132446, 'max_batch': 5.366337299346924}
step: 3810 @ episode report: {'average_total_reward': 10.82, 'reward_variance': 6.875641, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.332608187198639, 'actor_loss': -4.67207088470459, 'hyper_actor_loss': 0.09638221338391303, 'behavior_loss': 0.42125944793224335, 'mean_batch': 4.939557313919067, 'min_batch': 4.330861043930054, 'max_batch': 5.438718986511231}
step: 3820 @ episode report: {'average_total_reward': 10.410001, 'reward_variance': 3.3776603, 'max_total_reward': 14.45, 'min_total_reward': 7.46, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5702367782592774, 'actor_loss': -4.643963766098023, 'hyper_actor_loss': 0.09636354148387909, 'behavior_loss': 0.4333977073431015, 'mean_batch': 4.8619170665740965, 'min_batch': 4.278546476364136, 'max_batch': 5.352203750610352}
step: 3830 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 1.5767206, 'max_total_reward': 11.23, 'min_total_reward': 7.68, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5588058471679687, 'actor_loss': -4.621627569198608, 'hyper_actor_loss': 0.09654368460178375, 'behavior_loss': 0.43042814135551455, 'mean_batch': 4.8041401386260985, 'min_batch': 4.233548402786255, 'max_batch': 5.296784830093384}
step: 3840 @ episode report: {'average_total_reward': 9.133, 'reward_variance': 2.3671212, 'max_total_reward': 12.120001, 'min_total_reward': 6.68, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.367140829563141, 'actor_loss': -4.670148181915283, 'hyper_actor_loss': 0.09648897647857665, 'behavior_loss': 0.4301314055919647, 'mean_batch': 4.9090722560882565, 'min_batch': 4.349559545516968, 'max_batch': 5.424351358413697}
step: 3850 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 1.5260159, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.443057131767273, 'actor_loss': -4.673454284667969, 'hyper_actor_loss': 0.09655122235417365, 'behavior_loss': 0.4472899556159973, 'mean_batch': 4.925963449478149, 'min_batch': 4.349673271179199, 'max_batch': 5.3801148414611815}
step: 3860 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 5.946764, 'max_total_reward': 13.12, 'min_total_reward': 5.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4755675196647644, 'actor_loss': -4.619793510437011, 'hyper_actor_loss': 0.09668752327561378, 'behavior_loss': 0.44709632396697996, 'mean_batch': 4.790379571914673, 'min_batch': 4.2396282196044925, 'max_batch': 5.2686841011047365}
step: 3870 @ episode report: {'average_total_reward': 10.442, 'reward_variance': 3.846196, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5224019169807432, 'actor_loss': -4.640170669555664, 'hyper_actor_loss': 0.09669651836156845, 'behavior_loss': 0.4497110188007355, 'mean_batch': 4.8362642288208, 'min_batch': 4.28327317237854, 'max_batch': 5.287703657150269}
step: 3880 @ episode report: {'average_total_reward': 10.265, 'reward_variance': 2.232065, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.136946666240692, 'actor_loss': -4.675809288024903, 'hyper_actor_loss': 0.09647078961133956, 'behavior_loss': 0.4200304687023163, 'mean_batch': 4.934256172180175, 'min_batch': 4.351591300964356, 'max_batch': 5.385166454315185}
step: 3890 @ episode report: {'average_total_reward': 9.343, 'reward_variance': 6.82388, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3685074925422667, 'actor_loss': -4.707381868362427, 'hyper_actor_loss': 0.09615790247917175, 'behavior_loss': 0.42122915387153625, 'mean_batch': 5.02736759185791, 'min_batch': 4.408233547210694, 'max_batch': 5.541718292236328}
step: 3900 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 2.4092288, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4946773409843446, 'actor_loss': -4.701691579818726, 'hyper_actor_loss': 0.09613522663712501, 'behavior_loss': 0.43204901218414304, 'mean_batch': 4.974259233474731, 'min_batch': 4.428979206085205, 'max_batch': 5.509003019332885}
step: 3910 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 3.5253556, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.291492688655853, 'actor_loss': -4.729969215393067, 'hyper_actor_loss': 0.09628125056624412, 'behavior_loss': 0.43554810881614686, 'mean_batch': 5.06591682434082, 'min_batch': 4.474723768234253, 'max_batch': 5.577595567703247}
step: 3920 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 1.420441, 'max_total_reward': 11.120001, 'min_total_reward': 6.79, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4679718255996703, 'actor_loss': -4.738397312164307, 'hyper_actor_loss': 0.09644643887877465, 'behavior_loss': 0.42735232710838317, 'mean_batch': 5.08187575340271, 'min_batch': 4.497574806213379, 'max_batch': 5.573814487457275}
step: 3930 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 1.4281003, 'max_total_reward': 11.120001, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2570986986160277, 'actor_loss': -4.711627531051636, 'hyper_actor_loss': 0.0963261105120182, 'behavior_loss': 0.42189896702766416, 'mean_batch': 4.984760332107544, 'min_batch': 4.4637613773345945, 'max_batch': 5.448102855682373}
step: 3940 @ episode report: {'average_total_reward': 10.853, 'reward_variance': 2.0061216, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.321460509300232, 'actor_loss': -4.737239265441895, 'hyper_actor_loss': 0.09607623815536499, 'behavior_loss': 0.41603161096572877, 'mean_batch': 5.084840202331543, 'min_batch': 4.490789365768433, 'max_batch': 5.53929648399353}
step: 3950 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.959621, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4053542375564576, 'actor_loss': -4.714804410934448, 'hyper_actor_loss': 0.09583482071757317, 'behavior_loss': 0.4123081684112549, 'mean_batch': 5.015981674194336, 'min_batch': 4.450577592849731, 'max_batch': 5.49582462310791}
step: 3960 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 3.900182, 'max_total_reward': 13.340001, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2579339146614075, 'actor_loss': -4.7296836376190186, 'hyper_actor_loss': 0.09578296616673469, 'behavior_loss': 0.40788443982601164, 'mean_batch': 5.020245695114136, 'min_batch': 4.513438272476196, 'max_batch': 5.500703620910644}
step: 3970 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 2.1746204, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5894176602363586, 'actor_loss': -4.71867003440857, 'hyper_actor_loss': 0.09568103253841401, 'behavior_loss': 0.417485648393631, 'mean_batch': 4.987989616394043, 'min_batch': 4.493197631835938, 'max_batch': 5.474474000930786}
step: 3980 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.026644, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.610814118385315, 'actor_loss': -4.702153825759888, 'hyper_actor_loss': 0.09579820707440376, 'behavior_loss': 0.4267799943685532, 'mean_batch': 4.979310607910156, 'min_batch': 4.429974603652954, 'max_batch': 5.408010482788086}
step: 3990 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 7.0109444, 'max_total_reward': 14.56, 'min_total_reward': 6.7900004, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.435764181613922, 'actor_loss': -4.757151460647583, 'hyper_actor_loss': 0.09575041681528092, 'behavior_loss': 0.4119649738073349, 'mean_batch': 5.098019790649414, 'min_batch': 4.567622089385987, 'max_batch': 5.529969692230225}
step: 4000 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 2.9143167, 'max_total_reward': 14.450001, 'min_total_reward': 8.68, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4093424797058107, 'actor_loss': -4.708468580245972, 'hyper_actor_loss': 0.09574103876948356, 'behavior_loss': 0.41271707117557527, 'mean_batch': 5.041731834411621, 'min_batch': 4.40109076499939, 'max_batch': 5.55713300704956}
step: 4010 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 4.3577237, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.554908609390259, 'actor_loss': -4.724058532714844, 'hyper_actor_loss': 0.09563289731740951, 'behavior_loss': 0.40408808887004855, 'mean_batch': 5.038186931610108, 'min_batch': 4.472057962417603, 'max_batch': 5.5210693359375}
step: 4020 @ episode report: {'average_total_reward': 9.1, 'reward_variance': 2.4677799, 'max_total_reward': 12.12, 'min_total_reward': 6.7900004, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.379477834701538, 'actor_loss': -4.736816644668579, 'hyper_actor_loss': 0.09553510546684266, 'behavior_loss': 0.41933269798755646, 'mean_batch': 5.075487565994263, 'min_batch': 4.497231769561767, 'max_batch': 5.565829420089722}
step: 4030 @ episode report: {'average_total_reward': 9.144, 'reward_variance': 2.916863, 'max_total_reward': 12.34, 'min_total_reward': 6.680001, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.894999384880066, 'actor_loss': -4.700692224502563, 'hyper_actor_loss': 0.09585967361927032, 'behavior_loss': 0.4264229714870453, 'mean_batch': 4.97283706665039, 'min_batch': 4.42682113647461, 'max_batch': 5.40561056137085}
step: 4040 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 1.8364557, 'max_total_reward': 12.119999, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.557115340232849, 'actor_loss': -4.736667919158935, 'hyper_actor_loss': 0.09603728428483009, 'behavior_loss': 0.39927410185337064, 'mean_batch': 5.050359630584717, 'min_batch': 4.52027997970581, 'max_batch': 5.498570585250855}
step: 4050 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 4.9285, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.367231810092926, 'actor_loss': -4.7776960849761965, 'hyper_actor_loss': 0.09583610966801644, 'behavior_loss': 0.4034212350845337, 'mean_batch': 5.14289231300354, 'min_batch': 4.622021007537842, 'max_batch': 5.606797885894776}
step: 4060 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.6408572, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.470025897026062, 'actor_loss': -4.744610548019409, 'hyper_actor_loss': 0.09540090337395668, 'behavior_loss': 0.4143277436494827, 'mean_batch': 5.079544019699097, 'min_batch': 4.527460765838623, 'max_batch': 5.561900186538696}
step: 4070 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 2.4358687, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.370977532863617, 'actor_loss': -4.749815511703491, 'hyper_actor_loss': 0.09561367407441139, 'behavior_loss': 0.4083911031484604, 'mean_batch': 5.066376256942749, 'min_batch': 4.563076162338257, 'max_batch': 5.5212750911712645}
step: 4080 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 5.797261, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.629371166229248, 'actor_loss': -4.715307998657226, 'hyper_actor_loss': 0.09554693177342415, 'behavior_loss': 0.39108075201511383, 'mean_batch': 5.022046184539795, 'min_batch': 4.4491406917572025, 'max_batch': 5.48966612815857}
step: 4090 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.3762043, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5973864078521727, 'actor_loss': -4.7208327293396, 'hyper_actor_loss': 0.09540218487381935, 'behavior_loss': 0.41218550205230714, 'mean_batch': 5.006451988220215, 'min_batch': 4.485167455673218, 'max_batch': 5.455491161346435}
step: 4100 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 2.3060765, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3612220168113707, 'actor_loss': -4.71527099609375, 'hyper_actor_loss': 0.09569060802459717, 'behavior_loss': 0.4107867181301117, 'mean_batch': 5.001671504974365, 'min_batch': 4.465536260604859, 'max_batch': 5.461600255966187}
step: 4110 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 1.8790042, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1140554428100584, 'actor_loss': -4.760929155349731, 'hyper_actor_loss': 0.0956218920648098, 'behavior_loss': 0.3868861734867096, 'mean_batch': 5.134322881698608, 'min_batch': 4.553103256225586, 'max_batch': 5.578816032409668}
step: 4120 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 2.4638054, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.47927782535553, 'actor_loss': -4.756645345687867, 'hyper_actor_loss': 0.09555062130093575, 'behavior_loss': 0.39853808283805847, 'mean_batch': 5.115852403640747, 'min_batch': 4.55195460319519, 'max_batch': 5.581882476806641}
step: 4130 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 5.1439357, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1747557163238525, 'actor_loss': -4.740392398834229, 'hyper_actor_loss': 0.0955305427312851, 'behavior_loss': 0.4183679521083832, 'mean_batch': 5.054431390762329, 'min_batch': 4.5319023609161375, 'max_batch': 5.516070365905762}
step: 4140 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 2.425244, 'max_total_reward': 13.45, 'min_total_reward': 7.68, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.340608870983124, 'actor_loss': -4.753759098052979, 'hyper_actor_loss': 0.09539154917001724, 'behavior_loss': 0.39626079201698305, 'mean_batch': 5.109598445892334, 'min_batch': 4.542081117630005, 'max_batch': 5.567039060592651}
step: 4150 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 1.807676, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9000006, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.620189332962036, 'actor_loss': -4.723641395568848, 'hyper_actor_loss': 0.09546174556016922, 'behavior_loss': 0.39677360355854036, 'mean_batch': 5.034635162353515, 'min_batch': 4.475012302398682, 'max_batch': 5.488059711456299}
step: 4160 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 1.7624756, 'max_total_reward': 12.23, 'min_total_reward': 7.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.329790413379669, 'actor_loss': -4.715070724487305, 'hyper_actor_loss': 0.09542132019996644, 'behavior_loss': 0.4064061939716339, 'mean_batch': 5.011989450454712, 'min_batch': 4.4565918922424315, 'max_batch': 5.4704670906066895}
step: 4170 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 3.8015697, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7087392926216127, 'actor_loss': -4.772451734542846, 'hyper_actor_loss': 0.09552736803889275, 'behavior_loss': 0.382034620642662, 'mean_batch': 5.152464294433594, 'min_batch': 4.59083194732666, 'max_batch': 5.6318645000457765}
step: 4180 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.4595445, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.172243130207062, 'actor_loss': -4.728058767318726, 'hyper_actor_loss': 0.09516556039452553, 'behavior_loss': 0.39507206380367277, 'mean_batch': 5.04167218208313, 'min_batch': 4.486659097671509, 'max_batch': 5.445228528976441}
step: 4190 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 4.5700436, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.466922926902771, 'actor_loss': -4.733705806732178, 'hyper_actor_loss': 0.09498673677444458, 'behavior_loss': 0.39862667620182035, 'mean_batch': 5.04508786201477, 'min_batch': 4.508289575576782, 'max_batch': 5.498825407028198}
step: 4200 @ episode report: {'average_total_reward': 10.554001, 'reward_variance': 2.9124649, 'max_total_reward': 12.340001, 'min_total_reward': 7.68, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2897398233413697, 'actor_loss': -4.694937801361084, 'hyper_actor_loss': 0.09509219229221344, 'behavior_loss': 0.39251738488674165, 'mean_batch': 4.937970113754273, 'min_batch': 4.430983400344848, 'max_batch': 5.317015743255615}
step: 4210 @ episode report: {'average_total_reward': 9.577001, 'reward_variance': 5.1762223, 'max_total_reward': 14.34, 'min_total_reward': 6.46, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.055914801359177, 'actor_loss': -4.7327240943908695, 'hyper_actor_loss': 0.09535248279571533, 'behavior_loss': 0.4036853611469269, 'mean_batch': 5.065377998352051, 'min_batch': 4.488325357437134, 'max_batch': 5.538978147506714}
step: 4220 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 2.4570842, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.519420313835144, 'actor_loss': -4.75495753288269, 'hyper_actor_loss': 0.09543470814824104, 'behavior_loss': 0.4036384552717209, 'mean_batch': 5.126492357254028, 'min_batch': 4.533724355697632, 'max_batch': 5.554499626159668}
step: 4230 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.2016692, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.225679612159729, 'actor_loss': -4.703196287155151, 'hyper_actor_loss': 0.09527856931090355, 'behavior_loss': 0.39033201336860657, 'mean_batch': 5.003796625137329, 'min_batch': 4.410296678543091, 'max_batch': 5.4535914897918705}
step: 4240 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 1.6349688, 'max_total_reward': 12.01, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7276291251182556, 'actor_loss': -4.724753189086914, 'hyper_actor_loss': 0.09512264952063561, 'behavior_loss': 0.398841518163681, 'mean_batch': 5.0217804431915285, 'min_batch': 4.491381597518921, 'max_batch': 5.466752195358277}
step: 4250 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 4.1218796, 'max_total_reward': 13.01, 'min_total_reward': 5.57, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.067911374568939, 'actor_loss': -4.731008100509643, 'hyper_actor_loss': 0.09525018259882927, 'behavior_loss': 0.38457111418247225, 'mean_batch': 5.009961175918579, 'min_batch': 4.529353618621826, 'max_batch': 5.394614887237549}
step: 4260 @ episode report: {'average_total_reward': 10.443001, 'reward_variance': 1.8970817, 'max_total_reward': 13.340001, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2656085014343263, 'actor_loss': -4.757307243347168, 'hyper_actor_loss': 0.09521419033408166, 'behavior_loss': 0.3740048915147781, 'mean_batch': 5.113138198852539, 'min_batch': 4.55578384399414, 'max_batch': 5.545087718963623}
step: 4270 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.6905806, 'max_total_reward': 13.12, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1456112623214723, 'actor_loss': -4.723473119735718, 'hyper_actor_loss': 0.09499020799994469, 'behavior_loss': 0.38206805288791656, 'mean_batch': 5.014615392684936, 'min_batch': 4.491082239151001, 'max_batch': 5.418555021286011}
step: 4280 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 5.3380003, 'max_total_reward': 14.339999, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1825273275375365, 'actor_loss': -4.770376062393188, 'hyper_actor_loss': 0.09486365541815758, 'behavior_loss': 0.3988966017961502, 'mean_batch': 5.128660869598389, 'min_batch': 4.601563310623169, 'max_batch': 5.5515265464782715}
step: 4290 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 4.0740156, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.424424958229065, 'actor_loss': -4.7364664554595945, 'hyper_actor_loss': 0.09508028402924537, 'behavior_loss': 0.3803775578737259, 'mean_batch': 5.033450698852539, 'min_batch': 4.532087326049805, 'max_batch': 5.460660791397094}
step: 4300 @ episode report: {'average_total_reward': 11.242001, 'reward_variance': 2.3660562, 'max_total_reward': 14.45, 'min_total_reward': 9.009999, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.051791083812714, 'actor_loss': -4.768889665603638, 'hyper_actor_loss': 0.09500478357076644, 'behavior_loss': 0.3832535594701767, 'mean_batch': 5.136379241943359, 'min_batch': 4.589003562927246, 'max_batch': 5.566130018234253}
step: 4310 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 4.720516, 'max_total_reward': 12.009999, 'min_total_reward': 5.6800003, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.337835395336151, 'actor_loss': -4.799866437911987, 'hyper_actor_loss': 0.09495003446936608, 'behavior_loss': 0.3941561967134476, 'mean_batch': 5.192259168624878, 'min_batch': 4.682332754135132, 'max_batch': 5.626201629638672}
step: 4320 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.9368443, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.358943486213684, 'actor_loss': -4.710544061660767, 'hyper_actor_loss': 0.09510117545723915, 'behavior_loss': 0.37561901211738585, 'mean_batch': 4.983688545227051, 'min_batch': 4.460743045806884, 'max_batch': 5.40460786819458}
step: 4330 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 0.75652, 'max_total_reward': 11.2300005, 'min_total_reward': 8.79, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4891518115997315, 'actor_loss': -4.790641832351684, 'hyper_actor_loss': 0.0949784941971302, 'behavior_loss': 0.3760041773319244, 'mean_batch': 5.173836326599121, 'min_batch': 4.655442810058593, 'max_batch': 5.616759586334228}
step: 4340 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 2.5914612, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.190688908100128, 'actor_loss': -4.762112760543824, 'hyper_actor_loss': 0.0950050711631775, 'behavior_loss': 0.39297127425670625, 'mean_batch': 5.122674179077149, 'min_batch': 4.568440008163452, 'max_batch': 5.546859836578369}
step: 4350 @ episode report: {'average_total_reward': 10.731, 'reward_variance': 1.2648286, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.353917133808136, 'actor_loss': -4.7827223777771, 'hyper_actor_loss': 0.09499827176332473, 'behavior_loss': 0.3968993127346039, 'mean_batch': 5.1712123394012455, 'min_batch': 4.620699214935303, 'max_batch': 5.583215236663818}
step: 4360 @ episode report: {'average_total_reward': 9.821, 'reward_variance': 3.57379, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.412495231628418, 'actor_loss': -4.7595092296600345, 'hyper_actor_loss': 0.09496750831604003, 'behavior_loss': 0.3841396927833557, 'mean_batch': 5.096862125396728, 'min_batch': 4.580324506759643, 'max_batch': 5.5050133228302}
step: 4370 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 3.240509, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3011460065841676, 'actor_loss': -4.739727878570557, 'hyper_actor_loss': 0.09503409117460251, 'behavior_loss': 0.3753868669271469, 'mean_batch': 5.042921638488769, 'min_batch': 4.5385995388031, 'max_batch': 5.45630784034729}
step: 4380 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 4.479801, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.285736244916916, 'actor_loss': -4.747906827926636, 'hyper_actor_loss': 0.09491332173347473, 'behavior_loss': 0.39200602769851683, 'mean_batch': 5.072417068481445, 'min_batch': 4.550002813339233, 'max_batch': 5.4732297420501705}
step: 4390 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.7911441, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.523207759857178, 'actor_loss': -4.728712129592895, 'hyper_actor_loss': 0.09501256942749023, 'behavior_loss': 0.3614452362060547, 'mean_batch': 5.026158428192138, 'min_batch': 4.504174470901489, 'max_batch': 5.442235898971558}
step: 4400 @ episode report: {'average_total_reward': 10.554001, 'reward_variance': 5.4547663, 'max_total_reward': 15.670001, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.061098742485046, 'actor_loss': -4.786562299728393, 'hyper_actor_loss': 0.09469816684722901, 'behavior_loss': 0.3784602344036102, 'mean_batch': 5.163935136795044, 'min_batch': 4.64583044052124, 'max_batch': 5.580648279190063}
step: 4410 @ episode report: {'average_total_reward': 9.155001, 'reward_variance': 4.113006, 'max_total_reward': 12.010001, 'min_total_reward': 5.68, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7074225902557374, 'actor_loss': -4.749337196350098, 'hyper_actor_loss': 0.09459959417581558, 'behavior_loss': 0.3771078050136566, 'mean_batch': 5.0647119045257565, 'min_batch': 4.562097883224487, 'max_batch': 5.46940975189209}
step: 4420 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.3968291, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.440675675868988, 'actor_loss': -4.746938228607178, 'hyper_actor_loss': 0.09468827396631241, 'behavior_loss': 0.3760504871606827, 'mean_batch': 5.039314079284668, 'min_batch': 4.574508237838745, 'max_batch': 5.451278877258301}
step: 4430 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 3.3751843, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7252067089080811, 'actor_loss': -4.798155736923218, 'hyper_actor_loss': 0.09472385868430137, 'behavior_loss': 0.36898333132266997, 'mean_batch': 5.209736585617065, 'min_batch': 4.657967138290405, 'max_batch': 5.660081148147583}
step: 4440 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 3.2313488, 'max_total_reward': 13.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8482742428779602, 'actor_loss': -4.847093200683593, 'hyper_actor_loss': 0.0947843462228775, 'behavior_loss': 0.3549093872308731, 'mean_batch': 5.3242021083831785, 'min_batch': 4.785590410232544, 'max_batch': 5.800601387023926}
step: 4450 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 1.9440651, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4667813181877136, 'actor_loss': -4.769138336181641, 'hyper_actor_loss': 0.09459366872906685, 'behavior_loss': 0.38141126930713654, 'mean_batch': 5.087960910797119, 'min_batch': 4.633462285995483, 'max_batch': 5.495400905609131}
step: 4460 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 1.507385, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.589182949066162, 'actor_loss': -4.758616781234741, 'hyper_actor_loss': 0.09455602392554283, 'behavior_loss': 0.3793668359518051, 'mean_batch': 5.084762811660767, 'min_batch': 4.587280893325806, 'max_batch': 5.480924415588379}
step: 4470 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 3.000385, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.471454846858978, 'actor_loss': -4.7292245388031, 'hyper_actor_loss': 0.09488334655761718, 'behavior_loss': 0.3854710847139359, 'mean_batch': 5.00038776397705, 'min_batch': 4.528889226913452, 'max_batch': 5.373748779296875}
step: 4480 @ episode report: {'average_total_reward': 10.154, 'reward_variance': 2.7775638, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.064978379011154, 'actor_loss': -4.794436502456665, 'hyper_actor_loss': 0.09488671049475669, 'behavior_loss': 0.3705690920352936, 'mean_batch': 5.1949748516082765, 'min_batch': 4.654847574234009, 'max_batch': 5.5798415184021}
step: 4490 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 3.9072413, 'max_total_reward': 12.12, 'min_total_reward': 4.68, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4054927706718443, 'actor_loss': -4.807887220382691, 'hyper_actor_loss': 0.09477048143744468, 'behavior_loss': 0.3773780703544617, 'mean_batch': 5.235040521621704, 'min_batch': 4.682454681396484, 'max_batch': 5.649863767623901}
step: 4500 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 1.7968565, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3850346207618713, 'actor_loss': -4.75726351737976, 'hyper_actor_loss': 0.09474638774991036, 'behavior_loss': 0.37643401324748993, 'mean_batch': 5.087106037139892, 'min_batch': 4.5794093132019045, 'max_batch': 5.499467468261718}
step: 4510 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 2.41136, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0199969887733458, 'actor_loss': -4.809071254730225, 'hyper_actor_loss': 0.09456927552819253, 'behavior_loss': 0.36481930017471315, 'mean_batch': 5.213831520080566, 'min_batch': 4.704034280776978, 'max_batch': 5.630618572235107}
step: 4520 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 2.415881, 'max_total_reward': 12.339999, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0726261734962463, 'actor_loss': -4.821603107452392, 'hyper_actor_loss': 0.09448177590966225, 'behavior_loss': 0.3616034299135208, 'mean_batch': 5.228259563446045, 'min_batch': 4.750936269760132, 'max_batch': 5.633104848861694}
step: 4530 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 3.5217957, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3443475723266602, 'actor_loss': -4.767950868606567, 'hyper_actor_loss': 0.09440730065107346, 'behavior_loss': 0.3596757560968399, 'mean_batch': 5.071431493759155, 'min_batch': 4.641871547698974, 'max_batch': 5.455901861190796}
step: 4540 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 4.994265, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.020924377441406, 'actor_loss': -4.767133665084839, 'hyper_actor_loss': 0.09440628290176392, 'behavior_loss': 0.35639740228652955, 'mean_batch': 5.09827733039856, 'min_batch': 4.61479229927063, 'max_batch': 5.498673677444458}
step: 4550 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 11.760456, 'max_total_reward': 13.34, 'min_total_reward': 1.13, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.569857430458069, 'actor_loss': -4.782357168197632, 'hyper_actor_loss': 0.09432007148861885, 'behavior_loss': 0.3594366073608398, 'mean_batch': 5.147254991531372, 'min_batch': 4.640857410430908, 'max_batch': 5.54174222946167}
step: 4560 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 5.924926, 'max_total_reward': 13.450001, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1923946499824525, 'actor_loss': -4.764266157150269, 'hyper_actor_loss': 0.09428483247756958, 'behavior_loss': 0.36889161765575407, 'mean_batch': 5.1005675315856935, 'min_batch': 4.598206233978272, 'max_batch': 5.511159515380859}
step: 4570 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 5.0817766, 'max_total_reward': 13.340001, 'min_total_reward': 5.6800003, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4023862421512603, 'actor_loss': -4.754357719421387, 'hyper_actor_loss': 0.09443871825933456, 'behavior_loss': 0.37002975344657896, 'mean_batch': 5.117534351348877, 'min_batch': 4.538082075119019, 'max_batch': 5.482838201522827}
step: 4580 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 2.3522637, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4701740622520445, 'actor_loss': -4.766216135025024, 'hyper_actor_loss': 0.09459763020277023, 'behavior_loss': 0.365134009718895, 'mean_batch': 5.067561864852905, 'min_batch': 4.6369117259979244, 'max_batch': 5.43945164680481}
step: 4590 @ episode report: {'average_total_reward': 8.411, 'reward_variance': 4.6096497, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4184225678443907, 'actor_loss': -4.792664670944214, 'hyper_actor_loss': 0.09458707049489021, 'behavior_loss': 0.35880308747291567, 'mean_batch': 5.177937984466553, 'min_batch': 4.660061550140381, 'max_batch': 5.568017911911011}
step: 4600 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 3.6507556, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1804085254669188, 'actor_loss': -4.795945358276367, 'hyper_actor_loss': 0.09437157437205315, 'behavior_loss': 0.34934178590774534, 'mean_batch': 5.194430685043335, 'min_batch': 4.660165548324585, 'max_batch': 5.624404954910278}
step: 4610 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 5.6160636, 'max_total_reward': 14.339999, 'min_total_reward': 5.68, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1996145129203795, 'actor_loss': -4.8120440483093265, 'hyper_actor_loss': 0.09418898522853851, 'behavior_loss': 0.3573429465293884, 'mean_batch': 5.215517377853393, 'min_batch': 4.716810274124145, 'max_batch': 5.582502985000611}
step: 4620 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 1.4964767, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9149033665657043, 'actor_loss': -4.796893835067749, 'hyper_actor_loss': 0.09409871250391007, 'behavior_loss': 0.35445038676261903, 'mean_batch': 5.1740532398223875, 'min_batch': 4.683820915222168, 'max_batch': 5.574292755126953}
step: 4630 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 1.448849, 'max_total_reward': 12.339999, 'min_total_reward': 8.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.279052805900574, 'actor_loss': -4.803763723373413, 'hyper_actor_loss': 0.09416019096970558, 'behavior_loss': 0.3559786379337311, 'mean_batch': 5.202937173843384, 'min_batch': 4.690158987045288, 'max_batch': 5.575441074371338}
step: 4640 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 4.1310616, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2781064748764037, 'actor_loss': -4.787458610534668, 'hyper_actor_loss': 0.09425945281982422, 'behavior_loss': 0.3596276581287384, 'mean_batch': 5.1516083717346195, 'min_batch': 4.65924654006958, 'max_batch': 5.570876359939575}
step: 4650 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 2.664916, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.265312212705612, 'actor_loss': -4.7895914077758786, 'hyper_actor_loss': 0.0943174608051777, 'behavior_loss': 0.36869104504585265, 'mean_batch': 5.1716306686401365, 'min_batch': 4.651722764968872, 'max_batch': 5.569485235214233}
step: 4660 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 2.3493562, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.131156986951828, 'actor_loss': -4.805245065689087, 'hyper_actor_loss': 0.0944015733897686, 'behavior_loss': 0.34302533864974977, 'mean_batch': 5.173700904846191, 'min_batch': 4.723382759094238, 'max_batch': 5.554266548156738}
step: 4670 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 3.2884688, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5484015345573425, 'actor_loss': -4.784127187728882, 'hyper_actor_loss': 0.09421654418110847, 'behavior_loss': 0.35259856581687926, 'mean_batch': 5.148859882354737, 'min_batch': 4.647472667694092, 'max_batch': 5.535567903518677}
step: 4680 @ episode report: {'average_total_reward': 11.031001, 'reward_variance': 2.8380094, 'max_total_reward': 13.45, 'min_total_reward': 7.7899995, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.473707914352417, 'actor_loss': -4.749941444396972, 'hyper_actor_loss': 0.09405446648597718, 'behavior_loss': 0.35696237683296206, 'mean_batch': 5.060089778900147, 'min_batch': 4.569123601913452, 'max_batch': 5.437455034255981}
step: 4690 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.3683245, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5067313075065614, 'actor_loss': -4.794642210006714, 'hyper_actor_loss': 0.09413221254944801, 'behavior_loss': 0.35337903201580045, 'mean_batch': 5.1749430179595945, 'min_batch': 4.6722554683685305, 'max_batch': 5.550810956954956}
step: 4700 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 0.91241586, 'max_total_reward': 11.23, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.684955561161041, 'actor_loss': -4.740303325653076, 'hyper_actor_loss': 0.09415207877755165, 'behavior_loss': 0.34755692481994627, 'mean_batch': 5.059187936782837, 'min_batch': 4.527071142196656, 'max_batch': 5.4243903160095215}
step: 4710 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 1.9559053, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.273485743999481, 'actor_loss': -4.766057968139648, 'hyper_actor_loss': 0.09409191757440567, 'behavior_loss': 0.3606119841337204, 'mean_batch': 5.084405994415283, 'min_batch': 4.622238826751709, 'max_batch': 5.445134258270263}
step: 4720 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 4.70934, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.306201124191284, 'actor_loss': -4.791444635391235, 'hyper_actor_loss': 0.09411205500364303, 'behavior_loss': 0.3385583281517029, 'mean_batch': 5.161185884475708, 'min_batch': 4.669180202484131, 'max_batch': 5.518040323257447}
step: 4730 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.9376214, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7444944024085998, 'actor_loss': -4.741686487197876, 'hyper_actor_loss': 0.09409902840852738, 'behavior_loss': 0.34741830825805664, 'mean_batch': 5.03857192993164, 'min_batch': 4.5507972240448, 'max_batch': 5.423792886734009}
step: 4740 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 2.3413415, 'max_total_reward': 11.230001, 'min_total_reward': 6.6800003, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7108506560325623, 'actor_loss': -4.797855043411255, 'hyper_actor_loss': 0.09403400495648384, 'behavior_loss': 0.3434098705649376, 'mean_batch': 5.169274091720581, 'min_batch': 4.6941978454589846, 'max_batch': 5.56773362159729}
step: 4750 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 2.3030245, 'max_total_reward': 13.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5088157176971437, 'actor_loss': -4.812637138366699, 'hyper_actor_loss': 0.09396923631429673, 'behavior_loss': 0.3528477191925049, 'mean_batch': 5.217201042175293, 'min_batch': 4.7208233833312985, 'max_batch': 5.621797561645508}
step: 4760 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 3.7915223, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5774951219558715, 'actor_loss': -4.701799774169922, 'hyper_actor_loss': 0.09402871876955032, 'behavior_loss': 0.34016719460487366, 'mean_batch': 4.921137380599975, 'min_batch': 4.478996610641479, 'max_batch': 5.2719659328460695}
step: 4770 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.549521, 'max_total_reward': 12.339999, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.194621670246124, 'actor_loss': -4.77708067893982, 'hyper_actor_loss': 0.09393086805939674, 'behavior_loss': 0.35005472898483275, 'mean_batch': 5.117811965942383, 'min_batch': 4.644516897201538, 'max_batch': 5.515079021453857}
step: 4780 @ episode report: {'average_total_reward': 9.666, 'reward_variance': 1.613764, 'max_total_reward': 12.12, 'min_total_reward': 7.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.997798228263855, 'actor_loss': -4.840500736236573, 'hyper_actor_loss': 0.09379452019929886, 'behavior_loss': 0.33300724923610686, 'mean_batch': 5.260349988937378, 'min_batch': 4.811346340179443, 'max_batch': 5.656162118911743}
step: 4790 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 5.015264, 'max_total_reward': 15.559999, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0141783237457274, 'actor_loss': -4.812966346740723, 'hyper_actor_loss': 0.09367418810725212, 'behavior_loss': 0.31590710282325746, 'mean_batch': 5.202602243423462, 'min_batch': 4.732890653610229, 'max_batch': 5.591830205917359}
step: 4800 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 6.3339286, 'max_total_reward': 15.34, 'min_total_reward': 7.57, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.161453068256378, 'actor_loss': -4.78675651550293, 'hyper_actor_loss': 0.09353556856513023, 'behavior_loss': 0.358365997672081, 'mean_batch': 5.132038736343384, 'min_batch': 4.673488187789917, 'max_batch': 5.454266119003296}
step: 4810 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 2.074401, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1465990960597994, 'actor_loss': -4.832293128967285, 'hyper_actor_loss': 0.09364740327000617, 'behavior_loss': 0.35663982629776003, 'mean_batch': 5.242951679229736, 'min_batch': 4.788376522064209, 'max_batch': 5.639214086532593}
step: 4820 @ episode report: {'average_total_reward': 9.620999, 'reward_variance': 2.6553488, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.435288017988205, 'actor_loss': -4.759311294555664, 'hyper_actor_loss': 0.09393102526664734, 'behavior_loss': 0.3351597934961319, 'mean_batch': 5.064101028442383, 'min_batch': 4.609010982513428, 'max_batch': 5.426990699768067}
step: 4830 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 1.299044, 'max_total_reward': 11.12, 'min_total_reward': 6.7900004, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2614117860794067, 'actor_loss': -4.729263687133789, 'hyper_actor_loss': 0.09379858672618865, 'behavior_loss': 0.34312551021575927, 'mean_batch': 5.039356231689453, 'min_batch': 4.49496545791626, 'max_batch': 5.3964269161224365}
step: 4840 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 5.9699817, 'max_total_reward': 14.340001, 'min_total_reward': 6.57, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1601564645767213, 'actor_loss': -4.780228614807129, 'hyper_actor_loss': 0.0936585895717144, 'behavior_loss': 0.3308196187019348, 'mean_batch': 5.11333155632019, 'min_batch': 4.660911989212036, 'max_batch': 5.461892986297608}
step: 4850 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 1.6003809, 'max_total_reward': 11.120001, 'min_total_reward': 7.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3845242738723753, 'actor_loss': -4.772630929946899, 'hyper_actor_loss': 0.0936939351260662, 'behavior_loss': 0.3422068625688553, 'mean_batch': 5.108580112457275, 'min_batch': 4.630488109588623, 'max_batch': 5.486204528808594}
step: 4860 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 3.2696846, 'max_total_reward': 13.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.322782611846924, 'actor_loss': -4.732277774810791, 'hyper_actor_loss': 0.09368130713701248, 'behavior_loss': 0.3393278032541275, 'mean_batch': 5.031573104858398, 'min_batch': 4.514224863052368, 'max_batch': 5.374650192260742}
step: 4870 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 3.5034764, 'max_total_reward': 13.450001, 'min_total_reward': 6.680001, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.080497455596924, 'actor_loss': -4.8305412292480465, 'hyper_actor_loss': 0.09377328157424927, 'behavior_loss': 0.3263774305582047, 'mean_batch': 5.250389671325683, 'min_batch': 4.773554897308349, 'max_batch': 5.623630952835083}
step: 4880 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 8.662624, 'max_total_reward': 13.450001, 'min_total_reward': 4.57, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1652689456939695, 'actor_loss': -4.777226209640503, 'hyper_actor_loss': 0.0935278631746769, 'behavior_loss': 0.34190999567508695, 'mean_batch': 5.0938397407531735, 'min_batch': 4.6653807163238525, 'max_batch': 5.4400533676147464}
step: 4890 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 5.4040766, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.953981977701187, 'actor_loss': -4.771683263778686, 'hyper_actor_loss': 0.0934788852930069, 'behavior_loss': 0.3280437558889389, 'mean_batch': 5.094214630126953, 'min_batch': 4.637768411636353, 'max_batch': 5.447571277618408}
step: 4900 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 5.732596, 'max_total_reward': 14.339999, 'min_total_reward': 6.8999996, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.25970743894577, 'actor_loss': -4.8077123165130615, 'hyper_actor_loss': 0.09368305057287216, 'behavior_loss': 0.3344213366508484, 'mean_batch': 5.197187185287476, 'min_batch': 4.714276647567749, 'max_batch': 5.539077234268189}
step: 4910 @ episode report: {'average_total_reward': 10.088, 'reward_variance': 2.145376, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.041304314136505, 'actor_loss': -4.771030521392822, 'hyper_actor_loss': 0.09357389733195305, 'behavior_loss': 0.3298244148492813, 'mean_batch': 5.0761254787445065, 'min_batch': 4.651656007766723, 'max_batch': 5.433389949798584}
step: 4920 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 3.060249, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1100676238536833, 'actor_loss': -4.811385297775269, 'hyper_actor_loss': 0.0935260996222496, 'behavior_loss': 0.3235795944929123, 'mean_batch': 5.170238637924195, 'min_batch': 4.754948139190674, 'max_batch': 5.527897500991822}
step: 4930 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 4.4385004, 'max_total_reward': 14.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8926509141921997, 'actor_loss': -4.8610738754272464, 'hyper_actor_loss': 0.09331212118268013, 'behavior_loss': 0.31337966322898864, 'mean_batch': 5.329666996002198, 'min_batch': 4.847440719604492, 'max_batch': 5.692577743530274}
step: 4940 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.754004, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0083064913749693, 'actor_loss': -4.786644411087036, 'hyper_actor_loss': 0.09322581067681313, 'behavior_loss': 0.3367605209350586, 'mean_batch': 5.131583023071289, 'min_batch': 4.673619794845581, 'max_batch': 5.4414825439453125}
step: 4950 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.4994597, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8985377907752992, 'actor_loss': -4.77106990814209, 'hyper_actor_loss': 0.09338531494140626, 'behavior_loss': 0.3170906662940979, 'mean_batch': 5.119648361206055, 'min_batch': 4.61335129737854, 'max_batch': 5.469494295120239}
step: 4960 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 2.0430892, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.482562804222107, 'actor_loss': -4.7534435272216795, 'hyper_actor_loss': 0.09350368157029151, 'behavior_loss': 0.3283844590187073, 'mean_batch': 5.042772626876831, 'min_batch': 4.601828098297119, 'max_batch': 5.374175548553467}
step: 4970 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.843249, 'max_total_reward': 12.12, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.927583771944046, 'actor_loss': -4.741163921356201, 'hyper_actor_loss': 0.09330294579267502, 'behavior_loss': 0.3377023160457611, 'mean_batch': 4.9904059886932375, 'min_batch': 4.593739318847656, 'max_batch': 5.337278842926025}
step: 4980 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 3.4167094, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.442814302444458, 'actor_loss': -4.818645238876343, 'hyper_actor_loss': 0.09347072467207909, 'behavior_loss': 0.33377003073692324, 'mean_batch': 5.186315536499023, 'min_batch': 4.774914169311524, 'max_batch': 5.5335955142974855}
step: 4990 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 4.1122, 'max_total_reward': 13.340001, 'min_total_reward': 5.7900004, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2163416385650634, 'actor_loss': -4.739103174209594, 'hyper_actor_loss': 0.09356107860803604, 'behavior_loss': 0.3409797877073288, 'mean_batch': 4.980013513565064, 'min_batch': 4.5925273418426515, 'max_batch': 5.314609956741333}
step: 5000 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 2.5529952, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9638205289840698, 'actor_loss': -4.756997728347779, 'hyper_actor_loss': 0.09352677091956138, 'behavior_loss': 0.3171625882387161, 'mean_batch': 5.057934951782227, 'min_batch': 4.603826665878296, 'max_batch': 5.365704727172852}
step: 5010 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 1.4560357, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3506459951400758, 'actor_loss': -4.798753023147583, 'hyper_actor_loss': 0.093384800106287, 'behavior_loss': 0.32553955614566804, 'mean_batch': 5.1316526412963865, 'min_batch': 4.73054609298706, 'max_batch': 5.453693819046021}
step: 5020 @ episode report: {'average_total_reward': 10.554001, 'reward_variance': 1.4410044, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4167218804359436, 'actor_loss': -4.7148784637451175, 'hyper_actor_loss': 0.09332754090428352, 'behavior_loss': 0.32900276482105256, 'mean_batch': 4.921357488632202, 'min_batch': 4.536488676071167, 'max_batch': 5.204942846298218}
step: 5030 @ episode report: {'average_total_reward': 9.488, 'reward_variance': 2.3988767, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.099729871749878, 'actor_loss': -4.740087699890137, 'hyper_actor_loss': 0.09341287836432458, 'behavior_loss': 0.32106873095035554, 'mean_batch': 4.998768091201782, 'min_batch': 4.580026578903198, 'max_batch': 5.318875360488891}
step: 5040 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.087384, 'max_total_reward': 11.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8551012754440308, 'actor_loss': -4.833643674850464, 'hyper_actor_loss': 0.0932496465742588, 'behavior_loss': 0.31094340682029725, 'mean_batch': 5.230291652679443, 'min_batch': 4.805860090255737, 'max_batch': 5.544144344329834}
step: 5050 @ episode report: {'average_total_reward': 9.655, 'reward_variance': 1.9441048, 'max_total_reward': 12.34, 'min_total_reward': 7.3500004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9698131442070008, 'actor_loss': -4.816140508651733, 'hyper_actor_loss': 0.0931969240307808, 'behavior_loss': 0.32348085939884186, 'mean_batch': 5.161859226226807, 'min_batch': 4.7859564304351805, 'max_batch': 5.518059873580933}
step: 5060 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 2.4031246, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3214818239212036, 'actor_loss': -4.777053117752075, 'hyper_actor_loss': 0.09321115165948868, 'behavior_loss': 0.32908560931682584, 'mean_batch': 5.1006227970123295, 'min_batch': 4.657459545135498, 'max_batch': 5.459392023086548}
step: 5070 @ episode report: {'average_total_reward': 11.297001, 'reward_variance': 1.8729216, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1066845297813415, 'actor_loss': -4.794069910049439, 'hyper_actor_loss': 0.09327115789055825, 'behavior_loss': 0.3116085857152939, 'mean_batch': 5.119494915008545, 'min_batch': 4.720816040039063, 'max_batch': 5.447667121887207}
step: 5080 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 3.2181022, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3392325162887575, 'actor_loss': -4.8287426948547365, 'hyper_actor_loss': 0.09314054846763611, 'behavior_loss': 0.3084294080734253, 'mean_batch': 5.210842227935791, 'min_batch': 4.800401639938355, 'max_batch': 5.532591342926025}
step: 5090 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 1.4155414, 'max_total_reward': 12.01, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8993801832199098, 'actor_loss': -4.815109395980835, 'hyper_actor_loss': 0.09293784648180008, 'behavior_loss': 0.3218454658985138, 'mean_batch': 5.204684209823609, 'min_batch': 4.741486883163452, 'max_batch': 5.550818681716919}
step: 5100 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 3.6309772, 'max_total_reward': 13.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4769595980644226, 'actor_loss': -4.846252059936523, 'hyper_actor_loss': 0.09281568974256516, 'behavior_loss': 0.29390472173690796, 'mean_batch': 5.277854585647583, 'min_batch': 4.823815059661865, 'max_batch': 5.613158369064331}
step: 5110 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 3.5033574, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9722301840782166, 'actor_loss': -4.83947343826294, 'hyper_actor_loss': 0.09284453690052033, 'behavior_loss': 0.32214961647987367, 'mean_batch': 5.233150434494019, 'min_batch': 4.832185173034668, 'max_batch': 5.567059469223023}
step: 5120 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 1.9139684, 'max_total_reward': 11.23, 'min_total_reward': 6.57, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9354724168777466, 'actor_loss': -4.801941967010498, 'hyper_actor_loss': 0.09313789606094361, 'behavior_loss': 0.32189546525478363, 'mean_batch': 5.152918863296509, 'min_batch': 4.726063680648804, 'max_batch': 5.468994903564453}
step: 5130 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 1.6290634, 'max_total_reward': 12.339999, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9013424277305604, 'actor_loss': -4.829808616638184, 'hyper_actor_loss': 0.09326342642307281, 'behavior_loss': 0.3266799747943878, 'mean_batch': 5.218251419067383, 'min_batch': 4.79868369102478, 'max_batch': 5.548061323165894}
step: 5140 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 2.856937, 'max_total_reward': 13.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.030253493785858, 'actor_loss': -4.837402868270874, 'hyper_actor_loss': 0.09335320964455604, 'behavior_loss': 0.30532307326793673, 'mean_batch': 5.257954549789429, 'min_batch': 4.799687671661377, 'max_batch': 5.587436723709106}
step: 5150 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 1.9225155, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.392007076740265, 'actor_loss': -4.780539608001709, 'hyper_actor_loss': 0.09304453805088997, 'behavior_loss': 0.3171993762254715, 'mean_batch': 5.10020809173584, 'min_batch': 4.675247049331665, 'max_batch': 5.442959642410278}
step: 5160 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 2.3572814, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8544683933258057, 'actor_loss': -4.8106334686279295, 'hyper_actor_loss': 0.09313391372561455, 'behavior_loss': 0.3063980430364609, 'mean_batch': 5.189763355255127, 'min_batch': 4.737976169586181, 'max_batch': 5.5181091785430905}
step: 5170 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 4.680488, 'max_total_reward': 16.67, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 17.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.100033175945282, 'actor_loss': -4.845732402801514, 'hyper_actor_loss': 0.09281011149287224, 'behavior_loss': 0.3105063647031784, 'mean_batch': 5.286766433715821, 'min_batch': 4.813559722900391, 'max_batch': 5.65468316078186}
step: 5180 @ episode report: {'average_total_reward': 10.853, 'reward_variance': 2.3792806, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6263575494289397, 'actor_loss': -4.824970865249634, 'hyper_actor_loss': 0.09262648373842239, 'behavior_loss': 0.29251269847154615, 'mean_batch': 5.204139375686646, 'min_batch': 4.788377475738526, 'max_batch': 5.5407802104949955}
step: 5190 @ episode report: {'average_total_reward': 10.408999, 'reward_variance': 4.7824087, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1951631546020507, 'actor_loss': -4.8412988662719725, 'hyper_actor_loss': 0.09267922267317771, 'behavior_loss': 0.31259280145168306, 'mean_batch': 5.2587462902069095, 'min_batch': 4.817432308197022, 'max_batch': 5.585520172119141}
step: 5200 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 2.054096, 'max_total_reward': 12.12, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9953492641448975, 'actor_loss': -4.794623708724975, 'hyper_actor_loss': 0.09266080558300019, 'behavior_loss': 0.32255598306655886, 'mean_batch': 5.153354787826538, 'min_batch': 4.691186857223511, 'max_batch': 5.4712827682495115}
step: 5210 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 4.214764, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.30288051366806, 'actor_loss': -4.80444369316101, 'hyper_actor_loss': 0.09284453094005585, 'behavior_loss': 0.3023870065808296, 'mean_batch': 5.141423177719116, 'min_batch': 4.7482739925384525, 'max_batch': 5.440096855163574}
step: 5220 @ episode report: {'average_total_reward': 9.521, 'reward_variance': 2.669969, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.208220052719116, 'actor_loss': -4.806718254089356, 'hyper_actor_loss': 0.09284048303961753, 'behavior_loss': 0.30761215686798093, 'mean_batch': 5.120313405990601, 'min_batch': 4.7787659645080565, 'max_batch': 5.437722015380859}
step: 5230 @ episode report: {'average_total_reward': 10.831001, 'reward_variance': 2.2962089, 'max_total_reward': 13.120001, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.251215732097626, 'actor_loss': -4.83339900970459, 'hyper_actor_loss': 0.0927525945007801, 'behavior_loss': 0.3178172528743744, 'mean_batch': 5.208157920837403, 'min_batch': 4.825270509719848, 'max_batch': 5.504929399490356}
step: 5240 @ episode report: {'average_total_reward': 11.175, 'reward_variance': 2.1743853, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7871410727500916, 'actor_loss': -4.838738012313843, 'hyper_actor_loss': 0.09279481470584869, 'behavior_loss': 0.3002215802669525, 'mean_batch': 5.2110552310943605, 'min_batch': 4.84838547706604, 'max_batch': 5.532591724395752}
step: 5250 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 2.0637844, 'max_total_reward': 14.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.14264121055603, 'actor_loss': -4.830631303787231, 'hyper_actor_loss': 0.09254946112632752, 'behavior_loss': 0.29523909986019137, 'mean_batch': 5.238014221191406, 'min_batch': 4.78513388633728, 'max_batch': 5.539498138427734}
step: 5260 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 2.0686243, 'max_total_reward': 14.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.974654448032379, 'actor_loss': -4.79189977645874, 'hyper_actor_loss': 0.09234436601400375, 'behavior_loss': 0.31926551163196565, 'mean_batch': 5.101668071746826, 'min_batch': 4.726069068908691, 'max_batch': 5.409334993362426}
step: 5270 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 2.0099497, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.206948935985565, 'actor_loss': -4.810170650482178, 'hyper_actor_loss': 0.09258416891098023, 'behavior_loss': 0.30513693392276764, 'mean_batch': 5.159755849838257, 'min_batch': 4.758530712127685, 'max_batch': 5.480062627792359}
step: 5280 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 3.7945755, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.088978338241577, 'actor_loss': -4.8181122779846195, 'hyper_actor_loss': 0.09267015308141709, 'behavior_loss': 0.31565488278865816, 'mean_batch': 5.166271162033081, 'min_batch': 4.790329074859619, 'max_batch': 5.484701681137085}
step: 5290 @ episode report: {'average_total_reward': 9.887001, 'reward_variance': 3.3259602, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.896758234500885, 'actor_loss': -4.794858789443969, 'hyper_actor_loss': 0.09277573451399804, 'behavior_loss': 0.3051801785826683, 'mean_batch': 5.114185619354248, 'min_batch': 4.728402996063233, 'max_batch': 5.415787982940674}
step: 5300 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 5.4756365, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.032643175125122, 'actor_loss': -4.831951904296875, 'hyper_actor_loss': 0.09270078539848328, 'behavior_loss': 0.2985513374209404, 'mean_batch': 5.20942497253418, 'min_batch': 4.817344617843628, 'max_batch': 5.511023330688476}
step: 5310 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 6.182129, 'max_total_reward': 15.67, 'min_total_reward': 7.6800003, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8978668332099915, 'actor_loss': -4.819568252563476, 'hyper_actor_loss': 0.09247276782989503, 'behavior_loss': 0.300454193353653, 'mean_batch': 5.184901285171509, 'min_batch': 4.7806487560272215, 'max_batch': 5.498401212692261}
step: 5320 @ episode report: {'average_total_reward': 8.7, 'reward_variance': 5.100299, 'max_total_reward': 12.2300005, 'min_total_reward': 5.5700006, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9328578591346741, 'actor_loss': -4.818282985687256, 'hyper_actor_loss': 0.09240998029708862, 'behavior_loss': 0.3059588402509689, 'mean_batch': 5.161149597167968, 'min_batch': 4.796061754226685, 'max_batch': 5.4645825862884525}
step: 5330 @ episode report: {'average_total_reward': 9.654, 'reward_variance': 4.6696634, 'max_total_reward': 12.34, 'min_total_reward': 5.5700006, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9548560440540315, 'actor_loss': -4.812114238739014, 'hyper_actor_loss': 0.09229333847761154, 'behavior_loss': 0.28814734518527985, 'mean_batch': 5.153581666946411, 'min_batch': 4.773510217666626, 'max_batch': 5.444294500350952}
step: 5340 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 1.8736767, 'max_total_reward': 13.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2046259164810182, 'actor_loss': -4.784164619445801, 'hyper_actor_loss': 0.09229867160320282, 'behavior_loss': 0.2949995130300522, 'mean_batch': 5.095047235488892, 'min_batch': 4.697377443313599, 'max_batch': 5.400771284103394}
step: 5350 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 4.5380254, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6968639373779297, 'actor_loss': -4.838021612167358, 'hyper_actor_loss': 0.09241619110107421, 'behavior_loss': 0.3112661302089691, 'mean_batch': 5.2392324924469, 'min_batch': 4.8197221755981445, 'max_batch': 5.552732944488525}
step: 5360 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 3.035085, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7899995, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1540123343467714, 'actor_loss': -4.828390073776245, 'hyper_actor_loss': 0.09254376813769341, 'behavior_loss': 0.3213744819164276, 'mean_batch': 5.186143159866333, 'min_batch': 4.82232894897461, 'max_batch': 5.470140027999878}
step: 5370 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 2.8057806, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.002916967868805, 'actor_loss': -4.783727836608887, 'hyper_actor_loss': 0.09274219945073128, 'behavior_loss': 0.28589843660593034, 'mean_batch': 5.091167783737182, 'min_batch': 4.697688913345337, 'max_batch': 5.3788737773895265}
step: 5380 @ episode report: {'average_total_reward': 10.531001, 'reward_variance': 1.3132292, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0028722643852235, 'actor_loss': -4.80468864440918, 'hyper_actor_loss': 0.09263681694865226, 'behavior_loss': 0.29776240289211275, 'mean_batch': 5.157035160064697, 'min_batch': 4.735398149490356, 'max_batch': 5.448070383071899}
step: 5390 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 4.4464035, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.540126919746399, 'actor_loss': -4.833949279785156, 'hyper_actor_loss': 0.09246121868491172, 'behavior_loss': 0.3009990841150284, 'mean_batch': 5.211728811264038, 'min_batch': 4.8251166343688965, 'max_batch': 5.512571382522583}
step: 5400 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 2.3037496, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.990206441283226, 'actor_loss': -4.864074754714966, 'hyper_actor_loss': 0.09236206114292145, 'behavior_loss': 0.3083585545420647, 'mean_batch': 5.289058637619019, 'min_batch': 4.899541330337525, 'max_batch': 5.596631193161011}
step: 5410 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 3.7909043, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8467040657997131, 'actor_loss': -4.800475645065307, 'hyper_actor_loss': 0.09235106408596039, 'behavior_loss': 0.2821232333779335, 'mean_batch': 5.122707223892212, 'min_batch': 4.747328424453736, 'max_batch': 5.411346101760865}
step: 5420 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 3.0906901, 'max_total_reward': 13.340001, 'min_total_reward': 8.789999, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0534265279769897, 'actor_loss': -4.810809564590454, 'hyper_actor_loss': 0.09207206293940544, 'behavior_loss': 0.2932117819786072, 'mean_batch': 5.164583730697632, 'min_batch': 4.757867908477783, 'max_batch': 5.468964052200318}
step: 5430 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 3.1864216, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.889646089076996, 'actor_loss': -4.852594518661499, 'hyper_actor_loss': 0.09205656722187996, 'behavior_loss': 0.3013888955116272, 'mean_batch': 5.250624752044677, 'min_batch': 4.878746891021729, 'max_batch': 5.5670671463012695}
step: 5440 @ episode report: {'average_total_reward': 10.631001, 'reward_variance': 1.8943892, 'max_total_reward': 13.450001, 'min_total_reward': 8.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.107147777080536, 'actor_loss': -4.793926334381103, 'hyper_actor_loss': 0.09222985208034515, 'behavior_loss': 0.29176277220249175, 'mean_batch': 5.086961317062378, 'min_batch': 4.749512720108032, 'max_batch': 5.353227376937866}
step: 5450 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 2.6948247, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7165481448173523, 'actor_loss': -4.804861211776734, 'hyper_actor_loss': 0.09219517633318901, 'behavior_loss': 0.2954253673553467, 'mean_batch': 5.175399112701416, 'min_batch': 4.720362854003906, 'max_batch': 5.491791582107544}
step: 5460 @ episode report: {'average_total_reward': 11.242001, 'reward_variance': 5.733396, 'max_total_reward': 15.56, 'min_total_reward': 7.68, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.206133759021759, 'actor_loss': -4.843343210220337, 'hyper_actor_loss': 0.09224770292639732, 'behavior_loss': 0.2953351140022278, 'mean_batch': 5.238113498687744, 'min_batch': 4.846418809890747, 'max_batch': 5.515363931655884}
step: 5470 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 5.1244903, 'max_total_reward': 13.450001, 'min_total_reward': 4.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5312837600708007, 'actor_loss': -4.748995113372803, 'hyper_actor_loss': 0.09221974536776542, 'behavior_loss': 0.30233416259288787, 'mean_batch': 4.975650835037231, 'min_batch': 4.641945886611938, 'max_batch': 5.243403816223145}
step: 5480 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 1.9010414, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.280560827255249, 'actor_loss': -4.7741615772247314, 'hyper_actor_loss': 0.09222044497728348, 'behavior_loss': 0.3073544502258301, 'mean_batch': 5.023155641555786, 'min_batch': 4.715985536575317, 'max_batch': 5.314645528793335}
step: 5490 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 4.389737, 'max_total_reward': 14.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7320226073265075, 'actor_loss': -4.804584503173828, 'hyper_actor_loss': 0.09228622913360596, 'behavior_loss': 0.29357106536626815, 'mean_batch': 5.12776894569397, 'min_batch': 4.761661243438721, 'max_batch': 5.407326555252075}
step: 5500 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 0.8355964, 'max_total_reward': 11.2300005, 'min_total_reward': 9.009999, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.80438734292984, 'actor_loss': -4.849122476577759, 'hyper_actor_loss': 0.09229774922132492, 'behavior_loss': 0.3017051160335541, 'mean_batch': 5.263332462310791, 'min_batch': 4.850537490844727, 'max_batch': 5.565142250061035}
step: 5510 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 1.1793494, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.546152800321579, 'actor_loss': -4.859234619140625, 'hyper_actor_loss': 0.09220148622989655, 'behavior_loss': 0.28997376263141633, 'mean_batch': 5.268782424926758, 'min_batch': 4.894472312927246, 'max_batch': 5.5838377475738525}
step: 5520 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 2.298201, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5393336474895478, 'actor_loss': -4.858008623123169, 'hyper_actor_loss': 0.09193793907761574, 'behavior_loss': 0.27713905423879626, 'mean_batch': 5.270675373077393, 'min_batch': 4.887406826019287, 'max_batch': 5.568807697296142}
step: 5530 @ episode report: {'average_total_reward': 10.787001, 'reward_variance': 2.5542018, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9849102795124054, 'actor_loss': -4.864200067520142, 'hyper_actor_loss': 0.09165932834148408, 'behavior_loss': 0.2941152721643448, 'mean_batch': 5.317430877685547, 'min_batch': 4.874702644348145, 'max_batch': 5.616345405578613}
step: 5540 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 1.2468011, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8584157228469849, 'actor_loss': -4.821199655532837, 'hyper_actor_loss': 0.09168504178524017, 'behavior_loss': 0.2914304256439209, 'mean_batch': 5.1710046291351315, 'min_batch': 4.801470708847046, 'max_batch': 5.441107368469238}
step: 5550 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 2.0052562, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8139630794525146, 'actor_loss': -4.8497367858886715, 'hyper_actor_loss': 0.09189478084444999, 'behavior_loss': 0.2986297607421875, 'mean_batch': 5.273946809768677, 'min_batch': 4.843583297729492, 'max_batch': 5.59309139251709}
step: 5560 @ episode report: {'average_total_reward': 9.466001, 'reward_variance': 4.349404, 'max_total_reward': 13.45, 'min_total_reward': 5.4600005, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4576394319534303, 'actor_loss': -4.820793008804321, 'hyper_actor_loss': 0.0920297496020794, 'behavior_loss': 0.29567075073719024, 'mean_batch': 5.179997682571411, 'min_batch': 4.791371154785156, 'max_batch': 5.445125436782837}
step: 5570 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 3.9246006, 'max_total_reward': 12.339999, 'min_total_reward': 5.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0864552736282347, 'actor_loss': -4.832343530654907, 'hyper_actor_loss': 0.0919563613831997, 'behavior_loss': 0.2785455763339996, 'mean_batch': 5.20204873085022, 'min_batch': 4.8262697696685795, 'max_batch': 5.4996436595916744}
step: 5580 @ episode report: {'average_total_reward': 10.331, 'reward_variance': 3.2624698, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0199087798595428, 'actor_loss': -4.851884460449218, 'hyper_actor_loss': 0.0916341595351696, 'behavior_loss': 0.28396600037813186, 'mean_batch': 5.27441987991333, 'min_batch': 4.853747272491455, 'max_batch': 5.575465345382691}
step: 5590 @ episode report: {'average_total_reward': 11.396998, 'reward_variance': 1.3662608, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7809503436088563, 'actor_loss': -4.870827150344849, 'hyper_actor_loss': 0.09153877645730972, 'behavior_loss': 0.2880184128880501, 'mean_batch': 5.309284448623657, 'min_batch': 4.913686847686767, 'max_batch': 5.607666444778443}
step: 5600 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 5.038697, 'max_total_reward': 15.56, 'min_total_reward': 7.9000006, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4749173164367675, 'actor_loss': -4.8403441429138185, 'hyper_actor_loss': 0.0916456326842308, 'behavior_loss': 0.299687522649765, 'mean_batch': 5.203020811080933, 'min_batch': 4.864549398422241, 'max_batch': 5.526050567626953}
step: 5610 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 1.2834599, 'max_total_reward': 12.34, 'min_total_reward': 8.68, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.662901794910431, 'actor_loss': -4.832412433624268, 'hyper_actor_loss': 0.09161250293254852, 'behavior_loss': 0.2758411139249802, 'mean_batch': 5.188225793838501, 'min_batch': 4.8407135009765625, 'max_batch': 5.486002445220947}
step: 5620 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 2.5437605, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.06014107465744, 'actor_loss': -4.874143457412719, 'hyper_actor_loss': 0.09159990176558494, 'behavior_loss': 0.30365858376026156, 'mean_batch': 5.3191972255706785, 'min_batch': 4.921557474136352, 'max_batch': 5.639596939086914}
step: 5630 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 2.0986214, 'max_total_reward': 12.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1786655366420744, 'actor_loss': -4.80413670539856, 'hyper_actor_loss': 0.0916994996368885, 'behavior_loss': 0.2851814404129982, 'mean_batch': 5.120218276977539, 'min_batch': 4.766557836532593, 'max_batch': 5.401042890548706}
step: 5640 @ episode report: {'average_total_reward': 10.664, 'reward_variance': 3.3806844, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0405798077583315, 'actor_loss': -4.836854934692383, 'hyper_actor_loss': 0.09167274534702301, 'behavior_loss': 0.2891389042139053, 'mean_batch': 5.224061632156372, 'min_batch': 4.828076553344727, 'max_batch': 5.514894485473633}
step: 5650 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.4725087, 'max_total_reward': 13.45, 'min_total_reward': 7.7899995, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.726022982597351, 'actor_loss': -4.8690930843353275, 'hyper_actor_loss': 0.0915849193930626, 'behavior_loss': 0.27225264310836794, 'mean_batch': 5.29539999961853, 'min_batch': 4.917755270004273, 'max_batch': 5.564867210388184}
step: 5660 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 2.4861958, 'max_total_reward': 13.45, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9994716048240662, 'actor_loss': -4.862427282333374, 'hyper_actor_loss': 0.09134687185287475, 'behavior_loss': 0.2960125803947449, 'mean_batch': 5.263156986236572, 'min_batch': 4.915472793579101, 'max_batch': 5.525380182266235}
step: 5670 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.5439048, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7926070809364318, 'actor_loss': -4.874303197860717, 'hyper_actor_loss': 0.09137959778308868, 'behavior_loss': 0.27993982583284377, 'mean_batch': 5.315815830230713, 'min_batch': 4.925092124938965, 'max_batch': 5.595659828186035}
step: 5680 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 2.8691247, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8655492782592773, 'actor_loss': -4.860477638244629, 'hyper_actor_loss': 0.09138397872447968, 'behavior_loss': 0.2870045393705368, 'mean_batch': 5.271660327911377, 'min_batch': 4.898534822463989, 'max_batch': 5.573452711105347}
step: 5690 @ episode report: {'average_total_reward': 10.908999, 'reward_variance': 3.7627692, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8500760078430176, 'actor_loss': -4.8872722625732425, 'hyper_actor_loss': 0.09144229590892791, 'behavior_loss': 0.27863451540470124, 'mean_batch': 5.33345308303833, 'min_batch': 4.972749376296997, 'max_batch': 5.633854866027832}
step: 5700 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 3.783165, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1457412242889404, 'actor_loss': -4.852114629745484, 'hyper_actor_loss': 0.09118094816803932, 'behavior_loss': 0.2816241428256035, 'mean_batch': 5.245721673965454, 'min_batch': 4.882954216003418, 'max_batch': 5.520008516311646}
step: 5710 @ episode report: {'average_total_reward': 10.5529995, 'reward_variance': 4.1051817, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1971626043319703, 'actor_loss': -4.835195922851563, 'hyper_actor_loss': 0.09126105830073357, 'behavior_loss': 0.3071153283119202, 'mean_batch': 5.180171060562134, 'min_batch': 4.860095024108887, 'max_batch': 5.453094053268432}
step: 5720 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 4.5686, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3516698718070983, 'actor_loss': -4.916471815109253, 'hyper_actor_loss': 0.09148716777563096, 'behavior_loss': 0.28150064796209334, 'mean_batch': 5.411424398422241, 'min_batch': 5.046453809738159, 'max_batch': 5.724155712127685}
step: 5730 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 1.7415287, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9859835863113404, 'actor_loss': -4.901268434524536, 'hyper_actor_loss': 0.09126980528235436, 'behavior_loss': 0.26837644428014756, 'mean_batch': 5.384938049316406, 'min_batch': 4.996200370788574, 'max_batch': 5.687791538238526}
step: 5740 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 4.6099043, 'max_total_reward': 13.120001, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.024763745069504, 'actor_loss': -4.843544387817383, 'hyper_actor_loss': 0.0909280925989151, 'behavior_loss': 0.26805266588926313, 'mean_batch': 5.216249132156372, 'min_batch': 4.8677592277526855, 'max_batch': 5.469238996505737}
step: 5750 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 5.578701, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9938871681690216, 'actor_loss': -4.8691648006439205, 'hyper_actor_loss': 0.09064741879701614, 'behavior_loss': 0.28142866045236586, 'mean_batch': 5.293705749511719, 'min_batch': 4.920021677017212, 'max_batch': 5.5648205280303955}
step: 5760 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 2.045141, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.781974232196808, 'actor_loss': -4.895805358886719, 'hyper_actor_loss': 0.09065592363476753, 'behavior_loss': 0.2825858682394028, 'mean_batch': 5.351957702636719, 'min_batch': 4.997866106033325, 'max_batch': 5.655587768554687}
step: 5770 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 1.4912812, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.367268419265747, 'actor_loss': -4.859182119369507, 'hyper_actor_loss': 0.09091034382581711, 'behavior_loss': 0.28908668756484984, 'mean_batch': 5.260162687301635, 'min_batch': 4.903459692001343, 'max_batch': 5.5294013023376465}
step: 5780 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 3.0283287, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.051115798950195, 'actor_loss': -4.811420440673828, 'hyper_actor_loss': 0.09102079495787621, 'behavior_loss': 0.2736857205629349, 'mean_batch': 5.139683818817138, 'min_batch': 4.783990859985352, 'max_batch': 5.413032579421997}
step: 5790 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.6099052, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.014632153511047, 'actor_loss': -4.895087766647339, 'hyper_actor_loss': 0.0908160649240017, 'behavior_loss': 0.2808742687106133, 'mean_batch': 5.353983354568482, 'min_batch': 4.992870664596557, 'max_batch': 5.625521945953369}
step: 5800 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 1.9205449, 'max_total_reward': 13.23, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6909570217132568, 'actor_loss': -4.860939407348633, 'hyper_actor_loss': 0.0908292792737484, 'behavior_loss': 0.2770907551050186, 'mean_batch': 5.274440145492553, 'min_batch': 4.898067569732666, 'max_batch': 5.567060947418213}
step: 5810 @ episode report: {'average_total_reward': 11.153, 'reward_variance': 0.9686413, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9897633135318755, 'actor_loss': -4.874605464935303, 'hyper_actor_loss': 0.09070326313376427, 'behavior_loss': 0.2901521310210228, 'mean_batch': 5.308188629150391, 'min_batch': 4.933449935913086, 'max_batch': 5.600154066085816}
step: 5820 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 3.2673411, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5208490252494813, 'actor_loss': -4.887664651870727, 'hyper_actor_loss': 0.0907077930867672, 'behavior_loss': 0.2742646291851997, 'mean_batch': 5.333055448532105, 'min_batch': 4.975336360931396, 'max_batch': 5.615402269363403}
step: 5830 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 1.902456, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2858784794807434, 'actor_loss': -4.880363702774048, 'hyper_actor_loss': 0.0907120943069458, 'behavior_loss': 0.27309738397598265, 'mean_batch': 5.296240043640137, 'min_batch': 4.973423862457276, 'max_batch': 5.594437456130981}
step: 5840 @ episode report: {'average_total_reward': 10.610001, 'reward_variance': 1.0914595, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6319201290607452, 'actor_loss': -4.8291637897491455, 'hyper_actor_loss': 0.09066565111279487, 'behavior_loss': 0.29486670196056364, 'mean_batch': 5.181023693084716, 'min_batch': 4.831381702423096, 'max_batch': 5.438793563842774}
step: 5850 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 2.27111, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7954258918762207, 'actor_loss': -4.916069221496582, 'hyper_actor_loss': 0.09070933088660241, 'behavior_loss': 0.275733245909214, 'mean_batch': 5.399170541763306, 'min_batch': 5.055429553985595, 'max_batch': 5.676531887054443}
step: 5860 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 4.593629, 'max_total_reward': 15.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9433046936988831, 'actor_loss': -4.843709945678711, 'hyper_actor_loss': 0.09070566222071648, 'behavior_loss': 0.27811992168426514, 'mean_batch': 5.22817645072937, 'min_batch': 4.856736564636231, 'max_batch': 5.496278381347656}
step: 5870 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 1.0272211, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2329332709312437, 'actor_loss': -4.8441895008087155, 'hyper_actor_loss': 0.09050092697143555, 'behavior_loss': 0.2742005243897438, 'mean_batch': 5.215438938140869, 'min_batch': 4.870452785491944, 'max_batch': 5.47737488746643}
step: 5880 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 3.22155, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6701242566108703, 'actor_loss': -4.85001654624939, 'hyper_actor_loss': 0.09049966111779213, 'behavior_loss': 0.2714359700679779, 'mean_batch': 5.240457963943482, 'min_batch': 4.8771728515625, 'max_batch': 5.521930837631226}
step: 5890 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 2.6634417, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.883733582496643, 'actor_loss': -4.900091695785522, 'hyper_actor_loss': 0.09026238769292831, 'behavior_loss': 0.290726338326931, 'mean_batch': 5.358109331130981, 'min_batch': 5.013740968704224, 'max_batch': 5.623042106628418}
step: 5900 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 5.038465, 'max_total_reward': 13.450001, 'min_total_reward': 6.7899995, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.166158652305603, 'actor_loss': -4.804983615875244, 'hyper_actor_loss': 0.09055552110075951, 'behavior_loss': 0.30225391685962677, 'mean_batch': 5.1141969680786135, 'min_batch': 4.776575708389283, 'max_batch': 5.354403972625732}
step: 5910 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 2.593481, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.248781996965408, 'actor_loss': -4.813716793060303, 'hyper_actor_loss': 0.09074537679553032, 'behavior_loss': 0.2719444990158081, 'mean_batch': 5.140378952026367, 'min_batch': 4.794103384017944, 'max_batch': 5.394628810882568}
step: 5920 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 2.15504, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4598755478858947, 'actor_loss': -4.888265895843506, 'hyper_actor_loss': 0.09059802815318108, 'behavior_loss': 0.27116305828094484, 'mean_batch': 5.323621320724487, 'min_batch': 4.98743748664856, 'max_batch': 5.60093355178833}
step: 5930 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 5.0384245, 'max_total_reward': 15.56, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.630033004283905, 'actor_loss': -4.903088617324829, 'hyper_actor_loss': 0.09012846946716309, 'behavior_loss': 0.26843572705984114, 'mean_batch': 5.376810789108276, 'min_batch': 5.011071586608887, 'max_batch': 5.654402780532837}
step: 5940 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 4.324504, 'max_total_reward': 13.45, 'min_total_reward': 6.57, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9147522449493408, 'actor_loss': -4.855023384094238, 'hyper_actor_loss': 0.089828272908926, 'behavior_loss': 0.2688835605978966, 'mean_batch': 5.233598089218139, 'min_batch': 4.906742668151855, 'max_batch': 5.5006462097167965}
step: 5950 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 5.997342, 'max_total_reward': 14.56, 'min_total_reward': 5.68, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.15122332572937, 'actor_loss': -4.85044846534729, 'hyper_actor_loss': 0.08973434865474701, 'behavior_loss': 0.2590173050761223, 'mean_batch': 5.211248159408569, 'min_batch': 4.904925060272217, 'max_batch': 5.449147272109985}
step: 5960 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 2.3298633, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9914443612098693, 'actor_loss': -4.871807813644409, 'hyper_actor_loss': 0.08973915502429008, 'behavior_loss': 0.2793553382158279, 'mean_batch': 5.280996036529541, 'min_batch': 4.944841480255127, 'max_batch': 5.5412688732147215}
step: 5970 @ episode report: {'average_total_reward': 9.876, 'reward_variance': 4.1588645, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.30005761384964, 'actor_loss': -4.831163167953491, 'hyper_actor_loss': 0.08998664170503616, 'behavior_loss': 0.28119460940361024, 'mean_batch': 5.190764236450195, 'min_batch': 4.8309547901153564, 'max_batch': 5.437565088272095}
step: 5980 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 3.3457355, 'max_total_reward': 12.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7612515687942505, 'actor_loss': -4.830289649963379, 'hyper_actor_loss': 0.09014681205153466, 'behavior_loss': 0.2711460530757904, 'mean_batch': 5.183803272247315, 'min_batch': 4.833741664886475, 'max_batch': 5.4226349830627445}
step: 5990 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 1.1564171, 'max_total_reward': 12.230001, 'min_total_reward': 8.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7690244913101196, 'actor_loss': -4.886026191711426, 'hyper_actor_loss': 0.09009921625256538, 'behavior_loss': 0.26557898372411726, 'mean_batch': 5.328171682357788, 'min_batch': 4.971426153182984, 'max_batch': 5.569808626174927}
step: 6000 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.7714813, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7512985944747925, 'actor_loss': -4.847679328918457, 'hyper_actor_loss': 0.08996253982186317, 'behavior_loss': 0.27749665826559067, 'mean_batch': 5.245945978164673, 'min_batch': 4.860218858718872, 'max_batch': 5.484873247146607}
step: 6010 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.5263045, 'max_total_reward': 12.340001, 'min_total_reward': 6.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7641854166984559, 'actor_loss': -4.890667057037353, 'hyper_actor_loss': 0.09000808224081994, 'behavior_loss': 0.2902687549591064, 'mean_batch': 5.323945760726929, 'min_batch': 4.998587369918823, 'max_batch': 5.595914745330811}
step: 6020 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 2.0911846, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0921509623527528, 'actor_loss': -4.857272815704346, 'hyper_actor_loss': 0.09012952148914337, 'behavior_loss': 0.287022602558136, 'mean_batch': 5.2309144020080565, 'min_batch': 4.920698547363282, 'max_batch': 5.483780717849731}
step: 6030 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 1.046581, 'max_total_reward': 11.230001, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9088723182678222, 'actor_loss': -4.8478679180145265, 'hyper_actor_loss': 0.09002794176340104, 'behavior_loss': 0.26862277537584306, 'mean_batch': 5.20776743888855, 'min_batch': 4.896132755279541, 'max_batch': 5.452391338348389}
step: 6040 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 2.1709487, 'max_total_reward': 13.45, 'min_total_reward': 7.9000006, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6984750002622604, 'actor_loss': -4.889506101608276, 'hyper_actor_loss': 0.08981226310133934, 'behavior_loss': 0.2643147334456444, 'mean_batch': 5.329154777526855, 'min_batch': 4.987669324874878, 'max_batch': 5.592601776123047}
step: 6050 @ episode report: {'average_total_reward': 9.333, 'reward_variance': 3.163281, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9520691990852357, 'actor_loss': -4.910942506790161, 'hyper_actor_loss': 0.08961659222841263, 'behavior_loss': 0.2677693083882332, 'mean_batch': 5.381350421905518, 'min_batch': 5.046711587905884, 'max_batch': 5.621601247787476}
step: 6060 @ episode report: {'average_total_reward': 10.465001, 'reward_variance': 2.421645, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5214709520339966, 'actor_loss': -4.880971813201905, 'hyper_actor_loss': 0.08950418308377266, 'behavior_loss': 0.2742601573467255, 'mean_batch': 5.320568704605103, 'min_batch': 4.953316164016724, 'max_batch': 5.585655307769775}
step: 6070 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 2.5471008, 'max_total_reward': 12.12, 'min_total_reward': 5.6800003, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3736843407154082, 'actor_loss': -4.92623200416565, 'hyper_actor_loss': 0.08950760066509247, 'behavior_loss': 0.2695220559835434, 'mean_batch': 5.419310474395752, 'min_batch': 5.0888025760650635, 'max_batch': 5.670298624038696}
step: 6080 @ episode report: {'average_total_reward': 10.009001, 'reward_variance': 4.133929, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0344005107879637, 'actor_loss': -4.924389743804932, 'hyper_actor_loss': 0.08954664468765258, 'behavior_loss': 0.27010649889707566, 'mean_batch': 5.4172587394714355, 'min_batch': 5.081756496429444, 'max_batch': 5.698766136169434}
step: 6090 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 3.8017159, 'max_total_reward': 14.339999, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.947244155406952, 'actor_loss': -4.867838287353516, 'hyper_actor_loss': 0.08943898677825927, 'behavior_loss': 0.25585865080356596, 'mean_batch': 5.276092195510865, 'min_batch': 4.930771160125732, 'max_batch': 5.530528783798218}
step: 6100 @ episode report: {'average_total_reward': 10.787001, 'reward_variance': 1.724941, 'max_total_reward': 13.339999, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7215740621089934, 'actor_loss': -4.862288522720337, 'hyper_actor_loss': 0.08942249864339828, 'behavior_loss': 0.28857640027999876, 'mean_batch': 5.276199674606323, 'min_batch': 4.903114318847656, 'max_batch': 5.54041485786438}
step: 6110 @ episode report: {'average_total_reward': 10.564, 'reward_variance': 9.413244, 'max_total_reward': 14.56, 'min_total_reward': 3.46, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0665411949157715, 'actor_loss': -4.898994588851929, 'hyper_actor_loss': 0.08958382830023766, 'behavior_loss': 0.27612283229827883, 'mean_batch': 5.377040815353394, 'min_batch': 4.991128015518188, 'max_batch': 5.628738021850586}
step: 6120 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 2.7286196, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7321201682090759, 'actor_loss': -4.866369676589966, 'hyper_actor_loss': 0.08971754536032676, 'behavior_loss': 0.29124060422182085, 'mean_batch': 5.264799022674561, 'min_batch': 4.933332824707032, 'max_batch': 5.521957063674927}
step: 6130 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 1.9763607, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.764027151465416, 'actor_loss': -4.9008166790008545, 'hyper_actor_loss': 0.08983131349086762, 'behavior_loss': 0.2934814736247063, 'mean_batch': 5.35550971031189, 'min_batch': 5.0193564891815186, 'max_batch': 5.600156021118164}
step: 6140 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 7.866376, 'max_total_reward': 12.340001, 'min_total_reward': 1.9100001, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.92659450173378, 'actor_loss': -4.9038779735565186, 'hyper_actor_loss': 0.08972275853157044, 'behavior_loss': 0.27672541290521624, 'mean_batch': 5.355940246582032, 'min_batch': 5.034388828277588, 'max_batch': 5.619555902481079}
step: 6150 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 3.456529, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.073373484611511, 'actor_loss': -4.838742780685425, 'hyper_actor_loss': 0.08943952545523644, 'behavior_loss': 0.27873738408088683, 'mean_batch': 5.201774072647095, 'min_batch': 4.856861209869384, 'max_batch': 5.4492823600769045}
step: 6160 @ episode report: {'average_total_reward': 10.687001, 'reward_variance': 1.133601, 'max_total_reward': 12.340001, 'min_total_reward': 8.68, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8994857847690583, 'actor_loss': -4.898931789398193, 'hyper_actor_loss': 0.08930652737617492, 'behavior_loss': 0.26883613914251325, 'mean_batch': 5.356932592391968, 'min_batch': 5.009232759475708, 'max_batch': 5.597555303573609}
step: 6170 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.8835217, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0914369225502014, 'actor_loss': -4.8984967231750485, 'hyper_actor_loss': 0.08900277689099312, 'behavior_loss': 0.26231044679880144, 'mean_batch': 5.3543885231018065, 'min_batch': 5.010244607925415, 'max_batch': 5.596263408660889}
step: 6180 @ episode report: {'average_total_reward': 11.264, 'reward_variance': 1.340625, 'max_total_reward': 13.450001, 'min_total_reward': 10.009999, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.578017735481262, 'actor_loss': -4.795281457901001, 'hyper_actor_loss': 0.08884517848491669, 'behavior_loss': 0.2739355996251106, 'mean_batch': 5.066508007049561, 'min_batch': 4.774910116195679, 'max_batch': 5.280992746353149}
step: 6190 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 8.204056, 'max_total_reward': 13.23, 'min_total_reward': 2.46, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8662104845046996, 'actor_loss': -4.844925403594971, 'hyper_actor_loss': 0.08892623186111451, 'behavior_loss': 0.2716915398836136, 'mean_batch': 5.188986301422119, 'min_batch': 4.901215076446533, 'max_batch': 5.421679067611694}
step: 6200 @ episode report: {'average_total_reward': 11.641001, 'reward_variance': 3.9261699, 'max_total_reward': 14.559999, 'min_total_reward': 7.8999996, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0384533524513246, 'actor_loss': -4.912398958206177, 'hyper_actor_loss': 0.08901948183774948, 'behavior_loss': 0.271992489695549, 'mean_batch': 5.37042088508606, 'min_batch': 5.06386284828186, 'max_batch': 5.605402135848999}
step: 6210 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 11.001017, 'max_total_reward': 13.45, 'min_total_reward': 1.02, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9636973023414612, 'actor_loss': -4.866472244262695, 'hyper_actor_loss': 0.08906257450580597, 'behavior_loss': 0.2723958626389503, 'mean_batch': 5.25751838684082, 'min_batch': 4.941209554672241, 'max_batch': 5.505274772644043}
step: 6220 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 2.8837764, 'max_total_reward': 13.340001, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1873677492141725, 'actor_loss': -4.846095561981201, 'hyper_actor_loss': 0.08899352326989174, 'behavior_loss': 0.27045412361621857, 'mean_batch': 5.20253267288208, 'min_batch': 4.891997957229615, 'max_batch': 5.4463804244995115}
step: 6230 @ episode report: {'average_total_reward': 9.244, 'reward_variance': 9.975284, 'max_total_reward': 13.45, 'min_total_reward': 0.90999997, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8584295511245728, 'actor_loss': -4.8430522918701175, 'hyper_actor_loss': 0.0890082523226738, 'behavior_loss': 0.26300042420625686, 'mean_batch': 5.194016933441162, 'min_batch': 4.885575771331787, 'max_batch': 5.429210233688354}
step: 6240 @ episode report: {'average_total_reward': 11.686, 'reward_variance': 0.9578438, 'max_total_reward': 13.23, 'min_total_reward': 10.01, 'average_n_step': 12.5, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8459710359573365, 'actor_loss': -4.912035751342773, 'hyper_actor_loss': 0.08876315131783485, 'behavior_loss': 0.27659629881381986, 'mean_batch': 5.376607990264892, 'min_batch': 5.056570291519165, 'max_batch': 5.613283634185791}
step: 6250 @ episode report: {'average_total_reward': 11.153001, 'reward_variance': 2.9668412, 'max_total_reward': 15.67, 'min_total_reward': 10.009999, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2591436862945558, 'actor_loss': -4.834357595443725, 'hyper_actor_loss': 0.08883636593818664, 'behavior_loss': 0.27675613164901736, 'mean_batch': 5.149401473999023, 'min_batch': 4.885608959197998, 'max_batch': 5.382377672195434}
step: 6260 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.857884, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.091974651813507, 'actor_loss': -4.816797542572021, 'hyper_actor_loss': 0.08889872431755066, 'behavior_loss': 0.26543360352516177, 'mean_batch': 5.123967790603638, 'min_batch': 4.824186515808106, 'max_batch': 5.335790061950684}
step: 6270 @ episode report: {'average_total_reward': 11.264001, 'reward_variance': 1.9335645, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1424554109573366, 'actor_loss': -4.87473349571228, 'hyper_actor_loss': 0.08882100731134415, 'behavior_loss': 0.29091692715883255, 'mean_batch': 5.271051979064941, 'min_batch': 4.968728065490723, 'max_batch': 5.488055467605591}
step: 6280 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 1.8545841, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.866941797733307, 'actor_loss': -4.832140064239502, 'hyper_actor_loss': 0.08893747180700302, 'behavior_loss': 0.26384069174528124, 'mean_batch': 5.1741386413574215, 'min_batch': 4.850830984115601, 'max_batch': 5.388829135894776}
step: 6290 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 3.4158797, 'max_total_reward': 14.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7488189697265626, 'actor_loss': -4.884984111785888, 'hyper_actor_loss': 0.08903592303395272, 'behavior_loss': 0.2699339359998703, 'mean_batch': 5.292375659942627, 'min_batch': 4.99946961402893, 'max_batch': 5.526234149932861}
step: 6300 @ episode report: {'average_total_reward': 10.109001, 'reward_variance': 4.809809, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5389883548021317, 'actor_loss': -4.920356607437133, 'hyper_actor_loss': 0.0888812005519867, 'behavior_loss': 0.288543538749218, 'mean_batch': 5.389055395126343, 'min_batch': 5.086748027801514, 'max_batch': 5.617071723937988}
step: 6310 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 1.8980618, 'max_total_reward': 13.340001, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.833457612991333, 'actor_loss': -4.885746479034424, 'hyper_actor_loss': 0.08894153088331222, 'behavior_loss': 0.27121078222990036, 'mean_batch': 5.2898307800292965, 'min_batch': 5.005825662612915, 'max_batch': 5.501778697967529}
step: 6320 @ episode report: {'average_total_reward': 10.5529995, 'reward_variance': 5.1641207, 'max_total_reward': 14.559999, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6935571670532226, 'actor_loss': -4.858343172073364, 'hyper_actor_loss': 0.08879590332508087, 'behavior_loss': 0.27313235104084016, 'mean_batch': 5.227674198150635, 'min_batch': 4.929000806808472, 'max_batch': 5.460151290893554}
step: 6330 @ episode report: {'average_total_reward': 9.21, 'reward_variance': 16.84814, 'max_total_reward': 15.670001, 'min_total_reward': 1.13, 'average_n_step': 10.2, 'max_n_step': 16.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.002183258533478, 'actor_loss': -4.866421031951904, 'hyper_actor_loss': 0.08889875188469887, 'behavior_loss': 0.28435877412557603, 'mean_batch': 5.256311702728271, 'min_batch': 4.941388368606567, 'max_batch': 5.4649676322937015}
step: 6340 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 2.83746, 'max_total_reward': 12.12, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6159456729888917, 'actor_loss': -4.8815795421600345, 'hyper_actor_loss': 0.08864054009318352, 'behavior_loss': 0.2674471586942673, 'mean_batch': 5.266981887817383, 'min_batch': 5.006697654724121, 'max_batch': 5.488189554214477}
step: 6350 @ episode report: {'average_total_reward': 10.375999, 'reward_variance': 2.3620243, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8869012266397476, 'actor_loss': -4.898888635635376, 'hyper_actor_loss': 0.08871247470378876, 'behavior_loss': 0.2770650818943977, 'mean_batch': 5.318451309204102, 'min_batch': 5.044502019882202, 'max_batch': 5.534489297866822}
step: 6360 @ episode report: {'average_total_reward': 10.764, 'reward_variance': 3.6083026, 'max_total_reward': 13.339999, 'min_total_reward': 6.9000006, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.064579099416733, 'actor_loss': -4.853007411956787, 'hyper_actor_loss': 0.08873778209090233, 'behavior_loss': 0.2807140603661537, 'mean_batch': 5.205860376358032, 'min_batch': 4.923671102523803, 'max_batch': 5.416575813293457}
step: 6370 @ episode report: {'average_total_reward': 11.619, 'reward_variance': 2.0969288, 'max_total_reward': 13.45, 'min_total_reward': 10.01, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8381236672401429, 'actor_loss': -4.886728191375733, 'hyper_actor_loss': 0.08862190246582032, 'behavior_loss': 0.26663370430469513, 'mean_batch': 5.287532997131348, 'min_batch': 5.013192367553711, 'max_batch': 5.502347469329834}
step: 6380 @ episode report: {'average_total_reward': 11.752, 'reward_variance': 4.265497, 'max_total_reward': 15.56, 'min_total_reward': 8.9, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.722087013721466, 'actor_loss': -4.882524538040161, 'hyper_actor_loss': 0.08856052532792091, 'behavior_loss': 0.27239890396595, 'mean_batch': 5.276837396621704, 'min_batch': 5.0020195007324215, 'max_batch': 5.4729883670806885}
step: 6390 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 7.235265, 'max_total_reward': 13.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1507450103759767, 'actor_loss': -4.875013065338135, 'hyper_actor_loss': 0.08848978877067566, 'behavior_loss': 0.28647723197937014, 'mean_batch': 5.263553810119629, 'min_batch': 4.977408599853516, 'max_batch': 5.485017919540406}
step: 6400 @ episode report: {'average_total_reward': 9.877001, 'reward_variance': 2.788881, 'max_total_reward': 12.23, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.308488118648529, 'actor_loss': -4.814425706863403, 'hyper_actor_loss': 0.08853005319833755, 'behavior_loss': 0.2724447429180145, 'mean_batch': 5.102774000167846, 'min_batch': 4.832162237167358, 'max_batch': 5.297262716293335}
step: 6410 @ episode report: {'average_total_reward': 10.131999, 'reward_variance': 2.8322556, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9066728413105012, 'actor_loss': -4.833618402481079, 'hyper_actor_loss': 0.08856648206710815, 'behavior_loss': 0.2746960684657097, 'mean_batch': 5.148026943206787, 'min_batch': 4.883398580551147, 'max_batch': 5.346968412399292}
step: 6420 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 2.4861958, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.251703155040741, 'actor_loss': -4.891701555252075, 'hyper_actor_loss': 0.08847670182585717, 'behavior_loss': 0.28622264564037325, 'mean_batch': 5.321776294708252, 'min_batch': 5.005394172668457, 'max_batch': 5.5302904605865475}
step: 6430 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 5.5786448, 'max_total_reward': 14.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9539479553699493, 'actor_loss': -4.824422359466553, 'hyper_actor_loss': 0.08849290460348129, 'behavior_loss': 0.2758869528770447, 'mean_batch': 5.122924566268921, 'min_batch': 4.861375856399536, 'max_batch': 5.319470596313477}
step: 6440 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 7.6514397, 'max_total_reward': 15.67, 'min_total_reward': 4.57, 'average_n_step': 10.3, 'max_n_step': 16.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.737464678287506, 'actor_loss': -4.856827926635742, 'hyper_actor_loss': 0.08838729858398438, 'behavior_loss': 0.2649075284600258, 'mean_batch': 5.221574354171753, 'min_batch': 4.927247333526611, 'max_batch': 5.436921501159668}
step: 6450 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 3.6213486, 'max_total_reward': 15.67, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0408584594726564, 'actor_loss': -4.885546541213989, 'hyper_actor_loss': 0.08830284401774406, 'behavior_loss': 0.27254289835691453, 'mean_batch': 5.302792882919311, 'min_batch': 4.992767381668091, 'max_batch': 5.509270286560058}
step: 6460 @ episode report: {'average_total_reward': 10.431002, 'reward_variance': 2.4442701, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.832297158241272, 'actor_loss': -4.850400590896607, 'hyper_actor_loss': 0.08841821551322937, 'behavior_loss': 0.2862643077969551, 'mean_batch': 5.191323614120483, 'min_batch': 4.923374032974243, 'max_batch': 5.402543020248413}
step: 6470 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 1.4570044, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.793321669101715, 'actor_loss': -4.873083305358887, 'hyper_actor_loss': 0.08837273120880126, 'behavior_loss': 0.27766737192869184, 'mean_batch': 5.238554525375366, 'min_batch': 4.991067886352539, 'max_batch': 5.446265840530396}
step: 6480 @ episode report: {'average_total_reward': 11.364, 'reward_variance': 5.2202244, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6604655623435973, 'actor_loss': -4.878319883346558, 'hyper_actor_loss': 0.08833965957164765, 'behavior_loss': 0.26621161550283434, 'mean_batch': 5.27243390083313, 'min_batch': 4.98553957939148, 'max_batch': 5.466829538345337}
step: 6490 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 3.1626859, 'max_total_reward': 14.56, 'min_total_reward': 8.68, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.340829074382782, 'actor_loss': -4.922639989852906, 'hyper_actor_loss': 0.08809952586889266, 'behavior_loss': 0.2733399882912636, 'mean_batch': 5.391973257064819, 'min_batch': 5.095598983764648, 'max_batch': 5.610235357284546}
step: 6500 @ episode report: {'average_total_reward': 9.764999, 'reward_variance': 7.6921043, 'max_total_reward': 12.339999, 'min_total_reward': 2.46, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.058979943394661, 'actor_loss': -4.89905161857605, 'hyper_actor_loss': 0.08801505267620087, 'behavior_loss': 0.280009451508522, 'mean_batch': 5.310463809967041, 'min_batch': 5.054104280471802, 'max_batch': 5.5201746940612795}
step: 6510 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 3.7399642, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1442172169685363, 'actor_loss': -4.805925416946411, 'hyper_actor_loss': 0.08811690285801888, 'behavior_loss': 0.27971922010183337, 'mean_batch': 5.073292922973633, 'min_batch': 4.8191088199615475, 'max_batch': 5.261079978942871}
step: 6520 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 4.30219, 'max_total_reward': 14.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7908055305480957, 'actor_loss': -4.881409692764282, 'hyper_actor_loss': 0.0881592333316803, 'behavior_loss': 0.26422514766454697, 'mean_batch': 5.279804515838623, 'min_batch': 4.9945779800415036, 'max_batch': 5.478389596939087}
step: 6530 @ episode report: {'average_total_reward': 10.631, 'reward_variance': 3.441129, 'max_total_reward': 14.450001, 'min_total_reward': 7.9000006, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7352080762386322, 'actor_loss': -4.913878536224365, 'hyper_actor_loss': 0.08799642994999886, 'behavior_loss': 0.26832381039857867, 'mean_batch': 5.361187410354614, 'min_batch': 5.080064487457276, 'max_batch': 5.583493328094482}
step: 6540 @ episode report: {'average_total_reward': 10.831001, 'reward_variance': 1.9694694, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9369842767715455, 'actor_loss': -4.849603700637817, 'hyper_actor_loss': 0.08791696056723594, 'behavior_loss': 0.2889449134469032, 'mean_batch': 5.184948205947876, 'min_batch': 4.925814914703369, 'max_batch': 5.377610445022583}
step: 6550 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 4.7117243, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9223531126976012, 'actor_loss': -4.847225141525269, 'hyper_actor_loss': 0.08798042982816696, 'behavior_loss': 0.25484350323677063, 'mean_batch': 5.181012535095215, 'min_batch': 4.917865657806397, 'max_batch': 5.377928447723389}
step: 6560 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 3.5484893, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.741327029466629, 'actor_loss': -4.892225885391236, 'hyper_actor_loss': 0.08769020214676856, 'behavior_loss': 0.26617331355810164, 'mean_batch': 5.309516477584839, 'min_batch': 5.019762229919434, 'max_batch': 5.505085134506226}
step: 6570 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 2.1951165, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2267709195613863, 'actor_loss': -4.859856414794922, 'hyper_actor_loss': 0.0875961311161518, 'behavior_loss': 0.27582399994134904, 'mean_batch': 5.202551460266113, 'min_batch': 4.960261392593384, 'max_batch': 5.385864686965943}
step: 6580 @ episode report: {'average_total_reward': 10.164999, 'reward_variance': 4.0980043, 'max_total_reward': 13.339999, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.201905447244644, 'actor_loss': -4.791180419921875, 'hyper_actor_loss': 0.08775289356708527, 'behavior_loss': 0.2636441469192505, 'mean_batch': 5.035240697860718, 'min_batch': 4.784177160263061, 'max_batch': 5.219573020935059}
step: 6590 @ episode report: {'average_total_reward': 11.619, 'reward_variance': 5.17829, 'max_total_reward': 15.67, 'min_total_reward': 7.9, 'average_n_step': 12.4, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1432794451713564, 'actor_loss': -4.853847408294678, 'hyper_actor_loss': 0.08770985305309295, 'behavior_loss': 0.2871182501316071, 'mean_batch': 5.211574268341065, 'min_batch': 4.921730184555054, 'max_batch': 5.41378173828125}
step: 6600 @ episode report: {'average_total_reward': 11.486, 'reward_variance': 2.0911849, 'max_total_reward': 13.450001, 'min_total_reward': 9.9, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8958072900772094, 'actor_loss': -4.855606269836426, 'hyper_actor_loss': 0.08787131607532501, 'behavior_loss': 0.27360995262861254, 'mean_batch': 5.204439926147461, 'min_batch': 4.937040615081787, 'max_batch': 5.401235723495484}
step: 6610 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 5.594184, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4772473871707916, 'actor_loss': -4.883335590362549, 'hyper_actor_loss': 0.08778101652860641, 'behavior_loss': 0.2571290284395218, 'mean_batch': 5.2770082473754885, 'min_batch': 5.006196594238281, 'max_batch': 5.479778814315796}
step: 6620 @ episode report: {'average_total_reward': 10.731, 'reward_variance': 1.9992491, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8967211246490479, 'actor_loss': -4.885086870193481, 'hyper_actor_loss': 0.08752959296107292, 'behavior_loss': 0.28342087715864184, 'mean_batch': 5.278115367889404, 'min_batch': 5.013954019546508, 'max_batch': 5.459046936035156}
step: 6630 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.7202613, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.792618191242218, 'actor_loss': -4.8653065204620365, 'hyper_actor_loss': 0.0874884307384491, 'behavior_loss': 0.2812802538275719, 'mean_batch': 5.219392013549805, 'min_batch': 4.970654630661011, 'max_batch': 5.388250684738159}
step: 6640 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 6.606716, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0544615983963013, 'actor_loss': -4.856556701660156, 'hyper_actor_loss': 0.08777427449822425, 'behavior_loss': 0.2705472245812416, 'mean_batch': 5.199685335159302, 'min_batch': 4.946390771865845, 'max_batch': 5.392377662658691}
step: 6650 @ episode report: {'average_total_reward': 10.986, 'reward_variance': 2.8999248, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.728263944387436, 'actor_loss': -4.869669628143311, 'hyper_actor_loss': 0.08770304471254349, 'behavior_loss': 0.260423880815506, 'mean_batch': 5.254962015151977, 'min_batch': 4.9587788581848145, 'max_batch': 5.454211473464966}
step: 6660 @ episode report: {'average_total_reward': 11.153, 'reward_variance': 1.7371609, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7946144342422485, 'actor_loss': -4.873782539367676, 'hyper_actor_loss': 0.08756601959466934, 'behavior_loss': 0.27564214915037155, 'mean_batch': 5.262898969650268, 'min_batch': 4.971741104125977, 'max_batch': 5.462594842910766}
step: 6670 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 3.0818896, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.87127126455307, 'actor_loss': -4.8860045909881595, 'hyper_actor_loss': 0.08750663846731185, 'behavior_loss': 0.2709698364138603, 'mean_batch': 5.269197750091553, 'min_batch': 5.02675952911377, 'max_batch': 5.477256011962891}
step: 6680 @ episode report: {'average_total_reward': 9.910001, 'reward_variance': 2.2662, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.865827453136444, 'actor_loss': -4.8821207046508786, 'hyper_actor_loss': 0.08737350031733512, 'behavior_loss': 0.27201489806175233, 'mean_batch': 5.262046527862549, 'min_batch': 5.013802719116211, 'max_batch': 5.482349395751953}
step: 6690 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 4.821141, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9166405081748963, 'actor_loss': -4.871348667144775, 'hyper_actor_loss': 0.08742979988455772, 'behavior_loss': 0.28350573480129243, 'mean_batch': 5.239942502975464, 'min_batch': 4.981085014343262, 'max_batch': 5.435938882827759}
step: 6700 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.5245247, 'max_total_reward': 12.340001, 'min_total_reward': 7.57, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.908713710308075, 'actor_loss': -4.860038900375367, 'hyper_actor_loss': 0.0875528909265995, 'behavior_loss': 0.27773417532444, 'mean_batch': 5.205098056793213, 'min_batch': 4.958040332794189, 'max_batch': 5.3882355213165285}
step: 6710 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 3.4531407, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.104455029964447, 'actor_loss': -4.8609192848205565, 'hyper_actor_loss': 0.08758638352155686, 'behavior_loss': 0.2895023226737976, 'mean_batch': 5.21277642250061, 'min_batch': 4.955246543884277, 'max_batch': 5.400917673110962}
step: 6720 @ episode report: {'average_total_reward': 11.308001, 'reward_variance': 4.975896, 'max_total_reward': 15.559999, 'min_total_reward': 7.8999996, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9262315273284911, 'actor_loss': -4.854050540924073, 'hyper_actor_loss': 0.08760742023587227, 'behavior_loss': 0.28879413306713103, 'mean_batch': 5.175446367263794, 'min_batch': 4.9565544605255125, 'max_batch': 5.368464422225952}
step: 6730 @ episode report: {'average_total_reward': 11.397001, 'reward_variance': 4.4161406, 'max_total_reward': 15.559999, 'min_total_reward': 8.789999, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.623678243160248, 'actor_loss': -4.878559923171997, 'hyper_actor_loss': 0.08764804303646087, 'behavior_loss': 0.2672859400510788, 'mean_batch': 5.262860059738159, 'min_batch': 4.9957802295684814, 'max_batch': 5.458030700683594}
step: 6740 @ episode report: {'average_total_reward': 11.120001, 'reward_variance': 2.4494596, 'max_total_reward': 13.339999, 'min_total_reward': 8.679999, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5332775950431823, 'actor_loss': -4.922604084014893, 'hyper_actor_loss': 0.08747797831892967, 'behavior_loss': 0.2793169140815735, 'mean_batch': 5.371260499954223, 'min_batch': 5.115204334259033, 'max_batch': 5.5643072605133055}
step: 6750 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 4.8536487, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0146460056304933, 'actor_loss': -4.875027084350586, 'hyper_actor_loss': 0.0872353509068489, 'behavior_loss': 0.27802369743585587, 'mean_batch': 5.23256139755249, 'min_batch': 5.007432365417481, 'max_batch': 5.438990783691406}
step: 6760 @ episode report: {'average_total_reward': 10.364, 'reward_variance': 3.7390838, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7089104324579238, 'actor_loss': -4.89473524093628, 'hyper_actor_loss': 0.08719077482819557, 'behavior_loss': 0.2778868541121483, 'mean_batch': 5.281872701644898, 'min_batch': 5.05867190361023, 'max_batch': 5.469239902496338}
step: 6770 @ episode report: {'average_total_reward': 10.398, 'reward_variance': 5.0804768, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.213588237762451, 'actor_loss': -4.864846801757812, 'hyper_actor_loss': 0.08715537488460541, 'behavior_loss': 0.2824111208319664, 'mean_batch': 5.233871841430664, 'min_batch': 4.955039310455322, 'max_batch': 5.434802436828614}
step: 6780 @ episode report: {'average_total_reward': 11.453, 'reward_variance': 2.6981025, 'max_total_reward': 15.340001, 'min_total_reward': 10.12, 'average_n_step': 12.3, 'max_n_step': 16.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5287736892700194, 'actor_loss': -4.842828416824341, 'hyper_actor_loss': 0.08712255209684372, 'behavior_loss': 0.26606515496969224, 'mean_batch': 5.168711614608765, 'min_batch': 4.907887363433838, 'max_batch': 5.348425006866455}
step: 6790 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 2.6397767, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7879836916923524, 'actor_loss': -4.911256790161133, 'hyper_actor_loss': 0.08684351593255997, 'behavior_loss': 0.26301569789648055, 'mean_batch': 5.3385735034942625, 'min_batch': 5.088102912902832, 'max_batch': 5.508027029037476}
step: 6800 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 3.4572244, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7709694623947143, 'actor_loss': -4.871266508102417, 'hyper_actor_loss': 0.08671098202466965, 'behavior_loss': 0.2715741336345673, 'mean_batch': 5.242367076873779, 'min_batch': 4.979052495956421, 'max_batch': 5.410252380371094}
step: 6810 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.571521, 'max_total_reward': 14.34, 'min_total_reward': 8.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9129446625709534, 'actor_loss': -4.898289823532105, 'hyper_actor_loss': 0.08662212416529655, 'behavior_loss': 0.2616452068090439, 'mean_batch': 5.299647188186645, 'min_batch': 5.059680652618408, 'max_batch': 5.471240568161011}
step: 6820 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 3.395184, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.967706573009491, 'actor_loss': -4.8727357387542725, 'hyper_actor_loss': 0.0865494191646576, 'behavior_loss': 0.2684197574853897, 'mean_batch': 5.2241373538970945, 'min_batch': 5.00339937210083, 'max_batch': 5.388613700866699}
step: 6830 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 3.3318603, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9782122135162354, 'actor_loss': -4.855321979522705, 'hyper_actor_loss': 0.08662985265254974, 'behavior_loss': 0.27131716161966324, 'mean_batch': 5.191584682464599, 'min_batch': 4.947576379776001, 'max_batch': 5.364045667648315}
step: 6840 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 4.7733297, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4760460078716278, 'actor_loss': -4.899139499664306, 'hyper_actor_loss': 0.08676406741142273, 'behavior_loss': 0.2639188513159752, 'mean_batch': 5.304829788208008, 'min_batch': 5.0601438045501705, 'max_batch': 5.490353584289551}
step: 6850 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.877517, 'max_total_reward': 14.56, 'min_total_reward': 8.68, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0020122647285463, 'actor_loss': -4.91388955116272, 'hyper_actor_loss': 0.0865179419517517, 'behavior_loss': 0.2618972957134247, 'mean_batch': 5.346195316314697, 'min_batch': 5.094841575622558, 'max_batch': 5.521577024459839}
step: 6860 @ episode report: {'average_total_reward': 10.776001, 'reward_variance': 2.5068042, 'max_total_reward': 14.450001, 'min_total_reward': 8.68, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8151965975761413, 'actor_loss': -4.848713350296021, 'hyper_actor_loss': 0.08639872893691063, 'behavior_loss': 0.26680774092674253, 'mean_batch': 5.166064596176147, 'min_batch': 4.939288187026977, 'max_batch': 5.328276634216309}
step: 6870 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.919484, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7073074936866761, 'actor_loss': -4.886484146118164, 'hyper_actor_loss': 0.08648289293050766, 'behavior_loss': 0.2720234230160713, 'mean_batch': 5.2648721694946286, 'min_batch': 5.033271026611328, 'max_batch': 5.4393480777740475}
step: 6880 @ episode report: {'average_total_reward': 9.454, 'reward_variance': 2.6402242, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8337967276573182, 'actor_loss': -4.888741827011108, 'hyper_actor_loss': 0.08649237528443336, 'behavior_loss': 0.2719057410955429, 'mean_batch': 5.276849603652954, 'min_batch': 5.033043289184571, 'max_batch': 5.447398090362549}
step: 6890 @ episode report: {'average_total_reward': 11.064, 'reward_variance': 2.941484, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5429577708244324, 'actor_loss': -4.893481302261352, 'hyper_actor_loss': 0.08651650696992874, 'behavior_loss': 0.26412069499492646, 'mean_batch': 5.296673822402954, 'min_batch': 5.038198947906494, 'max_batch': 5.465955591201782}
step: 6900 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.9735844, 'max_total_reward': 13.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0062505543231963, 'actor_loss': -4.898538208007812, 'hyper_actor_loss': 0.08656186759471893, 'behavior_loss': 0.27722926437854767, 'mean_batch': 5.318197536468506, 'min_batch': 5.043033647537231, 'max_batch': 5.495483350753784}
step: 6910 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 3.8669574, 'max_total_reward': 13.340001, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9814318299293519, 'actor_loss': -4.8507946014404295, 'hyper_actor_loss': 0.08664873391389846, 'behavior_loss': 0.26991226673126223, 'mean_batch': 5.182134008407592, 'min_batch': 4.934509134292602, 'max_batch': 5.3505322456359865}
step: 6920 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 2.2152762, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.021088683605194, 'actor_loss': -4.882491493225098, 'hyper_actor_loss': 0.08653400614857673, 'behavior_loss': 0.25855486243963244, 'mean_batch': 5.2502062797546385, 'min_batch': 5.027295064926148, 'max_batch': 5.40821270942688}
step: 6930 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 2.9713244, 'max_total_reward': 14.559999, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.104818344116211, 'actor_loss': -4.852142333984375, 'hyper_actor_loss': 0.08637267574667931, 'behavior_loss': 0.28843663036823275, 'mean_batch': 5.1727746486663815, 'min_batch': 4.949969673156739, 'max_batch': 5.3353911399841305}
step: 6940 @ episode report: {'average_total_reward': 9.676001, 'reward_variance': 3.777064, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7861709356307984, 'actor_loss': -4.849817180633545, 'hyper_actor_loss': 0.0865272305905819, 'behavior_loss': 0.27479273825883865, 'mean_batch': 5.177992677688598, 'min_batch': 4.933954286575317, 'max_batch': 5.339245223999024}
step: 6950 @ episode report: {'average_total_reward': 8.111, 'reward_variance': 3.5113091, 'max_total_reward': 12.2300005, 'min_total_reward': 5.57, 'average_n_step': 9.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1415293395519255, 'actor_loss': -4.877159833908081, 'hyper_actor_loss': 0.08671391382813454, 'behavior_loss': 0.2927676782011986, 'mean_batch': 5.240638160705567, 'min_batch': 5.009406995773316, 'max_batch': 5.4012621402740475}
step: 6960 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 1.1327212, 'max_total_reward': 12.2300005, 'min_total_reward': 8.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9100711405277253, 'actor_loss': -4.830484294891358, 'hyper_actor_loss': 0.08678481578826905, 'behavior_loss': 0.2713243380188942, 'mean_batch': 5.133598184585571, 'min_batch': 4.880910634994507, 'max_batch': 5.299495124816895}
step: 6970 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 4.8286448, 'max_total_reward': 14.56, 'min_total_reward': 7.7899995, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8530162870883942, 'actor_loss': -4.867689514160157, 'hyper_actor_loss': 0.08660645335912705, 'behavior_loss': 0.2693631276488304, 'mean_batch': 5.216525363922119, 'min_batch': 4.985158205032349, 'max_batch': 5.368064832687378}
step: 6980 @ episode report: {'average_total_reward': 11.519, 'reward_variance': 3.5920894, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5641153216362, 'actor_loss': -4.896270513534546, 'hyper_actor_loss': 0.0863879531621933, 'behavior_loss': 0.26578686088323594, 'mean_batch': 5.293560314178467, 'min_batch': 5.05547571182251, 'max_batch': 5.460870599746704}
step: 6990 @ episode report: {'average_total_reward': 10.098, 'reward_variance': 4.486335, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8318955719470977, 'actor_loss': -4.902295637130737, 'hyper_actor_loss': 0.08616821393370629, 'behavior_loss': 0.2741452783346176, 'mean_batch': 5.31049075126648, 'min_batch': 5.069307661056518, 'max_batch': 5.476255416870117}
step: 7000 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.565484, 'max_total_reward': 12.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.98854101896286, 'actor_loss': -4.862525939941406, 'hyper_actor_loss': 0.08619243875145913, 'behavior_loss': 0.2618215814232826, 'mean_batch': 5.1902752876281735, 'min_batch': 4.98501181602478, 'max_batch': 5.344085645675659}
step: 7010 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 2.216289, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6938305020332336, 'actor_loss': -4.858579540252686, 'hyper_actor_loss': 0.0862695887684822, 'behavior_loss': 0.26209317445755004, 'mean_batch': 5.175715637207031, 'min_batch': 4.979313611984253, 'max_batch': 5.345546007156372}
step: 7020 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 5.540016, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4773094654083252, 'actor_loss': -4.913615083694458, 'hyper_actor_loss': 0.08621960133314133, 'behavior_loss': 0.28374564945697783, 'mean_batch': 5.33924617767334, 'min_batch': 5.099458360671997, 'max_batch': 5.513654994964599}
step: 7030 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 2.2036414, 'max_total_reward': 13.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9348442554473877, 'actor_loss': -4.891590261459351, 'hyper_actor_loss': 0.08625579848885537, 'behavior_loss': 0.24754708707332612, 'mean_batch': 5.273323726654053, 'min_batch': 5.052267169952392, 'max_batch': 5.424643898010254}
step: 7040 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.4308963, 'max_total_reward': 13.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7630330562591552, 'actor_loss': -4.864059734344482, 'hyper_actor_loss': 0.08610144183039665, 'behavior_loss': 0.2598140686750412, 'mean_batch': 5.192997169494629, 'min_batch': 4.989483404159546, 'max_batch': 5.33431487083435}
step: 7050 @ episode report: {'average_total_reward': 10.698001, 'reward_variance': 3.3521168, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9557559549808503, 'actor_loss': -4.886835718154908, 'hyper_actor_loss': 0.08589547276496887, 'behavior_loss': 0.2777455702424049, 'mean_batch': 5.247221803665161, 'min_batch': 5.0517411708831785, 'max_batch': 5.398085212707519}
step: 7060 @ episode report: {'average_total_reward': 9.754, 'reward_variance': 3.9890847, 'max_total_reward': 12.2300005, 'min_total_reward': 4.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7854614913463593, 'actor_loss': -4.883536243438721, 'hyper_actor_loss': 0.08606522977352142, 'behavior_loss': 0.26527500748634336, 'mean_batch': 5.247331190109253, 'min_batch': 5.035105752944946, 'max_batch': 5.406706666946411}
step: 7070 @ episode report: {'average_total_reward': 9.343, 'reward_variance': 3.940101, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9444737553596496, 'actor_loss': -4.876308012008667, 'hyper_actor_loss': 0.08607405126094818, 'behavior_loss': 0.2840865418314934, 'mean_batch': 5.220922422409058, 'min_batch': 5.024071979522705, 'max_batch': 5.377831029891968}
step: 7080 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 4.835749, 'max_total_reward': 13.01, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7436411499977111, 'actor_loss': -4.868183994293213, 'hyper_actor_loss': 0.08607060834765434, 'behavior_loss': 0.268101641535759, 'mean_batch': 5.203438854217529, 'min_batch': 5.000262832641601, 'max_batch': 5.359033536911011}
step: 7090 @ episode report: {'average_total_reward': 10.709001, 'reward_variance': 4.00669, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.095275676250458, 'actor_loss': -4.869219255447388, 'hyper_actor_loss': 0.08621629998087883, 'behavior_loss': 0.27617754489183427, 'mean_batch': 5.205487251281738, 'min_batch': 5.0035741329193115, 'max_batch': 5.3506019592285154}
step: 7100 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 4.970124, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0844064712524415, 'actor_loss': -4.8474925518035885, 'hyper_actor_loss': 0.08609822541475295, 'behavior_loss': 0.266099913418293, 'mean_batch': 5.153655052185059, 'min_batch': 4.945052623748779, 'max_batch': 5.302063131332398}
step: 7110 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 6.241896, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.814335823059082, 'actor_loss': -4.852644538879394, 'hyper_actor_loss': 0.08596216514706612, 'behavior_loss': 0.2825815439224243, 'mean_batch': 5.1610150814056395, 'min_batch': 4.963636445999145, 'max_batch': 5.312393140792847}
step: 7120 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 3.6142895, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9870769381523132, 'actor_loss': -4.860110473632813, 'hyper_actor_loss': 0.08595950454473496, 'behavior_loss': 0.2517231062054634, 'mean_batch': 5.188446569442749, 'min_batch': 4.974291467666626, 'max_batch': 5.3358251571655275}
step: 7130 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.4786406, 'max_total_reward': 13.12, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1044646918773653, 'actor_loss': -4.844629526138306, 'hyper_actor_loss': 0.08583205342292785, 'behavior_loss': 0.2783402860164642, 'mean_batch': 5.1304543018341064, 'min_batch': 4.953216075897217, 'max_batch': 5.277764844894409}
step: 7140 @ episode report: {'average_total_reward': 11.064, 'reward_variance': 3.1344233, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8937080264091493, 'actor_loss': -4.841011095046997, 'hyper_actor_loss': 0.08580764308571816, 'behavior_loss': 0.2643111541867256, 'mean_batch': 5.131520175933838, 'min_batch': 4.934309673309326, 'max_batch': 5.269021081924438}
step: 7150 @ episode report: {'average_total_reward': 9.232, 'reward_variance': 9.934256, 'max_total_reward': 13.45, 'min_total_reward': 3.5700002, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1209442138671877, 'actor_loss': -4.844240331649781, 'hyper_actor_loss': 0.08574610278010368, 'behavior_loss': 0.27502118349075316, 'mean_batch': 5.150159406661987, 'min_batch': 4.9328141689300535, 'max_batch': 5.296254968643188}
step: 7160 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 0.9394212, 'max_total_reward': 12.34, 'min_total_reward': 10.009999, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.858095109462738, 'actor_loss': -4.856687927246094, 'hyper_actor_loss': 0.08584195226430893, 'behavior_loss': 0.278738372027874, 'mean_batch': 5.167174863815307, 'min_batch': 4.977868318557739, 'max_batch': 5.306839370727539}
step: 7170 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 2.8917167, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.919516372680664, 'actor_loss': -4.852471828460693, 'hyper_actor_loss': 0.08596841990947723, 'behavior_loss': 0.273485378921032, 'mean_batch': 5.170902109146118, 'min_batch': 4.953380346298218, 'max_batch': 5.305325984954834}
step: 7180 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 2.0646563, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7787636280059815, 'actor_loss': -4.8533079624176025, 'hyper_actor_loss': 0.08589636012911797, 'behavior_loss': 0.2739895984530449, 'mean_batch': 5.162574100494385, 'min_batch': 4.965259552001953, 'max_batch': 5.30834469795227}
step: 7190 @ episode report: {'average_total_reward': 10.332001, 'reward_variance': 1.194096, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.869585394859314, 'actor_loss': -4.850784111022949, 'hyper_actor_loss': 0.08588381484150887, 'behavior_loss': 0.268499793112278, 'mean_batch': 5.151382875442505, 'min_batch': 4.96358642578125, 'max_batch': 5.287682580947876}
step: 7200 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 7.2293615, 'max_total_reward': 13.450001, 'min_total_reward': 4.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0298675894737244, 'actor_loss': -4.86088981628418, 'hyper_actor_loss': 0.08588458150625229, 'behavior_loss': 0.2826704740524292, 'mean_batch': 5.179945087432861, 'min_batch': 4.986348724365234, 'max_batch': 5.321495771408081}
step: 7210 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.6150243, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6383106291294098, 'actor_loss': -4.839493465423584, 'hyper_actor_loss': 0.08585565090179444, 'behavior_loss': 0.259340825676918, 'mean_batch': 5.113246583938599, 'min_batch': 4.944312191009521, 'max_batch': 5.247842597961426}
step: 7220 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 4.657704, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8681565254926682, 'actor_loss': -4.880723762512207, 'hyper_actor_loss': 0.08562482967972755, 'behavior_loss': 0.2688236325979233, 'mean_batch': 5.251880645751953, 'min_batch': 5.0165916919708256, 'max_batch': 5.403426027297973}
step: 7230 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 5.1385565, 'max_total_reward': 13.2300005, 'min_total_reward': 5.7899995, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6253053486347198, 'actor_loss': -4.869181060791016, 'hyper_actor_loss': 0.08549211397767068, 'behavior_loss': 0.2632417693734169, 'mean_batch': 5.210371589660644, 'min_batch': 4.998635864257812, 'max_batch': 5.354637956619262}
step: 7240 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 3.0166364, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9502116322517395, 'actor_loss': -4.870464849472046, 'hyper_actor_loss': 0.08544792383909225, 'behavior_loss': 0.26968943923711775, 'mean_batch': 5.1896344184875485, 'min_batch': 5.024787473678589, 'max_batch': 5.3321287631988525}
step: 7250 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.7362242, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4924113869667053, 'actor_loss': -4.862598848342896, 'hyper_actor_loss': 0.08549696952104568, 'behavior_loss': 0.2705303505063057, 'mean_batch': 5.178504610061646, 'min_batch': 4.996450614929199, 'max_batch': 5.321819877624511}
step: 7260 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 2.6815042, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2659481883049013, 'actor_loss': -4.877546167373657, 'hyper_actor_loss': 0.08547047376632691, 'behavior_loss': 0.2765226185321808, 'mean_batch': 5.219487953186035, 'min_batch': 5.031905651092529, 'max_batch': 5.371348762512207}
step: 7270 @ episode report: {'average_total_reward': 11.519, 'reward_variance': 2.9771483, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9709324955940246, 'actor_loss': -4.815309858322143, 'hyper_actor_loss': 0.08544357717037201, 'behavior_loss': 0.27981368601322176, 'mean_batch': 5.052105712890625, 'min_batch': 4.8847513675689695, 'max_batch': 5.233767175674439}
step: 7280 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 2.988716, 'max_total_reward': 14.559999, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9844845414161683, 'actor_loss': -4.838147783279419, 'hyper_actor_loss': 0.08562480136752129, 'behavior_loss': 0.27183693945407866, 'mean_batch': 5.1188582420349125, 'min_batch': 4.932415866851807, 'max_batch': 5.258445930480957}
step: 7290 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 4.460096, 'max_total_reward': 15.67, 'min_total_reward': 7.6800003, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.778130340576172, 'actor_loss': -4.862084007263183, 'hyper_actor_loss': 0.0855417437851429, 'behavior_loss': 0.2510049358010292, 'mean_batch': 5.183910655975342, 'min_batch': 4.988331985473633, 'max_batch': 5.361826229095459}
step: 7300 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 3.1248963, 'max_total_reward': 13.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.460278034210205, 'actor_loss': -4.870723295211792, 'hyper_actor_loss': 0.08520198687911033, 'behavior_loss': 0.2647820144891739, 'mean_batch': 5.2002434730529785, 'min_batch': 5.016029691696167, 'max_batch': 5.369577550888062}
step: 7310 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.640264, 'max_total_reward': 12.339999, 'min_total_reward': 6.7899995, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.780671089887619, 'actor_loss': -4.883725929260254, 'hyper_actor_loss': 0.08506088629364968, 'behavior_loss': 0.2747680276632309, 'mean_batch': 5.2270379066467285, 'min_batch': 5.055725622177124, 'max_batch': 5.3706676959991455}
step: 7320 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 3.3549404, 'max_total_reward': 12.339999, 'min_total_reward': 5.57, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7744005084037782, 'actor_loss': -4.85611891746521, 'hyper_actor_loss': 0.08510928601026535, 'behavior_loss': 0.2672289416193962, 'mean_batch': 5.16949462890625, 'min_batch': 4.972564315795898, 'max_batch': 5.34160099029541}
step: 7330 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 1.8677801, 'max_total_reward': 13.339999, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6890526235103607, 'actor_loss': -4.87683253288269, 'hyper_actor_loss': 0.08524550274014472, 'behavior_loss': 0.2588477239012718, 'mean_batch': 5.209205961227417, 'min_batch': 5.038007640838623, 'max_batch': 5.3682936668396}
step: 7340 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 3.07523, 'max_total_reward': 13.450001, 'min_total_reward': 7.7899995, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.881539171934128, 'actor_loss': -4.8749014377594, 'hyper_actor_loss': 0.084987223893404, 'behavior_loss': 0.26825694739818573, 'mean_batch': 5.210682058334351, 'min_batch': 5.02684440612793, 'max_batch': 5.348723840713501}
step: 7350 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 3.5308049, 'max_total_reward': 14.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9441845774650575, 'actor_loss': -4.842889451980591, 'hyper_actor_loss': 0.08496473431587219, 'behavior_loss': 0.25950105786323546, 'mean_batch': 5.1193726539611815, 'min_batch': 4.955426025390625, 'max_batch': 5.248638916015625}
step: 7360 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 4.9114895, 'max_total_reward': 13.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8321665823459625, 'actor_loss': -4.8448058605194095, 'hyper_actor_loss': 0.08490980789065361, 'behavior_loss': 0.24664950966835023, 'mean_batch': 5.123078680038452, 'min_batch': 4.961239671707153, 'max_batch': 5.2446802139282225}
step: 7370 @ episode report: {'average_total_reward': 11.6189995, 'reward_variance': 5.10745, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6396004289388657, 'actor_loss': -4.87495608329773, 'hyper_actor_loss': 0.08462519645690918, 'behavior_loss': 0.26293556690216063, 'mean_batch': 5.202985429763794, 'min_batch': 5.034477043151855, 'max_batch': 5.346801328659057}
step: 7380 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 1.4166453, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6099639892578126, 'actor_loss': -4.896371269226075, 'hyper_actor_loss': 0.08466714769601821, 'behavior_loss': 0.2593525886535645, 'mean_batch': 5.262358331680298, 'min_batch': 5.085399055480957, 'max_batch': 5.3983043193817135}
step: 7390 @ episode report: {'average_total_reward': 10.098001, 'reward_variance': 1.2828761, 'max_total_reward': 11.230001, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6653370708227158, 'actor_loss': -4.903928518295288, 'hyper_actor_loss': 0.08462606146931648, 'behavior_loss': 0.26950231194496155, 'mean_batch': 5.266768169403076, 'min_batch': 5.1197676181793215, 'max_batch': 5.413218450546265}
step: 7400 @ episode report: {'average_total_reward': 11.475, 'reward_variance': 3.8083053, 'max_total_reward': 14.56, 'min_total_reward': 8.570001, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9155836224555969, 'actor_loss': -4.855362224578857, 'hyper_actor_loss': 0.08471953868865967, 'behavior_loss': 0.2701944962143898, 'mean_batch': 5.1531336307525635, 'min_batch': 4.984924459457398, 'max_batch': 5.283151435852051}
step: 7410 @ episode report: {'average_total_reward': 11.042002, 'reward_variance': 0.59159577, 'max_total_reward': 12.34, 'min_total_reward': 10.01, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8006532192230225, 'actor_loss': -4.844897508621216, 'hyper_actor_loss': 0.08481684699654579, 'behavior_loss': 0.26262719333171847, 'mean_batch': 5.118336200714111, 'min_batch': 4.966268825531006, 'max_batch': 5.244781064987182}
step: 7420 @ episode report: {'average_total_reward': 10.631, 'reward_variance': 3.8387094, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.873061740398407, 'actor_loss': -4.8858287811279295, 'hyper_actor_loss': 0.08480777591466904, 'behavior_loss': 0.26571212261915206, 'mean_batch': 5.232181119918823, 'min_batch': 5.0612773418426515, 'max_batch': 5.372699451446533}
step: 7430 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 2.721703, 'max_total_reward': 13.45, 'min_total_reward': 8.570001, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9749724745750428, 'actor_loss': -4.843802738189697, 'hyper_actor_loss': 0.08469934687018395, 'behavior_loss': 0.28220492154359816, 'mean_batch': 5.12009563446045, 'min_batch': 4.959492444992065, 'max_batch': 5.241826009750366}
step: 7440 @ episode report: {'average_total_reward': 10.764, 'reward_variance': 5.6040826, 'max_total_reward': 15.669999, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7694244623184203, 'actor_loss': -4.855473232269287, 'hyper_actor_loss': 0.08484277576208114, 'behavior_loss': 0.26213784217834474, 'mean_batch': 5.144061803817749, 'min_batch': 4.993916273117065, 'max_batch': 5.27284574508667}
step: 7450 @ episode report: {'average_total_reward': 9.799001, 'reward_variance': 4.3845696, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9022613048553467, 'actor_loss': -4.8782219886779785, 'hyper_actor_loss': 0.08473781421780587, 'behavior_loss': 0.27406175434589386, 'mean_batch': 5.220035743713379, 'min_batch': 5.034503030776977, 'max_batch': 5.35048542022705}
step: 7460 @ episode report: {'average_total_reward': 10.242001, 'reward_variance': 3.7081559, 'max_total_reward': 12.339999, 'min_total_reward': 5.7899995, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.788900661468506, 'actor_loss': -4.853939771652222, 'hyper_actor_loss': 0.08464645221829414, 'behavior_loss': 0.24709317684173585, 'mean_batch': 5.152471256256104, 'min_batch': 4.978098058700562, 'max_batch': 5.285094833374023}
step: 7470 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 1.9792961, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7426422864198685, 'actor_loss': -4.876332473754883, 'hyper_actor_loss': 0.0843315452337265, 'behavior_loss': 0.25785071551799776, 'mean_batch': 5.211210441589356, 'min_batch': 5.03353271484375, 'max_batch': 5.336764717102051}
step: 7480 @ episode report: {'average_total_reward': 9.987, 'reward_variance': 3.360241, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8543084740638733, 'actor_loss': -4.8516946792602536, 'hyper_actor_loss': 0.08435548096895218, 'behavior_loss': 0.25313145816326144, 'mean_batch': 5.154231691360474, 'min_batch': 4.965288543701172, 'max_batch': 5.2858153820037845}
step: 7490 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.1946366, 'max_total_reward': 12.2300005, 'min_total_reward': 6.57, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9201923727989196, 'actor_loss': -4.8756349086761475, 'hyper_actor_loss': 0.08408579975366592, 'behavior_loss': 0.2528427869081497, 'mean_batch': 5.198662853240966, 'min_batch': 5.042070770263672, 'max_batch': 5.3273241996765135}
step: 7500 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 4.2565, 'max_total_reward': 14.56, 'min_total_reward': 6.57, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.652654480934143, 'actor_loss': -4.8686918258667, 'hyper_actor_loss': 0.08400890231132507, 'behavior_loss': 0.25363408476114274, 'mean_batch': 5.194790697097778, 'min_batch': 5.011290979385376, 'max_batch': 5.31813006401062}
step: 7510 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.1509633, 'max_total_reward': 13.23, 'min_total_reward': 7.9000006, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6867837727069854, 'actor_loss': -4.880106592178345, 'hyper_actor_loss': 0.08406492918729783, 'behavior_loss': 0.25454733818769454, 'mean_batch': 5.213135480880737, 'min_batch': 5.050557327270508, 'max_batch': 5.355140972137451}
step: 7520 @ episode report: {'average_total_reward': 10.209002, 'reward_variance': 3.4723296, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6365073323249817, 'actor_loss': -4.8881693363189695, 'hyper_actor_loss': 0.08409840166568756, 'behavior_loss': 0.2669560253620148, 'mean_batch': 5.238301801681518, 'min_batch': 5.0671319484710695, 'max_batch': 5.364111709594726}
step: 7530 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 2.291561, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8736512899398803, 'actor_loss': -4.863430452346802, 'hyper_actor_loss': 0.08422996550798416, 'behavior_loss': 0.277086566388607, 'mean_batch': 5.169854640960693, 'min_batch': 5.008874750137329, 'max_batch': 5.289990520477295}
step: 7540 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 3.0738456, 'max_total_reward': 13.450001, 'min_total_reward': 6.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.608799159526825, 'actor_loss': -4.853435707092285, 'hyper_actor_loss': 0.08451173752546311, 'behavior_loss': 0.271207694709301, 'mean_batch': 5.157959032058716, 'min_batch': 4.970521545410156, 'max_batch': 5.277660608291626}
step: 7550 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 3.5310016, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0215954422950744, 'actor_loss': -4.87443962097168, 'hyper_actor_loss': 0.08444205373525619, 'behavior_loss': 0.2638407200574875, 'mean_batch': 5.205756807327271, 'min_batch': 5.029308843612671, 'max_batch': 5.328289651870728}
step: 7560 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 1.3626237, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8298906087875366, 'actor_loss': -4.854250907897949, 'hyper_actor_loss': 0.0843093790113926, 'behavior_loss': 0.27046953290700915, 'mean_batch': 5.145060396194458, 'min_batch': 4.98674521446228, 'max_batch': 5.269715976715088}
step: 7570 @ episode report: {'average_total_reward': 8.844, 'reward_variance': 5.854524, 'max_total_reward': 14.56, 'min_total_reward': 5.6800003, 'average_n_step': 9.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8016474008560182, 'actor_loss': -4.872215652465821, 'hyper_actor_loss': 0.08433635756373406, 'behavior_loss': 0.266171869635582, 'mean_batch': 5.193807220458984, 'min_batch': 5.0295164585113525, 'max_batch': 5.306829023361206}
step: 7580 @ episode report: {'average_total_reward': 9.755, 'reward_variance': 7.7901244, 'max_total_reward': 12.339999, 'min_total_reward': 1.91, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3834778189659118, 'actor_loss': -4.890703582763672, 'hyper_actor_loss': 0.08419764935970306, 'behavior_loss': 0.26757724583148956, 'mean_batch': 5.242052888870239, 'min_batch': 5.0762824535369875, 'max_batch': 5.392874431610108}
step: 7590 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 1.4052207, 'max_total_reward': 13.23, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.555460900068283, 'actor_loss': -4.899883127212524, 'hyper_actor_loss': 0.08412674441933632, 'behavior_loss': 0.259324437379837, 'mean_batch': 5.280591535568237, 'min_batch': 5.085762405395508, 'max_batch': 5.4201130867004395}
step: 7600 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 4.862884, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8848464369773865, 'actor_loss': -4.891454410552979, 'hyper_actor_loss': 0.08404447883367538, 'behavior_loss': 0.271493624150753, 'mean_batch': 5.2385077476501465, 'min_batch': 5.083569574356079, 'max_batch': 5.3669939041137695}
step: 7610 @ episode report: {'average_total_reward': 10.687, 'reward_variance': 1.5239214, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.817632019519806, 'actor_loss': -4.86463885307312, 'hyper_actor_loss': 0.08397849500179291, 'behavior_loss': 0.2640351206064224, 'mean_batch': 5.176977634429932, 'min_batch': 5.007834959030151, 'max_batch': 5.342029666900634}
step: 7620 @ episode report: {'average_total_reward': 10.886, 'reward_variance': 2.692284, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6508011758327483, 'actor_loss': -4.873504543304444, 'hyper_actor_loss': 0.08404758796095849, 'behavior_loss': 0.2595801576972008, 'mean_batch': 5.193809747695923, 'min_batch': 5.036021566390991, 'max_batch': 5.331014728546142}
step: 7630 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 3.8885846, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8693713545799255, 'actor_loss': -4.871105766296386, 'hyper_actor_loss': 0.08379850760102273, 'behavior_loss': 0.2544601783156395, 'mean_batch': 5.1964904308319095, 'min_batch': 5.021360397338867, 'max_batch': 5.345586204528809}
step: 7640 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 1.5154846, 'max_total_reward': 13.34, 'min_total_reward': 9.009999, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5053446829319, 'actor_loss': -4.890804576873779, 'hyper_actor_loss': 0.0836636707186699, 'behavior_loss': 0.26364926546812056, 'mean_batch': 5.230140542984008, 'min_batch': 5.088355207443238, 'max_batch': 5.385624742507934}
step: 7650 @ episode report: {'average_total_reward': 10.964001, 'reward_variance': 0.9221846, 'max_total_reward': 12.340001, 'min_total_reward': 10.01, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.829297661781311, 'actor_loss': -4.905703210830689, 'hyper_actor_loss': 0.08359873145818711, 'behavior_loss': 0.255602078139782, 'mean_batch': 5.281021022796631, 'min_batch': 5.115205764770508, 'max_batch': 5.480225706100464}
step: 7660 @ episode report: {'average_total_reward': 10.342, 'reward_variance': 6.237956, 'max_total_reward': 14.559999, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8991618752479553, 'actor_loss': -4.8496815204620365, 'hyper_actor_loss': 0.0836211159825325, 'behavior_loss': 0.2562714159488678, 'mean_batch': 5.135449552536011, 'min_batch': 4.973515844345092, 'max_batch': 5.276348066329956}
step: 7670 @ episode report: {'average_total_reward': 9.776001, 'reward_variance': 3.0119636, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9785253882408143, 'actor_loss': -4.850382709503174, 'hyper_actor_loss': 0.08364296853542327, 'behavior_loss': 0.2745449781417847, 'mean_batch': 5.135396242141724, 'min_batch': 4.9770606517791744, 'max_batch': 5.267502021789551}
step: 7680 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 2.788256, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0220950126647947, 'actor_loss': -4.861982774734497, 'hyper_actor_loss': 0.08384162113070488, 'behavior_loss': 0.27395583391189576, 'mean_batch': 5.159711694717407, 'min_batch': 5.011250448226929, 'max_batch': 5.3087317943573}
step: 7690 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 2.323236, 'max_total_reward': 12.12, 'min_total_reward': 6.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.681495863199234, 'actor_loss': -4.849236488342285, 'hyper_actor_loss': 0.08405910953879356, 'behavior_loss': 0.27523201406002046, 'mean_batch': 5.127606534957886, 'min_batch': 4.9787492752075195, 'max_batch': 5.237941551208496}
step: 7700 @ episode report: {'average_total_reward': 11.231001, 'reward_variance': 2.9187694, 'max_total_reward': 14.2300005, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.055691397190094, 'actor_loss': -4.867859745025635, 'hyper_actor_loss': 0.08400716185569763, 'behavior_loss': 0.25987632423639295, 'mean_batch': 5.172045516967773, 'min_batch': 5.0286884784698485, 'max_batch': 5.28761305809021}
step: 7710 @ episode report: {'average_total_reward': 11.153002, 'reward_variance': 2.5739014, 'max_total_reward': 14.2300005, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8634591817855835, 'actor_loss': -4.861040258407593, 'hyper_actor_loss': 0.08369516879320145, 'behavior_loss': 0.2719054564833641, 'mean_batch': 5.154020357131958, 'min_batch': 5.011980819702148, 'max_batch': 5.276582860946656}
step: 7720 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 3.2581894, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7663841366767883, 'actor_loss': -4.859847927093506, 'hyper_actor_loss': 0.08367403447628022, 'behavior_loss': 0.26034471243619917, 'mean_batch': 5.155929327011108, 'min_batch': 5.004153442382813, 'max_batch': 5.289725875854492}
step: 7730 @ episode report: {'average_total_reward': 9.61, 'reward_variance': 9.2081785, 'max_total_reward': 13.45, 'min_total_reward': 5.7899995, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9409855246543883, 'actor_loss': -4.847366619110107, 'hyper_actor_loss': 0.08364195749163628, 'behavior_loss': 0.2845530405640602, 'mean_batch': 5.1239618301391605, 'min_batch': 4.973013877868652, 'max_batch': 5.234902477264404}
step: 7740 @ episode report: {'average_total_reward': 8.689, 'reward_variance': 2.7764688, 'max_total_reward': 11.12, 'min_total_reward': 4.68, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5439480900764466, 'actor_loss': -4.882322835922241, 'hyper_actor_loss': 0.08370529040694237, 'behavior_loss': 0.25734317153692243, 'mean_batch': 5.2095770835876465, 'min_batch': 5.065543508529663, 'max_batch': 5.320956182479859}
step: 7750 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 1.3643962, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6552200198173523, 'actor_loss': -4.894887018203735, 'hyper_actor_loss': 0.08354910165071487, 'behavior_loss': 0.2601131871342659, 'mean_batch': 5.250275945663452, 'min_batch': 5.089560651779175, 'max_batch': 5.3667120933532715}
step: 7760 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 3.730922, 'max_total_reward': 12.340001, 'min_total_reward': 6.9000006, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8631317675113679, 'actor_loss': -4.8582977771759035, 'hyper_actor_loss': 0.08335249349474907, 'behavior_loss': 0.27208552211523057, 'mean_batch': 5.150835371017456, 'min_batch': 5.001511764526367, 'max_batch': 5.270123291015625}
step: 7770 @ episode report: {'average_total_reward': 9.454, 'reward_variance': 2.5159035, 'max_total_reward': 11.23, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9547369360923768, 'actor_loss': -4.86082091331482, 'hyper_actor_loss': 0.08337474912405014, 'behavior_loss': 0.2637612372636795, 'mean_batch': 5.161536598205567, 'min_batch': 5.00379433631897, 'max_batch': 5.293009853363037}
step: 7780 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 3.282289, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8263257443904877, 'actor_loss': -4.8474749565124515, 'hyper_actor_loss': 0.08334826081991195, 'behavior_loss': 0.26977657079696654, 'mean_batch': 5.126766729354858, 'min_batch': 4.971000289916992, 'max_batch': 5.23951563835144}
step: 7790 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 2.3782248, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8224581360816956, 'actor_loss': -4.864458990097046, 'hyper_actor_loss': 0.08329925164580346, 'behavior_loss': 0.26195454597473145, 'mean_batch': 5.168530082702636, 'min_batch': 5.015129327774048, 'max_batch': 5.283324813842773}
step: 7800 @ episode report: {'average_total_reward': 11.153001, 'reward_variance': 5.482101, 'max_total_reward': 16.67, 'min_total_reward': 6.9, 'average_n_step': 12.0, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.129022717475891, 'actor_loss': -4.85218997001648, 'hyper_actor_loss': 0.08302003964781761, 'behavior_loss': 0.25368515253067014, 'mean_batch': 5.139555358886719, 'min_batch': 4.98190016746521, 'max_batch': 5.251170063018799}
step: 7810 @ episode report: {'average_total_reward': 10.5199995, 'reward_variance': 3.719139, 'max_total_reward': 14.559999, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8110440492630004, 'actor_loss': -4.837791681289673, 'hyper_actor_loss': 0.08276978805661202, 'behavior_loss': 0.2787278309464455, 'mean_batch': 5.1057457447052, 'min_batch': 4.9432989120483395, 'max_batch': 5.208371639251709}
step: 7820 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 3.6039433, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6704911887645721, 'actor_loss': -4.859065675735474, 'hyper_actor_loss': 0.08308133482933044, 'behavior_loss': 0.2594827234745026, 'mean_batch': 5.158709383010864, 'min_batch': 4.997682380676269, 'max_batch': 5.264803171157837}
step: 7830 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 2.2351007, 'max_total_reward': 13.45, 'min_total_reward': 8.789999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.525827705860138, 'actor_loss': -4.895577812194825, 'hyper_actor_loss': 0.08303493782877922, 'behavior_loss': 0.2674604669213295, 'mean_batch': 5.251164960861206, 'min_batch': 5.092215585708618, 'max_batch': 5.366543626785278}
step: 7840 @ episode report: {'average_total_reward': 10.843, 'reward_variance': 4.516241, 'max_total_reward': 14.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6458711445331573, 'actor_loss': -4.8834997653961185, 'hyper_actor_loss': 0.08300666734576226, 'behavior_loss': 0.26803328692913053, 'mean_batch': 5.210684394836425, 'min_batch': 5.070338153839112, 'max_batch': 5.330236768722534}
step: 7850 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 1.9013602, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0554762959480284, 'actor_loss': -4.848758268356323, 'hyper_actor_loss': 0.08297751918435096, 'behavior_loss': 0.27346332371234894, 'mean_batch': 5.1335862159729, 'min_batch': 4.970871448516846, 'max_batch': 5.23252854347229}
step: 7860 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 4.80433, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.007641613483429, 'actor_loss': -4.833327198028565, 'hyper_actor_loss': 0.08301163241267204, 'behavior_loss': 0.2656263768672943, 'mean_batch': 5.095677185058594, 'min_batch': 4.930824279785156, 'max_batch': 5.209560108184815}
step: 7870 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 3.0893369, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.725260430574417, 'actor_loss': -4.8482170581817625, 'hyper_actor_loss': 0.08306908905506134, 'behavior_loss': 0.2782743081450462, 'mean_batch': 5.126218795776367, 'min_batch': 4.9750532627105715, 'max_batch': 5.23665223121643}
step: 7880 @ episode report: {'average_total_reward': 9.71, 'reward_variance': 3.12304, 'max_total_reward': 12.23, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1869739532470702, 'actor_loss': -4.860964584350586, 'hyper_actor_loss': 0.0830312803387642, 'behavior_loss': 0.2644952118396759, 'mean_batch': 5.163646078109741, 'min_batch': 5.002575206756592, 'max_batch': 5.276269006729126}
step: 7890 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 1.7858413, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7628848791122436, 'actor_loss': -4.829264163970947, 'hyper_actor_loss': 0.08271564245223999, 'behavior_loss': 0.24782542437314986, 'mean_batch': 5.082674503326416, 'min_batch': 4.923612976074219, 'max_batch': 5.253135919570923}
step: 7900 @ episode report: {'average_total_reward': 10.432, 'reward_variance': 2.5371554, 'max_total_reward': 13.23, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0772493958473204, 'actor_loss': -4.855239391326904, 'hyper_actor_loss': 0.08239283487200737, 'behavior_loss': 0.2669309079647064, 'mean_batch': 5.144432830810547, 'min_batch': 4.992332887649536, 'max_batch': 5.272413301467895}
step: 7910 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 1.4814613, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.021743905544281, 'actor_loss': -4.827362728118897, 'hyper_actor_loss': 0.08236125409603119, 'behavior_loss': 0.2700976312160492, 'mean_batch': 5.071252632141113, 'min_batch': 4.925153541564941, 'max_batch': 5.1845954895019535}
step: 7920 @ episode report: {'average_total_reward': 9.931999, 'reward_variance': 3.4243157, 'max_total_reward': 13.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.949511170387268, 'actor_loss': -4.823503112792968, 'hyper_actor_loss': 0.08253977596759796, 'behavior_loss': 0.28044327050447465, 'mean_batch': 5.0659877300262455, 'min_batch': 4.9113390922546385, 'max_batch': 5.191545677185059}
step: 7930 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.6171699, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.616293239593506, 'actor_loss': -4.852227258682251, 'hyper_actor_loss': 0.08270306736230851, 'behavior_loss': 0.26650690734386445, 'mean_batch': 5.148415231704712, 'min_batch': 4.973594808578492, 'max_batch': 5.302532815933228}
step: 7940 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 1.8248011, 'max_total_reward': 11.120001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3210046678781509, 'actor_loss': -4.90678915977478, 'hyper_actor_loss': 0.08271773457527161, 'behavior_loss': 0.26778784245252607, 'mean_batch': 5.285108375549316, 'min_batch': 5.116678762435913, 'max_batch': 5.435571193695068}
step: 7950 @ episode report: {'average_total_reward': 11.530001, 'reward_variance': 4.5258803, 'max_total_reward': 14.34, 'min_total_reward': 6.79, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0708795189857483, 'actor_loss': -4.869955778121948, 'hyper_actor_loss': 0.08254366666078568, 'behavior_loss': 0.27750622779130935, 'mean_batch': 5.179474210739135, 'min_batch': 5.0331700325012205, 'max_batch': 5.332647228240967}
step: 7960 @ episode report: {'average_total_reward': 11.075001, 'reward_variance': 4.2443256, 'max_total_reward': 14.450001, 'min_total_reward': 7.79, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6944402933120728, 'actor_loss': -4.801556968688965, 'hyper_actor_loss': 0.08233134150505066, 'behavior_loss': 0.27061651796102526, 'mean_batch': 5.012349367141724, 'min_batch': 4.856461668014527, 'max_batch': 5.120768451690674}
step: 7970 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 1.4570415, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8504841148853302, 'actor_loss': -4.8638896465301515, 'hyper_actor_loss': 0.08231415897607804, 'behavior_loss': 0.24855858385562896, 'mean_batch': 5.177466201782226, 'min_batch': 5.003801870346069, 'max_batch': 5.305066967010498}
step: 7980 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 4.2410884, 'max_total_reward': 13.23, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7574239730834962, 'actor_loss': -4.87447943687439, 'hyper_actor_loss': 0.08206731975078582, 'behavior_loss': 0.2757233425974846, 'mean_batch': 5.2017014503479, 'min_batch': 5.033391046524048, 'max_batch': 5.339951229095459}
step: 7990 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 4.0050635, 'max_total_reward': 13.23, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6479989528656005, 'actor_loss': -4.862287855148315, 'hyper_actor_loss': 0.08181174769997597, 'behavior_loss': 0.25653655380010604, 'mean_batch': 5.173252296447754, 'min_batch': 4.999836540222168, 'max_batch': 5.3076080799102785}
step: 8000 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 3.8235614, 'max_total_reward': 14.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7037482738494873, 'actor_loss': -4.847878551483154, 'hyper_actor_loss': 0.08177116960287094, 'behavior_loss': 0.2708748713135719, 'mean_batch': 5.122211503982544, 'min_batch': 4.977424478530883, 'max_batch': 5.22797212600708}
step: 8010 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 2.0361009, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6023681998252868, 'actor_loss': -4.8753662109375, 'hyper_actor_loss': 0.08185079917311669, 'behavior_loss': 0.26757093220949174, 'mean_batch': 5.198632335662841, 'min_batch': 5.040919399261474, 'max_batch': 5.342767858505249}
step: 8020 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 1.6703966, 'max_total_reward': 13.010001, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6540263950824738, 'actor_loss': -4.897882127761841, 'hyper_actor_loss': 0.08174949437379837, 'behavior_loss': 0.25557548850774764, 'mean_batch': 5.2597864151000975, 'min_batch': 5.095594835281372, 'max_batch': 5.383947229385376}
step: 8030 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 2.0403087, 'max_total_reward': 12.339999, 'min_total_reward': 6.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5129161953926087, 'actor_loss': -4.883859300613404, 'hyper_actor_loss': 0.08151214793324471, 'behavior_loss': 0.25865896344184874, 'mean_batch': 5.207800054550171, 'min_batch': 5.074831628799439, 'max_batch': 5.316652488708496}
step: 8040 @ episode report: {'average_total_reward': 10.82, 'reward_variance': 2.9474597, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0671121001243593, 'actor_loss': -4.856748390197754, 'hyper_actor_loss': 0.08163598254323005, 'behavior_loss': 0.27469210177659986, 'mean_batch': 5.146933650970459, 'min_batch': 4.997750329971313, 'max_batch': 5.258090162277222}
step: 8050 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 3.3703036, 'max_total_reward': 12.339999, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.093174362182617, 'actor_loss': -4.819755792617798, 'hyper_actor_loss': 0.08171500414609909, 'behavior_loss': 0.2525878041982651, 'mean_batch': 5.055274391174317, 'min_batch': 4.903422689437866, 'max_batch': 5.14017424583435}
step: 8060 @ episode report: {'average_total_reward': 9.754, 'reward_variance': 4.389285, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5615734577178955, 'actor_loss': -4.856274700164795, 'hyper_actor_loss': 0.08155025541782379, 'behavior_loss': 0.2691594630479813, 'mean_batch': 5.149447965621948, 'min_batch': 4.993339109420776, 'max_batch': 5.251508140563965}
step: 8070 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 3.1119838, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7473177075386048, 'actor_loss': -4.896159648895264, 'hyper_actor_loss': 0.08145732954144477, 'behavior_loss': 0.25781832784414294, 'mean_batch': 5.246094417572022, 'min_batch': 5.100270414352417, 'max_batch': 5.350445413589478}
step: 8080 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 1.5326844, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.565581452846527, 'actor_loss': -4.863418102264404, 'hyper_actor_loss': 0.08144560977816581, 'behavior_loss': 0.2768313273787498, 'mean_batch': 5.144848823547363, 'min_batch': 5.032923173904419, 'max_batch': 5.251728916168213}
step: 8090 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 3.068889, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2349092602729796, 'actor_loss': -4.870602560043335, 'hyper_actor_loss': 0.0814437635242939, 'behavior_loss': 0.26637174785137174, 'mean_batch': 5.167362880706787, 'min_batch': 5.047201776504517, 'max_batch': 5.271325969696045}
step: 8100 @ episode report: {'average_total_reward': 8.911001, 'reward_variance': 1.323389, 'max_total_reward': 10.120001, 'min_total_reward': 6.57, 'average_n_step': 10.0, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.826577937602997, 'actor_loss': -4.838045501708985, 'hyper_actor_loss': 0.08139843642711639, 'behavior_loss': 0.27526419758796694, 'mean_batch': 5.085086965560913, 'min_batch': 4.964470386505127, 'max_batch': 5.178614854812622}
step: 8110 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 5.0708094, 'max_total_reward': 13.340001, 'min_total_reward': 5.7900004, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.116421902179718, 'actor_loss': -4.813683748245239, 'hyper_actor_loss': 0.08138992860913277, 'behavior_loss': 0.2680036693811417, 'mean_batch': 5.023853206634522, 'min_batch': 4.90411057472229, 'max_batch': 5.097891521453858}
step: 8120 @ episode report: {'average_total_reward': 11.031001, 'reward_variance': 3.447909, 'max_total_reward': 14.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7916054487228394, 'actor_loss': -4.849205780029297, 'hyper_actor_loss': 0.08155238181352616, 'behavior_loss': 0.27568085938692094, 'mean_batch': 5.112778902053833, 'min_batch': 4.993194580078125, 'max_batch': 5.200895309448242}
step: 8130 @ episode report: {'average_total_reward': 10.709001, 'reward_variance': 1.3033297, 'max_total_reward': 12.230001, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7366862297058105, 'actor_loss': -4.876234483718872, 'hyper_actor_loss': 0.08128816485404969, 'behavior_loss': 0.2635964408516884, 'mean_batch': 5.18088207244873, 'min_batch': 5.062322092056275, 'max_batch': 5.269142913818359}
step: 8140 @ episode report: {'average_total_reward': 9.499, 'reward_variance': 3.9876494, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.624180293083191, 'actor_loss': -4.889330434799194, 'hyper_actor_loss': 0.08118035793304443, 'behavior_loss': 0.2693221613764763, 'mean_batch': 5.211668491363525, 'min_batch': 5.098805236816406, 'max_batch': 5.294619131088257}
step: 8150 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 3.51356, 'max_total_reward': 12.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.753562331199646, 'actor_loss': -4.857394599914551, 'hyper_actor_loss': 0.08106632381677628, 'behavior_loss': 0.27259221524000166, 'mean_batch': 5.139783000946045, 'min_batch': 5.007724618911743, 'max_batch': 5.221107053756714}
step: 8160 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 1.9996611, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8337760150432587, 'actor_loss': -4.853938198089599, 'hyper_actor_loss': 0.0810782216489315, 'behavior_loss': 0.2749826893210411, 'mean_batch': 5.131609964370727, 'min_batch': 4.99822998046875, 'max_batch': 5.219985294342041}
step: 8170 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 10.638481, 'max_total_reward': 13.2300005, 'min_total_reward': 1.3500001, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6338414639234542, 'actor_loss': -4.859484529495239, 'hyper_actor_loss': 0.08103872090578079, 'behavior_loss': 0.2607554629445076, 'mean_batch': 5.153224039077759, 'min_batch': 5.005093145370483, 'max_batch': 5.2464879035949705}
step: 8180 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 1.9923853, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5614811718463897, 'actor_loss': -4.882418823242188, 'hyper_actor_loss': 0.08080194815993309, 'behavior_loss': 0.23787323534488677, 'mean_batch': 5.212285423278809, 'min_batch': 5.063194465637207, 'max_batch': 5.302681875228882}
step: 8190 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 1.5743008, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8495794177055358, 'actor_loss': -4.881096124649048, 'hyper_actor_loss': 0.08047251254320145, 'behavior_loss': 0.2726915284991264, 'mean_batch': 5.199965763092041, 'min_batch': 5.068465662002564, 'max_batch': 5.295149660110473}
step: 8200 @ episode report: {'average_total_reward': 9.766001, 'reward_variance': 6.7911634, 'max_total_reward': 11.2300005, 'min_total_reward': 2.24, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0278608322143556, 'actor_loss': -4.837298965454101, 'hyper_actor_loss': 0.08049148395657539, 'behavior_loss': 0.2732346221804619, 'mean_batch': 5.083521461486816, 'min_batch': 4.962344408035278, 'max_batch': 5.164372396469116}
step: 8210 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 2.252489, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.738737452030182, 'actor_loss': -4.860709095001221, 'hyper_actor_loss': 0.08069197162985801, 'behavior_loss': 0.27744782716035843, 'mean_batch': 5.146537351608276, 'min_batch': 5.017812967300415, 'max_batch': 5.225837564468383}
step: 8220 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 0.97926015, 'max_total_reward': 12.230001, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0940273642539977, 'actor_loss': -4.852719688415528, 'hyper_actor_loss': 0.08081638664007187, 'behavior_loss': 0.26394242197275164, 'mean_batch': 5.122817468643189, 'min_batch': 5.001174783706665, 'max_batch': 5.203588247299194}
step: 8230 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 2.969101, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7899995, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9123197674751282, 'actor_loss': -4.809957981109619, 'hyper_actor_loss': 0.08070395514369011, 'behavior_loss': 0.24388375878334045, 'mean_batch': 5.008516883850097, 'min_batch': 4.900824642181396, 'max_batch': 5.099414730072022}
step: 8240 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 2.6052253, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5725717961788177, 'actor_loss': -4.895256090164184, 'hyper_actor_loss': 0.08017199411988259, 'behavior_loss': 0.27324889600276947, 'mean_batch': 5.233133363723755, 'min_batch': 5.108928394317627, 'max_batch': 5.330334901809692}
step: 8250 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 4.311036, 'max_total_reward': 14.450001, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7785800278186799, 'actor_loss': -4.88093786239624, 'hyper_actor_loss': 0.08013885989785194, 'behavior_loss': 0.25914385318756106, 'mean_batch': 5.195705127716065, 'min_batch': 5.072343873977661, 'max_batch': 5.285466146469116}
step: 8260 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 6.1473646, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.779956930875778, 'actor_loss': -4.853255653381348, 'hyper_actor_loss': 0.08011236563324928, 'behavior_loss': 0.2715452030301094, 'mean_batch': 5.116363954544068, 'min_batch': 5.0098114013671875, 'max_batch': 5.204597854614258}
step: 8270 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 4.662316, 'max_total_reward': 12.339999, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.763738250732422, 'actor_loss': -4.840740489959717, 'hyper_actor_loss': 0.08027515336871147, 'behavior_loss': 0.26330204457044604, 'mean_batch': 5.085566616058349, 'min_batch': 4.977434396743774, 'max_batch': 5.163045167922974}
step: 8280 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 4.072329, 'max_total_reward': 13.120001, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.805532157421112, 'actor_loss': -4.875125598907471, 'hyper_actor_loss': 0.08029818162322044, 'behavior_loss': 0.26556063890457154, 'mean_batch': 5.18202428817749, 'min_batch': 5.055775928497314, 'max_batch': 5.26445426940918}
step: 8290 @ episode report: {'average_total_reward': 11.063999, 'reward_variance': 1.2873836, 'max_total_reward': 13.339999, 'min_total_reward': 10.009999, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8297903656959533, 'actor_loss': -4.868839406967163, 'hyper_actor_loss': 0.08018428683280945, 'behavior_loss': 0.279896043241024, 'mean_batch': 5.158615684509277, 'min_batch': 5.046925449371338, 'max_batch': 5.245360898971557}
step: 8300 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.2518415, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8567439913749695, 'actor_loss': -4.837482118606568, 'hyper_actor_loss': 0.08014102801680564, 'behavior_loss': 0.2851543813943863, 'mean_batch': 5.085824584960937, 'min_batch': 4.961024427413941, 'max_batch': 5.1634501934051515}
step: 8310 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.5686048, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6758077204227448, 'actor_loss': -4.858296155929565, 'hyper_actor_loss': 0.08028791472315788, 'behavior_loss': 0.269246818125248, 'mean_batch': 5.142771577835083, 'min_batch': 5.009417963027954, 'max_batch': 5.21745753288269}
step: 8320 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 3.7876503, 'max_total_reward': 14.450002, 'min_total_reward': 6.68, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.657625389099121, 'actor_loss': -4.871842575073242, 'hyper_actor_loss': 0.08019066080451012, 'behavior_loss': 0.2580972671508789, 'mean_batch': 5.172602367401123, 'min_batch': 5.048224401473999, 'max_batch': 5.248832702636719}
step: 8330 @ episode report: {'average_total_reward': 9.443, 'reward_variance': 2.2559204, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2030248641967773, 'actor_loss': -4.848540019989014, 'hyper_actor_loss': 0.07987781539559365, 'behavior_loss': 0.25707514882087706, 'mean_batch': 5.117908573150634, 'min_batch': 4.985331773757935, 'max_batch': 5.1963104724884035}
step: 8340 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 3.6540046, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3395015180110932, 'actor_loss': -4.838605451583862, 'hyper_actor_loss': 0.07945579215884209, 'behavior_loss': 0.25986794382333755, 'mean_batch': 5.098710060119629, 'min_batch': 4.954727745056152, 'max_batch': 5.172426462173462}
step: 8350 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 3.094121, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7416672468185426, 'actor_loss': -4.908845853805542, 'hyper_actor_loss': 0.0793626680970192, 'behavior_loss': 0.2529564008116722, 'mean_batch': 5.271110391616821, 'min_batch': 5.1406693935394285, 'max_batch': 5.35118088722229}
step: 8360 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 1.2591019, 'max_total_reward': 11.230001, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8498641490936278, 'actor_loss': -4.860084915161133, 'hyper_actor_loss': 0.07939054444432259, 'behavior_loss': 0.27266594469547273, 'mean_batch': 5.148125743865966, 'min_batch': 5.013619518280029, 'max_batch': 5.219934749603271}
step: 8370 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 4.0230355, 'max_total_reward': 13.23, 'min_total_reward': 6.6800003, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9843019604682923, 'actor_loss': -4.831869792938233, 'hyper_actor_loss': 0.07964319884777069, 'behavior_loss': 0.2650115489959717, 'mean_batch': 5.068120384216309, 'min_batch': 4.950384473800659, 'max_batch': 5.13918924331665}
step: 8380 @ episode report: {'average_total_reward': 10.698001, 'reward_variance': 2.1296957, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9505872130393982, 'actor_loss': -4.82339448928833, 'hyper_actor_loss': 0.07962595745921135, 'behavior_loss': 0.2666513308882713, 'mean_batch': 5.052805089950562, 'min_batch': 4.923561143875122, 'max_batch': 5.124159145355224}
step: 8390 @ episode report: {'average_total_reward': 10.665001, 'reward_variance': 3.1514246, 'max_total_reward': 13.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.61635702252388, 'actor_loss': -4.860279750823975, 'hyper_actor_loss': 0.07963627353310584, 'behavior_loss': 0.2568621352314949, 'mean_batch': 5.154268360137939, 'min_batch': 5.008519458770752, 'max_batch': 5.231250143051147}
step: 8400 @ episode report: {'average_total_reward': 10.765001, 'reward_variance': 1.6926457, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1422018706798553, 'actor_loss': -4.852906990051269, 'hyper_actor_loss': 0.07930676564574242, 'behavior_loss': 0.2446177512407303, 'mean_batch': 5.137685680389405, 'min_batch': 4.987584972381592, 'max_batch': 5.215055847167969}
step: 8410 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 3.3790364, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7141145646572113, 'actor_loss': -4.832004880905151, 'hyper_actor_loss': 0.07901595830917359, 'behavior_loss': 0.27730132043361666, 'mean_batch': 5.0818443775177, 'min_batch': 4.937684392929077, 'max_batch': 5.156275939941406}
step: 8420 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 5.433817, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5113970160484314, 'actor_loss': -4.861197757720947, 'hyper_actor_loss': 0.07932868897914887, 'behavior_loss': 0.2581087350845337, 'mean_batch': 5.151836633682251, 'min_batch': 5.0150378227233885, 'max_batch': 5.227230882644653}
step: 8430 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 2.8451412, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6141319513320922, 'actor_loss': -4.889938926696777, 'hyper_actor_loss': 0.07924943044781685, 'behavior_loss': 0.2800727427005768, 'mean_batch': 5.235918474197388, 'min_batch': 5.078292036056519, 'max_batch': 5.317564487457275}
step: 8440 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.2730641, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4393129646778107, 'actor_loss': -4.875946187973023, 'hyper_actor_loss': 0.07933747693896294, 'behavior_loss': 0.25972245782613756, 'mean_batch': 5.191922044754028, 'min_batch': 5.050138187408447, 'max_batch': 5.266771602630615}
step: 8450 @ episode report: {'average_total_reward': 10.4869995, 'reward_variance': 2.7428212, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6985801458358765, 'actor_loss': -4.864798212051392, 'hyper_actor_loss': 0.07909058853983879, 'behavior_loss': 0.24313047230243684, 'mean_batch': 5.168419742584229, 'min_batch': 5.0169713497161865, 'max_batch': 5.243605518341065}
step: 8460 @ episode report: {'average_total_reward': 11.197001, 'reward_variance': 2.022741, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0354153394699095, 'actor_loss': -4.852461910247802, 'hyper_actor_loss': 0.07870303988456726, 'behavior_loss': 0.26755708903074266, 'mean_batch': 5.135735940933228, 'min_batch': 4.9871138572692875, 'max_batch': 5.2101842880249025}
step: 8470 @ episode report: {'average_total_reward': 9.466001, 'reward_variance': 2.895304, 'max_total_reward': 12.2300005, 'min_total_reward': 6.57, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.05524742603302, 'actor_loss': -4.837537717819214, 'hyper_actor_loss': 0.07859884798526764, 'behavior_loss': 0.2655967965722084, 'mean_batch': 5.093227767944336, 'min_batch': 4.954133415222168, 'max_batch': 5.158098459243774}
step: 8480 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 1.5560496, 'max_total_reward': 12.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4931829929351808, 'actor_loss': -4.821134328842163, 'hyper_actor_loss': 0.07877827510237694, 'behavior_loss': 0.27584626972675325, 'mean_batch': 5.050232028961181, 'min_batch': 4.915061664581299, 'max_batch': 5.115541791915893}
step: 8490 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 8.9148655, 'max_total_reward': 13.2300005, 'min_total_reward': 2.02, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7419193267822266, 'actor_loss': -4.881890535354614, 'hyper_actor_loss': 0.078934246301651, 'behavior_loss': 0.26184234470129014, 'mean_batch': 5.211651468276978, 'min_batch': 5.061201190948486, 'max_batch': 5.2825006484985355}
step: 8500 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 5.800289, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1446580410003664, 'actor_loss': -4.862449693679809, 'hyper_actor_loss': 0.07875029668211937, 'behavior_loss': 0.2539056807756424, 'mean_batch': 5.15725531578064, 'min_batch': 5.0164848327636715, 'max_batch': 5.223868560791016}
step: 8510 @ episode report: {'average_total_reward': 10.331001, 'reward_variance': 4.472571, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5085572361946107, 'actor_loss': -4.817985868453979, 'hyper_actor_loss': 0.07849454656243324, 'behavior_loss': 0.26088224202394483, 'mean_batch': 5.03967547416687, 'min_batch': 4.909936952590942, 'max_batch': 5.103496980667114}
step: 8520 @ episode report: {'average_total_reward': 10.109, 'reward_variance': 2.8872895, 'max_total_reward': 12.34, 'min_total_reward': 5.7899995, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6632649660110475, 'actor_loss': -4.883531713485718, 'hyper_actor_loss': 0.07850119844079018, 'behavior_loss': 0.2696325838565826, 'mean_batch': 5.196711778640747, 'min_batch': 5.0842413902282715, 'max_batch': 5.269932794570923}
step: 8530 @ episode report: {'average_total_reward': 10.931002, 'reward_variance': 3.1786299, 'max_total_reward': 13.450001, 'min_total_reward': 6.68, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4902905464172362, 'actor_loss': -4.906475687026978, 'hyper_actor_loss': 0.07843344807624816, 'behavior_loss': 0.25633516609668733, 'mean_batch': 5.2686797142028805, 'min_batch': 5.130900526046753, 'max_batch': 5.345872640609741}
step: 8540 @ episode report: {'average_total_reward': 9.666, 'reward_variance': 1.8502842, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.540360116958618, 'actor_loss': -4.869619464874267, 'hyper_actor_loss': 0.07836605980992317, 'behavior_loss': 0.2526109889149666, 'mean_batch': 5.177887010574341, 'min_batch': 5.031972026824951, 'max_batch': 5.250238561630249}
step: 8550 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 1.9817293, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7593650937080383, 'actor_loss': -4.8925580978393555, 'hyper_actor_loss': 0.07816453725099563, 'behavior_loss': 0.26978576481342315, 'mean_batch': 5.2195312023162845, 'min_batch': 5.107556438446045, 'max_batch': 5.2888181686401365}
step: 8560 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 1.8464289, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1558916330337525, 'actor_loss': -4.8507421016693115, 'hyper_actor_loss': 0.07819805517792702, 'behavior_loss': 0.25856939405202867, 'mean_batch': 5.108237028121948, 'min_batch': 5.005961656570435, 'max_batch': 5.176443433761596}
step: 8570 @ episode report: {'average_total_reward': 10.132, 'reward_variance': 2.7589958, 'max_total_reward': 13.23, 'min_total_reward': 7.9000006, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9308796107769013, 'actor_loss': -4.834436082839966, 'hyper_actor_loss': 0.0781655877828598, 'behavior_loss': 0.2676029562950134, 'mean_batch': 5.067004442214966, 'min_batch': 4.96449842453003, 'max_batch': 5.1291240692138675}
step: 8580 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 3.57556, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7754782140254974, 'actor_loss': -4.849638938903809, 'hyper_actor_loss': 0.07829043865203858, 'behavior_loss': 0.2797946497797966, 'mean_batch': 5.108961486816407, 'min_batch': 4.998873615264893, 'max_batch': 5.168697547912598}
step: 8590 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 2.3226414, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8095693081617354, 'actor_loss': -4.840976715087891, 'hyper_actor_loss': 0.07835821509361267, 'behavior_loss': 0.2739271119236946, 'mean_batch': 5.0768999576568605, 'min_batch': 4.987071943283081, 'max_batch': 5.141149091720581}
step: 8600 @ episode report: {'average_total_reward': 11.508, 'reward_variance': 0.9643961, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 12.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8858442187309266, 'actor_loss': -4.864841461181641, 'hyper_actor_loss': 0.07857140377163888, 'behavior_loss': 0.26555261462926866, 'mean_batch': 5.13834319114685, 'min_batch': 5.046559190750122, 'max_batch': 5.2051654815673825}
step: 8610 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.9166203, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9094260454177856, 'actor_loss': -4.864061784744263, 'hyper_actor_loss': 0.07840710580348968, 'behavior_loss': 0.27069759368896484, 'mean_batch': 5.1392162322998045, 'min_batch': 5.041779232025147, 'max_batch': 5.221738624572754}
step: 8620 @ episode report: {'average_total_reward': 10.210001, 'reward_variance': 8.162881, 'max_total_reward': 12.340001, 'min_total_reward': 1.9100001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.919682788848877, 'actor_loss': -4.846239805221558, 'hyper_actor_loss': 0.07813550978899002, 'behavior_loss': 0.27181166261434553, 'mean_batch': 5.097560834884644, 'min_batch': 4.9931299686431885, 'max_batch': 5.159050416946411}
step: 8630 @ episode report: {'average_total_reward': 10.798, 'reward_variance': 5.0074563, 'max_total_reward': 15.45, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6422019958496095, 'actor_loss': -4.8542797565460205, 'hyper_actor_loss': 0.07809397354722022, 'behavior_loss': 0.25484311729669573, 'mean_batch': 5.112569952011109, 'min_batch': 5.018814182281494, 'max_batch': 5.1712257862091064}
step: 8640 @ episode report: {'average_total_reward': 9.9869995, 'reward_variance': 2.842981, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.653755509853363, 'actor_loss': -4.894213533401489, 'hyper_actor_loss': 0.07792765274643898, 'behavior_loss': 0.2711190640926361, 'mean_batch': 5.220956134796142, 'min_batch': 5.114656162261963, 'max_batch': 5.290052986145019}
step: 8650 @ episode report: {'average_total_reward': 11.286, 'reward_variance': 4.322524, 'max_total_reward': 14.559999, 'min_total_reward': 6.68, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2012155652046204, 'actor_loss': -4.860670661926269, 'hyper_actor_loss': 0.07789845615625382, 'behavior_loss': 0.2737433806061745, 'mean_batch': 5.135735511779785, 'min_batch': 5.02851095199585, 'max_batch': 5.196744060516357}
step: 8660 @ episode report: {'average_total_reward': 9.620999, 'reward_variance': 10.289331, 'max_total_reward': 15.56, 'min_total_reward': 4.5699997, 'average_n_step': 10.6, 'max_n_step': 16.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6725861072540282, 'actor_loss': -4.80882420539856, 'hyper_actor_loss': 0.0779502347111702, 'behavior_loss': 0.2581973984837532, 'mean_batch': 4.997774457931518, 'min_batch': 4.905900764465332, 'max_batch': 5.052304649353028}
step: 8670 @ episode report: {'average_total_reward': 10.5199995, 'reward_variance': 2.7383, 'max_total_reward': 12.34, 'min_total_reward': 6.9000006, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8990917921066284, 'actor_loss': -4.884711456298828, 'hyper_actor_loss': 0.07775646597146987, 'behavior_loss': 0.2652157887816429, 'mean_batch': 5.192597055435181, 'min_batch': 5.0942826747894285, 'max_batch': 5.257613468170166}
step: 8680 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 4.032485, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6060969352722168, 'actor_loss': -4.873490715026856, 'hyper_actor_loss': 0.07760315388441086, 'behavior_loss': 0.2562021195888519, 'mean_batch': 5.168698453903199, 'min_batch': 5.060444736480713, 'max_batch': 5.229827165603638}
step: 8690 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 4.193776, 'max_total_reward': 13.450001, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9596708238124847, 'actor_loss': -4.844635152816773, 'hyper_actor_loss': 0.07756793946027755, 'behavior_loss': 0.26770199835300446, 'mean_batch': 5.090349435806274, 'min_batch': 4.992187547683716, 'max_batch': 5.150273084640503}
step: 8700 @ episode report: {'average_total_reward': 11.686001, 'reward_variance': 4.817623, 'max_total_reward': 15.67, 'min_total_reward': 9.01, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3785739839076996, 'actor_loss': -4.865147924423217, 'hyper_actor_loss': 0.07750137075781822, 'behavior_loss': 0.2703980982303619, 'mean_batch': 5.1353757858276365, 'min_batch': 5.051225996017456, 'max_batch': 5.204048156738281}
step: 8710 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 4.82914, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.151820409297943, 'actor_loss': -4.88623046875, 'hyper_actor_loss': 0.07761182934045792, 'behavior_loss': 0.27059326171875, 'mean_batch': 5.190976095199585, 'min_batch': 5.103777313232422, 'max_batch': 5.269949054718017}
step: 8720 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.7271638, 'max_total_reward': 14.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8609700083732605, 'actor_loss': -4.840923929214478, 'hyper_actor_loss': 0.07759866267442703, 'behavior_loss': 0.26335199922323227, 'mean_batch': 5.070241022109985, 'min_batch': 4.993317413330078, 'max_batch': 5.134307336807251}
step: 8730 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 4.6746206, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0648436188697814, 'actor_loss': -4.836076784133911, 'hyper_actor_loss': 0.0772753268480301, 'behavior_loss': 0.25260129421949384, 'mean_batch': 5.057844543457032, 'min_batch': 4.981348752975464, 'max_batch': 5.1333037376403805}
step: 8740 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 5.001656, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8791698217391968, 'actor_loss': -4.854322099685669, 'hyper_actor_loss': 0.07712653204798699, 'behavior_loss': 0.2714460000395775, 'mean_batch': 5.109087371826172, 'min_batch': 5.022483968734742, 'max_batch': 5.1785125732421875}
step: 8750 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.1954441, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7426340758800507, 'actor_loss': -4.8683922290802, 'hyper_actor_loss': 0.07719605043530464, 'behavior_loss': 0.2804933488368988, 'mean_batch': 5.144174337387085, 'min_batch': 5.058615112304688, 'max_batch': 5.22726001739502}
step: 8760 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 3.049944, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9430498898029327, 'actor_loss': -4.857410097122193, 'hyper_actor_loss': 0.07724012956023216, 'behavior_loss': 0.265162493288517, 'mean_batch': 5.112574434280395, 'min_batch': 5.034325742721558, 'max_batch': 5.1756726741790775}
step: 8770 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 3.4888241, 'max_total_reward': 14.56, 'min_total_reward': 7.6800003, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9149445295333862, 'actor_loss': -4.828709697723388, 'hyper_actor_loss': 0.07714962288737297, 'behavior_loss': 0.25802088230848313, 'mean_batch': 5.041208791732788, 'min_batch': 4.961129522323608, 'max_batch': 5.11082181930542}
step: 8780 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 1.2013489, 'max_total_reward': 12.339999, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.711398458480835, 'actor_loss': -4.862828111648559, 'hyper_actor_loss': 0.07695447504520417, 'behavior_loss': 0.2653272658586502, 'mean_batch': 5.133245134353638, 'min_batch': 5.04181432723999, 'max_batch': 5.205922317504883}
step: 8790 @ episode report: {'average_total_reward': 11.0529995, 'reward_variance': 3.7490227, 'max_total_reward': 14.450001, 'min_total_reward': 8.789999, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.2359174370765686, 'actor_loss': -4.893972969055175, 'hyper_actor_loss': 0.07673637270927429, 'behavior_loss': 0.26536666303873063, 'mean_batch': 5.214731121063233, 'min_batch': 5.119524812698364, 'max_batch': 5.2993072986602785}
step: 8800 @ episode report: {'average_total_reward': 10.931, 'reward_variance': 3.4714694, 'max_total_reward': 14.45, 'min_total_reward': 8.789999, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9036578774452209, 'actor_loss': -4.880828142166138, 'hyper_actor_loss': 0.07670276165008545, 'behavior_loss': 0.2659565731883049, 'mean_batch': 5.177581405639648, 'min_batch': 5.089315700531006, 'max_batch': 5.244438934326172}
step: 8810 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 1.7585557, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7607914209365845, 'actor_loss': -4.8587549209594725, 'hyper_actor_loss': 0.07678760960698128, 'behavior_loss': 0.2701248437166214, 'mean_batch': 5.124689435958862, 'min_batch': 5.029280328750611, 'max_batch': 5.189670896530151}
step: 8820 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 3.1029496, 'max_total_reward': 14.450001, 'min_total_reward': 8.790001, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7404828906059264, 'actor_loss': -4.8700364112854, 'hyper_actor_loss': 0.07678311839699745, 'behavior_loss': 0.2730783477425575, 'mean_batch': 5.153871726989746, 'min_batch': 5.05747423171997, 'max_batch': 5.238578367233276}
step: 8830 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 4.86107, 'max_total_reward': 14.450001, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0084763407707213, 'actor_loss': -4.863408088684082, 'hyper_actor_loss': 0.07662354409694672, 'behavior_loss': 0.24838408678770066, 'mean_batch': 5.1326133728027346, 'min_batch': 5.044843912124634, 'max_batch': 5.220036602020263}
step: 8840 @ episode report: {'average_total_reward': 11.397, 'reward_variance': 1.8566812, 'max_total_reward': 13.340001, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9809770345687867, 'actor_loss': -4.8251410007476805, 'hyper_actor_loss': 0.07650310397148133, 'behavior_loss': 0.274956950545311, 'mean_batch': 5.031527709960938, 'min_batch': 4.9530457019805905, 'max_batch': 5.0974030017852785}
step: 8850 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 3.2607245, 'max_total_reward': 13.340001, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7394731283187865, 'actor_loss': -4.860824632644653, 'hyper_actor_loss': 0.0762470506131649, 'behavior_loss': 0.249512280523777, 'mean_batch': 5.132602071762085, 'min_batch': 5.032363080978394, 'max_batch': 5.206721925735474}
step: 8860 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 2.5696566, 'max_total_reward': 13.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5561924785375596, 'actor_loss': -4.876502418518067, 'hyper_actor_loss': 0.07626725062727928, 'behavior_loss': 0.26828997433185575, 'mean_batch': 5.17050518989563, 'min_batch': 5.073894453048706, 'max_batch': 5.2557543277740475}
step: 8870 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 7.33835, 'max_total_reward': 13.45, 'min_total_reward': 5.35, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.006508302688599, 'actor_loss': -4.867205476760864, 'hyper_actor_loss': 0.0763941265642643, 'behavior_loss': 0.2692803919315338, 'mean_batch': 5.150959396362305, 'min_batch': 5.046139669418335, 'max_batch': 5.244364786148071}
step: 8880 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 1.8207207, 'max_total_reward': 11.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8700734376907349, 'actor_loss': -4.837197351455688, 'hyper_actor_loss': 0.07642725557088852, 'behavior_loss': 0.26618857979774474, 'mean_batch': 5.061491584777832, 'min_batch': 4.983352851867676, 'max_batch': 5.146847820281982}
step: 8890 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 3.4851449, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0037230610847474, 'actor_loss': -4.827752733230591, 'hyper_actor_loss': 0.07631314918398857, 'behavior_loss': 0.25476502180099486, 'mean_batch': 5.0436474800109865, 'min_batch': 4.953973293304443, 'max_batch': 5.14066071510315}
step: 8900 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.4206846, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6978498697280884, 'actor_loss': -4.8664943218231205, 'hyper_actor_loss': 0.07611793056130409, 'behavior_loss': 0.26650323867797854, 'mean_batch': 5.140754222869873, 'min_batch': 5.052693319320679, 'max_batch': 5.246347522735595}
step: 8910 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 2.4256492, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7737771987915039, 'actor_loss': -4.878351879119873, 'hyper_actor_loss': 0.07600141242146492, 'behavior_loss': 0.26988708823919294, 'mean_batch': 5.179615259170532, 'min_batch': 5.074385452270508, 'max_batch': 5.312984561920166}
step: 8920 @ episode report: {'average_total_reward': 11.519, 'reward_variance': 3.7478893, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.80048668384552, 'actor_loss': -4.853030204772949, 'hyper_actor_loss': 0.07601045221090316, 'behavior_loss': 0.2751729115843773, 'mean_batch': 5.105437421798706, 'min_batch': 5.019336700439453, 'max_batch': 5.2374364852905275}
step: 8930 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 4.2675695, 'max_total_reward': 14.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9432146072387695, 'actor_loss': -4.838983201980591, 'hyper_actor_loss': 0.07613027468323708, 'behavior_loss': 0.26552820205688477, 'mean_batch': 5.071418571472168, 'min_batch': 4.982516527175903, 'max_batch': 5.216625070571899}
step: 8940 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 3.6102366, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4990946024656295, 'actor_loss': -4.867343950271606, 'hyper_actor_loss': 0.07593704164028167, 'behavior_loss': 0.24458580315113068, 'mean_batch': 5.1467407703399655, 'min_batch': 5.0512782573699955, 'max_batch': 5.26942195892334}
step: 8950 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 2.5203836, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8786999940872193, 'actor_loss': -4.88686466217041, 'hyper_actor_loss': 0.07563963904976845, 'behavior_loss': 0.26542688012123106, 'mean_batch': 5.197130346298218, 'min_batch': 5.100604677200318, 'max_batch': 5.301690769195557}
step: 8960 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 2.060156, 'max_total_reward': 12.340001, 'min_total_reward': 7.7900004, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8186684131622315, 'actor_loss': -4.8354494094848635, 'hyper_actor_loss': 0.07547105252742767, 'behavior_loss': 0.2576265424489975, 'mean_batch': 5.0571677684783936, 'min_batch': 4.978997039794922, 'max_batch': 5.133710718154907}
step: 8970 @ episode report: {'average_total_reward': 10.653001, 'reward_variance': 0.8272213, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1271062016487123, 'actor_loss': -4.832605075836182, 'hyper_actor_loss': 0.07553216293454171, 'behavior_loss': 0.2610457926988602, 'mean_batch': 5.044660234451294, 'min_batch': 4.977100992202759, 'max_batch': 5.116096448898316}
step: 8980 @ episode report: {'average_total_reward': 8.766001, 'reward_variance': 3.5951855, 'max_total_reward': 12.340001, 'min_total_reward': 4.68, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7882785737514495, 'actor_loss': -4.844897890090943, 'hyper_actor_loss': 0.07561936303973198, 'behavior_loss': 0.2834900408983231, 'mean_batch': 5.0753334045410154, 'min_batch': 5.008618497848511, 'max_batch': 5.1420440673828125}
step: 8990 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.1023235, 'max_total_reward': 12.339999, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8307838916778565, 'actor_loss': -4.871645975112915, 'hyper_actor_loss': 0.07579207196831703, 'behavior_loss': 0.2677980974316597, 'mean_batch': 5.151169204711914, 'min_batch': 5.068213605880738, 'max_batch': 5.238273668289184}
step: 9000 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 9.396368, 'max_total_reward': 16.779999, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7143464922904967, 'actor_loss': -4.865549468994141, 'hyper_actor_loss': 0.0757939264178276, 'behavior_loss': 0.2706577882170677, 'mean_batch': 5.133641624450684, 'min_batch': 5.0546328067779545, 'max_batch': 5.207511043548584}
step: 9010 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 2.5734284, 'max_total_reward': 12.23, 'min_total_reward': 5.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1563361167907713, 'actor_loss': -4.836260366439819, 'hyper_actor_loss': 0.07559776306152344, 'behavior_loss': 0.26112821102142336, 'mean_batch': 5.056388998031617, 'min_batch': 4.9839198112487795, 'max_batch': 5.114723157882691}
step: 9020 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 1.4102608, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6474910616874694, 'actor_loss': -4.824222421646118, 'hyper_actor_loss': 0.07534601390361786, 'behavior_loss': 0.25339063405990603, 'mean_batch': 5.023813486099243, 'min_batch': 4.956064224243164, 'max_batch': 5.09360089302063}
step: 9030 @ episode report: {'average_total_reward': 9.521, 'reward_variance': 2.7775483, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4646685481071473, 'actor_loss': -4.899076080322265, 'hyper_actor_loss': 0.07517262175679207, 'behavior_loss': 0.27993243634700776, 'mean_batch': 5.2214563369750975, 'min_batch': 5.139578008651734, 'max_batch': 5.295075464248657}
step: 9040 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 1.5478694, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4564154133200646, 'actor_loss': -4.901596546173096, 'hyper_actor_loss': 0.07531948834657669, 'behavior_loss': 0.2555805191397667, 'mean_batch': 5.2292955875396725, 'min_batch': 5.144400358200073, 'max_batch': 5.297572660446167}
step: 9050 @ episode report: {'average_total_reward': 9.809999, 'reward_variance': 3.1317606, 'max_total_reward': 12.34, 'min_total_reward': 7.4599996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.958917498588562, 'actor_loss': -4.8681787014007565, 'hyper_actor_loss': 0.07525548711419106, 'behavior_loss': 0.26669787168502807, 'mean_batch': 5.140742206573487, 'min_batch': 5.0613123893737795, 'max_batch': 5.20121808052063}
step: 9060 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 1.0644562, 'max_total_reward': 11.23, 'min_total_reward': 7.8999996, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7561601102352142, 'actor_loss': -4.842463493347168, 'hyper_actor_loss': 0.07522213533520698, 'behavior_loss': 0.2661509394645691, 'mean_batch': 5.07443642616272, 'min_batch': 4.996939039230346, 'max_batch': 5.129177808761597}
step: 9070 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 1.3605449, 'max_total_reward': 11.120001, 'min_total_reward': 6.6800003, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6723922491073608, 'actor_loss': -4.873450374603271, 'hyper_actor_loss': 0.07512166276574135, 'behavior_loss': 0.2582335978746414, 'mean_batch': 5.152246284484863, 'min_batch': 5.076320600509644, 'max_batch': 5.219445848464966}
step: 9080 @ episode report: {'average_total_reward': 9.999001, 'reward_variance': 2.0820286, 'max_total_reward': 13.23, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.762207818031311, 'actor_loss': -4.8696493148803714, 'hyper_actor_loss': 0.07505625560879707, 'behavior_loss': 0.2649740934371948, 'mean_batch': 5.146702241897583, 'min_batch': 5.062525510787964, 'max_batch': 5.205226707458496}
step: 9090 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 2.0445352, 'max_total_reward': 13.45, 'min_total_reward': 7.9000006, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9863756895065308, 'actor_loss': -4.848280334472657, 'hyper_actor_loss': 0.07519734874367714, 'behavior_loss': 0.28050714284181594, 'mean_batch': 5.083416509628296, 'min_batch': 5.017379999160767, 'max_batch': 5.146467781066894}
step: 9100 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 2.4602005, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9138267993927003, 'actor_loss': -4.831423664093018, 'hyper_actor_loss': 0.07542973309755326, 'behavior_loss': 0.27775035351514815, 'mean_batch': 5.041709852218628, 'min_batch': 4.974194002151489, 'max_batch': 5.1077838897705075}
step: 9110 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 2.6366007, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.778256243467331, 'actor_loss': -4.859232759475708, 'hyper_actor_loss': 0.07527602687478066, 'behavior_loss': 0.2645836353302002, 'mean_batch': 5.113893508911133, 'min_batch': 5.042205333709717, 'max_batch': 5.177694416046142}
step: 9120 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 3.408976, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7758547902107238, 'actor_loss': -4.878957653045655, 'hyper_actor_loss': 0.075090641528368, 'behavior_loss': 0.2666361019015312, 'mean_batch': 5.16714916229248, 'min_batch': 5.089632225036621, 'max_batch': 5.2616462230682375}
step: 9130 @ episode report: {'average_total_reward': 10.641999, 'reward_variance': 2.6138158, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3777031004428864, 'actor_loss': -4.882883501052857, 'hyper_actor_loss': 0.07484524771571159, 'behavior_loss': 0.2733180597424507, 'mean_batch': 5.181443786621093, 'min_batch': 5.095611524581909, 'max_batch': 5.2507964134216305}
step: 9140 @ episode report: {'average_total_reward': 8.611, 'reward_variance': 2.4229493, 'max_total_reward': 10.01, 'min_total_reward': 5.79, 'average_n_step': 9.7, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.541232693195343, 'actor_loss': -4.8980052947998045, 'hyper_actor_loss': 0.07484493479132652, 'behavior_loss': 0.2634709522128105, 'mean_batch': 5.22321310043335, 'min_batch': 5.131814050674438, 'max_batch': 5.291637706756592}
step: 9150 @ episode report: {'average_total_reward': 9.998001, 'reward_variance': 3.9814155, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9039187014102936, 'actor_loss': -4.885229206085205, 'hyper_actor_loss': 0.0748743936419487, 'behavior_loss': 0.2876138433814049, 'mean_batch': 5.181862735748291, 'min_batch': 5.1074607372283936, 'max_batch': 5.254487085342407}
step: 9160 @ episode report: {'average_total_reward': 9.932, 'reward_variance': 9.267757, 'max_total_reward': 14.450002, 'min_total_reward': 2.13, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9647884368896484, 'actor_loss': -4.815648746490479, 'hyper_actor_loss': 0.0750004805624485, 'behavior_loss': 0.2746258705854416, 'mean_batch': 5.003908967971801, 'min_batch': 4.933442115783691, 'max_batch': 5.050713396072387}
step: 9170 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 4.042616, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.854201900959015, 'actor_loss': -4.8396806716918945, 'hyper_actor_loss': 0.07496237084269523, 'behavior_loss': 0.26698353290557864, 'mean_batch': 5.06466851234436, 'min_batch': 4.9929773807525635, 'max_batch': 5.115673160552978}
step: 9180 @ episode report: {'average_total_reward': 8.534, 'reward_variance': 8.278105, 'max_total_reward': 13.450001, 'min_total_reward': 2.46, 'average_n_step': 9.7, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7615070670843125, 'actor_loss': -4.889370346069336, 'hyper_actor_loss': 0.07490975856781006, 'behavior_loss': 0.29438029080629347, 'mean_batch': 5.196391534805298, 'min_batch': 5.113996410369873, 'max_batch': 5.256887531280517}
step: 9190 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 1.6834443, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7630633234977722, 'actor_loss': -4.877161598205566, 'hyper_actor_loss': 0.07501381635665894, 'behavior_loss': 0.28687001317739486, 'mean_batch': 5.1688560962677, 'min_batch': 5.078825902938843, 'max_batch': 5.244733667373657}
step: 9200 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 2.539796, 'max_total_reward': 11.2300005, 'min_total_reward': 6.68, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.786262285709381, 'actor_loss': -4.8452376365661625, 'hyper_actor_loss': 0.07488380447030067, 'behavior_loss': 0.25635172724723815, 'mean_batch': 5.078875207901001, 'min_batch': 5.006471824645996, 'max_batch': 5.13501009941101}
step: 9210 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 5.7082033, 'max_total_reward': 13.449999, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8669860124588014, 'actor_loss': -4.862212371826172, 'hyper_actor_loss': 0.07444110214710235, 'behavior_loss': 0.25649301558732984, 'mean_batch': 5.117466259002685, 'min_batch': 5.053776979446411, 'max_batch': 5.1888831615447994}
step: 9220 @ episode report: {'average_total_reward': 9.553999, 'reward_variance': 9.636445, 'max_total_reward': 12.34, 'min_total_reward': 1.24, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7900626540184021, 'actor_loss': -4.87418041229248, 'hyper_actor_loss': 0.07402502819895744, 'behavior_loss': 0.26783958822488785, 'mean_batch': 5.154034519195557, 'min_batch': 5.078230476379394, 'max_batch': 5.242048597335815}
step: 9230 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 2.0744767, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4276107192039489, 'actor_loss': -4.8840906620025635, 'hyper_actor_loss': 0.07406069710850716, 'behavior_loss': 0.2696123570203781, 'mean_batch': 5.182604837417602, 'min_batch': 5.100637483596802, 'max_batch': 5.249914169311523}
step: 9240 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 3.5081162, 'max_total_reward': 12.12, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8524443536996842, 'actor_loss': -4.898618125915528, 'hyper_actor_loss': 0.07408228665590286, 'behavior_loss': 0.26797322928905487, 'mean_batch': 5.2178877830505375, 'min_batch': 5.140309429168701, 'max_batch': 5.287855195999145}
step: 9250 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 2.7838244, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8568500339984895, 'actor_loss': -4.860362863540649, 'hyper_actor_loss': 0.07412877976894379, 'behavior_loss': 0.26890256106853483, 'mean_batch': 5.113191080093384, 'min_batch': 5.048570966720581, 'max_batch': 5.178976535797119}
step: 9260 @ episode report: {'average_total_reward': 10.542, 'reward_variance': 4.3087354, 'max_total_reward': 14.559999, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9829521775245667, 'actor_loss': -4.836324739456177, 'hyper_actor_loss': 0.07422697693109512, 'behavior_loss': 0.26191638559103014, 'mean_batch': 5.055400943756103, 'min_batch': 4.985050344467163, 'max_batch': 5.1333824634552006}
step: 9270 @ episode report: {'average_total_reward': 9.61, 'reward_variance': 2.9090393, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0341376662254333, 'actor_loss': -4.8433867454528805, 'hyper_actor_loss': 0.07408753037452698, 'behavior_loss': 0.26470562219619753, 'mean_batch': 5.068407487869263, 'min_batch': 5.007444572448731, 'max_batch': 5.149090003967285}
step: 9280 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 3.7191403, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.746778178215027, 'actor_loss': -4.862626266479492, 'hyper_actor_loss': 0.0739374354481697, 'behavior_loss': 0.27930495589971543, 'mean_batch': 5.125101566314697, 'min_batch': 5.048354387283325, 'max_batch': 5.220997142791748}
step: 9290 @ episode report: {'average_total_reward': 9.921, 'reward_variance': 1.8767493, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9621179580688477, 'actor_loss': -4.870876359939575, 'hyper_actor_loss': 0.07404959052801133, 'behavior_loss': 0.26469238102436066, 'mean_batch': 5.148758316040039, 'min_batch': 5.066741895675659, 'max_batch': 5.240342426300049}
step: 9300 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 2.0255241, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7976245939731599, 'actor_loss': -4.872320461273193, 'hyper_actor_loss': 0.07399188205599785, 'behavior_loss': 0.2738451808691025, 'mean_batch': 5.1476161003112795, 'min_batch': 5.075126028060913, 'max_batch': 5.246181583404541}
step: 9310 @ episode report: {'average_total_reward': 10.443001, 'reward_variance': 2.1144416, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8413082778453826, 'actor_loss': -4.8487396240234375, 'hyper_actor_loss': 0.073921699821949, 'behavior_loss': 0.2588930860161781, 'mean_batch': 5.085357618331909, 'min_batch': 5.017677068710327, 'max_batch': 5.178484630584717}
step: 9320 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 5.2994843, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6682618796825408, 'actor_loss': -4.887051105499268, 'hyper_actor_loss': 0.07362855151295662, 'behavior_loss': 0.27028380185365675, 'mean_batch': 5.187213468551636, 'min_batch': 5.111753320693969, 'max_batch': 5.272175884246826}
step: 9330 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 7.1877456, 'max_total_reward': 13.34, 'min_total_reward': 4.68, 'average_n_step': 10.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7614854231476784, 'actor_loss': -4.862333583831787, 'hyper_actor_loss': 0.07355840131640434, 'behavior_loss': 0.2735092654824257, 'mean_batch': 5.119070196151734, 'min_batch': 5.053144407272339, 'max_batch': 5.199884271621704}
step: 9340 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 3.6144497, 'max_total_reward': 12.340001, 'min_total_reward': 7.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4565904200077058, 'actor_loss': -4.893842601776123, 'hyper_actor_loss': 0.07350883707404136, 'behavior_loss': 0.26259119957685473, 'mean_batch': 5.207486486434936, 'min_batch': 5.12669825553894, 'max_batch': 5.279672384262085}
step: 9350 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 5.2068205, 'max_total_reward': 13.23, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.060782343149185, 'actor_loss': -4.912136507034302, 'hyper_actor_loss': 0.0734476625919342, 'behavior_loss': 0.2555115565657616, 'mean_batch': 5.255685520172119, 'min_batch': 5.173261308670044, 'max_batch': 5.333372688293457}
step: 9360 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 2.5815616, 'max_total_reward': 12.12, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.978928166627884, 'actor_loss': -4.831046676635742, 'hyper_actor_loss': 0.07320754006505012, 'behavior_loss': 0.26427639573812484, 'mean_batch': 5.037911128997803, 'min_batch': 4.976174259185791, 'max_batch': 5.1071545600891115}
step: 9370 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 2.173065, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9388070821762085, 'actor_loss': -4.8257080078125, 'hyper_actor_loss': 0.07298203334212303, 'behavior_loss': 0.2696658208966255, 'mean_batch': 5.0253486156463625, 'min_batch': 4.962061738967895, 'max_batch': 5.091597938537598}
step: 9380 @ episode report: {'average_total_reward': 10.553001, 'reward_variance': 3.8123422, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2931270480155943, 'actor_loss': -4.8539262294769285, 'hyper_actor_loss': 0.07316571548581123, 'behavior_loss': 0.27932716310024264, 'mean_batch': 5.096810626983642, 'min_batch': 5.0323127746582035, 'max_batch': 5.172046089172364}
step: 9390 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 4.543326, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9517840266227722, 'actor_loss': -4.833406591415406, 'hyper_actor_loss': 0.07334817498922348, 'behavior_loss': 0.2647300913929939, 'mean_batch': 5.046327114105225, 'min_batch': 4.979397630691528, 'max_batch': 5.1118134498596195}
step: 9400 @ episode report: {'average_total_reward': 10.099001, 'reward_variance': 2.106009, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8232422351837159, 'actor_loss': -4.859114027023315, 'hyper_actor_loss': 0.07314967438578605, 'behavior_loss': 0.27123108357191084, 'mean_batch': 5.118945550918579, 'min_batch': 5.036649417877197, 'max_batch': 5.1877415657043455}
step: 9410 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 1.2375456, 'max_total_reward': 13.450001, 'min_total_reward': 10.009999, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8934116601943969, 'actor_loss': -4.865939331054688, 'hyper_actor_loss': 0.07300029173493386, 'behavior_loss': 0.2625368222594261, 'mean_batch': 5.139573621749878, 'min_batch': 5.050718975067139, 'max_batch': 5.201132917404175}
step: 9420 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 4.0768056, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4642582356929779, 'actor_loss': -4.872888469696045, 'hyper_actor_loss': 0.07295592501759529, 'behavior_loss': 0.27422660440206525, 'mean_batch': 5.15706582069397, 'min_batch': 5.068837118148804, 'max_batch': 5.21117377281189}
step: 9430 @ episode report: {'average_total_reward': 10.098, 'reward_variance': 5.674436, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6615369975566865, 'actor_loss': -4.890218591690063, 'hyper_actor_loss': 0.07297694608569145, 'behavior_loss': 0.2660986304283142, 'mean_batch': 5.204010534286499, 'min_batch': 5.110807418823242, 'max_batch': 5.258693361282349}
step: 9440 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 2.938824, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9671929240226746, 'actor_loss': -4.874861526489258, 'hyper_actor_loss': 0.07280899658799171, 'behavior_loss': 0.2719827726483345, 'mean_batch': 5.16595950126648, 'min_batch': 5.070095252990723, 'max_batch': 5.22162971496582}
step: 9450 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.157526, 'max_total_reward': 13.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6608687341213226, 'actor_loss': -4.837948513031006, 'hyper_actor_loss': 0.0726328082382679, 'behavior_loss': 0.2845099166035652, 'mean_batch': 5.062672519683838, 'min_batch': 4.985934257507324, 'max_batch': 5.122770309448242}
step: 9460 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 3.061896, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7105425596237183, 'actor_loss': -4.878671073913575, 'hyper_actor_loss': 0.07278320118784905, 'behavior_loss': 0.2658929482102394, 'mean_batch': 5.180790138244629, 'min_batch': 5.075191164016724, 'max_batch': 5.235099792480469}
step: 9470 @ episode report: {'average_total_reward': 9.232, 'reward_variance': 3.6784966, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4495743423700334, 'actor_loss': -4.90378851890564, 'hyper_actor_loss': 0.07253801748156548, 'behavior_loss': 0.25714130997657775, 'mean_batch': 5.236920738220215, 'min_batch': 5.148066854476928, 'max_batch': 5.296701574325562}
step: 9480 @ episode report: {'average_total_reward': 9.466001, 'reward_variance': 1.4605844, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6512002348899841, 'actor_loss': -4.894162893295288, 'hyper_actor_loss': 0.07221593707799911, 'behavior_loss': 0.25170126259326936, 'mean_batch': 5.217075538635254, 'min_batch': 5.11814923286438, 'max_batch': 5.277474069595337}
step: 9490 @ episode report: {'average_total_reward': 10.653001, 'reward_variance': 3.069421, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7260874509811401, 'actor_loss': -4.882903814315796, 'hyper_actor_loss': 0.07194023430347443, 'behavior_loss': 0.2715627983212471, 'mean_batch': 5.18605260848999, 'min_batch': 5.091118049621582, 'max_batch': 5.2506006240844725}
step: 9500 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 1.3173438, 'max_total_reward': 10.12, 'min_total_reward': 6.7900004, 'average_n_step': 9.8, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7800045609474182, 'actor_loss': -4.870390510559082, 'hyper_actor_loss': 0.07192831262946128, 'behavior_loss': 0.26808680295944215, 'mean_batch': 5.151335954666138, 'min_batch': 5.061754941940308, 'max_batch': 5.215893888473511}
step: 9510 @ episode report: {'average_total_reward': 8.811, 'reward_variance': 6.9294677, 'max_total_reward': 13.23, 'min_total_reward': 4.3500004, 'average_n_step': 9.9, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6297590255737304, 'actor_loss': -4.892406845092774, 'hyper_actor_loss': 0.0721138633787632, 'behavior_loss': 0.2729375034570694, 'mean_batch': 5.207901287078857, 'min_batch': 5.118261623382568, 'max_batch': 5.276500034332275}
step: 9520 @ episode report: {'average_total_reward': 9.876, 'reward_variance': 5.5687647, 'max_total_reward': 13.340001, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.764563411474228, 'actor_loss': -4.896820449829102, 'hyper_actor_loss': 0.07232561483979225, 'behavior_loss': 0.2700584426522255, 'mean_batch': 5.217100954055786, 'min_batch': 5.13181791305542, 'max_batch': 5.276790714263916}
step: 9530 @ episode report: {'average_total_reward': 9.087999, 'reward_variance': 5.590836, 'max_total_reward': 12.34, 'min_total_reward': 3.4599998, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6204102516174317, 'actor_loss': -4.87176480293274, 'hyper_actor_loss': 0.0722664400935173, 'behavior_loss': 0.2659215912222862, 'mean_batch': 5.150018548965454, 'min_batch': 5.069977807998657, 'max_batch': 5.218937683105469}
step: 9540 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.6566805, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7109325766563415, 'actor_loss': -4.898163080215454, 'hyper_actor_loss': 0.07204469367861747, 'behavior_loss': 0.2581190884113312, 'mean_batch': 5.221474361419678, 'min_batch': 5.134330797195434, 'max_batch': 5.311370038986206}
step: 9550 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 4.5256443, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.987585985660553, 'actor_loss': -4.893368244171143, 'hyper_actor_loss': 0.07176753208041191, 'behavior_loss': 0.2579358249902725, 'mean_batch': 5.210396385192871, 'min_batch': 5.120722246170044, 'max_batch': 5.275985383987427}
step: 9560 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 3.7579284, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.810901939868927, 'actor_loss': -4.854494953155518, 'hyper_actor_loss': 0.07152453437447548, 'behavior_loss': 0.269279482960701, 'mean_batch': 5.105186223983765, 'min_batch': 5.026970672607422, 'max_batch': 5.168872451782226}
step: 9570 @ episode report: {'average_total_reward': 8.189, 'reward_variance': 1.5202093, 'max_total_reward': 10.120001, 'min_total_reward': 6.79, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.80667245388031, 'actor_loss': -4.883127355575562, 'hyper_actor_loss': 0.07168060764670373, 'behavior_loss': 0.2766411125659943, 'mean_batch': 5.184945011138916, 'min_batch': 5.093508720397949, 'max_batch': 5.240427255630493}
step: 9580 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 2.861021, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7655958592891694, 'actor_loss': -4.884166622161866, 'hyper_actor_loss': 0.07197375521063805, 'behavior_loss': 0.2706670626997948, 'mean_batch': 5.197375011444092, 'min_batch': 5.086519479751587, 'max_batch': 5.264487648010254}
step: 9590 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 4.381981, 'max_total_reward': 12.340001, 'min_total_reward': 5.7900004, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.734868723154068, 'actor_loss': -4.869770336151123, 'hyper_actor_loss': 0.07193802520632744, 'behavior_loss': 0.2619634583592415, 'mean_batch': 5.154270601272583, 'min_batch': 5.055701637268067, 'max_batch': 5.226547622680664}
step: 9600 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 3.1571617, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.846132755279541, 'actor_loss': -4.883661937713623, 'hyper_actor_loss': 0.07173524796962738, 'behavior_loss': 0.2529470816254616, 'mean_batch': 5.193690633773803, 'min_batch': 5.087468671798706, 'max_batch': 5.261550998687744}
step: 9610 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 3.6790566, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9360451579093934, 'actor_loss': -4.880677700042725, 'hyper_actor_loss': 0.07138503491878509, 'behavior_loss': 0.26179759204387665, 'mean_batch': 5.186731433868408, 'min_batch': 5.079257345199585, 'max_batch': 5.269339179992675}
step: 9620 @ episode report: {'average_total_reward': 9.144, 'reward_variance': 2.5386643, 'max_total_reward': 12.12, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6149139404296875, 'actor_loss': -4.865655422210693, 'hyper_actor_loss': 0.07133808583021164, 'behavior_loss': 0.2671894535422325, 'mean_batch': 5.138431358337402, 'min_batch': 5.050475931167602, 'max_batch': 5.2339507102966305}
step: 9630 @ episode report: {'average_total_reward': 8.845, 'reward_variance': 0.42722493, 'max_total_reward': 10.12, 'min_total_reward': 7.7900004, 'average_n_step': 10.0, 'max_n_step': 11.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9214847207069397, 'actor_loss': -4.889274835586548, 'hyper_actor_loss': 0.0715042658150196, 'behavior_loss': 0.2703838810324669, 'mean_batch': 5.202924013137817, 'min_batch': 5.107105016708374, 'max_batch': 5.272323179244995}
step: 9640 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 1.9541619, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.01521954536438, 'actor_loss': -4.8560832977294925, 'hyper_actor_loss': 0.07175752222537994, 'behavior_loss': 0.2790940165519714, 'mean_batch': 5.120956611633301, 'min_batch': 5.0195960521698, 'max_batch': 5.204517841339111}
step: 9650 @ episode report: {'average_total_reward': 8.655001, 'reward_variance': 2.2686455, 'max_total_reward': 11.2300005, 'min_total_reward': 6.68, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.689586240053177, 'actor_loss': -4.862383508682251, 'hyper_actor_loss': 0.07146547138690948, 'behavior_loss': 0.2667857617139816, 'mean_batch': 5.141186714172363, 'min_batch': 5.031437921524048, 'max_batch': 5.227687931060791}
step: 9660 @ episode report: {'average_total_reward': 9.155001, 'reward_variance': 4.010485, 'max_total_reward': 13.23, 'min_total_reward': 6.680001, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6160826086997986, 'actor_loss': -4.9067929744720455, 'hyper_actor_loss': 0.07136565074324608, 'behavior_loss': 0.26860592514276505, 'mean_batch': 5.253951120376587, 'min_batch': 5.146922540664673, 'max_batch': 5.381458187103272}
step: 9670 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 2.0123844, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.256993591785431, 'actor_loss': -4.8598165035247805, 'hyper_actor_loss': 0.07132752761244773, 'behavior_loss': 0.2716651692986488, 'mean_batch': 5.130273723602295, 'min_batch': 5.030126333236694, 'max_batch': 5.223513221740722}
step: 9680 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 1.4000088, 'max_total_reward': 11.12, 'min_total_reward': 6.7900004, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7983421325683593, 'actor_loss': -4.829816293716431, 'hyper_actor_loss': 0.07136973142623901, 'behavior_loss': 0.2697783589363098, 'mean_batch': 5.045885133743286, 'min_batch': 4.962159538269043, 'max_batch': 5.10066442489624}
step: 9690 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 1.496476, 'max_total_reward': 11.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8132032036781311, 'actor_loss': -4.902556324005127, 'hyper_actor_loss': 0.07124598026275634, 'behavior_loss': 0.27266603261232375, 'mean_batch': 5.23888931274414, 'min_batch': 5.1402058601379395, 'max_batch': 5.308909845352173}
step: 9700 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 2.467336, 'max_total_reward': 12.23, 'min_total_reward': 6.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3488167762756347, 'actor_loss': -4.864218616485596, 'hyper_actor_loss': 0.07110312730073928, 'behavior_loss': 0.2707358837127686, 'mean_batch': 5.127975749969482, 'min_batch': 5.054595279693603, 'max_batch': 5.203710126876831}
step: 9710 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 2.0749285, 'max_total_reward': 11.23, 'min_total_reward': 5.57, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3002783000469207, 'actor_loss': -4.848407649993897, 'hyper_actor_loss': 0.07106816172599792, 'behavior_loss': 0.2743789628148079, 'mean_batch': 5.091460418701172, 'min_batch': 5.0111478805542, 'max_batch': 5.148499870300293}
step: 9720 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 4.5086837, 'max_total_reward': 14.12, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6373351454734801, 'actor_loss': -4.917974615097046, 'hyper_actor_loss': 0.0711612120270729, 'behavior_loss': 0.2820481613278389, 'mean_batch': 5.279299402236939, 'min_batch': 5.1797514915466305, 'max_batch': 5.35643253326416}
step: 9730 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 2.5700288, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6355084091424943, 'actor_loss': -4.909077835083008, 'hyper_actor_loss': 0.0713087946176529, 'behavior_loss': 0.27633998543024063, 'mean_batch': 5.251140069961548, 'min_batch': 5.161445379257202, 'max_batch': 5.321011734008789}
step: 9740 @ episode report: {'average_total_reward': 9.254999, 'reward_variance': 5.010745, 'max_total_reward': 13.34, 'min_total_reward': 5.57, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9176745653152465, 'actor_loss': -4.882857847213745, 'hyper_actor_loss': 0.071159777790308, 'behavior_loss': 0.27577370405197144, 'mean_batch': 5.182393980026245, 'min_batch': 5.094577074050903, 'max_batch': 5.26588134765625}
step: 9750 @ episode report: {'average_total_reward': 9.999001, 'reward_variance': 1.8894888, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.078718972206116, 'actor_loss': -4.862244653701782, 'hyper_actor_loss': 0.07102920562028885, 'behavior_loss': 0.26868876069784164, 'mean_batch': 5.1258501529693605, 'min_batch': 5.045792198181152, 'max_batch': 5.188656616210937}
step: 9760 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 3.3235888, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9271182537078857, 'actor_loss': -4.856388235092163, 'hyper_actor_loss': 0.07086828202009202, 'behavior_loss': 0.2671632319688797, 'mean_batch': 5.099804639816284, 'min_batch': 5.041749477386475, 'max_batch': 5.145101165771484}
step: 9770 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 2.1336448, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.915581277012825, 'actor_loss': -4.887073421478272, 'hyper_actor_loss': 0.07059913501143456, 'behavior_loss': 0.24435315430164337, 'mean_batch': 5.188920354843139, 'min_batch': 5.109631681442261, 'max_batch': 5.240590333938599}
step: 9780 @ episode report: {'average_total_reward': 9.244, 'reward_variance': 3.5899644, 'max_total_reward': 12.23, 'min_total_reward': 6.57, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8761784076690673, 'actor_loss': -4.884528779983521, 'hyper_actor_loss': 0.07033751606941223, 'behavior_loss': 0.27133475840091703, 'mean_batch': 5.1783106327056885, 'min_batch': 5.107106924057007, 'max_batch': 5.227784204483032}
step: 9790 @ episode report: {'average_total_reward': 8.788, 'reward_variance': 3.1148162, 'max_total_reward': 11.120001, 'min_total_reward': 5.79, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0337041139602663, 'actor_loss': -4.854101705551147, 'hyper_actor_loss': 0.07034623026847839, 'behavior_loss': 0.27450861036777496, 'mean_batch': 5.101363325119019, 'min_batch': 5.028758573532104, 'max_batch': 5.159561109542847}
step: 9800 @ episode report: {'average_total_reward': 8.833, 'reward_variance': 1.8115609, 'max_total_reward': 10.900001, 'min_total_reward': 6.7900004, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8582865476608277, 'actor_loss': -4.860242891311645, 'hyper_actor_loss': 0.0704554907977581, 'behavior_loss': 0.2670804962515831, 'mean_batch': 5.109498167037964, 'min_batch': 5.051692771911621, 'max_batch': 5.166123342514038}
step: 9810 @ episode report: {'average_total_reward': 8.911, 'reward_variance': 2.077189, 'max_total_reward': 12.12, 'min_total_reward': 6.680001, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9597941428422927, 'actor_loss': -4.868666076660157, 'hyper_actor_loss': 0.07055896297097206, 'behavior_loss': 0.2748969003558159, 'mean_batch': 5.136373138427734, 'min_batch': 5.067691850662231, 'max_batch': 5.181184482574463}
step: 9820 @ episode report: {'average_total_reward': 8.8550005, 'reward_variance': 5.1490645, 'max_total_reward': 12.12, 'min_total_reward': 4.57, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7736014783382417, 'actor_loss': -4.8637536525726315, 'hyper_actor_loss': 0.07063673809170723, 'behavior_loss': 0.27776834070682527, 'mean_batch': 5.123874521255493, 'min_batch': 5.055159378051758, 'max_batch': 5.169698190689087}
step: 9830 @ episode report: {'average_total_reward': 8.6, 'reward_variance': 2.8203006, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.535362932085991, 'actor_loss': -4.877531242370606, 'hyper_actor_loss': 0.07051229551434517, 'behavior_loss': 0.27187223434448243, 'mean_batch': 5.163322114944458, 'min_batch': 5.086279678344726, 'max_batch': 5.211932563781739}
step: 9840 @ episode report: {'average_total_reward': 9.321, 'reward_variance': 3.2079482, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7182632446289063, 'actor_loss': -4.920254898071289, 'hyper_actor_loss': 0.07047297805547714, 'behavior_loss': 0.2756719946861267, 'mean_batch': 5.268270587921142, 'min_batch': 5.202383899688721, 'max_batch': 5.314929533004761}
step: 9850 @ episode report: {'average_total_reward': 8.8220005, 'reward_variance': 1.5528563, 'max_total_reward': 11.12, 'min_total_reward': 6.7899995, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9539684534072876, 'actor_loss': -4.875598478317261, 'hyper_actor_loss': 0.07057897970080376, 'behavior_loss': 0.29165526330471037, 'mean_batch': 5.148418140411377, 'min_batch': 5.091414260864258, 'max_batch': 5.196744060516357}
step: 9860 @ episode report: {'average_total_reward': 9.766001, 'reward_variance': 1.8066645, 'max_total_reward': 12.12, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7598458021879195, 'actor_loss': -4.864196825027466, 'hyper_actor_loss': 0.07073022425174713, 'behavior_loss': 0.265460678935051, 'mean_batch': 5.125935363769531, 'min_batch': 5.0554728507995605, 'max_batch': 5.1702958106994625}
step: 9870 @ episode report: {'average_total_reward': 8.2, 'reward_variance': 3.6158805, 'max_total_reward': 11.2300005, 'min_total_reward': 4.68, 'average_n_step': 9.3, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8202618956565857, 'actor_loss': -4.882436943054199, 'hyper_actor_loss': 0.07051391154527664, 'behavior_loss': 0.25720197707414627, 'mean_batch': 5.178817796707153, 'min_batch': 5.0958521366119385, 'max_batch': 5.225425100326538}
step: 9880 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 2.6296895, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0901123762130736, 'actor_loss': -4.864113855361938, 'hyper_actor_loss': 0.07025008723139763, 'behavior_loss': 0.28418204188346863, 'mean_batch': 5.123476028442383, 'min_batch': 5.0574242115020756, 'max_batch': 5.159833526611328}
step: 9890 @ episode report: {'average_total_reward': 9.165999, 'reward_variance': 4.9210043, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8323717951774596, 'actor_loss': -4.848270559310913, 'hyper_actor_loss': 0.07030121833086014, 'behavior_loss': 0.2597497865557671, 'mean_batch': 5.075142908096313, 'min_batch': 5.025281143188477, 'max_batch': 5.123758983612061}
step: 9900 @ episode report: {'average_total_reward': 8.722, 'reward_variance': 4.072077, 'max_total_reward': 11.2300005, 'min_total_reward': 5.5699997, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9427741408348083, 'actor_loss': -4.87550539970398, 'hyper_actor_loss': 0.0701289139688015, 'behavior_loss': 0.2694603160023689, 'mean_batch': 5.147107076644898, 'min_batch': 5.09187536239624, 'max_batch': 5.192783689498901}
step: 9910 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 2.751429, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.993882405757904, 'actor_loss': -4.859245300292969, 'hyper_actor_loss': 0.07030288055539131, 'behavior_loss': 0.2859803318977356, 'mean_batch': 5.107349300384522, 'min_batch': 5.048721170425415, 'max_batch': 5.1433593273162845}
step: 9920 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 5.872365, 'max_total_reward': 13.12, 'min_total_reward': 4.68, 'average_n_step': 10.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7201507925987243, 'actor_loss': -4.857686185836792, 'hyper_actor_loss': 0.070338174700737, 'behavior_loss': 0.26263202279806136, 'mean_batch': 5.100059127807617, 'min_batch': 5.048173522949218, 'max_batch': 5.142913103103638}
step: 9930 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 1.6598848, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8314616441726685, 'actor_loss': -4.892373418807983, 'hyper_actor_loss': 0.07027754858136177, 'behavior_loss': 0.26178663820028303, 'mean_batch': 5.189311790466308, 'min_batch': 5.136329507827758, 'max_batch': 5.235744857788086}
step: 9940 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 3.8581898, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.061950123310089, 'actor_loss': -4.872028493881226, 'hyper_actor_loss': 0.07001826092600823, 'behavior_loss': 0.27181824296712875, 'mean_batch': 5.132956647872925, 'min_batch': 5.088279438018799, 'max_batch': 5.16606764793396}
step: 9950 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 2.2060409, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.698333752155304, 'actor_loss': -4.852918195724487, 'hyper_actor_loss': 0.06986088454723358, 'behavior_loss': 0.26193862557411196, 'mean_batch': 5.084911823272705, 'min_batch': 5.0390547752380375, 'max_batch': 5.12756199836731}
step: 9960 @ episode report: {'average_total_reward': 9.332001, 'reward_variance': 3.0092566, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.214589297771454, 'actor_loss': -4.854238700866699, 'hyper_actor_loss': 0.06987814158201218, 'behavior_loss': 0.2897464394569397, 'mean_batch': 5.087535762786866, 'min_batch': 5.043446207046509, 'max_batch': 5.129856586456299}
step: 9970 @ episode report: {'average_total_reward': 8.777, 'reward_variance': 4.6722813, 'max_total_reward': 11.23, 'min_total_reward': 4.68, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.141423535346985, 'actor_loss': -4.823715925216675, 'hyper_actor_loss': 0.07017240673303604, 'behavior_loss': 0.282102170586586, 'mean_batch': 5.008683586120606, 'min_batch': 4.968467950820923, 'max_batch': 5.040858793258667}
step: 9980 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 2.591461, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.091728448867798, 'actor_loss': -4.833438682556152, 'hyper_actor_loss': 0.07044958472251892, 'behavior_loss': 0.2739310473203659, 'mean_batch': 5.031506443023682, 'min_batch': 4.9942512035369875, 'max_batch': 5.065319633483886}
step: 9990 @ episode report: {'average_total_reward': 8.511, 'reward_variance': 9.83585, 'max_total_reward': 12.2300005, 'min_total_reward': 1.13, 'average_n_step': 9.6, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7883851051330566, 'actor_loss': -4.856328964233398, 'hyper_actor_loss': 0.07038506045937538, 'behavior_loss': 0.2778454557061195, 'mean_batch': 5.091153240203857, 'min_batch': 5.050023555755615, 'max_batch': 5.1280577182769775}
step: 10000 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 0.97102404, 'max_total_reward': 10.120001, 'min_total_reward': 6.6800003, 'average_n_step': 10.2, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9950969815254211, 'actor_loss': -4.846264362335205, 'hyper_actor_loss': 0.07021617591381073, 'behavior_loss': 0.28638810813426974, 'mean_batch': 5.07116060256958, 'min_batch': 5.019276237487793, 'max_batch': 5.1163512706756595}
step: 10010 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 2.1567044, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8908153533935548, 'actor_loss': -4.829814720153808, 'hyper_actor_loss': 0.07013422921299935, 'behavior_loss': 0.2714701578021049, 'mean_batch': 5.033303833007812, 'min_batch': 4.97439546585083, 'max_batch': 5.0664520263671875}
step: 10020 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.4394445, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5018261820077896, 'actor_loss': -4.873350000381469, 'hyper_actor_loss': 0.06995043605566025, 'behavior_loss': 0.27822091728448867, 'mean_batch': 5.14737901687622, 'min_batch': 5.080842733383179, 'max_batch': 5.181804466247558}
step: 10030 @ episode report: {'average_total_reward': 8.378, 'reward_variance': 2.6037164, 'max_total_reward': 11.12, 'min_total_reward': 5.7899995, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.548633062839508, 'actor_loss': -4.8958179473876955, 'hyper_actor_loss': 0.06984048783779144, 'behavior_loss': 0.2807166546583176, 'mean_batch': 5.202716922760009, 'min_batch': 5.140802240371704, 'max_batch': 5.240584516525269}
step: 10040 @ episode report: {'average_total_reward': 10.354, 'reward_variance': 2.877544, 'max_total_reward': 13.450001, 'min_total_reward': 7.9000006, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.060690867900848, 'actor_loss': -4.862526559829712, 'hyper_actor_loss': 0.0698498822748661, 'behavior_loss': 0.2868098184466362, 'mean_batch': 5.117941904067993, 'min_batch': 5.0551999568939205, 'max_batch': 5.151220035552979}
step: 10050 @ episode report: {'average_total_reward': 9.211, 'reward_variance': 2.5611088, 'max_total_reward': 12.01, 'min_total_reward': 7.5699997, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6316182374954225, 'actor_loss': -4.813410234451294, 'hyper_actor_loss': 0.06985261216759682, 'behavior_loss': 0.2715851113200188, 'mean_batch': 4.991723585128784, 'min_batch': 4.934309768676758, 'max_batch': 5.021793365478516}
step: 10060 @ episode report: {'average_total_reward': 9.865999, 'reward_variance': 1.9945034, 'max_total_reward': 12.339999, 'min_total_reward': 7.5699997, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9440733671188355, 'actor_loss': -4.868782806396484, 'hyper_actor_loss': 0.0698013074696064, 'behavior_loss': 0.28536058962345123, 'mean_batch': 5.135976123809814, 'min_batch': 5.068781900405884, 'max_batch': 5.169533157348633}
step: 10070 @ episode report: {'average_total_reward': 9.910001, 'reward_variance': 6.259761, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9015873849391938, 'actor_loss': -4.8578102588653564, 'hyper_actor_loss': 0.06994481459259987, 'behavior_loss': 0.2864466324448586, 'mean_batch': 5.1076678276062015, 'min_batch': 5.041194343566895, 'max_batch': 5.137322425842285}
step: 10080 @ episode report: {'average_total_reward': 11.174999, 'reward_variance': 3.750585, 'max_total_reward': 14.56, 'min_total_reward': 6.7899995, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9043362736701965, 'actor_loss': -4.829593372344971, 'hyper_actor_loss': 0.06992730125784874, 'behavior_loss': 0.2836413323879242, 'mean_batch': 5.032922315597534, 'min_batch': 4.973707962036133, 'max_batch': 5.061907958984375}
step: 10090 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 3.7950695, 'max_total_reward': 12.340001, 'min_total_reward': 5.35, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8897703886032104, 'actor_loss': -4.833495569229126, 'hyper_actor_loss': 0.06977645382285118, 'behavior_loss': 0.2721360608935356, 'mean_batch': 5.051182746887207, 'min_batch': 4.975106430053711, 'max_batch': 5.0820066928863525}
step: 10100 @ episode report: {'average_total_reward': 9.365999, 'reward_variance': 1.563884, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1556916356086733, 'actor_loss': -4.822911405563355, 'hyper_actor_loss': 0.06965980306267738, 'behavior_loss': 0.2852850630879402, 'mean_batch': 5.0265833854675295, 'min_batch': 4.946940946578979, 'max_batch': 5.060880327224732}
step: 10110 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 2.6921964, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8303058922290802, 'actor_loss': -4.819046068191528, 'hyper_actor_loss': 0.06970857009291649, 'behavior_loss': 0.2727577671408653, 'mean_batch': 5.014823246002197, 'min_batch': 4.939274549484253, 'max_batch': 5.045571374893188}
step: 10120 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 2.0402293, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7353529810905457, 'actor_loss': -4.84519853591919, 'hyper_actor_loss': 0.06967145428061486, 'behavior_loss': 0.2822644576430321, 'mean_batch': 5.074328851699829, 'min_batch': 5.010716199874878, 'max_batch': 5.101640748977661}
step: 10130 @ episode report: {'average_total_reward': 10.154, 'reward_variance': 2.6042037, 'max_total_reward': 14.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3129987597465516, 'actor_loss': -4.889497566223144, 'hyper_actor_loss': 0.06957046762108803, 'behavior_loss': 0.2710624635219574, 'mean_batch': 5.183147621154785, 'min_batch': 5.128055047988892, 'max_batch': 5.215077352523804}
step: 10140 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 2.9237359, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9968776047229766, 'actor_loss': -4.88212022781372, 'hyper_actor_loss': 0.06948110461235046, 'behavior_loss': 0.2909538209438324, 'mean_batch': 5.162108755111694, 'min_batch': 5.111431503295899, 'max_batch': 5.1936094760894775}
step: 10150 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 5.711956, 'max_total_reward': 12.23, 'min_total_reward': 4.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7184039235115052, 'actor_loss': -4.824887657165528, 'hyper_actor_loss': 0.06959613189101219, 'behavior_loss': 0.26766583025455476, 'mean_batch': 5.017876863479614, 'min_batch': 4.965155982971192, 'max_batch': 5.040685606002808}
step: 10160 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 4.7534165, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.719199275970459, 'actor_loss': -4.854682350158692, 'hyper_actor_loss': 0.0694644495844841, 'behavior_loss': 0.2710340082645416, 'mean_batch': 5.090891170501709, 'min_batch': 5.0420609474182125, 'max_batch': 5.117858219146728}
step: 10170 @ episode report: {'average_total_reward': 8.755, 'reward_variance': 3.8908055, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7899995, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.814369198679924, 'actor_loss': -4.864054012298584, 'hyper_actor_loss': 0.06921197175979614, 'behavior_loss': 0.27986596524715424, 'mean_batch': 5.118000316619873, 'min_batch': 5.062478542327881, 'max_batch': 5.150550174713135}
step: 10180 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 2.6178958, 'max_total_reward': 12.339999, 'min_total_reward': 6.4599996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0573868632316588, 'actor_loss': -4.833228588104248, 'hyper_actor_loss': 0.06933397799730301, 'behavior_loss': 0.28500182628631593, 'mean_batch': 5.043855619430542, 'min_batch': 4.981090354919433, 'max_batch': 5.069858694076538}
step: 10190 @ episode report: {'average_total_reward': 9.577001, 'reward_variance': 3.9663208, 'max_total_reward': 13.45, 'min_total_reward': 6.4599996, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6292719423770905, 'actor_loss': -4.81874532699585, 'hyper_actor_loss': 0.06930136680603027, 'behavior_loss': 0.27222301065921783, 'mean_batch': 5.00819149017334, 'min_batch': 4.944411420822144, 'max_batch': 5.0375001430511475}
step: 10200 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 5.6400495, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7523350834846496, 'actor_loss': -4.869176054000855, 'hyper_actor_loss': 0.06922173276543617, 'behavior_loss': 0.27606732994318006, 'mean_batch': 5.141652965545655, 'min_batch': 5.065167951583862, 'max_batch': 5.171429538726807}
step: 10210 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 1.6354496, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8455630898475648, 'actor_loss': -4.8724939823150635, 'hyper_actor_loss': 0.06904536485671997, 'behavior_loss': 0.28153099566698075, 'mean_batch': 5.150141859054566, 'min_batch': 5.073545455932617, 'max_batch': 5.184652805328369}
step: 10220 @ episode report: {'average_total_reward': 9.110001, 'reward_variance': 2.6565201, 'max_total_reward': 11.12, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6733768939971925, 'actor_loss': -4.847318363189697, 'hyper_actor_loss': 0.06919685080647468, 'behavior_loss': 0.2829030230641365, 'mean_batch': 5.081461572647095, 'min_batch': 5.014250326156616, 'max_batch': 5.113119125366211}
step: 10230 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 5.967881, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.624982225894928, 'actor_loss': -4.849111175537109, 'hyper_actor_loss': 0.06919428557157517, 'behavior_loss': 0.27210330963134766, 'mean_batch': 5.087132692337036, 'min_batch': 5.017705821990967, 'max_batch': 5.130956029891967}
step: 10240 @ episode report: {'average_total_reward': 10.720001, 'reward_variance': 4.036401, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8310705363750457, 'actor_loss': -4.867142629623413, 'hyper_actor_loss': 0.06895070150494576, 'behavior_loss': 0.2758974194526672, 'mean_batch': 5.14036192893982, 'min_batch': 5.056097602844238, 'max_batch': 5.230126237869262}
step: 10250 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 0.888381, 'max_total_reward': 11.120001, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6506470739841461, 'actor_loss': -4.86028413772583, 'hyper_actor_loss': 0.06861193999648094, 'behavior_loss': 0.25907506942749026, 'mean_batch': 5.11831259727478, 'min_batch': 5.043093490600586, 'max_batch': 5.167525672912598}
step: 10260 @ episode report: {'average_total_reward': 9.799001, 'reward_variance': 1.7108895, 'max_total_reward': 13.34, 'min_total_reward': 8.789999, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9433745563030242, 'actor_loss': -4.862100505828858, 'hyper_actor_loss': 0.068279979377985, 'behavior_loss': 0.27304490357637407, 'mean_batch': 5.130043458938599, 'min_batch': 5.040791416168213, 'max_batch': 5.1751336574554445}
step: 10270 @ episode report: {'average_total_reward': 8.411, 'reward_variance': 4.6560693, 'max_total_reward': 12.12, 'min_total_reward': 5.4599996, 'average_n_step': 9.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6376337647438048, 'actor_loss': -4.826947116851807, 'hyper_actor_loss': 0.0683864951133728, 'behavior_loss': 0.27555835992097855, 'mean_batch': 5.037744379043579, 'min_batch': 4.955808544158936, 'max_batch': 5.07907395362854}
step: 10280 @ episode report: {'average_total_reward': 8.966001, 'reward_variance': 1.6814239, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.886320662498474, 'actor_loss': -4.8411470413208, 'hyper_actor_loss': 0.06869456693530082, 'behavior_loss': 0.2786486804485321, 'mean_batch': 5.073829603195191, 'min_batch': 4.990890741348267, 'max_batch': 5.1124616146087645}
step: 10290 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 1.4551892, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.646558654308319, 'actor_loss': -4.849517488479615, 'hyper_actor_loss': 0.0687647096812725, 'behavior_loss': 0.265672878921032, 'mean_batch': 5.092456197738647, 'min_batch': 5.014495754241944, 'max_batch': 5.13049168586731}
step: 10300 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 5.8268614, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9510385692119598, 'actor_loss': -4.867695951461792, 'hyper_actor_loss': 0.06853143349289895, 'behavior_loss': 0.2886381700634956, 'mean_batch': 5.143916940689087, 'min_batch': 5.055387115478515, 'max_batch': 5.184728574752808}
step: 10310 @ episode report: {'average_total_reward': 10.653, 'reward_variance': 3.27406, 'max_total_reward': 13.23, 'min_total_reward': 6.9000006, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.269839334487915, 'actor_loss': -4.806215572357178, 'hyper_actor_loss': 0.0684915728867054, 'behavior_loss': 0.27882359623909, 'mean_batch': 4.986627292633057, 'min_batch': 4.904377555847168, 'max_batch': 5.031081008911133}
step: 10320 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 1.8179233, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8330369353294373, 'actor_loss': -4.792565488815308, 'hyper_actor_loss': 0.06837514340877533, 'behavior_loss': 0.2647115096449852, 'mean_batch': 4.956030464172363, 'min_batch': 4.867485046386719, 'max_batch': 5.013597822189331}
step: 10330 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 1.225229, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8653955698013305, 'actor_loss': -4.843452501296997, 'hyper_actor_loss': 0.06828057467937469, 'behavior_loss': 0.27910668700933455, 'mean_batch': 5.086025142669678, 'min_batch': 4.990582895278931, 'max_batch': 5.144555950164795}
step: 10340 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 3.6019688, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1069397568702697, 'actor_loss': -4.842277717590332, 'hyper_actor_loss': 0.06831284686923027, 'behavior_loss': 0.2918576255440712, 'mean_batch': 5.076633358001709, 'min_batch': 4.994156360626221, 'max_batch': 5.128959655761719}
step: 10350 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 2.1894488, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7985045194625855, 'actor_loss': -4.7962089538574215, 'hyper_actor_loss': 0.06860374584794045, 'behavior_loss': 0.281655552983284, 'mean_batch': 4.958850908279419, 'min_batch': 4.882276630401611, 'max_batch': 5.00704140663147}
step: 10360 @ episode report: {'average_total_reward': 10.442001, 'reward_variance': 2.1188364, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5381162405014037, 'actor_loss': -4.8582563400268555, 'hyper_actor_loss': 0.06846553236246108, 'behavior_loss': 0.285031920671463, 'mean_batch': 5.119687509536743, 'min_batch': 5.032057189941407, 'max_batch': 5.16907262802124}
step: 10370 @ episode report: {'average_total_reward': 9.887001, 'reward_variance': 3.4991207, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9122401118278503, 'actor_loss': -4.8747844219207765, 'hyper_actor_loss': 0.06844998225569725, 'behavior_loss': 0.28821431696414945, 'mean_batch': 5.162099409103393, 'min_batch': 5.0735924243927, 'max_batch': 5.214406538009643}
step: 10380 @ episode report: {'average_total_reward': 9.566, 'reward_variance': 4.8844233, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.85472971200943, 'actor_loss': -4.821027326583862, 'hyper_actor_loss': 0.06850182563066483, 'behavior_loss': 0.27890981882810595, 'mean_batch': 5.018005609512329, 'min_batch': 4.9461475849151615, 'max_batch': 5.063080596923828}
step: 10390 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 3.886211, 'max_total_reward': 12.340001, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9229278326034547, 'actor_loss': -4.818292474746704, 'hyper_actor_loss': 0.06823060885071755, 'behavior_loss': 0.2845103606581688, 'mean_batch': 5.0093464851379395, 'min_batch': 4.94092869758606, 'max_batch': 5.05921688079834}
step: 10400 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.435884, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8855461359024048, 'actor_loss': -4.842715644836426, 'hyper_actor_loss': 0.06811444908380508, 'behavior_loss': 0.2871942430734634, 'mean_batch': 5.074696350097656, 'min_batch': 4.997950458526612, 'max_batch': 5.129696464538574}
step: 10410 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 2.0230632, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5303077161312104, 'actor_loss': -4.843975162506103, 'hyper_actor_loss': 0.06806010976433755, 'behavior_loss': 0.26159144937992096, 'mean_batch': 5.072977590560913, 'min_batch': 5.005919027328491, 'max_batch': 5.129610013961792}
step: 10420 @ episode report: {'average_total_reward': 10.687001, 'reward_variance': 0.9529812, 'max_total_reward': 12.23, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9569345951080321, 'actor_loss': -4.8487968921661375, 'hyper_actor_loss': 0.06777542531490326, 'behavior_loss': 0.2985068440437317, 'mean_batch': 5.089019155502319, 'min_batch': 5.0142738819122314, 'max_batch': 5.156910753250122}
step: 10430 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 3.1459646, 'max_total_reward': 13.12, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6820884764194488, 'actor_loss': -4.849200487136841, 'hyper_actor_loss': 0.06782873421907425, 'behavior_loss': 0.28178469091653824, 'mean_batch': 5.0862133502960205, 'min_batch': 5.0191261768341064, 'max_batch': 5.151473331451416}
step: 10440 @ episode report: {'average_total_reward': 10.332, 'reward_variance': 4.758817, 'max_total_reward': 13.340001, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5327736228704452, 'actor_loss': -4.849191570281983, 'hyper_actor_loss': 0.06784963682293892, 'behavior_loss': 0.2748968943953514, 'mean_batch': 5.10454568862915, 'min_batch': 5.001262664794922, 'max_batch': 5.190542936325073}
step: 10450 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 4.04629, 'max_total_reward': 14.560001, 'min_total_reward': 7.6800003, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5313238501548767, 'actor_loss': -4.863953971862793, 'hyper_actor_loss': 0.06763728708028793, 'behavior_loss': 0.26837791204452516, 'mean_batch': 5.157844352722168, 'min_batch': 5.023498678207398, 'max_batch': 5.258125114440918}
step: 10460 @ episode report: {'average_total_reward': 10.764001, 'reward_variance': 2.2250443, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.104821741580963, 'actor_loss': -4.862509441375733, 'hyper_actor_loss': 0.0673621378839016, 'behavior_loss': 0.262732195854187, 'mean_batch': 5.148989820480347, 'min_batch': 5.025927734375, 'max_batch': 5.216025686264038}
step: 10470 @ episode report: {'average_total_reward': 9.632, 'reward_variance': 3.2898357, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.717386782169342, 'actor_loss': -4.788725328445435, 'hyper_actor_loss': 0.0670919582247734, 'behavior_loss': 0.2813726782798767, 'mean_batch': 4.96626124382019, 'min_batch': 4.838804101943969, 'max_batch': 5.054567956924439}
step: 10480 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 4.175906, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5040529251098633, 'actor_loss': -4.877728748321533, 'hyper_actor_loss': 0.06714233234524727, 'behavior_loss': 0.2709434345364571, 'mean_batch': 5.164027070999145, 'min_batch': 5.087812614440918, 'max_batch': 5.267625570297241}
step: 10490 @ episode report: {'average_total_reward': 10.665, 'reward_variance': 2.7584662, 'max_total_reward': 13.340001, 'min_total_reward': 7.7900004, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.787682259082794, 'actor_loss': -4.8875401496887205, 'hyper_actor_loss': 0.06739892065525055, 'behavior_loss': 0.300994747877121, 'mean_batch': 5.179236030578613, 'min_batch': 5.121841239929199, 'max_batch': 5.265844869613647}
step: 10500 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.6524894, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1637624382972716, 'actor_loss': -4.830339622497559, 'hyper_actor_loss': 0.0677678868174553, 'behavior_loss': 0.2699383556842804, 'mean_batch': 5.027522611618042, 'min_batch': 4.983129644393921, 'max_batch': 5.096923732757569}
step: 10510 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 5.3460093, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7788333952426911, 'actor_loss': -4.814094400405883, 'hyper_actor_loss': 0.06759235635399818, 'behavior_loss': 0.29611430168151853, 'mean_batch': 4.990188026428223, 'min_batch': 4.939355897903442, 'max_batch': 5.083335304260254}
step: 10520 @ episode report: {'average_total_reward': 11.518999, 'reward_variance': 4.287149, 'max_total_reward': 15.45, 'min_total_reward': 9.009999, 'average_n_step': 12.3, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3452380061149598, 'actor_loss': -4.866531276702881, 'hyper_actor_loss': 0.06776543855667114, 'behavior_loss': 0.2876615136861801, 'mean_batch': 5.1325750827789305, 'min_batch': 5.061137008666992, 'max_batch': 5.2403950691223145}
step: 10530 @ episode report: {'average_total_reward': 10.210001, 'reward_variance': 4.9786015, 'max_total_reward': 15.560001, 'min_total_reward': 7.5699997, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6174020290374755, 'actor_loss': -4.906193590164184, 'hyper_actor_loss': 0.067567478120327, 'behavior_loss': 0.2766724929213524, 'mean_batch': 5.239258527755737, 'min_batch': 5.158222103118897, 'max_batch': 5.339359092712402}
step: 10540 @ episode report: {'average_total_reward': 9.977, 'reward_variance': 3.3615818, 'max_total_reward': 13.01, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0207862973213198, 'actor_loss': -4.846895790100097, 'hyper_actor_loss': 0.06743788346648216, 'behavior_loss': 0.28396638929843904, 'mean_batch': 5.089248943328857, 'min_batch': 5.005073070526123, 'max_batch': 5.174404191970825}
step: 10550 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 3.4051056, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8146957159042358, 'actor_loss': -4.816077518463135, 'hyper_actor_loss': 0.06710766181349755, 'behavior_loss': 0.27416630685329435, 'mean_batch': 5.007658243179321, 'min_batch': 4.931735610961914, 'max_batch': 5.091437292098999}
step: 10560 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 5.8753257, 'max_total_reward': 15.560001, 'min_total_reward': 6.8999996, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0352837204933167, 'actor_loss': -4.851323509216309, 'hyper_actor_loss': 0.06694062128663063, 'behavior_loss': 0.28516978621482847, 'mean_batch': 5.09814305305481, 'min_batch': 5.017945671081543, 'max_batch': 5.197429656982422}
step: 10570 @ episode report: {'average_total_reward': 10.764002, 'reward_variance': 3.9255643, 'max_total_reward': 15.560001, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4706070601940155, 'actor_loss': -4.857474088668823, 'hyper_actor_loss': 0.06672246679663658, 'behavior_loss': 0.27433252036571504, 'mean_batch': 5.109155511856079, 'min_batch': 5.037988233566284, 'max_batch': 5.219354104995728}
step: 10580 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 4.2244844, 'max_total_reward': 12.23, 'min_total_reward': 5.68, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5427805244922639, 'actor_loss': -4.880482339859009, 'hyper_actor_loss': 0.06667722389101982, 'behavior_loss': 0.276699960231781, 'mean_batch': 5.171090507507325, 'min_batch': 5.093513631820679, 'max_batch': 5.307950210571289}
step: 10590 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.044004, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9251455783843994, 'actor_loss': -4.872672748565674, 'hyper_actor_loss': 0.06672214493155479, 'behavior_loss': 0.29026985764503477, 'mean_batch': 5.149946212768555, 'min_batch': 5.074864387512207, 'max_batch': 5.2894651889801025}
step: 10600 @ episode report: {'average_total_reward': 9.444, 'reward_variance': 2.2535248, 'max_total_reward': 12.23, 'min_total_reward': 6.7899995, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.612498265504837, 'actor_loss': -4.838203001022339, 'hyper_actor_loss': 0.06679565757513047, 'behavior_loss': 0.2824478209018707, 'mean_batch': 5.063795900344848, 'min_batch': 4.986079740524292, 'max_batch': 5.186814308166504}
step: 10610 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 5.2502165, 'max_total_reward': 15.56, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5922571063041686, 'actor_loss': -4.867380619049072, 'hyper_actor_loss': 0.06689080446958542, 'behavior_loss': 0.2801980391144753, 'mean_batch': 5.140727567672729, 'min_batch': 5.056919097900391, 'max_batch': 5.277135896682739}
step: 10620 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 8.041385, 'max_total_reward': 12.009999, 'min_total_reward': 1.24, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8394729614257812, 'actor_loss': -4.871560907363891, 'hyper_actor_loss': 0.0667218178510666, 'behavior_loss': 0.2679747804999352, 'mean_batch': 5.153326940536499, 'min_batch': 5.065739488601684, 'max_batch': 5.265349292755127}
step: 10630 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 1.3982246, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.586080050468445, 'actor_loss': -4.867231702804565, 'hyper_actor_loss': 0.06637943461537361, 'behavior_loss': 0.2731952428817749, 'mean_batch': 5.136477613449097, 'min_batch': 5.060308933258057, 'max_batch': 5.222872018814087}
step: 10640 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 3.2182643, 'max_total_reward': 13.23, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.792582368850708, 'actor_loss': -4.872084665298462, 'hyper_actor_loss': 0.06627801284193993, 'behavior_loss': 0.2816988229751587, 'mean_batch': 5.147754096984864, 'min_batch': 5.073772716522217, 'max_batch': 5.235728216171265}
step: 10650 @ episode report: {'average_total_reward': 8.911, 'reward_variance': 6.710729, 'max_total_reward': 12.2300005, 'min_total_reward': 2.0200002, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9329127550125123, 'actor_loss': -4.84284782409668, 'hyper_actor_loss': 0.0662064291536808, 'behavior_loss': 0.27473414689302444, 'mean_batch': 5.073815250396729, 'min_batch': 4.999576377868652, 'max_batch': 5.167410135269165}
step: 10660 @ episode report: {'average_total_reward': 9.3220005, 'reward_variance': 4.3424172, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0191779136657715, 'actor_loss': -4.8384082317352295, 'hyper_actor_loss': 0.06624552682042122, 'behavior_loss': 0.2918645918369293, 'mean_batch': 5.060148096084594, 'min_batch': 4.990729761123657, 'max_batch': 5.134308004379273}
step: 10670 @ episode report: {'average_total_reward': 11.320002, 'reward_variance': 2.2457805, 'max_total_reward': 13.2300005, 'min_total_reward': 7.79, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7710171461105346, 'actor_loss': -4.851613521575928, 'hyper_actor_loss': 0.06641785576939582, 'behavior_loss': 0.2704364061355591, 'mean_batch': 5.091844177246093, 'min_batch': 5.025624513626099, 'max_batch': 5.148790550231934}
step: 10680 @ episode report: {'average_total_reward': 9.066, 'reward_variance': 1.3606441, 'max_total_reward': 11.23, 'min_total_reward': 7.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.050034987926483, 'actor_loss': -4.845981454849243, 'hyper_actor_loss': 0.06650185212492943, 'behavior_loss': 0.29035723954439163, 'mean_batch': 5.077055883407593, 'min_batch': 5.0120467185974125, 'max_batch': 5.1566671371459964}
step: 10690 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 4.846486, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7899995, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9526146292686462, 'actor_loss': -4.829915523529053, 'hyper_actor_loss': 0.06661638543009758, 'behavior_loss': 0.2992432713508606, 'mean_batch': 5.027356719970703, 'min_batch': 4.980752801895141, 'max_batch': 5.087391710281372}
step: 10700 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 4.553264, 'max_total_reward': 14.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.116786789894104, 'actor_loss': -4.818307495117187, 'hyper_actor_loss': 0.06648977175354957, 'behavior_loss': 0.28452892005443575, 'mean_batch': 4.995595502853393, 'min_batch': 4.954578447341919, 'max_batch': 5.046402645111084}
step: 10710 @ episode report: {'average_total_reward': 10.098001, 'reward_variance': 6.664756, 'max_total_reward': 14.56, 'min_total_reward': 4.6800003, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8776013612747193, 'actor_loss': -4.822279357910157, 'hyper_actor_loss': 0.06636046767234802, 'behavior_loss': 0.2684440553188324, 'mean_batch': 5.006294918060303, 'min_batch': 4.963781690597534, 'max_batch': 5.062175989151001}
step: 10720 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 2.3606644, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9005421936511993, 'actor_loss': -4.855071258544922, 'hyper_actor_loss': 0.06582563072443008, 'behavior_loss': 0.2765100419521332, 'mean_batch': 5.087881660461425, 'min_batch': 5.046888780593872, 'max_batch': 5.14319543838501}
step: 10730 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.1461809, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.2213628977537154, 'actor_loss': -4.86721830368042, 'hyper_actor_loss': 0.06569859534502029, 'behavior_loss': 0.28473587334156036, 'mean_batch': 5.121722745895386, 'min_batch': 5.074896812438965, 'max_batch': 5.165705776214599}
step: 10740 @ episode report: {'average_total_reward': 9.632, 'reward_variance': 1.7404757, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.619034516811371, 'actor_loss': -4.897203874588013, 'hyper_actor_loss': 0.0655704103410244, 'behavior_loss': 0.2785657480359077, 'mean_batch': 5.20513391494751, 'min_batch': 5.1455339908599855, 'max_batch': 5.241212654113769}
step: 10750 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 1.2784357, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6916024804115295, 'actor_loss': -4.886383819580078, 'hyper_actor_loss': 0.06561407521367073, 'behavior_loss': 0.27325800955295565, 'mean_batch': 5.170626831054688, 'min_batch': 5.124113607406616, 'max_batch': 5.208909559249878}
step: 10760 @ episode report: {'average_total_reward': 10.686999, 'reward_variance': 4.1076016, 'max_total_reward': 13.34, 'min_total_reward': 6.68, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.679238063097, 'actor_loss': -4.849188804626465, 'hyper_actor_loss': 0.06561102345585823, 'behavior_loss': 0.284158755838871, 'mean_batch': 5.073733377456665, 'min_batch': 5.031346130371094, 'max_batch': 5.1139589786529545}
step: 10770 @ episode report: {'average_total_reward': 9.743, 'reward_variance': 2.306021, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.298302936553955, 'actor_loss': -4.831871128082275, 'hyper_actor_loss': 0.06577257290482522, 'behavior_loss': 0.2772540062665939, 'mean_batch': 5.031851959228516, 'min_batch': 4.9861509799957275, 'max_batch': 5.062425184249878}
step: 10780 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 4.592645, 'max_total_reward': 11.900001, 'min_total_reward': 3.5700002, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9923946261405945, 'actor_loss': -4.81137375831604, 'hyper_actor_loss': 0.06575289368629456, 'behavior_loss': 0.28584368228912355, 'mean_batch': 4.978256464004517, 'min_batch': 4.937483930587769, 'max_batch': 5.02545199394226}
step: 10790 @ episode report: {'average_total_reward': 9.644, 'reward_variance': 2.518023, 'max_total_reward': 13.339999, 'min_total_reward': 7.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9715992212295532, 'actor_loss': -4.8023231506347654, 'hyper_actor_loss': 0.06575976312160492, 'behavior_loss': 0.29179849475622177, 'mean_batch': 4.958885335922242, 'min_batch': 4.912173509597778, 'max_batch': 4.986947107315063}
step: 10800 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 4.673129, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8099153876304626, 'actor_loss': -4.849734306335449, 'hyper_actor_loss': 0.0657707005739212, 'behavior_loss': 0.27043973207473754, 'mean_batch': 5.0805017948150635, 'min_batch': 5.027539968490601, 'max_batch': 5.114216136932373}
step: 10810 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 1.5278893, 'max_total_reward': 11.2300005, 'min_total_reward': 7.68, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7433420658111571, 'actor_loss': -4.876415824890136, 'hyper_actor_loss': 0.06554214879870415, 'behavior_loss': 0.28712971955537797, 'mean_batch': 5.147944498062134, 'min_batch': 5.095619535446167, 'max_batch': 5.206090879440308}
step: 10820 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 2.2464294, 'max_total_reward': 11.23, 'min_total_reward': 5.7899995, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7155650556087494, 'actor_loss': -4.843130826950073, 'hyper_actor_loss': 0.06548222228884697, 'behavior_loss': 0.2819820880889893, 'mean_batch': 5.06379885673523, 'min_batch': 5.010812282562256, 'max_batch': 5.171155023574829}
step: 10830 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 2.4074354, 'max_total_reward': 13.34, 'min_total_reward': 8.570001, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7263467133045196, 'actor_loss': -4.846725225448608, 'hyper_actor_loss': 0.06555590331554413, 'behavior_loss': 0.2785069063305855, 'mean_batch': 5.075867605209351, 'min_batch': 5.016802883148193, 'max_batch': 5.185979557037354}
step: 10840 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 1.4840758, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9714110374450684, 'actor_loss': -4.858944988250732, 'hyper_actor_loss': 0.06544195935130119, 'behavior_loss': 0.2788307756185532, 'mean_batch': 5.112168502807617, 'min_batch': 5.042445659637451, 'max_batch': 5.245085859298706}
step: 10850 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 2.737196, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6434524476528167, 'actor_loss': -4.836854457855225, 'hyper_actor_loss': 0.06544999480247497, 'behavior_loss': 0.2917443498969078, 'mean_batch': 5.050251483917236, 'min_batch': 4.992738676071167, 'max_batch': 5.104071187973022}
step: 10860 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 2.196909, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2809021890163423, 'actor_loss': -4.810436820983886, 'hyper_actor_loss': 0.06545479446649552, 'behavior_loss': 0.2763448402285576, 'mean_batch': 4.986830329895019, 'min_batch': 4.92480058670044, 'max_batch': 5.055091524124146}
step: 10870 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 1.84452, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5012657940387726, 'actor_loss': -4.8311529636383055, 'hyper_actor_loss': 0.0652503065764904, 'behavior_loss': 0.2704430058598518, 'mean_batch': 5.040282487869263, 'min_batch': 4.97483081817627, 'max_batch': 5.10036940574646}
step: 10880 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.4369485, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6501684613525867, 'actor_loss': -4.895601224899292, 'hyper_actor_loss': 0.0648806095123291, 'behavior_loss': 0.2740520104765892, 'mean_batch': 5.205400371551514, 'min_batch': 5.137130212783814, 'max_batch': 5.267512226104737}
step: 10890 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 0.8879964, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.06171510219574, 'actor_loss': -4.840517139434814, 'hyper_actor_loss': 0.06475386321544647, 'behavior_loss': 0.2752730190753937, 'mean_batch': 5.057597732543945, 'min_batch': 5.004309225082397, 'max_batch': 5.112973356246949}
step: 10900 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 3.9053848, 'max_total_reward': 13.23, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6231284141540527, 'actor_loss': -4.802986431121826, 'hyper_actor_loss': 0.06469346806406975, 'behavior_loss': 0.26810106486082075, 'mean_batch': 4.954951286315918, 'min_batch': 4.91942138671875, 'max_batch': 5.006742095947265}
step: 10910 @ episode report: {'average_total_reward': 9.1, 'reward_variance': 2.4607205, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0195993900299074, 'actor_loss': -4.845509958267212, 'hyper_actor_loss': 0.06452066823840141, 'behavior_loss': 0.2732821047306061, 'mean_batch': 5.061461687088013, 'min_batch': 5.024970817565918, 'max_batch': 5.133180284500122}
step: 10920 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 1.8857845, 'max_total_reward': 11.01, 'min_total_reward': 6.7899995, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.930353718996048, 'actor_loss': -4.850653457641601, 'hyper_actor_loss': 0.06430593207478523, 'behavior_loss': 0.2704026773571968, 'mean_batch': 5.077447032928466, 'min_batch': 5.0350950241088865, 'max_batch': 5.139085865020752}
step: 10930 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 2.9232097, 'max_total_reward': 13.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.556868839263916, 'actor_loss': -4.831466388702393, 'hyper_actor_loss': 0.06426101252436638, 'behavior_loss': 0.2738713204860687, 'mean_batch': 5.028580379486084, 'min_batch': 4.987355184555054, 'max_batch': 5.086737489700317}
step: 10940 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 1.5659493, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8539844006299973, 'actor_loss': -4.856829261779785, 'hyper_actor_loss': 0.06419149786233902, 'behavior_loss': 0.2765285849571228, 'mean_batch': 5.098045587539673, 'min_batch': 5.045708894729614, 'max_batch': 5.17498631477356}
step: 10950 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 3.5099049, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.801047420501709, 'actor_loss': -4.8385735034942625, 'hyper_actor_loss': 0.06422907337546349, 'behavior_loss': 0.26909066885709765, 'mean_batch': 5.051600456237793, 'min_batch': 4.9999627590179445, 'max_batch': 5.108942365646362}
step: 10960 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 2.9227242, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.62075434923172, 'actor_loss': -4.841716241836548, 'hyper_actor_loss': 0.06425117254257202, 'behavior_loss': 0.2843483880162239, 'mean_batch': 5.064424657821656, 'min_batch': 5.0030169010162355, 'max_batch': 5.127891635894775}
step: 10970 @ episode report: {'average_total_reward': 10.542002, 'reward_variance': 3.822956, 'max_total_reward': 13.450001, 'min_total_reward': 6.9000006, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8011807739734649, 'actor_loss': -4.855784559249878, 'hyper_actor_loss': 0.06426573246717453, 'behavior_loss': 0.2576163962483406, 'mean_batch': 5.097735452651977, 'min_batch': 5.040763902664184, 'max_batch': 5.217292976379395}
step: 10980 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 0.7621894, 'max_total_reward': 12.01, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7600648880004883, 'actor_loss': -4.8362969875335695, 'hyper_actor_loss': 0.06410902440547943, 'behavior_loss': 0.27353357821702956, 'mean_batch': 5.047041273117065, 'min_batch': 4.993243408203125, 'max_batch': 5.138460969924926}
step: 10990 @ episode report: {'average_total_reward': 9.133, 'reward_variance': 4.2236423, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3719009757041931, 'actor_loss': -4.846305847167969, 'hyper_actor_loss': 0.0638623908162117, 'behavior_loss': 0.27314628660678864, 'mean_batch': 5.074442195892334, 'min_batch': 5.0162718296051025, 'max_batch': 5.171748352050781}
step: 11000 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 3.045282, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0493590116500853, 'actor_loss': -4.856408596038818, 'hyper_actor_loss': 0.06383235827088356, 'behavior_loss': 0.2767918422818184, 'mean_batch': 5.0988977432250975, 'min_batch': 5.043092107772827, 'max_batch': 5.156459474563599}
step: 11010 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.8343246, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4916843116283416, 'actor_loss': -4.852366256713867, 'hyper_actor_loss': 0.06382450088858604, 'behavior_loss': 0.2717763975262642, 'mean_batch': 5.087809276580811, 'min_batch': 5.033552932739258, 'max_batch': 5.167565584182739}
step: 11020 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.368324, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7440761148929596, 'actor_loss': -4.856263828277588, 'hyper_actor_loss': 0.06386324688792229, 'behavior_loss': 0.2881653606891632, 'mean_batch': 5.095826101303101, 'min_batch': 5.045156621932984, 'max_batch': 5.194540786743164}
step: 11030 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 2.3548093, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7986005663871765, 'actor_loss': -4.847776889801025, 'hyper_actor_loss': 0.06384442448616028, 'behavior_loss': 0.29166112244129183, 'mean_batch': 5.068478631973266, 'min_batch': 5.029388952255249, 'max_batch': 5.12190318107605}
step: 11040 @ episode report: {'average_total_reward': 11.442001, 'reward_variance': 2.3531368, 'max_total_reward': 13.45, 'min_total_reward': 8.57, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7425480365753174, 'actor_loss': -4.860829305648804, 'hyper_actor_loss': 0.06413292586803436, 'behavior_loss': 0.2736342906951904, 'mean_batch': 5.105374383926391, 'min_batch': 5.0587536811828615, 'max_batch': 5.179558849334716}
step: 11050 @ episode report: {'average_total_reward': 10.853, 'reward_variance': 3.862641, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5908323645591735, 'actor_loss': -4.845571041107178, 'hyper_actor_loss': 0.06382176578044892, 'behavior_loss': 0.2894153416156769, 'mean_batch': 5.066272974014282, 'min_batch': 5.020519351959228, 'max_batch': 5.134939432144165}
step: 11060 @ episode report: {'average_total_reward': 10.963999, 'reward_variance': 3.0400643, 'max_total_reward': 14.559999, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7161097168922423, 'actor_loss': -4.85386643409729, 'hyper_actor_loss': 0.06373951211571693, 'behavior_loss': 0.2709143847227097, 'mean_batch': 5.095408535003662, 'min_batch': 5.033430814743042, 'max_batch': 5.163744306564331}
step: 11070 @ episode report: {'average_total_reward': 10.109, 'reward_variance': 1.9480298, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0004149943590166, 'actor_loss': -4.846971225738526, 'hyper_actor_loss': 0.0635737955570221, 'behavior_loss': 0.2617941826581955, 'mean_batch': 5.071075820922852, 'min_batch': 5.022919321060181, 'max_batch': 5.144167852401734}
step: 11080 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 6.0953903, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 10.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8281248092651368, 'actor_loss': -4.818490505218506, 'hyper_actor_loss': 0.06345423981547356, 'behavior_loss': 0.29086163491010664, 'mean_batch': 4.99864764213562, 'min_batch': 4.95247106552124, 'max_batch': 5.080205202102661}
step: 11090 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 3.8622642, 'max_total_reward': 12.23, 'min_total_reward': 6.7899995, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9243496894836425, 'actor_loss': -4.848265171051025, 'hyper_actor_loss': 0.0634378083050251, 'behavior_loss': 0.2876949816942215, 'mean_batch': 5.074740886688232, 'min_batch': 5.02569465637207, 'max_batch': 5.167045164108276}
step: 11100 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 3.718296, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7559103846549988, 'actor_loss': -4.828263759613037, 'hyper_actor_loss': 0.06352270618081093, 'behavior_loss': 0.2667567700147629, 'mean_batch': 5.021624279022217, 'min_batch': 4.978341960906983, 'max_batch': 5.112775421142578}
step: 11110 @ episode report: {'average_total_reward': 8.422, 'reward_variance': 3.784556, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 9.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.516304087638855, 'actor_loss': -4.859814119338989, 'hyper_actor_loss': 0.06342986896634102, 'behavior_loss': 0.2850612089037895, 'mean_batch': 5.101733016967773, 'min_batch': 5.057484865188599, 'max_batch': 5.258412170410156}
step: 11120 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 3.2916417, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6351726323366165, 'actor_loss': -4.883388662338257, 'hyper_actor_loss': 0.06335752755403519, 'behavior_loss': 0.2734701484441757, 'mean_batch': 5.163051652908325, 'min_batch': 5.11627950668335, 'max_batch': 5.286025810241699}
step: 11130 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 1.1809839, 'max_total_reward': 11.12, 'min_total_reward': 6.79, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8723169207572936, 'actor_loss': -4.8569776058197025, 'hyper_actor_loss': 0.06339803487062454, 'behavior_loss': 0.29253027588129044, 'mean_batch': 5.0935293674469, 'min_batch': 5.050978517532348, 'max_batch': 5.1785365581512455}
step: 11140 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 0.9696094, 'max_total_reward': 11.2300005, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9830803990364074, 'actor_loss': -4.820096445083618, 'hyper_actor_loss': 0.0633479468524456, 'behavior_loss': 0.2767194837331772, 'mean_batch': 4.996807956695557, 'min_batch': 4.962340879440307, 'max_batch': 5.074399375915528}
step: 11150 @ episode report: {'average_total_reward': 9.799, 'reward_variance': 2.3328888, 'max_total_reward': 12.23, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0585813999176024, 'actor_loss': -4.829715347290039, 'hyper_actor_loss': 0.06327455341815949, 'behavior_loss': 0.28109822422266006, 'mean_batch': 5.024062299728394, 'min_batch': 4.9830811500549315, 'max_batch': 5.087063598632812}
step: 11160 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 2.3993602, 'max_total_reward': 12.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6821330666542054, 'actor_loss': -4.836555147171021, 'hyper_actor_loss': 0.06314700469374657, 'behavior_loss': 0.27420211434364317, 'mean_batch': 5.038188409805298, 'min_batch': 5.003250217437744, 'max_batch': 5.139626169204712}
step: 11170 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 2.5017362, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0291664958000184, 'actor_loss': -4.844219112396241, 'hyper_actor_loss': 0.06294838413596153, 'behavior_loss': 0.2832804873585701, 'mean_batch': 5.059214353561401, 'min_batch': 5.020737552642823, 'max_batch': 5.123763132095337}
step: 11180 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 2.4626203, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8351085543632508, 'actor_loss': -4.824503707885742, 'hyper_actor_loss': 0.06303168982267379, 'behavior_loss': 0.2684105783700943, 'mean_batch': 5.008861351013183, 'min_batch': 4.972202444076538, 'max_batch': 5.079713344573975}
step: 11190 @ episode report: {'average_total_reward': 10.442, 'reward_variance': 2.484936, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6320505619049073, 'actor_loss': -4.852270555496216, 'hyper_actor_loss': 0.06288456842303276, 'behavior_loss': 0.2890103042125702, 'mean_batch': 5.078460788726806, 'min_batch': 5.0422163009643555, 'max_batch': 5.142083692550659}
step: 11200 @ episode report: {'average_total_reward': 8.911, 'reward_variance': 7.586011, 'max_total_reward': 11.2300005, 'min_total_reward': 1.24, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7345479637384416, 'actor_loss': -4.861457252502442, 'hyper_actor_loss': 0.06299306154251098, 'behavior_loss': 0.28473810404539107, 'mean_batch': 5.102240896224975, 'min_batch': 5.064937925338745, 'max_batch': 5.164417839050293}
step: 11210 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 2.1933556, 'max_total_reward': 12.23, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.901191657781601, 'actor_loss': -4.84456353187561, 'hyper_actor_loss': 0.06303656548261642, 'behavior_loss': 0.2650116324424744, 'mean_batch': 5.058184337615967, 'min_batch': 5.023542785644532, 'max_batch': 5.133356142044067}
step: 11220 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 3.4853444, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9372142195701598, 'actor_loss': -4.814380788803101, 'hyper_actor_loss': 0.0628601472824812, 'behavior_loss': 0.2775755226612091, 'mean_batch': 4.978658962249756, 'min_batch': 4.951993036270141, 'max_batch': 5.084261655807495}
step: 11230 @ episode report: {'average_total_reward': 10.443001, 'reward_variance': 5.6470613, 'max_total_reward': 14.56, 'min_total_reward': 5.6800003, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6148212194442748, 'actor_loss': -4.84734034538269, 'hyper_actor_loss': 0.06257940754294396, 'behavior_loss': 0.28554095774888993, 'mean_batch': 5.065462970733643, 'min_batch': 5.030644369125366, 'max_batch': 5.139935445785523}
step: 11240 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 1.9014359, 'max_total_reward': 11.2300005, 'min_total_reward': 6.57, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8218858361244201, 'actor_loss': -4.879907417297363, 'hyper_actor_loss': 0.06263081692159175, 'behavior_loss': 0.25812831819057463, 'mean_batch': 5.153281879425049, 'min_batch': 5.108153820037842, 'max_batch': 5.21320915222168}
step: 11250 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 2.4255245, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6841329008340835, 'actor_loss': -4.846844339370728, 'hyper_actor_loss': 0.062304743379354474, 'behavior_loss': 0.2700447767972946, 'mean_batch': 5.066324377059937, 'min_batch': 5.026910591125488, 'max_batch': 5.1278375625610355}
step: 11260 @ episode report: {'average_total_reward': 10.421, 'reward_variance': 2.2038484, 'max_total_reward': 13.339999, 'min_total_reward': 7.57, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.743051114678383, 'actor_loss': -4.840888833999633, 'hyper_actor_loss': 0.06224315352737904, 'behavior_loss': 0.2897486686706543, 'mean_batch': 5.047052955627441, 'min_batch': 5.016072559356689, 'max_batch': 5.134058666229248}
step: 11270 @ episode report: {'average_total_reward': 10.420001, 'reward_variance': 0.7785201, 'max_total_reward': 12.339999, 'min_total_reward': 9.009999, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.788803869485855, 'actor_loss': -4.839912986755371, 'hyper_actor_loss': 0.06241724267601967, 'behavior_loss': 0.2906896322965622, 'mean_batch': 5.047013473510742, 'min_batch': 5.011213541030884, 'max_batch': 5.137875175476074}
step: 11280 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 4.4993296, 'max_total_reward': 14.450001, 'min_total_reward': 6.7900004, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0109768748283385, 'actor_loss': -4.8423515319824215, 'hyper_actor_loss': 0.06287034004926681, 'behavior_loss': 0.28535756170749665, 'mean_batch': 5.055538702011108, 'min_batch': 5.015018177032471, 'max_batch': 5.130731725692749}
step: 11290 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.7079408, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9396380662918091, 'actor_loss': -4.824810981750488, 'hyper_actor_loss': 0.06264415793120862, 'behavior_loss': 0.27514526546001433, 'mean_batch': 5.009311532974243, 'min_batch': 4.973295831680298, 'max_batch': 5.055742406845093}
step: 11300 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 1.5326837, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4039059400558471, 'actor_loss': -4.8445716381073, 'hyper_actor_loss': 0.06256021410226822, 'behavior_loss': 0.2769401788711548, 'mean_batch': 5.057825756072998, 'min_batch': 5.024333667755127, 'max_batch': 5.087656164169312}
step: 11310 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 4.052461, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8383045554161073, 'actor_loss': -4.891788530349731, 'hyper_actor_loss': 0.06211276538670063, 'behavior_loss': 0.27540996968746184, 'mean_batch': 5.181997680664063, 'min_batch': 5.140626525878906, 'max_batch': 5.215598487854004}
step: 11320 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 2.1572814, 'max_total_reward': 13.23, 'min_total_reward': 7.7899995, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7335485100746155, 'actor_loss': -4.838913440704346, 'hyper_actor_loss': 0.06196438409388065, 'behavior_loss': 0.2797809138894081, 'mean_batch': 5.042133331298828, 'min_batch': 5.011341857910156, 'max_batch': 5.060032320022583}
step: 11330 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.2265446, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8767154932022094, 'actor_loss': -4.827224636077881, 'hyper_actor_loss': 0.06217254363000393, 'behavior_loss': 0.29357184171676637, 'mean_batch': 5.016291570663452, 'min_batch': 4.978345060348511, 'max_batch': 5.037620639801025}
step: 11340 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 1.5743089, 'max_total_reward': 12.23, 'min_total_reward': 7.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.863596749305725, 'actor_loss': -4.833089065551758, 'hyper_actor_loss': 0.062431765347719194, 'behavior_loss': 0.29483334720134735, 'mean_batch': 5.038317346572876, 'min_batch': 4.985745763778686, 'max_batch': 5.076090240478516}
step: 11350 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 1.3606892, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7256561636924743, 'actor_loss': -4.843429851531982, 'hyper_actor_loss': 0.062454191222786906, 'behavior_loss': 0.2834203034639359, 'mean_batch': 5.060654544830323, 'min_batch': 5.015349340438843, 'max_batch': 5.082013893127441}
step: 11360 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 1.0528399, 'max_total_reward': 11.120001, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6407111525535583, 'actor_loss': -4.851214838027954, 'hyper_actor_loss': 0.06225409246981144, 'behavior_loss': 0.2684383988380432, 'mean_batch': 5.086822032928467, 'min_batch': 5.028587198257446, 'max_batch': 5.110330104827881}
step: 11370 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.9634838, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.861123275756836, 'actor_loss': -4.846989297866822, 'hyper_actor_loss': 0.06190222166478634, 'behavior_loss': 0.284925265610218, 'mean_batch': 5.081597185134887, 'min_batch': 5.0125041007995605, 'max_batch': 5.113782596588135}
step: 11380 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 4.521529, 'max_total_reward': 12.34, 'min_total_reward': 5.46, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.73527090549469, 'actor_loss': -4.830890893936157, 'hyper_actor_loss': 0.06197630129754543, 'behavior_loss': 0.28351989984512327, 'mean_batch': 5.03765869140625, 'min_batch': 4.975442934036255, 'max_batch': 5.081759738922119}
step: 11390 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 3.3667245, 'max_total_reward': 13.450001, 'min_total_reward': 7.7899995, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8685793161392212, 'actor_loss': -4.83994951248169, 'hyper_actor_loss': 0.061815297603607176, 'behavior_loss': 0.2892225131392479, 'mean_batch': 5.057824516296387, 'min_batch': 5.000752592086792, 'max_batch': 5.091049242019653}
step: 11400 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 2.842876, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.226398432254791, 'actor_loss': -4.808799791336059, 'hyper_actor_loss': 0.06188695020973682, 'behavior_loss': 0.29891144931316377, 'mean_batch': 4.9855796813964846, 'min_batch': 4.918036794662475, 'max_batch': 5.010833644866944}
step: 11410 @ episode report: {'average_total_reward': 9.921, 'reward_variance': 3.7700086, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9207230806350708, 'actor_loss': -4.7902501106262205, 'hyper_actor_loss': 0.06219362542033195, 'behavior_loss': 0.27708987295627596, 'mean_batch': 4.929446697235107, 'min_batch': 4.88222484588623, 'max_batch': 4.955564832687378}
step: 11420 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 3.057661, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8604156374931335, 'actor_loss': -4.834345722198487, 'hyper_actor_loss': 0.06204272098839283, 'behavior_loss': 0.27695714086294176, 'mean_batch': 5.040523862838745, 'min_batch': 4.989880752563477, 'max_batch': 5.075785827636719}
step: 11430 @ episode report: {'average_total_reward': 10.776001, 'reward_variance': 6.498164, 'max_total_reward': 14.559999, 'min_total_reward': 6.7899995, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5841966703534127, 'actor_loss': -4.8513425350189205, 'hyper_actor_loss': 0.061635537445545195, 'behavior_loss': 0.26514741480350495, 'mean_batch': 5.080836963653565, 'min_batch': 5.035111618041992, 'max_batch': 5.105203771591187}
step: 11440 @ episode report: {'average_total_reward': 9.144, 'reward_variance': 2.3751838, 'max_total_reward': 11.2300005, 'min_total_reward': 6.5700006, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6521329224109649, 'actor_loss': -4.854841232299805, 'hyper_actor_loss': 0.061349847540259364, 'behavior_loss': 0.2809465304017067, 'mean_batch': 5.090876674652099, 'min_batch': 5.042759037017822, 'max_batch': 5.122597551345825}
step: 11450 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 3.058601, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.958323633670807, 'actor_loss': -4.853210306167602, 'hyper_actor_loss': 0.06117023155093193, 'behavior_loss': 0.26729304194450376, 'mean_batch': 5.087581062316895, 'min_batch': 5.037869596481324, 'max_batch': 5.112054824829102}
step: 11460 @ episode report: {'average_total_reward': 10.598, 'reward_variance': 3.1942365, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.700255435705185, 'actor_loss': -4.828054666519165, 'hyper_actor_loss': 0.06125677078962326, 'behavior_loss': 0.2745716214179993, 'mean_batch': 5.013674545288086, 'min_batch': 4.985091638565064, 'max_batch': 5.036860752105713}
step: 11470 @ episode report: {'average_total_reward': 10.210001, 'reward_variance': 2.46072, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7850987195968628, 'actor_loss': -4.83800630569458, 'hyper_actor_loss': 0.06113175600767136, 'behavior_loss': 0.2628150463104248, 'mean_batch': 5.042971611022949, 'min_batch': 5.005699825286865, 'max_batch': 5.093689680099487}
step: 11480 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 0.9382002, 'max_total_reward': 11.2300005, 'min_total_reward': 8.68, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8482451915740967, 'actor_loss': -4.844515371322632, 'hyper_actor_loss': 0.061011189594864845, 'behavior_loss': 0.2758479192852974, 'mean_batch': 5.060767984390258, 'min_batch': 5.020706510543823, 'max_batch': 5.128630971908569}
step: 11490 @ episode report: {'average_total_reward': 10.842, 'reward_variance': 4.9339566, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7350379407405854, 'actor_loss': -4.836256265640259, 'hyper_actor_loss': 0.06098868176341057, 'behavior_loss': 0.2705674678087234, 'mean_batch': 5.039795541763306, 'min_batch': 5.000074243545532, 'max_batch': 5.108185768127441}
step: 11500 @ episode report: {'average_total_reward': 10.099001, 'reward_variance': 1.8109491, 'max_total_reward': 13.45, 'min_total_reward': 8.57, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5496763050556184, 'actor_loss': -4.853508424758911, 'hyper_actor_loss': 0.0609438993036747, 'behavior_loss': 0.26805401742458346, 'mean_batch': 5.084171772003174, 'min_batch': 5.042729282379151, 'max_batch': 5.158675622940064}
step: 11510 @ episode report: {'average_total_reward': 11.286001, 'reward_variance': 1.5630636, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5210142195224763, 'actor_loss': -4.875063800811768, 'hyper_actor_loss': 0.060611174628138545, 'behavior_loss': 0.2686284750699997, 'mean_batch': 5.140501689910889, 'min_batch': 5.096092271804809, 'max_batch': 5.199098730087281}
step: 11520 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 2.1184013, 'max_total_reward': 11.2300005, 'min_total_reward': 6.5699997, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8367003321647644, 'actor_loss': -4.86377592086792, 'hyper_actor_loss': 0.060698358714580535, 'behavior_loss': 0.2901164397597313, 'mean_batch': 5.109553861618042, 'min_batch': 5.069561624526978, 'max_batch': 5.16712064743042}
step: 11530 @ episode report: {'average_total_reward': 10.908999, 'reward_variance': 5.4120283, 'max_total_reward': 15.67, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8063092470169066, 'actor_loss': -4.839807033538818, 'hyper_actor_loss': 0.061063440144062044, 'behavior_loss': 0.2932589203119278, 'mean_batch': 5.04417667388916, 'min_batch': 5.0135103225708, 'max_batch': 5.086159038543701}
step: 11540 @ episode report: {'average_total_reward': 11.497001, 'reward_variance': 4.497161, 'max_total_reward': 15.67, 'min_total_reward': 8.79, 'average_n_step': 12.3, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.406956136226654, 'actor_loss': -4.844016027450562, 'hyper_actor_loss': 0.06128125488758087, 'behavior_loss': 0.2759593933820724, 'mean_batch': 5.055319118499756, 'min_batch': 5.023861074447632, 'max_batch': 5.128992891311645}
step: 11550 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 3.905265, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0348910212516786, 'actor_loss': -4.8643909931182865, 'hyper_actor_loss': 0.06110487282276154, 'behavior_loss': 0.28751398622989655, 'mean_batch': 5.113205480575561, 'min_batch': 5.069017457962036, 'max_batch': 5.212158346176148}
step: 11560 @ episode report: {'average_total_reward': 11.386, 'reward_variance': 2.5984845, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3096434116363525, 'actor_loss': -4.8011322021484375, 'hyper_actor_loss': 0.06098794937133789, 'behavior_loss': 0.27077783495187757, 'mean_batch': 4.9470862865448, 'min_batch': 4.918430423736572, 'max_batch': 5.012481021881103}
step: 11570 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 2.7044885, 'max_total_reward': 12.339999, 'min_total_reward': 6.5700006, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7749001562595368, 'actor_loss': -4.786310911178589, 'hyper_actor_loss': 0.060791419073939326, 'behavior_loss': 0.28485745638608934, 'mean_batch': 4.909187889099121, 'min_batch': 4.883308172225952, 'max_batch': 4.946633768081665}
step: 11580 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 2.6281044, 'max_total_reward': 13.45, 'min_total_reward': 8.68, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.008394593000412, 'actor_loss': -4.846233272552491, 'hyper_actor_loss': 0.060541429370641706, 'behavior_loss': 0.28558341711759566, 'mean_batch': 5.065169382095337, 'min_batch': 5.025048398971558, 'max_batch': 5.123252010345459}
step: 11590 @ episode report: {'average_total_reward': 10.087999, 'reward_variance': 0.39643598, 'max_total_reward': 11.23, 'min_total_reward': 8.79, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8697506427764892, 'actor_loss': -4.826415157318115, 'hyper_actor_loss': 0.060581044480204585, 'behavior_loss': 0.2821790188550949, 'mean_batch': 5.014966726303101, 'min_batch': 4.97581148147583, 'max_batch': 5.073103237152099}
step: 11600 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 1.2493598, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7285135686397552, 'actor_loss': -4.820194673538208, 'hyper_actor_loss': 0.06051511391997337, 'behavior_loss': 0.2750325843691826, 'mean_batch': 4.9990091800689695, 'min_batch': 4.960591602325439, 'max_batch': 5.066771173477173}
step: 11610 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 4.140244, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.468340089917183, 'actor_loss': -4.873552656173706, 'hyper_actor_loss': 0.06035356260836124, 'behavior_loss': 0.2711271867156029, 'mean_batch': 5.139164876937866, 'min_batch': 5.0900952339172365, 'max_batch': 5.208310174942016}
step: 11620 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.770601, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.04477681517601, 'actor_loss': -4.861374235153198, 'hyper_actor_loss': 0.05996291264891625, 'behavior_loss': 0.30010682344436646, 'mean_batch': 5.10389404296875, 'min_batch': 5.063159465789795, 'max_batch': 5.18227915763855}
step: 11630 @ episode report: {'average_total_reward': 9.332001, 'reward_variance': 2.1920962, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.736820387840271, 'actor_loss': -4.79286379814148, 'hyper_actor_loss': 0.06038840487599373, 'behavior_loss': 0.27703189104795456, 'mean_batch': 4.926411437988281, 'min_batch': 4.898193597793579, 'max_batch': 5.021790075302124}
step: 11640 @ episode report: {'average_total_reward': 9.553999, 'reward_variance': 2.834364, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9549509763717652, 'actor_loss': -4.823827743530273, 'hyper_actor_loss': 0.06023995727300644, 'behavior_loss': 0.2872517600655556, 'mean_batch': 5.005895519256592, 'min_batch': 4.97198748588562, 'max_batch': 5.105583381652832}
step: 11650 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.795941, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5405523896217346, 'actor_loss': -4.845881414413452, 'hyper_actor_loss': 0.06011766344308853, 'behavior_loss': 0.2621159374713898, 'mean_batch': 5.06483211517334, 'min_batch': 5.023533964157105, 'max_batch': 5.173958253860474}
step: 11660 @ episode report: {'average_total_reward': 10.331, 'reward_variance': 1.1887888, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.906989872455597, 'actor_loss': -4.859360837936402, 'hyper_actor_loss': 0.05980374366044998, 'behavior_loss': 0.274635948240757, 'mean_batch': 5.09861478805542, 'min_batch': 5.05790228843689, 'max_batch': 5.186022043228149}
step: 11670 @ episode report: {'average_total_reward': 10.964001, 'reward_variance': 6.816484, 'max_total_reward': 14.45, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7658665180206299, 'actor_loss': -4.8376819610595705, 'hyper_actor_loss': 0.05959784500300884, 'behavior_loss': 0.2706690326333046, 'mean_batch': 5.039871454238892, 'min_batch': 5.00717511177063, 'max_batch': 5.1599644184112545}
step: 11680 @ episode report: {'average_total_reward': 10.154, 'reward_variance': 2.726304, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.584880566596985, 'actor_loss': -4.853853464126587, 'hyper_actor_loss': 0.0594057485461235, 'behavior_loss': 0.279317606985569, 'mean_batch': 5.082521533966064, 'min_batch': 5.046223402023315, 'max_batch': 5.169927501678467}
step: 11690 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 2.103721, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.019479477405548, 'actor_loss': -4.8499932289123535, 'hyper_actor_loss': 0.05947929807007313, 'behavior_loss': 0.28772554397583006, 'mean_batch': 5.073029470443726, 'min_batch': 5.036250638961792, 'max_batch': 5.154834747314453}
step: 11700 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 2.9018695, 'max_total_reward': 13.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7819518446922302, 'actor_loss': -4.821432495117188, 'hyper_actor_loss': 0.059829477965831754, 'behavior_loss': 0.29155150800943375, 'mean_batch': 4.99674129486084, 'min_batch': 4.968934392929077, 'max_batch': 5.089753103256226}
step: 11710 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 5.8535295, 'max_total_reward': 14.559999, 'min_total_reward': 6.7900004, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6245144248008727, 'actor_loss': -4.844726991653443, 'hyper_actor_loss': 0.05973549522459507, 'behavior_loss': 0.27510744631290435, 'mean_batch': 5.0597490787506105, 'min_batch': 5.022870302200317, 'max_batch': 5.206672334671021}
step: 11720 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 4.005397, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8555957913398742, 'actor_loss': -4.845569038391114, 'hyper_actor_loss': 0.05969850793480873, 'behavior_loss': 0.2760632008314133, 'mean_batch': 5.063616132736206, 'min_batch': 5.0231564998626705, 'max_batch': 5.154888772964478}
step: 11730 @ episode report: {'average_total_reward': 10.553001, 'reward_variance': 1.2922403, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8373407125473022, 'actor_loss': -4.83249797821045, 'hyper_actor_loss': 0.05949830748140812, 'behavior_loss': 0.27432801127433776, 'mean_batch': 5.026032495498657, 'min_batch': 4.994949579238892, 'max_batch': 5.108895587921142}
step: 11740 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 1.518122, 'max_total_reward': 12.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.977754133939743, 'actor_loss': -4.835993862152099, 'hyper_actor_loss': 0.0593050342053175, 'behavior_loss': 0.2780620023608208, 'mean_batch': 5.029852724075317, 'min_batch': 5.008627891540527, 'max_batch': 5.085873174667358}
step: 11750 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 6.9594445, 'max_total_reward': 12.34, 'min_total_reward': 3.46, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6512830138206482, 'actor_loss': -4.826914739608765, 'hyper_actor_loss': 0.059043577313423155, 'behavior_loss': 0.28766727149486543, 'mean_batch': 5.0084587097167965, 'min_batch': 4.984611845016479, 'max_batch': 5.030599546432495}
step: 11760 @ episode report: {'average_total_reward': 10.553, 'reward_variance': 4.058761, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6728841662406921, 'actor_loss': -4.8595795154571535, 'hyper_actor_loss': 0.05929150618612766, 'behavior_loss': 0.29919807314872743, 'mean_batch': 5.094304132461548, 'min_batch': 5.063318347930908, 'max_batch': 5.131632518768311}
step: 11770 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 3.508981, 'max_total_reward': 14.559999, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6860312521457672, 'actor_loss': -4.85336594581604, 'hyper_actor_loss': 0.05967063158750534, 'behavior_loss': 0.29521241039037704, 'mean_batch': 5.079981899261474, 'min_batch': 5.046181917190552, 'max_batch': 5.11508355140686}
step: 11780 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 1.2204409, 'max_total_reward': 11.01, 'min_total_reward': 6.6800003, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7193144321441651, 'actor_loss': -4.839187145233154, 'hyper_actor_loss': 0.0596188634634018, 'behavior_loss': 0.2827033787965775, 'mean_batch': 5.046391725540161, 'min_batch': 5.008200454711914, 'max_batch': 5.087381076812744}
step: 11790 @ episode report: {'average_total_reward': 8.877001, 'reward_variance': 3.2161407, 'max_total_reward': 11.2300005, 'min_total_reward': 5.6800003, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5110500395298003, 'actor_loss': -4.848010444641114, 'hyper_actor_loss': 0.059437389671802524, 'behavior_loss': 0.28870250284671783, 'mean_batch': 5.071572351455688, 'min_batch': 5.027507019042969, 'max_batch': 5.1145130634307865}
step: 11800 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.4341258, 'max_total_reward': 13.2300005, 'min_total_reward': 8.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0393361032009123, 'actor_loss': -4.8635820865631105, 'hyper_actor_loss': 0.05949154570698738, 'behavior_loss': 0.2902944892644882, 'mean_batch': 5.112631368637085, 'min_batch': 5.065492963790893, 'max_batch': 5.159764385223388}
step: 11810 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 4.7009363, 'max_total_reward': 13.120001, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7650831699371339, 'actor_loss': -4.814850997924805, 'hyper_actor_loss': 0.05939237512648106, 'behavior_loss': 0.2844869062304497, 'mean_batch': 4.985863876342774, 'min_batch': 4.947184944152832, 'max_batch': 5.055317354202271}
step: 11820 @ episode report: {'average_total_reward': 10.443001, 'reward_variance': 1.3531812, 'max_total_reward': 12.34, 'min_total_reward': 8.68, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6592775106430053, 'actor_loss': -4.838547849655152, 'hyper_actor_loss': 0.05916663259267807, 'behavior_loss': 0.28954209834337236, 'mean_batch': 5.04686484336853, 'min_batch': 5.004800796508789, 'max_batch': 5.110596466064453}
step: 11830 @ episode report: {'average_total_reward': 11.242, 'reward_variance': 3.4155164, 'max_total_reward': 14.56, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7766494750976562, 'actor_loss': -4.860773229598999, 'hyper_actor_loss': 0.05913180373609066, 'behavior_loss': 0.279363688826561, 'mean_batch': 5.101968574523926, 'min_batch': 5.061731195449829, 'max_batch': 5.167814588546753}
step: 11840 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.6571248, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.1895506069064141, 'actor_loss': -4.862068367004395, 'hyper_actor_loss': 0.05893562100827694, 'behavior_loss': 0.2736825242638588, 'mean_batch': 5.108464765548706, 'min_batch': 5.06203441619873, 'max_batch': 5.160780429840088}
step: 11850 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 3.247561, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0769634366035463, 'actor_loss': -4.886620712280274, 'hyper_actor_loss': 0.05867104865610599, 'behavior_loss': 0.2759661555290222, 'mean_batch': 5.1677381038665775, 'min_batch': 5.128374195098877, 'max_batch': 5.2326866626739506}
step: 11860 @ episode report: {'average_total_reward': 10.420001, 'reward_variance': 2.3593602, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9336077749729157, 'actor_loss': -4.811910629272461, 'hyper_actor_loss': 0.0584410510957241, 'behavior_loss': 0.2715198442339897, 'mean_batch': 4.972632884979248, 'min_batch': 4.946106719970703, 'max_batch': 5.027731847763062}
step: 11870 @ episode report: {'average_total_reward': 10.120001, 'reward_variance': 3.6010406, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7092783212661744, 'actor_loss': -4.818656730651855, 'hyper_actor_loss': 0.058204390481114386, 'behavior_loss': 0.2713945657014847, 'mean_batch': 4.987400674819947, 'min_batch': 4.964937543869018, 'max_batch': 5.041654872894287}
step: 11880 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 3.4334354, 'max_total_reward': 12.339999, 'min_total_reward': 5.6800003, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9512802958488464, 'actor_loss': -4.865188121795654, 'hyper_actor_loss': 0.058033964782953265, 'behavior_loss': 0.26402832865715026, 'mean_batch': 5.104368400573731, 'min_batch': 5.08173508644104, 'max_batch': 5.130733299255371}
step: 11890 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 1.6303241, 'max_total_reward': 12.2300005, 'min_total_reward': 7.68, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.847895586490631, 'actor_loss': -4.838654375076294, 'hyper_actor_loss': 0.057994844019412996, 'behavior_loss': 0.2725210189819336, 'mean_batch': 5.035232305526733, 'min_batch': 5.016659307479858, 'max_batch': 5.072708082199097}
step: 11900 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 5.1487246, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5808642983436585, 'actor_loss': -4.838023519515991, 'hyper_actor_loss': 0.05790885500609875, 'behavior_loss': 0.27841815203428266, 'mean_batch': 5.0346051216125485, 'min_batch': 5.0140913963317875, 'max_batch': 5.076734638214111}
step: 11910 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 2.8310285, 'max_total_reward': 13.339999, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8130395472049714, 'actor_loss': -4.868858289718628, 'hyper_actor_loss': 0.05796950459480286, 'behavior_loss': 0.27653204649686813, 'mean_batch': 5.112862634658813, 'min_batch': 5.091971445083618, 'max_batch': 5.174755001068116}
step: 11920 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 3.186364, 'max_total_reward': 11.790001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9411381244659425, 'actor_loss': -4.84202127456665, 'hyper_actor_loss': 0.057993099093437195, 'behavior_loss': 0.2730740621685982, 'mean_batch': 5.043249464035034, 'min_batch': 5.0256999969482425, 'max_batch': 5.08509407043457}
step: 11930 @ episode report: {'average_total_reward': 8.467, 'reward_variance': 8.174842, 'max_total_reward': 13.340001, 'min_total_reward': 1.13, 'average_n_step': 9.6, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9633103132247924, 'actor_loss': -4.819327640533447, 'hyper_actor_loss': 0.057924861833453176, 'behavior_loss': 0.2849593281745911, 'mean_batch': 4.985563325881958, 'min_batch': 4.969601774215699, 'max_batch': 5.008381986618042}
step: 11940 @ episode report: {'average_total_reward': 10.177, 'reward_variance': 1.4199413, 'max_total_reward': 12.2300005, 'min_total_reward': 8.68, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2617239236831663, 'actor_loss': -4.79382586479187, 'hyper_actor_loss': 0.058092203736305234, 'behavior_loss': 0.28348046988248826, 'mean_batch': 4.924986553192139, 'min_batch': 4.9043309688568115, 'max_batch': 4.946187686920166}
step: 11950 @ episode report: {'average_total_reward': 9.776001, 'reward_variance': 3.3362846, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7307021141052246, 'actor_loss': -4.800997352600097, 'hyper_actor_loss': 0.05800601728260517, 'behavior_loss': 0.2804695650935173, 'mean_batch': 4.948605871200561, 'min_batch': 4.91614179611206, 'max_batch': 4.965300798416138}
step: 11960 @ episode report: {'average_total_reward': 11.009001, 'reward_variance': 4.1656094, 'max_total_reward': 14.450001, 'min_total_reward': 6.79, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0100142478942873, 'actor_loss': -4.818143558502197, 'hyper_actor_loss': 0.05792734585702419, 'behavior_loss': 0.28161806166172026, 'mean_batch': 5.014206838607788, 'min_batch': 4.935597658157349, 'max_batch': 5.036016321182251}
step: 11970 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 3.7337098, 'max_total_reward': 12.340001, 'min_total_reward': 5.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.628323060274124, 'actor_loss': -4.820980548858643, 'hyper_actor_loss': 0.057817409932613376, 'behavior_loss': 0.26256452053785323, 'mean_batch': 5.0155243396759035, 'min_batch': 4.948422431945801, 'max_batch': 5.037057304382325}
step: 11980 @ episode report: {'average_total_reward': 9.222, 'reward_variance': 4.453656, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9615307807922364, 'actor_loss': -4.831954574584961, 'hyper_actor_loss': 0.05754047855734825, 'behavior_loss': 0.29030788838863375, 'mean_batch': 5.0463310241699215, 'min_batch': 4.972430801391601, 'max_batch': 5.075308990478516}
step: 11990 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 0.9862008, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9860158920288087, 'actor_loss': -4.798770189285278, 'hyper_actor_loss': 0.05752891264855862, 'behavior_loss': 0.26712473928928376, 'mean_batch': 4.953485631942749, 'min_batch': 4.900262260437012, 'max_batch': 4.9757932186126705}
step: 12000 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 3.235061, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8678372085094452, 'actor_loss': -4.800064325332642, 'hyper_actor_loss': 0.05742994286119938, 'behavior_loss': 0.29305376410484313, 'mean_batch': 4.955250644683838, 'min_batch': 4.904796361923218, 'max_batch': 4.976691246032715}
step: 12010 @ episode report: {'average_total_reward': 8.988, 'reward_variance': 5.0863357, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.909550964832306, 'actor_loss': -4.818762350082397, 'hyper_actor_loss': 0.057569928094744684, 'behavior_loss': 0.29409086108207705, 'mean_batch': 5.0040350437164305, 'min_batch': 4.948602628707886, 'max_batch': 5.030014371871948}
step: 12020 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 4.572657, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.710591971874237, 'actor_loss': -4.817333745956421, 'hyper_actor_loss': 0.057863909378647806, 'behavior_loss': 0.2934467911720276, 'mean_batch': 4.994975233078003, 'min_batch': 4.950466775894165, 'max_batch': 5.014653491973877}
step: 12030 @ episode report: {'average_total_reward': 9.332001, 'reward_variance': 3.5265164, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6930099308490754, 'actor_loss': -4.833714151382447, 'hyper_actor_loss': 0.05786978602409363, 'behavior_loss': 0.28862132877111435, 'mean_batch': 5.027412033081054, 'min_batch': 4.999764728546142, 'max_batch': 5.0418566226959225}
step: 12040 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.8621411, 'max_total_reward': 12.34, 'min_total_reward': 6.57, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8810207962989807, 'actor_loss': -4.823829936981201, 'hyper_actor_loss': 0.05774589776992798, 'behavior_loss': 0.279998579621315, 'mean_batch': 5.00158724784851, 'min_batch': 4.976149082183838, 'max_batch': 5.014782285690307}
step: 12050 @ episode report: {'average_total_reward': 11.120001, 'reward_variance': 1.8833605, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 12.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.180229663848877, 'actor_loss': -4.7946678638458256, 'hyper_actor_loss': 0.0573642548173666, 'behavior_loss': 0.2745137244462967, 'mean_batch': 4.934812736511231, 'min_batch': 4.898721504211426, 'max_batch': 4.951837158203125}
step: 12060 @ episode report: {'average_total_reward': 11.186, 'reward_variance': 2.3718438, 'max_total_reward': 13.34, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7335340201854705, 'actor_loss': -4.793353462219239, 'hyper_actor_loss': 0.057043413445353505, 'behavior_loss': 0.27419676780700686, 'mean_batch': 4.92758960723877, 'min_batch': 4.899474859237671, 'max_batch': 4.9454246997833256}
step: 12070 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 2.0597804, 'max_total_reward': 11.12, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.115098637342453, 'actor_loss': -4.817664623260498, 'hyper_actor_loss': 0.056881708279252055, 'behavior_loss': 0.2801445424556732, 'mean_batch': 4.9857869148254395, 'min_batch': 4.96116042137146, 'max_batch': 5.003986167907715}
step: 12080 @ episode report: {'average_total_reward': 9.454, 'reward_variance': 2.1473846, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5500663816928864, 'actor_loss': -4.815694093704224, 'hyper_actor_loss': 0.05676385015249252, 'behavior_loss': 0.26713305711746216, 'mean_batch': 4.976177406311035, 'min_batch': 4.96096773147583, 'max_batch': 4.9923145294189455}
step: 12090 @ episode report: {'average_total_reward': 9.155001, 'reward_variance': 2.6954236, 'max_total_reward': 11.229999, 'min_total_reward': 5.7900004, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0526548504829405, 'actor_loss': -4.837571668624878, 'hyper_actor_loss': 0.05650521591305733, 'behavior_loss': 0.28314014971256257, 'mean_batch': 5.0334553718566895, 'min_batch': 5.01304612159729, 'max_batch': 5.042552185058594}
step: 12100 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 3.1209605, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7208998441696166, 'actor_loss': -4.792100048065185, 'hyper_actor_loss': 0.05654381588101387, 'behavior_loss': 0.2807223454117775, 'mean_batch': 4.926476097106933, 'min_batch': 4.894277906417846, 'max_batch': 4.93517370223999}
step: 12110 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 1.8020813, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.54863298535347, 'actor_loss': -4.818431806564331, 'hyper_actor_loss': 0.05653356276452541, 'behavior_loss': 0.2747929275035858, 'mean_batch': 4.992251396179199, 'min_batch': 4.9589920997619625, 'max_batch': 5.004320812225342}
step: 12120 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.301005, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.47267284989357, 'actor_loss': -4.846794939041137, 'hyper_actor_loss': 0.056490082293748856, 'behavior_loss': 0.27075827270746233, 'mean_batch': 5.077685737609864, 'min_batch': 5.015474939346314, 'max_batch': 5.089492130279541}
step: 12130 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 1.2737801, 'max_total_reward': 13.340001, 'min_total_reward': 9.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7191654682159423, 'actor_loss': -4.844821453094482, 'hyper_actor_loss': 0.056374454870820045, 'behavior_loss': 0.2840570151805878, 'mean_batch': 5.076188421249389, 'min_batch': 5.007080507278443, 'max_batch': 5.088605499267578}
step: 12140 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 2.3780448, 'max_total_reward': 13.450001, 'min_total_reward': 7.6800003, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6176923871040345, 'actor_loss': -4.830079078674316, 'hyper_actor_loss': 0.056304946169257165, 'behavior_loss': 0.275513231754303, 'mean_batch': 5.0365824699401855, 'min_batch': 4.972547960281372, 'max_batch': 5.049458312988281}
step: 12150 @ episode report: {'average_total_reward': 11.108, 'reward_variance': 4.1545773, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5910917282104493, 'actor_loss': -4.809484529495239, 'hyper_actor_loss': 0.05625189803540707, 'behavior_loss': 0.2717784196138382, 'mean_batch': 4.9875024318695065, 'min_batch': 4.91924090385437, 'max_batch': 5.004165840148926}
step: 12160 @ episode report: {'average_total_reward': 11.320001, 'reward_variance': 1.1822002, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 12.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.553384268283844, 'actor_loss': -4.842850065231323, 'hyper_actor_loss': 0.056147411838173865, 'behavior_loss': 0.26619707196950915, 'mean_batch': 5.071678400039673, 'min_batch': 5.001705932617187, 'max_batch': 5.085351800918579}
step: 12170 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 2.969749, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5682300329208374, 'actor_loss': -4.85721492767334, 'hyper_actor_loss': 0.05590011067688465, 'behavior_loss': 0.2747014343738556, 'mean_batch': 5.112360858917237, 'min_batch': 5.033575057983398, 'max_batch': 5.125364685058594}
step: 12180 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 1.0448092, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.882652711868286, 'actor_loss': -4.82939133644104, 'hyper_actor_loss': 0.05578363314270973, 'behavior_loss': 0.2744242399930954, 'mean_batch': 5.026463651657105, 'min_batch': 4.979158782958985, 'max_batch': 5.038042211532593}
step: 12190 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 2.126645, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7015053689479829, 'actor_loss': -4.814851856231689, 'hyper_actor_loss': 0.0557610597461462, 'behavior_loss': 0.2800538033246994, 'mean_batch': 4.999433135986328, 'min_batch': 4.933838939666748, 'max_batch': 5.012360095977783}
step: 12200 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 2.5161362, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8054306745529174, 'actor_loss': -4.812587022781372, 'hyper_actor_loss': 0.055680219829082486, 'behavior_loss': 0.2776816815137863, 'mean_batch': 4.996138668060302, 'min_batch': 4.925834703445434, 'max_batch': 5.010225677490235}
step: 12210 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.1591604, 'max_total_reward': 12.339999, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6946598172187806, 'actor_loss': -4.826357889175415, 'hyper_actor_loss': 0.05577454045414924, 'behavior_loss': 0.273913300037384, 'mean_batch': 5.030125141143799, 'min_batch': 4.960431480407715, 'max_batch': 5.045897483825684}
step: 12220 @ episode report: {'average_total_reward': 11.286001, 'reward_variance': 3.707784, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.165358418226242, 'actor_loss': -4.804542064666748, 'hyper_actor_loss': 0.055878860503435136, 'behavior_loss': 0.3091392531991005, 'mean_batch': 4.970120048522949, 'min_batch': 4.912151670455932, 'max_batch': 4.989401197433471}
step: 12230 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 4.872001, 'max_total_reward': 13.23, 'min_total_reward': 4.68, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5426032721996308, 'actor_loss': -4.799235868453979, 'hyper_actor_loss': 0.056128551438450816, 'behavior_loss': 0.2775616154074669, 'mean_batch': 4.957822465896607, 'min_batch': 4.898408985137939, 'max_batch': 4.977892446517944}
step: 12240 @ episode report: {'average_total_reward': 11.009001, 'reward_variance': 0.59140897, 'max_total_reward': 12.2300005, 'min_total_reward': 9.79, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.609562087059021, 'actor_loss': -4.843318176269531, 'hyper_actor_loss': 0.055746154859662056, 'behavior_loss': 0.2843776404857635, 'mean_batch': 5.075902605056763, 'min_batch': 4.999741315841675, 'max_batch': 5.095537996292114}
step: 12250 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 4.2210684, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.489988923072815, 'actor_loss': -4.843253469467163, 'hyper_actor_loss': 0.055729197710752486, 'behavior_loss': 0.28221809267997744, 'mean_batch': 5.073302221298218, 'min_batch': 5.001966333389282, 'max_batch': 5.091232967376709}
step: 12260 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 1.9017694, 'max_total_reward': 12.340001, 'min_total_reward': 7.68, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0429792523384096, 'actor_loss': -4.817340135574341, 'hyper_actor_loss': 0.055581051483750345, 'behavior_loss': 0.2848523110151291, 'mean_batch': 5.001011180877685, 'min_batch': 4.944669198989868, 'max_batch': 5.022372722625732}
step: 12270 @ episode report: {'average_total_reward': 9.910001, 'reward_variance': 4.1933603, 'max_total_reward': 13.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8410038352012634, 'actor_loss': -4.8050093173980715, 'hyper_actor_loss': 0.0554262638092041, 'behavior_loss': 0.2679291144013405, 'mean_batch': 4.9637494564056395, 'min_batch': 4.920509099960327, 'max_batch': 4.997195768356323}
step: 12280 @ episode report: {'average_total_reward': 10.853, 'reward_variance': 1.9841211, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.020711386203766, 'actor_loss': -4.802673768997193, 'hyper_actor_loss': 0.05515405461192131, 'behavior_loss': 0.2890389204025269, 'mean_batch': 4.956447601318359, 'min_batch': 4.916273355484009, 'max_batch': 4.9996232986450195}
step: 12290 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 1.4120762, 'max_total_reward': 11.120001, 'min_total_reward': 7.68, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8354792505502702, 'actor_loss': -4.803406476974487, 'hyper_actor_loss': 0.055258769914507865, 'behavior_loss': 0.2943821519613266, 'mean_batch': 4.957068252563476, 'min_batch': 4.919230604171753, 'max_batch': 4.999839115142822}
step: 12300 @ episode report: {'average_total_reward': 10.665001, 'reward_variance': 2.3411252, 'max_total_reward': 13.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5474637925624848, 'actor_loss': -4.829663467407227, 'hyper_actor_loss': 0.05531444400548935, 'behavior_loss': 0.2773778811097145, 'mean_batch': 5.021157455444336, 'min_batch': 4.9859428882598875, 'max_batch': 5.057153701782227}
step: 12310 @ episode report: {'average_total_reward': 10.631, 'reward_variance': 2.8847091, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5841719150543212, 'actor_loss': -4.853412199020386, 'hyper_actor_loss': 0.05511326789855957, 'behavior_loss': 0.27362978607416155, 'mean_batch': 5.078961753845215, 'min_batch': 5.047355508804321, 'max_batch': 5.107723569869995}
step: 12320 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 2.081061, 'max_total_reward': 12.009999, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.537357646226883, 'actor_loss': -4.848431921005249, 'hyper_actor_loss': 0.05504701584577561, 'behavior_loss': 0.29951189309358595, 'mean_batch': 5.064626026153564, 'min_batch': 5.03650050163269, 'max_batch': 5.110665798187256}
step: 12330 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 4.048136, 'max_total_reward': 15.45, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6872151911258697, 'actor_loss': -4.837355518341065, 'hyper_actor_loss': 0.05507603473961353, 'behavior_loss': 0.28910370767116544, 'mean_batch': 5.033931732177734, 'min_batch': 5.011440944671631, 'max_batch': 5.080173110961914}
step: 12340 @ episode report: {'average_total_reward': 11.242, 'reward_variance': 6.2308755, 'max_total_reward': 15.45, 'min_total_reward': 6.68, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7489263236522674, 'actor_loss': -4.830777978897094, 'hyper_actor_loss': 0.05517697259783745, 'behavior_loss': 0.27797246873378756, 'mean_batch': 5.017993927001953, 'min_batch': 4.994358539581299, 'max_batch': 5.081060600280762}
step: 12350 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.2242246, 'max_total_reward': 13.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.058720827102661, 'actor_loss': -4.820800352096557, 'hyper_actor_loss': 0.05491093061864376, 'behavior_loss': 0.28617949336767196, 'mean_batch': 4.993601083755493, 'min_batch': 4.968929719924927, 'max_batch': 5.037639522552491}
step: 12360 @ episode report: {'average_total_reward': 10.164999, 'reward_variance': 2.2582245, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.916191303730011, 'actor_loss': -4.804783773422241, 'hyper_actor_loss': 0.05469821020960808, 'behavior_loss': 0.282473036646843, 'mean_batch': 4.955063772201538, 'min_batch': 4.928066158294678, 'max_batch': 5.032943773269653}
step: 12370 @ episode report: {'average_total_reward': 12.606999, 'reward_variance': 1.9328616, 'max_total_reward': 14.450001, 'min_total_reward': 10.01, 'average_n_step': 13.3, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9232644438743591, 'actor_loss': -4.7938331127166744, 'hyper_actor_loss': 0.0548372894525528, 'behavior_loss': 0.2777203217148781, 'mean_batch': 4.930962181091308, 'min_batch': 4.898174715042114, 'max_batch': 5.0013594150543215}
step: 12380 @ episode report: {'average_total_reward': 11.386001, 'reward_variance': 4.176904, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.791057014465332, 'actor_loss': -4.810411357879639, 'hyper_actor_loss': 0.05463970303535461, 'behavior_loss': 0.2855795830488205, 'mean_batch': 4.971183252334595, 'min_batch': 4.9397704124450685, 'max_batch': 5.007162761688233}
step: 12390 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 3.6921165, 'max_total_reward': 12.340001, 'min_total_reward': 6.9000006, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6215309858322144, 'actor_loss': -4.834584665298462, 'hyper_actor_loss': 0.05442043952643871, 'behavior_loss': 0.2817026928067207, 'mean_batch': 5.03468132019043, 'min_batch': 4.9968408107757565, 'max_batch': 5.068843507766724}
step: 12400 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 1.3483241, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6793623745441437, 'actor_loss': -4.840192556381226, 'hyper_actor_loss': 0.05427219904959202, 'behavior_loss': 0.2608062759041786, 'mean_batch': 5.0487456798553465, 'min_batch': 5.010911464691162, 'max_batch': 5.08448634147644}
step: 12410 @ episode report: {'average_total_reward': 11.142, 'reward_variance': 1.6096153, 'max_total_reward': 13.2300005, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6433531284332275, 'actor_loss': -4.842646312713623, 'hyper_actor_loss': 0.05393917262554169, 'behavior_loss': 0.2743425354361534, 'mean_batch': 5.053371906280518, 'min_batch': 5.018607807159424, 'max_batch': 5.094385004043579}
step: 12420 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.8158443, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6758084654808045, 'actor_loss': -4.831129503250122, 'hyper_actor_loss': 0.05393132716417313, 'behavior_loss': 0.29436871111392976, 'mean_batch': 5.0270768165588375, 'min_batch': 4.987120914459228, 'max_batch': 5.054315090179443}
step: 12430 @ episode report: {'average_total_reward': 10.764001, 'reward_variance': 2.0518847, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5785433411598206, 'actor_loss': -4.826431083679199, 'hyper_actor_loss': 0.05391907878220081, 'behavior_loss': 0.2655223309993744, 'mean_batch': 5.014832162857056, 'min_batch': 4.97584023475647, 'max_batch': 5.038275098800659}
step: 12440 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 5.0027356, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.76869897544384, 'actor_loss': -4.846327877044677, 'hyper_actor_loss': 0.05395485870540142, 'behavior_loss': 0.2685455337166786, 'mean_batch': 5.064436960220337, 'min_batch': 5.026153135299682, 'max_batch': 5.08570351600647}
step: 12450 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 4.4212265, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6097360849380493, 'actor_loss': -4.837191915512085, 'hyper_actor_loss': 0.05370621755719185, 'behavior_loss': 0.29305018931627275, 'mean_batch': 5.036588335037232, 'min_batch': 5.007970666885376, 'max_batch': 5.050356435775757}
step: 12460 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 1.237656, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.576152727007866, 'actor_loss': -4.827686357498169, 'hyper_actor_loss': 0.05374392122030258, 'behavior_loss': 0.27637853622436526, 'mean_batch': 5.008806371688843, 'min_batch': 4.988076639175415, 'max_batch': 5.052586936950684}
step: 12470 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 6.2809076, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.526529711484909, 'actor_loss': -4.863628244400024, 'hyper_actor_loss': 0.053620538860559466, 'behavior_loss': 0.26862226277589796, 'mean_batch': 5.103245782852173, 'min_batch': 5.075033807754517, 'max_batch': 5.164158058166504}
step: 12480 @ episode report: {'average_total_reward': 11.6970005, 'reward_variance': 1.163641, 'max_total_reward': 13.34, 'min_total_reward': 10.01, 'average_n_step': 12.5, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7186037659645081, 'actor_loss': -4.858624601364136, 'hyper_actor_loss': 0.05335762575268745, 'behavior_loss': 0.27643567472696307, 'mean_batch': 5.084940671920776, 'min_batch': 5.067857646942139, 'max_batch': 5.130665111541748}
step: 12490 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 4.873229, 'max_total_reward': 14.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7522356986999512, 'actor_loss': -4.832613182067871, 'hyper_actor_loss': 0.053218862414360045, 'behavior_loss': 0.27943906784057615, 'mean_batch': 5.020374202728272, 'min_batch': 5.001207494735718, 'max_batch': 5.061470460891724}
step: 12500 @ episode report: {'average_total_reward': 10.354, 'reward_variance': 4.0537443, 'max_total_reward': 13.450001, 'min_total_reward': 6.68, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6365280508995057, 'actor_loss': -4.841854619979858, 'hyper_actor_loss': 0.05315261706709862, 'behavior_loss': 0.2764958620071411, 'mean_batch': 5.041300964355469, 'min_batch': 5.026866292953491, 'max_batch': 5.085327863693237}
step: 12510 @ episode report: {'average_total_reward': 11.320002, 'reward_variance': 2.3531396, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8727486610412598, 'actor_loss': -4.844018602371216, 'hyper_actor_loss': 0.053245456889271736, 'behavior_loss': 0.275628761947155, 'mean_batch': 5.05192232131958, 'min_batch': 5.02699842453003, 'max_batch': 5.101292991638184}
step: 12520 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 2.3707435, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.927772057056427, 'actor_loss': -4.80762357711792, 'hyper_actor_loss': 0.053214384242892265, 'behavior_loss': 0.2840238720178604, 'mean_batch': 4.9626635074615475, 'min_batch': 4.934575939178467, 'max_batch': 5.024225091934204}
step: 12530 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 3.0528214, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7616523444652556, 'actor_loss': -4.8290245056152346, 'hyper_actor_loss': 0.05303382687270641, 'behavior_loss': 0.2825793564319611, 'mean_batch': 5.019973182678223, 'min_batch': 4.983818531036377, 'max_batch': 5.093140411376953}
step: 12540 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 7.5778627, 'max_total_reward': 15.67, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6121542930603028, 'actor_loss': -4.848646259307861, 'hyper_actor_loss': 0.053080163151025775, 'behavior_loss': 0.2767797812819481, 'mean_batch': 5.064152574539184, 'min_batch': 5.038059711456299, 'max_batch': 5.118389654159546}
step: 12550 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.678681, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9990577816963195, 'actor_loss': -4.827890110015869, 'hyper_actor_loss': 0.052955982461571696, 'behavior_loss': 0.28190962970256805, 'mean_batch': 5.007612991333008, 'min_batch': 4.990475511550903, 'max_batch': 5.054973840713501}
step: 12560 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 11.595909, 'max_total_reward': 13.450001, 'min_total_reward': 1.13, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8345648407936097, 'actor_loss': -4.801818609237671, 'hyper_actor_loss': 0.05292678810656071, 'behavior_loss': 0.2727463454008102, 'mean_batch': 4.941149616241455, 'min_batch': 4.92725305557251, 'max_batch': 5.002181577682495}
step: 12570 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 12.434244, 'max_total_reward': 14.34, 'min_total_reward': 1.13, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9857527196407319, 'actor_loss': -4.834156322479248, 'hyper_actor_loss': 0.052807708829641344, 'behavior_loss': 0.2767374038696289, 'mean_batch': 5.02531681060791, 'min_batch': 5.004098224639892, 'max_batch': 5.075400972366333}
step: 12580 @ episode report: {'average_total_reward': 9.876, 'reward_variance': 3.9170833, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7221307814121247, 'actor_loss': -4.817312955856323, 'hyper_actor_loss': 0.05269083864986897, 'behavior_loss': 0.28398954421281813, 'mean_batch': 4.984088134765625, 'min_batch': 4.961089468002319, 'max_batch': 5.021908521652222}
step: 12590 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 3.1096616, 'max_total_reward': 14.34, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.056432682275772, 'actor_loss': -4.815832090377808, 'hyper_actor_loss': 0.05251847058534622, 'behavior_loss': 0.268216609954834, 'mean_batch': 4.979780530929565, 'min_batch': 4.958037805557251, 'max_batch': 5.024070930480957}
step: 12600 @ episode report: {'average_total_reward': 11.1310005, 'reward_variance': 3.2505498, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0799158573150636, 'actor_loss': -4.789549207687378, 'hyper_actor_loss': 0.05248457305133343, 'behavior_loss': 0.29675193428993224, 'mean_batch': 4.912985992431641, 'min_batch': 4.895156383514404, 'max_batch': 4.974952268600464}
step: 12610 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.623756, 'max_total_reward': 15.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6424907922744751, 'actor_loss': -4.801208639144898, 'hyper_actor_loss': 0.05249956212937832, 'behavior_loss': 0.2676057755947113, 'mean_batch': 4.941382217407226, 'min_batch': 4.924317741394043, 'max_batch': 5.0074074268341064}
step: 12620 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.3146452, 'max_total_reward': 12.34, 'min_total_reward': 8.68, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5050852417945861, 'actor_loss': -4.849708938598633, 'hyper_actor_loss': 0.05255754217505455, 'behavior_loss': 0.2727335885167122, 'mean_batch': 5.063945531845093, 'min_batch': 5.043721055984497, 'max_batch': 5.106772470474243}
step: 12630 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 1.6572361, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5706943571567535, 'actor_loss': -4.862533473968506, 'hyper_actor_loss': 0.05225655920803547, 'behavior_loss': 0.27716496139764785, 'mean_batch': 5.097105026245117, 'min_batch': 5.075477123260498, 'max_batch': 5.175429391860962}
step: 12640 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 4.73021, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9265246748924256, 'actor_loss': -4.828369092941284, 'hyper_actor_loss': 0.052179738879203796, 'behavior_loss': 0.29067875146865846, 'mean_batch': 5.007857608795166, 'min_batch': 4.992834568023682, 'max_batch': 5.053254079818726}
step: 12650 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 1.2442039, 'max_total_reward': 12.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6165169179439545, 'actor_loss': -4.8081340312957765, 'hyper_actor_loss': 0.05235059261322021, 'behavior_loss': 0.27447005063295365, 'mean_batch': 4.95969557762146, 'min_batch': 4.940098905563355, 'max_batch': 5.021139001846313}
step: 12660 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 11.614344, 'max_total_reward': 13.450001, 'min_total_reward': 0.91, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7349397450685502, 'actor_loss': -4.846515941619873, 'hyper_actor_loss': 0.052220729365944865, 'behavior_loss': 0.26648783683776855, 'mean_batch': 5.06054368019104, 'min_batch': 5.030965900421142, 'max_batch': 5.118829965591431}
step: 12670 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 1.9198831, 'max_total_reward': 13.339999, 'min_total_reward': 7.8999996, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9628899216651916, 'actor_loss': -4.825835561752319, 'hyper_actor_loss': 0.05211584009230137, 'behavior_loss': 0.2922214806079865, 'mean_batch': 5.0078291416168215, 'min_batch': 4.980108976364136, 'max_batch': 5.046709775924683}
step: 12680 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 4.357201, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.580522644519806, 'actor_loss': -4.8034838199615475, 'hyper_actor_loss': 0.052120867371559146, 'behavior_loss': 0.27269228994846345, 'mean_batch': 4.951119327545166, 'min_batch': 4.925574207305909, 'max_batch': 4.997909736633301}
step: 12690 @ episode report: {'average_total_reward': 10.797998, 'reward_variance': 1.8041956, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9365407943725585, 'actor_loss': -4.824737596511841, 'hyper_actor_loss': 0.05209745392203331, 'behavior_loss': 0.29879908859729765, 'mean_batch': 5.007432651519776, 'min_batch': 4.974747848510742, 'max_batch': 5.039382743835449}
step: 12700 @ episode report: {'average_total_reward': 10.297999, 'reward_variance': 7.343756, 'max_total_reward': 14.559999, 'min_total_reward': 5.5699997, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6590760886669158, 'actor_loss': -4.8342447757720945, 'hyper_actor_loss': 0.05212208069860935, 'behavior_loss': 0.27602565586566924, 'mean_batch': 5.027336263656617, 'min_batch': 5.002414321899414, 'max_batch': 5.0440226078033445}
step: 12710 @ episode report: {'average_total_reward': 10.886001, 'reward_variance': 3.8999639, 'max_total_reward': 14.559999, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8216359436511993, 'actor_loss': -4.8204902648925785, 'hyper_actor_loss': 0.05206741131842137, 'behavior_loss': 0.2768470853567123, 'mean_batch': 4.988921689987182, 'min_batch': 4.972220802307129, 'max_batch': 5.015837097167969}
step: 12720 @ episode report: {'average_total_reward': 11.264001, 'reward_variance': 5.0125046, 'max_total_reward': 15.56, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7950673401355743, 'actor_loss': -4.813204765319824, 'hyper_actor_loss': 0.051873565465211866, 'behavior_loss': 0.28260926604270936, 'mean_batch': 4.969332885742188, 'min_batch': 4.955426979064941, 'max_batch': 4.999741315841675}
step: 12730 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 1.2692957, 'max_total_reward': 12.339999, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8035291969776153, 'actor_loss': -4.835979318618774, 'hyper_actor_loss': 0.05180434063076973, 'behavior_loss': 0.2835215300321579, 'mean_batch': 5.032314825057983, 'min_batch': 5.00613374710083, 'max_batch': 5.078314542770386}
step: 12740 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 3.113684, 'max_total_reward': 14.45, 'min_total_reward': 8.789999, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8158810019493103, 'actor_loss': -4.8176830291748045, 'hyper_actor_loss': 0.05156631991267204, 'behavior_loss': 0.2765089377760887, 'mean_batch': 4.994086027145386, 'min_batch': 4.953051376342773, 'max_batch': 5.054304885864258}
step: 12750 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 4.6580095, 'max_total_reward': 14.45, 'min_total_reward': 5.6799994, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8401280164718627, 'actor_loss': -4.808033514022827, 'hyper_actor_loss': 0.051382314413785934, 'behavior_loss': 0.2742935627698898, 'mean_batch': 4.970521879196167, 'min_batch': 4.92868218421936, 'max_batch': 5.0164693832397464}
step: 12760 @ episode report: {'average_total_reward': 11.540999, 'reward_variance': 2.961529, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6633164495229722, 'actor_loss': -4.808815383911133, 'hyper_actor_loss': 0.05138493739068508, 'behavior_loss': 0.2840434774756432, 'mean_batch': 4.973648309707642, 'min_batch': 4.929511594772339, 'max_batch': 5.005549430847168}
step: 12770 @ episode report: {'average_total_reward': 9.821, 'reward_variance': 3.2738883, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9810925841331481, 'actor_loss': -4.809519863128662, 'hyper_actor_loss': 0.051428171992301944, 'behavior_loss': 0.2910246804356575, 'mean_batch': 4.977758884429932, 'min_batch': 4.928879594802856, 'max_batch': 5.008984661102295}
step: 12780 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 2.2280686, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.1764672607183457, 'actor_loss': -4.830700397491455, 'hyper_actor_loss': 0.051386032998561856, 'behavior_loss': 0.2694956585764885, 'mean_batch': 5.039183664321899, 'min_batch': 4.973657417297363, 'max_batch': 5.070015716552734}
step: 12790 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 2.5633407, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4837730646133422, 'actor_loss': -4.868936586380005, 'hyper_actor_loss': 0.051297785714268684, 'behavior_loss': 0.2708005353808403, 'mean_batch': 5.1493871212005615, 'min_batch': 5.056296634674072, 'max_batch': 5.177123022079468}
step: 12800 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 2.3489168, 'max_total_reward': 14.450001, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6563776016235352, 'actor_loss': -4.837632846832276, 'hyper_actor_loss': 0.05106719695031643, 'behavior_loss': 0.2782421812415123, 'mean_batch': 5.061981916427612, 'min_batch': 4.98523211479187, 'max_batch': 5.088133049011231}
step: 12810 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 3.0485451, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7220382690429688, 'actor_loss': -4.8363844871521, 'hyper_actor_loss': 0.05088074319064617, 'behavior_loss': 0.25974241495132444, 'mean_batch': 5.07073073387146, 'min_batch': 4.970322799682617, 'max_batch': 5.101334190368652}
step: 12820 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 2.1846094, 'max_total_reward': 13.340001, 'min_total_reward': 7.9000006, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.029424262046814, 'actor_loss': -4.805769252777099, 'hyper_actor_loss': 0.050739044323563576, 'behavior_loss': 0.2503842458128929, 'mean_batch': 4.998827409744263, 'min_batch': 4.890243721008301, 'max_batch': 5.031960344314575}
step: 12830 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 1.5356686, 'max_total_reward': 12.339999, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.898933207988739, 'actor_loss': -4.755525779724121, 'hyper_actor_loss': 0.05038694441318512, 'behavior_loss': 0.25850959867239, 'mean_batch': 4.879930686950684, 'min_batch': 4.763415908813476, 'max_batch': 4.918434286117554}
step: 12840 @ episode report: {'average_total_reward': 11.364, 'reward_variance': 3.7172856, 'max_total_reward': 14.56, 'min_total_reward': 7.7899995, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9274982035160064, 'actor_loss': -4.8115908145904545, 'hyper_actor_loss': 0.05019094161689282, 'behavior_loss': 0.2714408189058304, 'mean_batch': 5.01944785118103, 'min_batch': 4.8984921932220455, 'max_batch': 5.053677940368653}
step: 12850 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 4.024745, 'max_total_reward': 13.450001, 'min_total_reward': 6.7900004, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0400816321372988, 'actor_loss': -4.81737756729126, 'hyper_actor_loss': 0.050178021937608716, 'behavior_loss': 0.27000527679920194, 'mean_batch': 5.026902770996093, 'min_batch': 4.919432830810547, 'max_batch': 5.057579278945923}
step: 12860 @ episode report: {'average_total_reward': 9.532, 'reward_variance': 5.7928567, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.286068892478943, 'actor_loss': -4.744254922866821, 'hyper_actor_loss': 0.05030645132064819, 'behavior_loss': 0.2875255584716797, 'mean_batch': 4.836498594284057, 'min_batch': 4.752769899368286, 'max_batch': 4.866874504089355}
step: 12870 @ episode report: {'average_total_reward': 10.465, 'reward_variance': 3.0805857, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7774338126182556, 'actor_loss': -4.757703018188477, 'hyper_actor_loss': 0.05055510774254799, 'behavior_loss': 0.29074382185935976, 'mean_batch': 4.873313140869141, 'min_batch': 4.780718040466309, 'max_batch': 4.906443548202515}
step: 12880 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 1.393024, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8337603271007539, 'actor_loss': -4.797845411300659, 'hyper_actor_loss': 0.05088028647005558, 'behavior_loss': 0.2785726100206375, 'mean_batch': 4.975372409820556, 'min_batch': 4.873957204818725, 'max_batch': 5.003826427459717}
step: 12890 @ episode report: {'average_total_reward': 10.764001, 'reward_variance': 2.6250439, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.063682425022125, 'actor_loss': -4.798997163772583, 'hyper_actor_loss': 0.05079768523573876, 'behavior_loss': 0.2940636038780212, 'mean_batch': 4.979896211624146, 'min_batch': 4.875352382659912, 'max_batch': 5.012099266052246}
step: 12900 @ episode report: {'average_total_reward': 8.189, 'reward_variance': 7.663769, 'max_total_reward': 11.12, 'min_total_reward': 1.24, 'average_n_step': 9.3, 'max_n_step': 12.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3971431732177735, 'actor_loss': -4.792743158340454, 'hyper_actor_loss': 0.05071800611913204, 'behavior_loss': 0.27575094997882843, 'mean_batch': 4.95697169303894, 'min_batch': 4.867408227920532, 'max_batch': 4.987936353683471}
step: 12910 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 3.5059414, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9657416582107543, 'actor_loss': -4.80463924407959, 'hyper_actor_loss': 0.05048769973218441, 'behavior_loss': 0.2701826483011246, 'mean_batch': 4.985878992080688, 'min_batch': 4.896857976913452, 'max_batch': 5.008302354812622}
step: 12920 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 1.0130042, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.050479221343994, 'actor_loss': -4.799282121658325, 'hyper_actor_loss': 0.050292518362402915, 'behavior_loss': 0.27537331730127335, 'mean_batch': 4.958645343780518, 'min_batch': 4.8975104808807375, 'max_batch': 4.97997932434082}
step: 12930 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 2.2626207, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5148224905133247, 'actor_loss': -4.792806625366211, 'hyper_actor_loss': 0.0498668160289526, 'behavior_loss': 0.26508587449789045, 'mean_batch': 4.938052940368652, 'min_batch': 4.886198997497559, 'max_batch': 4.95694580078125}
step: 12940 @ episode report: {'average_total_reward': 9.377, 'reward_variance': 12.941103, 'max_total_reward': 14.450001, 'min_total_reward': 1.13, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8479038953781128, 'actor_loss': -4.8202471256256105, 'hyper_actor_loss': 0.04971001669764519, 'behavior_loss': 0.2836644321680069, 'mean_batch': 5.008458185195923, 'min_batch': 4.951456785202026, 'max_batch': 5.0245623111724855}
step: 12950 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 5.5829663, 'max_total_reward': 15.120001, 'min_total_reward': 5.7899995, 'average_n_step': 10.9, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8035087570548058, 'actor_loss': -4.811492156982422, 'hyper_actor_loss': 0.04980772621929645, 'behavior_loss': 0.2887778073549271, 'mean_batch': 4.994966506958008, 'min_batch': 4.921608543395996, 'max_batch': 5.015224456787109}
step: 12960 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 4.498777, 'max_total_reward': 15.120001, 'min_total_reward': 6.8999996, 'average_n_step': 10.5, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7105889558792113, 'actor_loss': -4.797317266464233, 'hyper_actor_loss': 0.04992291666567326, 'behavior_loss': 0.2688283070921898, 'mean_batch': 4.959319734573365, 'min_batch': 4.887177276611328, 'max_batch': 4.983396673202515}
step: 12970 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.9611657, 'max_total_reward': 13.450001, 'min_total_reward': 7.7899995, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8824072480201721, 'actor_loss': -4.787616348266601, 'hyper_actor_loss': 0.04986351430416107, 'behavior_loss': 0.2796775594353676, 'mean_batch': 4.93889422416687, 'min_batch': 4.859996938705445, 'max_batch': 4.963664722442627}
step: 12980 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 1.2005647, 'max_total_reward': 12.2300005, 'min_total_reward': 7.899999, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5434481501579285, 'actor_loss': -4.79314112663269, 'hyper_actor_loss': 0.049753681570291516, 'behavior_loss': 0.28061038702726365, 'mean_batch': 4.953124141693115, 'min_batch': 4.872947692871094, 'max_batch': 4.9813759326934814}
step: 12990 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 1.1629208, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6157631814479827, 'actor_loss': -4.815617656707763, 'hyper_actor_loss': 0.04959651939570904, 'behavior_loss': 0.26867995262145994, 'mean_batch': 5.015948486328125, 'min_batch': 4.921214532852173, 'max_batch': 5.0429847717285154}
step: 13000 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 2.415881, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8776080191135407, 'actor_loss': -4.824707078933716, 'hyper_actor_loss': 0.04946792125701904, 'behavior_loss': 0.2869425266981125, 'mean_batch': 5.037446355819702, 'min_batch': 4.94500732421875, 'max_batch': 5.063390302658081}
step: 13010 @ episode report: {'average_total_reward': 10.443001, 'reward_variance': 3.3245416, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6210392951965331, 'actor_loss': -4.794782447814941, 'hyper_actor_loss': 0.04946490712463856, 'behavior_loss': 0.27187861651182177, 'mean_batch': 4.958117294311523, 'min_batch': 4.876001214981079, 'max_batch': 4.991728734970093}
step: 13020 @ episode report: {'average_total_reward': 11.009001, 'reward_variance': 3.0531895, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5538271069526672, 'actor_loss': -4.820338249206543, 'hyper_actor_loss': 0.0492364663630724, 'behavior_loss': 0.2643227443099022, 'mean_batch': 5.028715658187866, 'min_batch': 4.9321990489959715, 'max_batch': 5.061354351043701}
step: 13030 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 3.9396892, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9363797307014465, 'actor_loss': -4.819680786132812, 'hyper_actor_loss': 0.04914414547383785, 'behavior_loss': 0.2844181746244431, 'mean_batch': 5.03100209236145, 'min_batch': 4.926592397689819, 'max_batch': 5.067272567749024}
step: 13040 @ episode report: {'average_total_reward': 11.142001, 'reward_variance': 3.2905579, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.924604105949402, 'actor_loss': -4.769438314437866, 'hyper_actor_loss': 0.04897732399404049, 'behavior_loss': 0.27840466350317, 'mean_batch': 4.89978666305542, 'min_batch': 4.810655832290649, 'max_batch': 4.9467504024505615}
step: 13050 @ episode report: {'average_total_reward': 11.375002, 'reward_variance': 5.320686, 'max_total_reward': 13.450001, 'min_total_reward': 7.6800003, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5357621282339096, 'actor_loss': -4.79967679977417, 'hyper_actor_loss': 0.048881614580750465, 'behavior_loss': 0.26128672510385514, 'mean_batch': 4.974902391433716, 'min_batch': 4.883950901031494, 'max_batch': 5.028497219085693}
step: 13060 @ episode report: {'average_total_reward': 11.0199995, 'reward_variance': 3.00304, 'max_total_reward': 14.34, 'min_total_reward': 8.79, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9267510175704956, 'actor_loss': -4.815145683288574, 'hyper_actor_loss': 0.04881924130022526, 'behavior_loss': 0.28893968611955645, 'mean_batch': 5.013489770889282, 'min_batch': 4.921418762207031, 'max_batch': 5.069202947616577}
step: 13070 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 3.8391843, 'max_total_reward': 14.45, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.691920244693756, 'actor_loss': -4.791842699050903, 'hyper_actor_loss': 0.04882107302546501, 'behavior_loss': 0.2635094314813614, 'mean_batch': 4.953854942321778, 'min_batch': 4.865829658508301, 'max_batch': 5.0063711643219}
step: 13080 @ episode report: {'average_total_reward': 10.332001, 'reward_variance': 3.2286162, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7579574704170227, 'actor_loss': -4.8019805431365965, 'hyper_actor_loss': 0.04860927872359753, 'behavior_loss': 0.26218678057193756, 'mean_batch': 4.980194997787476, 'min_batch': 4.889405822753906, 'max_batch': 5.023270225524902}
step: 13090 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 2.9474604, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6848132133483886, 'actor_loss': -4.806672525405884, 'hyper_actor_loss': 0.04840051457285881, 'behavior_loss': 0.2767449080944061, 'mean_batch': 4.99651951789856, 'min_batch': 4.896350383758545, 'max_batch': 5.0307567596435545}
step: 13100 @ episode report: {'average_total_reward': 9.876, 'reward_variance': 1.6678241, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7598088145256043, 'actor_loss': -4.810667610168457, 'hyper_actor_loss': 0.048295368626713756, 'behavior_loss': 0.29262751042842866, 'mean_batch': 5.002453231811524, 'min_batch': 4.910118818283081, 'max_batch': 5.034736490249633}
step: 13110 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 6.2567196, 'max_total_reward': 13.34, 'min_total_reward': 3.5700002, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.790124762058258, 'actor_loss': -4.806483316421509, 'hyper_actor_loss': 0.048501542583107946, 'behavior_loss': 0.2736332505941391, 'mean_batch': 4.98034896850586, 'min_batch': 4.911339902877808, 'max_batch': 5.008359479904175}
step: 13120 @ episode report: {'average_total_reward': 10.309001, 'reward_variance': 3.39579, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5727314233779908, 'actor_loss': -4.807052040100098, 'hyper_actor_loss': 0.048469720780849455, 'behavior_loss': 0.2817915424704552, 'mean_batch': 4.980647373199463, 'min_batch': 4.913853645324707, 'max_batch': 5.001685047149659}
step: 13130 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 2.7883687, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8079420328140259, 'actor_loss': -4.831059455871582, 'hyper_actor_loss': 0.048340845853090286, 'behavior_loss': 0.279853929579258, 'mean_batch': 5.035506772994995, 'min_batch': 4.978400468826294, 'max_batch': 5.052216529846191}
step: 13140 @ episode report: {'average_total_reward': 9.776, 'reward_variance': 3.4828033, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6031738698482514, 'actor_loss': -4.821214771270752, 'hyper_actor_loss': 0.04821038283407688, 'behavior_loss': 0.2669637858867645, 'mean_batch': 5.002667713165283, 'min_batch': 4.961982488632202, 'max_batch': 5.019143152236938}
step: 13150 @ episode report: {'average_total_reward': 9.099001, 'reward_variance': 7.11979, 'max_total_reward': 11.2300005, 'min_total_reward': 3.4600003, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.878988152742386, 'actor_loss': -4.818947982788086, 'hyper_actor_loss': 0.04806758239865303, 'behavior_loss': 0.2740452945232391, 'mean_batch': 4.996501636505127, 'min_batch': 4.956855916976929, 'max_batch': 5.007613897323608}
step: 13160 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 1.7092413, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6917329788208009, 'actor_loss': -4.801040744781494, 'hyper_actor_loss': 0.047846249863505365, 'behavior_loss': 0.2795274168252945, 'mean_batch': 4.956910562515259, 'min_batch': 4.907767295837402, 'max_batch': 4.97142333984375}
step: 13170 @ episode report: {'average_total_reward': 8.865999, 'reward_variance': 2.772724, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7420849621295929, 'actor_loss': -4.801640939712525, 'hyper_actor_loss': 0.0477977704256773, 'behavior_loss': 0.2659792691469193, 'mean_batch': 4.9582582950592045, 'min_batch': 4.909380292892456, 'max_batch': 4.97045373916626}
step: 13180 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 1.3454641, 'max_total_reward': 10.120001, 'min_total_reward': 6.7900004, 'average_n_step': 10.1, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4819637179374694, 'actor_loss': -4.841108512878418, 'hyper_actor_loss': 0.04768282882869244, 'behavior_loss': 0.29068360328674314, 'mean_batch': 5.061320352554321, 'min_batch': 5.003215885162353, 'max_batch': 5.075147342681885}
step: 13190 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 3.579202, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6312152981758117, 'actor_loss': -4.839040899276734, 'hyper_actor_loss': 0.04781100079417229, 'behavior_loss': 0.2757767140865326, 'mean_batch': 5.052077198028565, 'min_batch': 5.001938915252685, 'max_batch': 5.065586709976197}
step: 13200 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 3.49682, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6449878573417664, 'actor_loss': -4.817542314529419, 'hyper_actor_loss': 0.047840709984302524, 'behavior_loss': 0.27525078803300856, 'mean_batch': 5.001004600524903, 'min_batch': 4.945483255386352, 'max_batch': 5.017059230804444}
step: 13210 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 2.6159663, 'max_total_reward': 12.230001, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.941543698310852, 'actor_loss': -4.821863460540771, 'hyper_actor_loss': 0.047778068110346794, 'behavior_loss': 0.283241930603981, 'mean_batch': 5.014139604568482, 'min_batch': 4.953830718994141, 'max_batch': 5.0340252876281735}
step: 13220 @ episode report: {'average_total_reward': 10.687001, 'reward_variance': 0.7114013, 'max_total_reward': 12.34, 'min_total_reward': 10.009999, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.873526132106781, 'actor_loss': -4.801073598861694, 'hyper_actor_loss': 0.04777069054543972, 'behavior_loss': 0.2847792014479637, 'mean_batch': 4.9595568656921385, 'min_batch': 4.905390453338623, 'max_batch': 4.980013608932495}
step: 13230 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.7715642, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.753219223022461, 'actor_loss': -4.800521421432495, 'hyper_actor_loss': 0.04774380438029766, 'behavior_loss': 0.2815181717276573, 'mean_batch': 4.950518274307251, 'min_batch': 4.911657762527466, 'max_batch': 4.9728704452514645}
step: 13240 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 3.721316, 'max_total_reward': 12.23, 'min_total_reward': 4.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6946979761123657, 'actor_loss': -4.820127391815186, 'hyper_actor_loss': 0.04765753075480461, 'behavior_loss': 0.26594454795122147, 'mean_batch': 4.9967029094696045, 'min_batch': 4.96254153251648, 'max_batch': 5.01377305984497}
step: 13250 @ episode report: {'average_total_reward': 9.488, 'reward_variance': 4.465077, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.415000969171524, 'actor_loss': -4.848627710342408, 'hyper_actor_loss': 0.047458325326442716, 'behavior_loss': 0.2734696760773659, 'mean_batch': 5.069504976272583, 'min_batch': 5.0327740669250485, 'max_batch': 5.093298053741455}
step: 13260 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 9.150108, 'max_total_reward': 16.67, 'min_total_reward': 5.5700006, 'average_n_step': 11.1, 'max_n_step': 17.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.704826021194458, 'actor_loss': -4.849789667129516, 'hyper_actor_loss': 0.04721205085515976, 'behavior_loss': 0.2827520504593849, 'mean_batch': 5.067854881286621, 'min_batch': 5.040220832824707, 'max_batch': 5.08444561958313}
step: 13270 @ episode report: {'average_total_reward': 9.921, 'reward_variance': 5.151049, 'max_total_reward': 14.45, 'min_total_reward': 5.46, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4016253530979157, 'actor_loss': -4.840721464157104, 'hyper_actor_loss': 0.047159440070390704, 'behavior_loss': 0.27176696211099627, 'mean_batch': 5.040867137908935, 'min_batch': 5.021438503265381, 'max_batch': 5.087901449203491}
step: 13280 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 7.199656, 'max_total_reward': 14.56, 'min_total_reward': 5.7900004, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6844010710716248, 'actor_loss': -4.857246065139771, 'hyper_actor_loss': 0.04713919088244438, 'behavior_loss': 0.28490930497646333, 'mean_batch': 5.08483920097351, 'min_batch': 5.060921382904053, 'max_batch': 5.1658610820770265}
step: 13290 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 1.5210298, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6903380393981933, 'actor_loss': -4.84106411933899, 'hyper_actor_loss': 0.047136925905942914, 'behavior_loss': 0.272923119366169, 'mean_batch': 5.045927476882935, 'min_batch': 5.018060255050659, 'max_batch': 5.23311676979065}
step: 13300 @ episode report: {'average_total_reward': 8.745, 'reward_variance': 5.905886, 'max_total_reward': 13.2300005, 'min_total_reward': 5.4599996, 'average_n_step': 9.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7311492800712585, 'actor_loss': -4.833941793441772, 'hyper_actor_loss': 0.04708320200443268, 'behavior_loss': 0.2770770758390427, 'mean_batch': 5.027362632751465, 'min_batch': 5.000840759277343, 'max_batch': 5.1292030811309814}
step: 13310 @ episode report: {'average_total_reward': 9.200001, 'reward_variance': 3.7278805, 'max_total_reward': 12.12, 'min_total_reward': 5.4599996, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5019452452659607, 'actor_loss': -4.836604118347168, 'hyper_actor_loss': 0.04687248654663563, 'behavior_loss': 0.26678733229637147, 'mean_batch': 5.034950685501099, 'min_batch': 5.006680488586426, 'max_batch': 5.12049298286438}
step: 13320 @ episode report: {'average_total_reward': 9.233, 'reward_variance': 2.808101, 'max_total_reward': 12.12, 'min_total_reward': 6.6800003, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0294873118400574, 'actor_loss': -4.845970916748047, 'hyper_actor_loss': 0.04679391868412495, 'behavior_loss': 0.29665138721466067, 'mean_batch': 5.058860874176025, 'min_batch': 5.029937267303467, 'max_batch': 5.200594425201416}
step: 13330 @ episode report: {'average_total_reward': 9.066, 'reward_variance': 3.4319043, 'max_total_reward': 12.2300005, 'min_total_reward': 5.6800003, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6920881569385529, 'actor_loss': -4.7992928981781, 'hyper_actor_loss': 0.04694517776370048, 'behavior_loss': 0.2734459787607193, 'mean_batch': 4.940856981277466, 'min_batch': 4.915173101425171, 'max_batch': 5.047782373428345}
step: 13340 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.7113361, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5430887520313263, 'actor_loss': -4.826235628128051, 'hyper_actor_loss': 0.04698463603854179, 'behavior_loss': 0.2730980172753334, 'mean_batch': 5.017506647109985, 'min_batch': 4.97251877784729, 'max_batch': 5.14690146446228}
step: 13350 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 4.467917, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0336447238922117, 'actor_loss': -4.861023092269898, 'hyper_actor_loss': 0.046887040883302686, 'behavior_loss': 0.279158753156662, 'mean_batch': 5.1094671249389645, 'min_batch': 5.055679512023926, 'max_batch': 5.24866099357605}
step: 13360 @ episode report: {'average_total_reward': 8.333, 'reward_variance': 5.6325407, 'max_total_reward': 12.339999, 'min_total_reward': 4.5699997, 'average_n_step': 9.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7656179368495941, 'actor_loss': -4.808553218841553, 'hyper_actor_loss': 0.04676105566322804, 'behavior_loss': 0.25983848720788955, 'mean_batch': 4.967281341552734, 'min_batch': 4.934538173675537, 'max_batch': 5.09576735496521}
step: 13370 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 2.145449, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.709952747821808, 'actor_loss': -4.8145078182220455, 'hyper_actor_loss': 0.04650631695985794, 'behavior_loss': 0.2569172650575638, 'mean_batch': 4.988446760177612, 'min_batch': 4.943006086349487, 'max_batch': 5.114192485809326}
step: 13380 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 2.2088964, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4843677580356598, 'actor_loss': -4.848171281814575, 'hyper_actor_loss': 0.04610850252211094, 'behavior_loss': 0.2663782432675362, 'mean_batch': 5.078601551055908, 'min_batch': 5.021408033370972, 'max_batch': 5.222437238693237}
step: 13390 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 1.1748054, 'max_total_reward': 11.120001, 'min_total_reward': 7.6800003, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8633190751075746, 'actor_loss': -4.837622117996216, 'hyper_actor_loss': 0.04607721008360386, 'behavior_loss': 0.2737181067466736, 'mean_batch': 5.053927993774414, 'min_batch': 4.993091869354248, 'max_batch': 5.2258275032043455}
step: 13400 @ episode report: {'average_total_reward': 11.208, 'reward_variance': 1.9977162, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5808136940002442, 'actor_loss': -4.8197619915008545, 'hyper_actor_loss': 0.04610111564397812, 'behavior_loss': 0.25480911433696746, 'mean_batch': 5.006666803359986, 'min_batch': 4.950849628448486, 'max_batch': 5.170339727401734}
step: 13410 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 3.1904557, 'max_total_reward': 12.12, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7369694352149962, 'actor_loss': -4.856455850601196, 'hyper_actor_loss': 0.04606906212866306, 'behavior_loss': 0.2762425675988197, 'mean_batch': 5.1057757377624515, 'min_batch': 5.036211204528809, 'max_batch': 5.3098968982696535}
step: 13420 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 7.514399, 'max_total_reward': 12.2300005, 'min_total_reward': 4.57, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8802463591098786, 'actor_loss': -4.814822101593018, 'hyper_actor_loss': 0.046067637577652934, 'behavior_loss': 0.2753662928938866, 'mean_batch': 4.9927104949951175, 'min_batch': 4.940878534317017, 'max_batch': 5.1777385711669925}
step: 13430 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 1.5417643, 'max_total_reward': 10.120001, 'min_total_reward': 6.79, 'average_n_step': 9.8, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.042016386985779, 'actor_loss': -4.79316291809082, 'hyper_actor_loss': 0.04606500789523125, 'behavior_loss': 0.26817136704921724, 'mean_batch': 4.933169746398926, 'min_batch': 4.892687511444092, 'max_batch': 5.111171531677246}
step: 13440 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 2.181244, 'max_total_reward': 12.34, 'min_total_reward': 6.46, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.977640199661255, 'actor_loss': -4.819104814529419, 'hyper_actor_loss': 0.04600442163646221, 'behavior_loss': 0.26974820494651797, 'mean_batch': 4.994063854217529, 'min_batch': 4.96016001701355, 'max_batch': 5.106091690063477}
step: 13450 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 3.8431816, 'max_total_reward': 13.34, 'min_total_reward': 5.5699997, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3293189525604248, 'actor_loss': -4.832120513916015, 'hyper_actor_loss': 0.04586307480931282, 'behavior_loss': 0.26056559532880785, 'mean_batch': 5.024774837493896, 'min_batch': 4.994491863250732, 'max_batch': 5.122790718078614}
step: 13460 @ episode report: {'average_total_reward': 10.053999, 'reward_variance': 1.6715238, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9445656895637513, 'actor_loss': -4.865918159484863, 'hyper_actor_loss': 0.04545074738562107, 'behavior_loss': 0.27393627166748047, 'mean_batch': 5.11343822479248, 'min_batch': 5.076453590393067, 'max_batch': 5.215891027450562}
step: 13470 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 4.867756, 'max_total_reward': 13.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.842749685049057, 'actor_loss': -4.8202372074127195, 'hyper_actor_loss': 0.04551602266728878, 'behavior_loss': 0.27723765969276426, 'mean_batch': 4.992254686355591, 'min_batch': 4.9676038265228275, 'max_batch': 5.053279972076416}
step: 13480 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 2.7885156, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8337064325809478, 'actor_loss': -4.799951410293579, 'hyper_actor_loss': 0.04570432268083095, 'behavior_loss': 0.26679928600788116, 'mean_batch': 4.940923452377319, 'min_batch': 4.9183001041412355, 'max_batch': 5.037277412414551}
step: 13490 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 3.020805, 'max_total_reward': 13.34, 'min_total_reward': 6.9000006, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.298531985282898, 'actor_loss': -4.807513570785522, 'hyper_actor_loss': 0.04583248607814312, 'behavior_loss': 0.27780318558216094, 'mean_batch': 4.9625598907470705, 'min_batch': 4.934029150009155, 'max_batch': 5.087335777282715}
step: 13500 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 4.398782, 'max_total_reward': 13.450001, 'min_total_reward': 6.7899995, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9041765809059144, 'actor_loss': -4.782981586456299, 'hyper_actor_loss': 0.04558749385178089, 'behavior_loss': 0.2577347457408905, 'mean_batch': 4.901974725723266, 'min_batch': 4.873944664001465, 'max_batch': 5.055692052841186}
step: 13510 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 1.2710439, 'max_total_reward': 12.12, 'min_total_reward': 7.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5284998536109924, 'actor_loss': -4.819125699996948, 'hyper_actor_loss': 0.04540222212672233, 'behavior_loss': 0.27609669119119645, 'mean_batch': 4.993910884857177, 'min_batch': 4.960660219192505, 'max_batch': 5.137782287597656}
step: 13520 @ episode report: {'average_total_reward': 8.711, 'reward_variance': 3.7933693, 'max_total_reward': 11.2300005, 'min_total_reward': 4.57, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.524735677242279, 'actor_loss': -4.856555557250976, 'hyper_actor_loss': 0.04533159099519253, 'behavior_loss': 0.28096289485692977, 'mean_batch': 5.08741979598999, 'min_batch': 5.054847240447998, 'max_batch': 5.1876993656158445}
step: 13530 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 0.725004, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6801585793495177, 'actor_loss': -4.850531721115113, 'hyper_actor_loss': 0.0454148318618536, 'behavior_loss': 0.2628801763057709, 'mean_batch': 5.070594787597656, 'min_batch': 5.041264915466309, 'max_batch': 5.156858253479004}
step: 13540 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 1.6981016, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.720233792066574, 'actor_loss': -4.839279985427856, 'hyper_actor_loss': 0.04531704485416412, 'behavior_loss': 0.2807835221290588, 'mean_batch': 5.040246486663818, 'min_batch': 5.014760065078735, 'max_batch': 5.105381059646606}
step: 13550 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 0.71241605, 'max_total_reward': 11.2300005, 'min_total_reward': 8.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7587440133094787, 'actor_loss': -4.827734041213989, 'hyper_actor_loss': 0.0453074786812067, 'behavior_loss': 0.2876181975007057, 'mean_batch': 5.014685583114624, 'min_batch': 4.982505798339844, 'max_batch': 5.055287647247314}
step: 13560 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 2.338537, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7015745639801025, 'actor_loss': -4.811502122879029, 'hyper_actor_loss': 0.045492054894566536, 'behavior_loss': 0.2893486127257347, 'mean_batch': 4.968140172958374, 'min_batch': 4.948195171356201, 'max_batch': 5.005458498001099}
step: 13570 @ episode report: {'average_total_reward': 9.61, 'reward_variance': 2.54556, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6821921944618226, 'actor_loss': -4.831453418731689, 'hyper_actor_loss': 0.04540240801870823, 'behavior_loss': 0.2716318637132645, 'mean_batch': 5.022023248672485, 'min_batch': 4.993803071975708, 'max_batch': 5.065146446228027}
step: 13580 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 5.0347853, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5679157495498657, 'actor_loss': -4.850433254241944, 'hyper_actor_loss': 0.045302193611860275, 'behavior_loss': 0.27643395513296126, 'mean_batch': 5.067903995513916, 'min_batch': 5.043327188491821, 'max_batch': 5.0955006122589115}
step: 13590 @ episode report: {'average_total_reward': 10.188001, 'reward_variance': 2.5348155, 'max_total_reward': 12.339999, 'min_total_reward': 6.46, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7116111934185028, 'actor_loss': -4.851095342636109, 'hyper_actor_loss': 0.04525466375052929, 'behavior_loss': 0.2854058235883713, 'mean_batch': 5.076096248626709, 'min_batch': 5.038630104064941, 'max_batch': 5.107422924041748}
step: 13600 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 3.6247025, 'max_total_reward': 13.340001, 'min_total_reward': 7.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.848280207812786, 'actor_loss': -4.8194653511047365, 'hyper_actor_loss': 0.04519975036382675, 'behavior_loss': 0.2869580745697021, 'mean_batch': 4.988227033615113, 'min_batch': 4.967683553695679, 'max_batch': 5.008943843841553}
step: 13610 @ episode report: {'average_total_reward': 9.289, 'reward_variance': 13.422949, 'max_total_reward': 13.45, 'min_total_reward': 0.8, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6353278756141663, 'actor_loss': -4.763250780105591, 'hyper_actor_loss': 0.045369144156575204, 'behavior_loss': 0.28340933173894883, 'mean_batch': 4.8487584590911865, 'min_batch': 4.831996440887451, 'max_batch': 4.877971887588501}
step: 13620 @ episode report: {'average_total_reward': 11.286, 'reward_variance': 1.6339039, 'max_total_reward': 13.45, 'min_total_reward': 9.9, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8985383987426758, 'actor_loss': -4.752763032913208, 'hyper_actor_loss': 0.04524944461882115, 'behavior_loss': 0.28249154090881345, 'mean_batch': 4.827530384063721, 'min_batch': 4.802042675018311, 'max_batch': 4.845667362213135}
step: 13630 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.6547043, 'max_total_reward': 12.23, 'min_total_reward': 7.9000006, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8322247505187987, 'actor_loss': -4.810616397857666, 'hyper_actor_loss': 0.04509834423661232, 'behavior_loss': 0.27213298678398135, 'mean_batch': 4.9659487247467045, 'min_batch': 4.946139478683472, 'max_batch': 4.973354434967041}
step: 13640 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 0.88130075, 'max_total_reward': 11.2300005, 'min_total_reward': 8.68, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7442646890878677, 'actor_loss': -4.839675951004028, 'hyper_actor_loss': 0.04482841640710831, 'behavior_loss': 0.2749361276626587, 'mean_batch': 5.039867925643921, 'min_batch': 5.017160892486572, 'max_batch': 5.048968362808227}
step: 13650 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 3.6181006, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.034143328666687, 'actor_loss': -4.819209623336792, 'hyper_actor_loss': 0.04464865401387215, 'behavior_loss': 0.2786035746335983, 'mean_batch': 4.995553636550904, 'min_batch': 4.959305143356323, 'max_batch': 5.014238023757935}
step: 13660 @ episode report: {'average_total_reward': 9.110001, 'reward_variance': 2.7541997, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6394812226295472, 'actor_loss': -4.790733337402344, 'hyper_actor_loss': 0.0445292204618454, 'behavior_loss': 0.26295106112957, 'mean_batch': 4.9279608726501465, 'min_batch': 4.8860009670257565, 'max_batch': 4.94692907333374}
step: 13670 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 1.7580805, 'max_total_reward': 12.339999, 'min_total_reward': 7.9000006, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7622567176818849, 'actor_loss': -4.809630966186523, 'hyper_actor_loss': 0.04433777667582035, 'behavior_loss': 0.2706189826130867, 'mean_batch': 4.978334951400757, 'min_batch': 4.928911638259888, 'max_batch': 5.002854204177856}
step: 13680 @ episode report: {'average_total_reward': 9.877001, 'reward_variance': 2.4353015, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3584181249141694, 'actor_loss': -4.848009347915649, 'hyper_actor_loss': 0.04433945566415787, 'behavior_loss': 0.269565224647522, 'mean_batch': 5.076169633865357, 'min_batch': 5.023163938522339, 'max_batch': 5.092307662963867}
step: 13690 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 4.061141, 'max_total_reward': 13.450001, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8629709601402282, 'actor_loss': -4.833329725265503, 'hyper_actor_loss': 0.04417797662317753, 'behavior_loss': 0.27259382605552673, 'mean_batch': 5.044813394546509, 'min_batch': 4.980962228775025, 'max_batch': 5.06774525642395}
step: 13700 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 1.9249363, 'max_total_reward': 12.2300005, 'min_total_reward': 7.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.403197306394577, 'actor_loss': -4.820047378540039, 'hyper_actor_loss': 0.044253745675086976, 'behavior_loss': 0.26083541959524154, 'mean_batch': 5.001828002929687, 'min_batch': 4.957251167297363, 'max_batch': 5.020067882537842}
step: 13710 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 1.9768757, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8921709656715393, 'actor_loss': -4.83952784538269, 'hyper_actor_loss': 0.04404471665620804, 'behavior_loss': 0.27320663779973986, 'mean_batch': 5.055235242843628, 'min_batch': 5.001269578933716, 'max_batch': 5.091773271560669}
step: 13720 @ episode report: {'average_total_reward': 9.089, 'reward_variance': 1.7340088, 'max_total_reward': 11.01, 'min_total_reward': 6.7900004, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8439046263694763, 'actor_loss': -4.801062393188476, 'hyper_actor_loss': 0.043967364728450774, 'behavior_loss': 0.2679433077573776, 'mean_batch': 4.966736555099487, 'min_batch': 4.898413801193238, 'max_batch': 5.025331354141235}
step: 13730 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 5.4610696, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9428946018218993, 'actor_loss': -4.773628377914429, 'hyper_actor_loss': 0.04400335922837258, 'behavior_loss': 0.2906265914440155, 'mean_batch': 4.8940473079681395, 'min_batch': 4.83649845123291, 'max_batch': 4.96401162147522}
step: 13740 @ episode report: {'average_total_reward': 8.8550005, 'reward_variance': 5.556946, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 9.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6322498738765716, 'actor_loss': -4.811658906936645, 'hyper_actor_loss': 0.04399724416434765, 'behavior_loss': 0.27003915011882784, 'mean_batch': 4.987199878692627, 'min_batch': 4.930461311340332, 'max_batch': 5.048479986190796}
step: 13750 @ episode report: {'average_total_reward': 8.766001, 'reward_variance': 1.894664, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.703154242038727, 'actor_loss': -4.830726385116577, 'hyper_actor_loss': 0.04394167624413967, 'behavior_loss': 0.28463665395975113, 'mean_batch': 5.043004131317138, 'min_batch': 4.969485473632813, 'max_batch': 5.126144123077393}
step: 13760 @ episode report: {'average_total_reward': 9.733, 'reward_variance': 1.9176209, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7786218106746674, 'actor_loss': -4.82832899093628, 'hyper_actor_loss': 0.04400980286300182, 'behavior_loss': 0.28890745639801024, 'mean_batch': 5.027429580688477, 'min_batch': 4.972789001464844, 'max_batch': 5.099254560470581}
step: 13770 @ episode report: {'average_total_reward': 9.155001, 'reward_variance': 1.3511251, 'max_total_reward': 11.120001, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8078094840049743, 'actor_loss': -4.798666095733642, 'hyper_actor_loss': 0.044209830835461615, 'behavior_loss': 0.28332151770591735, 'mean_batch': 4.956969738006592, 'min_batch': 4.89623327255249, 'max_batch': 5.032854080200195}
step: 13780 @ episode report: {'average_total_reward': 9.321, 'reward_variance': 9.770669, 'max_total_reward': 14.45, 'min_total_reward': 4.57, 'average_n_step': 10.3, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7137512683868408, 'actor_loss': -4.803386878967285, 'hyper_actor_loss': 0.04407816901803017, 'behavior_loss': 0.2610266372561455, 'mean_batch': 4.962872076034546, 'min_batch': 4.91350622177124, 'max_batch': 5.031206321716309}
step: 13790 @ episode report: {'average_total_reward': 9.454, 'reward_variance': 1.7278042, 'max_total_reward': 11.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8289007365703582, 'actor_loss': -4.826322937011719, 'hyper_actor_loss': 0.0437747847288847, 'behavior_loss': 0.2751786306500435, 'mean_batch': 5.021223640441894, 'min_batch': 4.968991470336914, 'max_batch': 5.076620960235596}
step: 13800 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 7.1572638, 'max_total_reward': 14.450001, 'min_total_reward': 4.68, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1655393958091738, 'actor_loss': -4.81346025466919, 'hyper_actor_loss': 0.04364391565322876, 'behavior_loss': 0.280837282538414, 'mean_batch': 4.986419725418091, 'min_batch': 4.93990740776062, 'max_batch': 5.03356614112854}
step: 13810 @ episode report: {'average_total_reward': 8.7, 'reward_variance': 4.822401, 'max_total_reward': 12.2300005, 'min_total_reward': 4.46, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5278838634490968, 'actor_loss': -4.770231056213379, 'hyper_actor_loss': 0.04333273880183697, 'behavior_loss': 0.26585339605808256, 'mean_batch': 4.883510541915894, 'min_batch': 4.8305267810821535, 'max_batch': 4.926315689086914}
step: 13820 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 2.418385, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5824257493019105, 'actor_loss': -4.828002023696899, 'hyper_actor_loss': 0.04325070753693581, 'behavior_loss': 0.28408548831939695, 'mean_batch': 5.017990159988403, 'min_batch': 4.980900478363037, 'max_batch': 5.073946142196656}
step: 13830 @ episode report: {'average_total_reward': 10.098, 'reward_variance': 5.254655, 'max_total_reward': 14.45, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5827678978443145, 'actor_loss': -4.861701822280883, 'hyper_actor_loss': 0.04325701966881752, 'behavior_loss': 0.27505575567483903, 'mean_batch': 5.097623491287232, 'min_batch': 5.070768642425537, 'max_batch': 5.136842393875122}
step: 13840 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 3.6493962, 'max_total_reward': 14.45, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8931166172027587, 'actor_loss': -4.818184471130371, 'hyper_actor_loss': 0.04313935786485672, 'behavior_loss': 0.26896305084228517, 'mean_batch': 4.995612001419067, 'min_batch': 4.954587459564209, 'max_batch': 5.028119611740112}
step: 13850 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.5802248, 'max_total_reward': 12.340001, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7251591324806212, 'actor_loss': -4.7870019435882565, 'hyper_actor_loss': 0.04317331984639168, 'behavior_loss': 0.27871211618185043, 'mean_batch': 4.923077821731567, 'min_batch': 4.872694253921509, 'max_batch': 4.9762224674224855}
step: 13860 @ episode report: {'average_total_reward': 9.332001, 'reward_variance': 4.385456, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4538235127925874, 'actor_loss': -4.837474393844604, 'hyper_actor_loss': 0.042977190017700194, 'behavior_loss': 0.27085288912057875, 'mean_batch': 5.043561553955078, 'min_batch': 5.002875232696534, 'max_batch': 5.089918613433838}
step: 13870 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 3.1737897, 'max_total_reward': 12.23, 'min_total_reward': 5.5699997, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3994668185710908, 'actor_loss': -4.866640233993531, 'hyper_actor_loss': 0.04292150363326073, 'behavior_loss': 0.27433679401874544, 'mean_batch': 5.111722755432129, 'min_batch': 5.08178596496582, 'max_batch': 5.145035934448242}
step: 13880 @ episode report: {'average_total_reward': 9.91, 'reward_variance': 1.6246202, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.741250079870224, 'actor_loss': -4.859002208709716, 'hyper_actor_loss': 0.04278936460614204, 'behavior_loss': 0.2673305690288544, 'mean_batch': 5.098612928390503, 'min_batch': 5.056219625473022, 'max_batch': 5.137171268463135}
step: 13890 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 2.8215647, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5424236208200455, 'actor_loss': -4.8210777759552, 'hyper_actor_loss': 0.04275972954928875, 'behavior_loss': 0.2758705049753189, 'mean_batch': 4.998222970962525, 'min_batch': 4.965742731094361, 'max_batch': 5.049958419799805}
step: 13900 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 1.333804, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.2971198379993438, 'actor_loss': -4.859949588775635, 'hyper_actor_loss': 0.04268584698438645, 'behavior_loss': 0.28783208429813384, 'mean_batch': 5.095271968841553, 'min_batch': 5.064713382720948, 'max_batch': 5.141903114318848}
step: 13910 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 1.9225166, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9183681309223175, 'actor_loss': -4.8716836929321286, 'hyper_actor_loss': 0.0428047176450491, 'behavior_loss': 0.26355787813663484, 'mean_batch': 5.12625904083252, 'min_batch': 5.093407535552979, 'max_batch': 5.183939838409424}
step: 13920 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 0.7268561, 'max_total_reward': 11.120001, 'min_total_reward': 7.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6188915073871613, 'actor_loss': -4.817628240585327, 'hyper_actor_loss': 0.04257575571537018, 'behavior_loss': 0.2605437472462654, 'mean_batch': 4.99470853805542, 'min_batch': 4.95213565826416, 'max_batch': 5.05236439704895}
step: 13930 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 1.8334639, 'max_total_reward': 11.120001, 'min_total_reward': 7.6800003, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6804596543312074, 'actor_loss': -4.829798650741577, 'hyper_actor_loss': 0.04235476516187191, 'behavior_loss': 0.2695790022611618, 'mean_batch': 5.0167640209197994, 'min_batch': 4.990696668624878, 'max_batch': 5.067771148681641}
step: 13940 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.0070646, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8081612586975098, 'actor_loss': -4.847084474563599, 'hyper_actor_loss': 0.04218230694532395, 'behavior_loss': 0.27601422518491747, 'mean_batch': 5.059148836135864, 'min_batch': 5.035163545608521, 'max_batch': 5.092761850357055}
step: 13950 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 4.760757, 'max_total_reward': 14.450001, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8769726037979126, 'actor_loss': -4.826639842987061, 'hyper_actor_loss': 0.0421674158424139, 'behavior_loss': 0.2700716003775597, 'mean_batch': 5.017230606079101, 'min_batch': 4.974783229827881, 'max_batch': 5.040685987472534}
step: 13960 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 5.0658703, 'max_total_reward': 12.340001, 'min_total_reward': 5.6800003, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7010682940483093, 'actor_loss': -4.813199615478515, 'hyper_actor_loss': 0.04206562340259552, 'behavior_loss': 0.27932682633399963, 'mean_batch': 4.983300065994262, 'min_batch': 4.941582155227661, 'max_batch': 5.005062770843506}
step: 13970 @ episode report: {'average_total_reward': 10.154, 'reward_variance': 6.6567025, 'max_total_reward': 16.779999, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3710826873779296, 'actor_loss': -4.8416736125946045, 'hyper_actor_loss': 0.04203024767339229, 'behavior_loss': 0.27280132174491883, 'mean_batch': 5.068320083618164, 'min_batch': 4.999317932128906, 'max_batch': 5.08504729270935}
step: 13980 @ episode report: {'average_total_reward': 9.776001, 'reward_variance': 2.3506045, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6400709867477417, 'actor_loss': -4.866229057312012, 'hyper_actor_loss': 0.04198281541466713, 'behavior_loss': 0.272673898935318, 'mean_batch': 5.1461433410644535, 'min_batch': 5.045762729644776, 'max_batch': 5.167084980010986}
step: 13990 @ episode report: {'average_total_reward': 9.443999, 'reward_variance': 0.60910404, 'max_total_reward': 11.2300005, 'min_total_reward': 8.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8657218992710114, 'actor_loss': -4.8256877899169925, 'hyper_actor_loss': 0.041942496225237845, 'behavior_loss': 0.26191727817058563, 'mean_batch': 5.041386461257934, 'min_batch': 4.946500301361084, 'max_batch': 5.0656835556030275}
step: 14000 @ episode report: {'average_total_reward': 8.644, 'reward_variance': 2.3131843, 'max_total_reward': 11.2300005, 'min_total_reward': 5.46, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8199771642684937, 'actor_loss': -4.808951377868652, 'hyper_actor_loss': 0.0418206088244915, 'behavior_loss': 0.2645225524902344, 'mean_batch': 5.00643892288208, 'min_batch': 4.897909784317017, 'max_batch': 5.035689783096314}
step: 14010 @ episode report: {'average_total_reward': 8.7, 'reward_variance': 5.3200803, 'max_total_reward': 13.34, 'min_total_reward': 5.46, 'average_n_step': 9.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7276766061782838, 'actor_loss': -4.813293409347534, 'hyper_actor_loss': 0.04157919660210609, 'behavior_loss': 0.27925333827733995, 'mean_batch': 5.023797273635864, 'min_batch': 4.902236127853394, 'max_batch': 5.054019784927368}
step: 14020 @ episode report: {'average_total_reward': 9.654, 'reward_variance': 4.9405036, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7486503958702087, 'actor_loss': -4.821005964279175, 'hyper_actor_loss': 0.041665710136294366, 'behavior_loss': 0.25879888236522675, 'mean_batch': 5.040498208999634, 'min_batch': 4.92372145652771, 'max_batch': 5.066907167434692}
step: 14030 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 2.4690409, 'max_total_reward': 12.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4348218500614167, 'actor_loss': -4.836575078964233, 'hyper_actor_loss': 0.04141381829977035, 'behavior_loss': 0.27077856212854384, 'mean_batch': 5.076755619049072, 'min_batch': 4.965338706970215, 'max_batch': 5.102642393112182}
step: 14040 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 3.098864, 'max_total_reward': 12.339999, 'min_total_reward': 6.5699997, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7962020277976989, 'actor_loss': -4.852773857116699, 'hyper_actor_loss': 0.041390009224414825, 'behavior_loss': 0.26769639551639557, 'mean_batch': 5.109051942825317, 'min_batch': 5.014479732513427, 'max_batch': 5.132812118530273}
step: 14050 @ episode report: {'average_total_reward': 9.254999, 'reward_variance': 5.4325237, 'max_total_reward': 12.339999, 'min_total_reward': 5.5700006, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.73351331949234, 'actor_loss': -4.824729251861572, 'hyper_actor_loss': 0.04142768643796444, 'behavior_loss': 0.2830214902758598, 'mean_batch': 5.033941745758057, 'min_batch': 4.948575830459594, 'max_batch': 5.06464409828186}
step: 14060 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 3.1926448, 'max_total_reward': 12.120001, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1924744844436646, 'actor_loss': -4.809633827209472, 'hyper_actor_loss': 0.041448811814188954, 'behavior_loss': 0.2710710033774376, 'mean_batch': 4.9963761329650875, 'min_batch': 4.911099004745483, 'max_batch': 5.018404102325439}
step: 14070 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 6.596904, 'max_total_reward': 12.2300005, 'min_total_reward': 4.57, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.770930862426758, 'actor_loss': -4.784189987182617, 'hyper_actor_loss': 0.041432496160268784, 'behavior_loss': 0.26328642964363097, 'mean_batch': 4.925726318359375, 'min_batch': 4.856393051147461, 'max_batch': 4.946802568435669}
step: 14080 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 3.5506196, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.936587119102478, 'actor_loss': -4.826634454727173, 'hyper_actor_loss': 0.04116024412214756, 'behavior_loss': 0.274821312725544, 'mean_batch': 5.031130313873291, 'min_batch': 4.960894250869751, 'max_batch': 5.06226921081543}
step: 14090 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 2.973545, 'max_total_reward': 14.34, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5435007214546204, 'actor_loss': -4.823548460006714, 'hyper_actor_loss': 0.04111255146563053, 'behavior_loss': 0.28448988050222396, 'mean_batch': 5.027888250350952, 'min_batch': 4.948692893981933, 'max_batch': 5.046512460708618}
step: 14100 @ episode report: {'average_total_reward': 9.221, 'reward_variance': 6.31961, 'max_total_reward': 13.45, 'min_total_reward': 5.57, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7040268182754517, 'actor_loss': -4.835026645660401, 'hyper_actor_loss': 0.04118643142282963, 'behavior_loss': 0.280294705927372, 'mean_batch': 5.05321946144104, 'min_batch': 4.9806983947753904, 'max_batch': 5.079228925704956}
step: 14110 @ episode report: {'average_total_reward': 10.875, 'reward_variance': 1.2561252, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.04688378572464, 'actor_loss': -4.815199947357177, 'hyper_actor_loss': 0.04119404479861259, 'behavior_loss': 0.27669286727905273, 'mean_batch': 5.009615039825439, 'min_batch': 4.925805187225341, 'max_batch': 5.031740713119507}
step: 14120 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 10.923394, 'max_total_reward': 13.34, 'min_total_reward': 1.3500001, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2330785393714905, 'actor_loss': -4.776929140090942, 'hyper_actor_loss': 0.04117528349161148, 'behavior_loss': 0.2753487914800644, 'mean_batch': 4.9188316822052, 'min_batch': 4.828038358688355, 'max_batch': 4.946992063522339}
step: 14130 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 4.7188206, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.792210304737091, 'actor_loss': -4.771641254425049, 'hyper_actor_loss': 0.04101148769259453, 'behavior_loss': 0.25919404327869416, 'mean_batch': 4.907884025573731, 'min_batch': 4.813439893722534, 'max_batch': 4.94557638168335}
step: 14140 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.3263054, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6945327520370483, 'actor_loss': -4.81332483291626, 'hyper_actor_loss': 0.0409240547567606, 'behavior_loss': 0.2743980139493942, 'mean_batch': 5.014881610870361, 'min_batch': 4.911226844787597, 'max_batch': 5.050196647644043}
step: 14150 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 2.3250613, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7760241031646729, 'actor_loss': -4.835399770736695, 'hyper_actor_loss': 0.040794241800904275, 'behavior_loss': 0.2685045003890991, 'mean_batch': 5.061252307891846, 'min_batch': 4.974694633483887, 'max_batch': 5.086596345901489}
step: 14160 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 1.9341358, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6093022346496582, 'actor_loss': -4.82618670463562, 'hyper_actor_loss': 0.04066094495356083, 'behavior_loss': 0.2759919509291649, 'mean_batch': 5.028899383544922, 'min_batch': 4.960749721527099, 'max_batch': 5.07527494430542}
step: 14170 @ episode report: {'average_total_reward': 9.3220005, 'reward_variance': 4.4988365, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3349738717079163, 'actor_loss': -4.8458263874053955, 'hyper_actor_loss': 0.040555433556437495, 'behavior_loss': 0.2775037497282028, 'mean_batch': 5.081292629241943, 'min_batch': 5.007130336761475, 'max_batch': 5.104682064056396}
step: 14180 @ episode report: {'average_total_reward': 8.665999, 'reward_variance': 2.5506034, 'max_total_reward': 11.12, 'min_total_reward': 6.7900004, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8677035748958588, 'actor_loss': -4.869761323928833, 'hyper_actor_loss': 0.04069909602403641, 'behavior_loss': 0.2741414785385132, 'mean_batch': 5.134540033340454, 'min_batch': 5.075372838973999, 'max_batch': 5.174137735366822}
step: 14190 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 2.6454968, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9803289651870728, 'actor_loss': -4.79431300163269, 'hyper_actor_loss': 0.04071793220937252, 'behavior_loss': 0.282789109647274, 'mean_batch': 4.940728378295899, 'min_batch': 4.891214895248413, 'max_batch': 4.975129270553589}
step: 14200 @ episode report: {'average_total_reward': 8.766, 'reward_variance': 6.5009637, 'max_total_reward': 12.34, 'min_total_reward': 2.46, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9161967992782594, 'actor_loss': -4.771477699279785, 'hyper_actor_loss': 0.04085562601685524, 'behavior_loss': 0.28124109357595445, 'mean_batch': 4.895452165603638, 'min_batch': 4.82462511062622, 'max_batch': 4.91668553352356}
step: 14210 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 6.470084, 'max_total_reward': 12.2300005, 'min_total_reward': 2.46, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.790218758583069, 'actor_loss': -4.811107730865478, 'hyper_actor_loss': 0.040686576440930364, 'behavior_loss': 0.2662219166755676, 'mean_batch': 5.000149393081665, 'min_batch': 4.914817953109742, 'max_batch': 5.021726512908936}
step: 14220 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 5.0152664, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5317557096481322, 'actor_loss': -4.826697492599488, 'hyper_actor_loss': 0.040559801086783406, 'behavior_loss': 0.2862431824207306, 'mean_batch': 5.046888828277588, 'min_batch': 4.9456400871276855, 'max_batch': 5.07101001739502}
step: 14230 @ episode report: {'average_total_reward': 10.975, 'reward_variance': 5.3866854, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9965522050857545, 'actor_loss': -4.813689756393432, 'hyper_actor_loss': 0.04054584950208664, 'behavior_loss': 0.28013656586408614, 'mean_batch': 5.020129203796387, 'min_batch': 4.9077705383300785, 'max_batch': 5.051687812805175}
step: 14240 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 3.0058246, 'max_total_reward': 12.12, 'min_total_reward': 5.7899995, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.691640704870224, 'actor_loss': -4.7832941055297855, 'hyper_actor_loss': 0.040502201020717624, 'behavior_loss': 0.2901483491063118, 'mean_batch': 4.939156770706177, 'min_batch': 4.8388285636901855, 'max_batch': 5.000817155838012}
step: 14250 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 7.264035, 'max_total_reward': 14.34, 'min_total_reward': 4.46, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.691364985704422, 'actor_loss': -4.828432035446167, 'hyper_actor_loss': 0.04065584503114224, 'behavior_loss': 0.28782539665699003, 'mean_batch': 5.038225412368774, 'min_batch': 4.962913656234742, 'max_batch': 5.063095617294311}
step: 14260 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 4.000425, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7534851729869843, 'actor_loss': -4.85122241973877, 'hyper_actor_loss': 0.040629060193896296, 'behavior_loss': 0.27798532843589785, 'mean_batch': 5.090032052993775, 'min_batch': 5.025464916229248, 'max_batch': 5.111075210571289}
step: 14270 @ episode report: {'average_total_reward': 9.91, 'reward_variance': 4.01314, 'max_total_reward': 13.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6801213383674622, 'actor_loss': -4.815710592269897, 'hyper_actor_loss': 0.04063844159245491, 'behavior_loss': 0.2758891522884369, 'mean_batch': 5.003862810134888, 'min_batch': 4.933644437789917, 'max_batch': 5.030417203903198}
step: 14280 @ episode report: {'average_total_reward': 8.666, 'reward_variance': 3.421444, 'max_total_reward': 11.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3723573297262193, 'actor_loss': -4.821518039703369, 'hyper_actor_loss': 0.04054656550288201, 'behavior_loss': 0.27149265855550764, 'mean_batch': 5.025497150421143, 'min_batch': 4.941055250167847, 'max_batch': 5.044441509246826}
step: 14290 @ episode report: {'average_total_reward': 9.110001, 'reward_variance': 2.4589398, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6444322347640992, 'actor_loss': -4.859614849090576, 'hyper_actor_loss': 0.040308327227830884, 'behavior_loss': 0.2799114868044853, 'mean_batch': 5.11806583404541, 'min_batch': 5.040135526657105, 'max_batch': 5.13450927734375}
step: 14300 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 1.8554637, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8477115988731385, 'actor_loss': -4.837954664230347, 'hyper_actor_loss': 0.04020000733435154, 'behavior_loss': 0.2648224368691444, 'mean_batch': 5.05957064628601, 'min_batch': 4.989143562316895, 'max_batch': 5.072770881652832}
step: 14310 @ episode report: {'average_total_reward': 8.211, 'reward_variance': 4.40331, 'max_total_reward': 12.34, 'min_total_reward': 4.46, 'average_n_step': 9.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9190627217292786, 'actor_loss': -4.805891227722168, 'hyper_actor_loss': 0.03997192233800888, 'behavior_loss': 0.274173891544342, 'mean_batch': 4.969744491577148, 'min_batch': 4.918997383117675, 'max_batch': 4.981016969680786}
step: 14320 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.4729657, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.743967056274414, 'actor_loss': -4.807333898544312, 'hyper_actor_loss': 0.0398517120629549, 'behavior_loss': 0.26109917610883715, 'mean_batch': 4.978745365142823, 'min_batch': 4.917223215103149, 'max_batch': 4.992058563232422}
step: 14330 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 1.3028561, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7383379936218262, 'actor_loss': -4.822754430770874, 'hyper_actor_loss': 0.0396323598921299, 'behavior_loss': 0.2622081130743027, 'mean_batch': 5.018977546691895, 'min_batch': 4.953614807128906, 'max_batch': 5.034740304946899}
step: 14340 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 0.49732894, 'max_total_reward': 10.12, 'min_total_reward': 7.9, 'average_n_step': 10.3, 'max_n_step': 11.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7654300451278686, 'actor_loss': -4.841657495498657, 'hyper_actor_loss': 0.03954911567270756, 'behavior_loss': 0.29745742231607436, 'mean_batch': 5.059679746627808, 'min_batch': 5.007493734359741, 'max_batch': 5.078168773651123}
step: 14350 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 2.938136, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7269848465919495, 'actor_loss': -4.822775077819824, 'hyper_actor_loss': 0.03979315012693405, 'behavior_loss': 0.27867598831653595, 'mean_batch': 5.00614447593689, 'min_batch': 4.966374921798706, 'max_batch': 5.026450729370117}
step: 14360 @ episode report: {'average_total_reward': 10.110001, 'reward_variance': 2.7198796, 'max_total_reward': 13.23, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0730931758880615, 'actor_loss': -4.812176990509033, 'hyper_actor_loss': 0.03991665728390217, 'behavior_loss': 0.27790302187204363, 'mean_batch': 4.978472661972046, 'min_batch': 4.941320133209229, 'max_batch': 5.0182451725006105}
step: 14370 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 2.1593604, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.028639626502991, 'actor_loss': -4.790092325210571, 'hyper_actor_loss': 0.03984721302986145, 'behavior_loss': 0.28423072546720507, 'mean_batch': 4.9224272727966305, 'min_batch': 4.888332986831665, 'max_batch': 4.979547214508057}
step: 14380 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 2.3568244, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.615090972185135, 'actor_loss': -4.799374294281006, 'hyper_actor_loss': 0.03981351666152477, 'behavior_loss': 0.2738999009132385, 'mean_batch': 4.951253414154053, 'min_batch': 4.905351972579956, 'max_batch': 5.0208343982696535}
step: 14390 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 2.5721564, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7616640985012055, 'actor_loss': -4.84906849861145, 'hyper_actor_loss': 0.03970584571361542, 'behavior_loss': 0.279401122033596, 'mean_batch': 5.076848125457763, 'min_batch': 5.027681446075439, 'max_batch': 5.1472993850708}
step: 14400 @ episode report: {'average_total_reward': 8.877001, 'reward_variance': 2.6036212, 'max_total_reward': 11.120001, 'min_total_reward': 6.79, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7142880976200103, 'actor_loss': -4.823042488098144, 'hyper_actor_loss': 0.039512410014867785, 'behavior_loss': 0.2724990248680115, 'mean_batch': 5.0086822509765625, 'min_batch': 4.965245389938355, 'max_batch': 5.0782026767730715}
step: 14410 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 2.8736863, 'max_total_reward': 12.340001, 'min_total_reward': 7.4599996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7595012664794922, 'actor_loss': -4.822132301330567, 'hyper_actor_loss': 0.039378955215215686, 'behavior_loss': 0.28542656600475313, 'mean_batch': 5.003267621994018, 'min_batch': 4.966012668609619, 'max_batch': 5.073919010162354}
step: 14420 @ episode report: {'average_total_reward': 9.222, 'reward_variance': 3.6239758, 'max_total_reward': 12.23, 'min_total_reward': 5.57, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7660982012748718, 'actor_loss': -4.820487976074219, 'hyper_actor_loss': 0.03932478427886963, 'behavior_loss': 0.2719715878367424, 'mean_batch': 4.995991897583008, 'min_batch': 4.965024995803833, 'max_batch': 5.054501724243164}
step: 14430 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 4.1263704, 'max_total_reward': 13.450001, 'min_total_reward': 6.68, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7888369485735893, 'actor_loss': -4.82851881980896, 'hyper_actor_loss': 0.039394669607281683, 'behavior_loss': 0.2612584367394447, 'mean_batch': 5.016699504852295, 'min_batch': 4.984385538101196, 'max_batch': 5.068778800964355}
step: 14440 @ episode report: {'average_total_reward': 9.632, 'reward_variance': 2.923736, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5979438126087189, 'actor_loss': -4.828539705276489, 'hyper_actor_loss': 0.03914290517568588, 'behavior_loss': 0.295529218018055, 'mean_batch': 5.018330049514771, 'min_batch': 4.982879781723023, 'max_batch': 5.072072315216064}
step: 14450 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 1.6780365, 'max_total_reward': 11.230001, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3248321890830994, 'actor_loss': -4.852178621292114, 'hyper_actor_loss': 0.03921779505908489, 'behavior_loss': 0.27482493668794633, 'mean_batch': 5.081376838684082, 'min_batch': 5.038830041885376, 'max_batch': 5.164234972000122}
step: 14460 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 1.4946198, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5593926668167115, 'actor_loss': -4.865688228607178, 'hyper_actor_loss': 0.03916378542780876, 'behavior_loss': 0.26336232125759124, 'mean_batch': 5.117821788787841, 'min_batch': 5.070936107635498, 'max_batch': 5.195836687088013}
step: 14470 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 3.4619842, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8830195248126984, 'actor_loss': -4.84485936164856, 'hyper_actor_loss': 0.03888596259057522, 'behavior_loss': 0.26562387496232986, 'mean_batch': 5.062547302246093, 'min_batch': 5.020736646652222, 'max_batch': 5.151650524139404}
step: 14480 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 3.0304446, 'max_total_reward': 12.2300005, 'min_total_reward': 6.4599996, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.102145028114319, 'actor_loss': -4.800881481170654, 'hyper_actor_loss': 0.03874046355485916, 'behavior_loss': 0.2861080914735794, 'mean_batch': 4.9504358768463135, 'min_batch': 4.913606977462768, 'max_batch': 5.069704866409301}
step: 14490 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 7.860261, 'max_total_reward': 11.2300005, 'min_total_reward': 1.1300001, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8138221979141236, 'actor_loss': -4.775455617904663, 'hyper_actor_loss': 0.03876231722533703, 'behavior_loss': 0.28897920846939085, 'mean_batch': 4.884133338928223, 'min_batch': 4.8551342487335205, 'max_batch': 4.996586275100708}
step: 14500 @ episode report: {'average_total_reward': 9.365999, 'reward_variance': 4.4597645, 'max_total_reward': 12.34, 'min_total_reward': 6.46, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.1991716384887696, 'actor_loss': -4.83787317276001, 'hyper_actor_loss': 0.03889772966504097, 'behavior_loss': 0.2681880533695221, 'mean_batch': 5.045722341537475, 'min_batch': 5.003442096710205, 'max_batch': 5.205788087844849}
step: 14510 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 5.297996, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5433257460594176, 'actor_loss': -4.89305272102356, 'hyper_actor_loss': 0.03892141729593277, 'behavior_loss': 0.2916000083088875, 'mean_batch': 5.185910892486572, 'min_batch': 5.143194389343262, 'max_batch': 5.315920162200928}
step: 14520 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 5.675925, 'max_total_reward': 14.2300005, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5720312356948853, 'actor_loss': -4.863985157012939, 'hyper_actor_loss': 0.03883595690131188, 'behavior_loss': 0.2747603476047516, 'mean_batch': 5.100228548049927, 'min_batch': 5.0799314975738525, 'max_batch': 5.193745088577271}
step: 14530 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 2.908729, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3509007334709167, 'actor_loss': -4.859123277664184, 'hyper_actor_loss': 0.038657587766647336, 'behavior_loss': 0.2487498104572296, 'mean_batch': 5.086107206344605, 'min_batch': 5.069249248504638, 'max_batch': 5.154013347625733}
step: 14540 @ episode report: {'average_total_reward': 8.688001, 'reward_variance': 5.5781956, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 9.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6686898589134216, 'actor_loss': -4.869854974746704, 'hyper_actor_loss': 0.03836082890629768, 'behavior_loss': 0.26602431386709213, 'mean_batch': 5.115609216690063, 'min_batch': 5.094291019439697, 'max_batch': 5.184072875976563}
step: 14550 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 1.0325695, 'max_total_reward': 12.34, 'min_total_reward': 8.68, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.594214963912964, 'actor_loss': -4.863489198684692, 'hyper_actor_loss': 0.03805586472153664, 'behavior_loss': 0.2684353217482567, 'mean_batch': 5.09992151260376, 'min_batch': 5.077528381347657, 'max_batch': 5.15693039894104}
step: 14560 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 2.6628559, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4758143484592439, 'actor_loss': -4.86110143661499, 'hyper_actor_loss': 0.03805265203118324, 'behavior_loss': 0.2849322497844696, 'mean_batch': 5.09152455329895, 'min_batch': 5.0737780094146725, 'max_batch': 5.105241155624389}
step: 14570 @ episode report: {'average_total_reward': 9.221001, 'reward_variance': 3.9088893, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.86459721326828, 'actor_loss': -4.859982013702393, 'hyper_actor_loss': 0.03820765316486359, 'behavior_loss': 0.2726369798183441, 'mean_batch': 5.094433784484863, 'min_batch': 5.065243482589722, 'max_batch': 5.099483251571655}
step: 14580 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 1.8898243, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.587051111459732, 'actor_loss': -4.850524950027466, 'hyper_actor_loss': 0.038276014104485515, 'behavior_loss': 0.27865623533725736, 'mean_batch': 5.06300106048584, 'min_batch': 5.048678731918335, 'max_batch': 5.072389459609985}
step: 14590 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 6.392464, 'max_total_reward': 12.34, 'min_total_reward': 2.13, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6269507884979248, 'actor_loss': -4.861084794998169, 'hyper_actor_loss': 0.03835743740200996, 'behavior_loss': 0.26033575385808944, 'mean_batch': 5.091659736633301, 'min_batch': 5.073597717285156, 'max_batch': 5.1069082736969}
step: 14600 @ episode report: {'average_total_reward': 10.309001, 'reward_variance': 5.2184095, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7012781739234923, 'actor_loss': -4.867282056808472, 'hyper_actor_loss': 0.038153549283742906, 'behavior_loss': 0.28531250506639483, 'mean_batch': 5.108538103103638, 'min_batch': 5.088251256942749, 'max_batch': 5.124676275253296}
step: 14610 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 3.1529207, 'max_total_reward': 12.34, 'min_total_reward': 6.57, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5749661326408386, 'actor_loss': -4.847920656204224, 'hyper_actor_loss': 0.03813380189239979, 'behavior_loss': 0.2731824189424515, 'mean_batch': 5.05993332862854, 'min_batch': 5.038603925704956, 'max_batch': 5.083176469802856}
step: 14620 @ episode report: {'average_total_reward': 11.1310005, 'reward_variance': 3.2677093, 'max_total_reward': 13.23, 'min_total_reward': 6.7899995, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9220460891723632, 'actor_loss': -4.848067140579223, 'hyper_actor_loss': 0.037992486357688905, 'behavior_loss': 0.29737233817577363, 'mean_batch': 5.06009259223938, 'min_batch': 5.039229011535644, 'max_batch': 5.085365533828735}
step: 14630 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.520261, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6785428643226623, 'actor_loss': -4.8335765361785885, 'hyper_actor_loss': 0.03813992366194725, 'behavior_loss': 0.26770189255475996, 'mean_batch': 5.022234630584717, 'min_batch': 5.004137563705444, 'max_batch': 5.050818634033203}
step: 14640 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 5.9442163, 'max_total_reward': 15.45, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0438788294792176, 'actor_loss': -4.849509620666504, 'hyper_actor_loss': 0.038062913715839385, 'behavior_loss': 0.28693517446517947, 'mean_batch': 5.065389728546142, 'min_batch': 5.041181898117065, 'max_batch': 5.097793245315552}
step: 14650 @ episode report: {'average_total_reward': 9.066, 'reward_variance': 4.100324, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8279296517372132, 'actor_loss': -4.825938177108765, 'hyper_actor_loss': 0.0379412766546011, 'behavior_loss': 0.2807357430458069, 'mean_batch': 5.00493049621582, 'min_batch': 4.983225870132446, 'max_batch': 5.0432384490966795}
step: 14660 @ episode report: {'average_total_reward': 9.554001, 'reward_variance': 4.4152036, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.729986336827278, 'actor_loss': -4.835810613632202, 'hyper_actor_loss': 0.037781073898077014, 'behavior_loss': 0.2752299830317497, 'mean_batch': 5.032628583908081, 'min_batch': 5.0049553394317625, 'max_batch': 5.076583576202393}
step: 14670 @ episode report: {'average_total_reward': 9.932, 'reward_variance': 4.3046365, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9051090598106384, 'actor_loss': -4.849599552154541, 'hyper_actor_loss': 0.0378424484282732, 'behavior_loss': 0.2794605419039726, 'mean_batch': 5.069626331329346, 'min_batch': 5.03742151260376, 'max_batch': 5.119697046279907}
step: 14680 @ episode report: {'average_total_reward': 10.709002, 'reward_variance': 2.1303897, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6694292545318603, 'actor_loss': -4.837699222564697, 'hyper_actor_loss': 0.03781996406614781, 'behavior_loss': 0.27015812546014784, 'mean_batch': 5.040023756027222, 'min_batch': 5.007050466537476, 'max_batch': 5.093447065353393}
step: 14690 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 0.99830085, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5891331076622008, 'actor_loss': -4.8448389053344725, 'hyper_actor_loss': 0.037636042758822444, 'behavior_loss': 0.2800749272108078, 'mean_batch': 5.055866050720215, 'min_batch': 5.027161359786987, 'max_batch': 5.096439981460572}
step: 14700 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 3.6215649, 'max_total_reward': 12.2300005, 'min_total_reward': 5.6800003, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.475411170721054, 'actor_loss': -4.870968389511108, 'hyper_actor_loss': 0.037550630420446394, 'behavior_loss': 0.2743724316358566, 'mean_batch': 5.1252377986907955, 'min_batch': 5.0904864311218265, 'max_batch': 5.155378580093384}
step: 14710 @ episode report: {'average_total_reward': 9.787001, 'reward_variance': 3.8597817, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0411476254463197, 'actor_loss': -4.863497161865235, 'hyper_actor_loss': 0.03740376830101013, 'behavior_loss': 0.28748217821121214, 'mean_batch': 5.106155729293823, 'min_batch': 5.071689558029175, 'max_batch': 5.138525104522705}
step: 14720 @ episode report: {'average_total_reward': 10.098001, 'reward_variance': 6.828438, 'max_total_reward': 13.450001, 'min_total_reward': 4.5699997, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6077840864658355, 'actor_loss': -4.814309692382812, 'hyper_actor_loss': 0.037414048612117765, 'behavior_loss': 0.2870518654584885, 'mean_batch': 4.978965997695923, 'min_batch': 4.9513349533081055, 'max_batch': 5.025172185897827}
step: 14730 @ episode report: {'average_total_reward': 9.676001, 'reward_variance': 5.0335836, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9294855833053588, 'actor_loss': -4.836741018295288, 'hyper_actor_loss': 0.03739825375378132, 'behavior_loss': 0.2707075968384743, 'mean_batch': 5.037001657485962, 'min_batch': 5.0052694320678714, 'max_batch': 5.095697402954102}
step: 14740 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 5.12873, 'max_total_reward': 13.34, 'min_total_reward': 4.68, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6885100543498992, 'actor_loss': -4.846778202056885, 'hyper_actor_loss': 0.037245338782668114, 'behavior_loss': 0.2711751013994217, 'mean_batch': 5.0666053771972654, 'min_batch': 5.0262229442596436, 'max_batch': 5.116835594177246}
step: 14750 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.91178, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.11561758518219, 'actor_loss': -4.829097604751587, 'hyper_actor_loss': 0.03712017722427845, 'behavior_loss': 0.277718560397625, 'mean_batch': 5.02407054901123, 'min_batch': 4.98004641532898, 'max_batch': 5.0583484172821045}
step: 14760 @ episode report: {'average_total_reward': 11.508, 'reward_variance': 1.928076, 'max_total_reward': 14.56, 'min_total_reward': 10.01, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8074438214302062, 'actor_loss': -4.800160503387451, 'hyper_actor_loss': 0.03702254816889763, 'behavior_loss': 0.2780261516571045, 'mean_batch': 4.9439092636108395, 'min_batch': 4.916368865966797, 'max_batch': 4.967716884613037}
step: 14770 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 4.9092207, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7170323252677917, 'actor_loss': -4.841635227203369, 'hyper_actor_loss': 0.037002939358353616, 'behavior_loss': 0.27559136748313906, 'mean_batch': 5.052786493301392, 'min_batch': 5.014298582077027, 'max_batch': 5.067795515060425}
step: 14780 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 2.015025, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6026548743247986, 'actor_loss': -4.86925311088562, 'hyper_actor_loss': 0.03683351278305054, 'behavior_loss': 0.27687842547893526, 'mean_batch': 5.128028488159179, 'min_batch': 5.078906011581421, 'max_batch': 5.137182092666626}
step: 14790 @ episode report: {'average_total_reward': 10.409001, 'reward_variance': 1.1545293, 'max_total_reward': 12.2300005, 'min_total_reward': 9.009999, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0771892428398133, 'actor_loss': -4.831711053848267, 'hyper_actor_loss': 0.03683581873774529, 'behavior_loss': 0.2748291909694672, 'mean_batch': 5.02651948928833, 'min_batch': 4.990874242782593, 'max_batch': 5.036374473571778}
step: 14800 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 1.232896, 'max_total_reward': 10.120001, 'min_total_reward': 6.9000006, 'average_n_step': 10.4, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8581396341323853, 'actor_loss': -4.807092142105103, 'hyper_actor_loss': 0.03684394769370556, 'behavior_loss': 0.27729924470186235, 'mean_batch': 4.961005830764771, 'min_batch': 4.9335109233856205, 'max_batch': 4.976521301269531}
step: 14810 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 2.9891217, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6302487194538116, 'actor_loss': -4.836624622344971, 'hyper_actor_loss': 0.03676733076572418, 'behavior_loss': 0.2743489608168602, 'mean_batch': 5.033171796798706, 'min_batch': 5.008568334579468, 'max_batch': 5.0405549049377445}
step: 14820 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 3.6313763, 'max_total_reward': 13.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6209958046674728, 'actor_loss': -4.856310081481934, 'hyper_actor_loss': 0.0365277148783207, 'behavior_loss': 0.2985819518566132, 'mean_batch': 5.080165386199951, 'min_batch': 5.060809659957886, 'max_batch': 5.084145784378052}
step: 14830 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.5934818, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8225369811058045, 'actor_loss': -4.851474142074585, 'hyper_actor_loss': 0.03662145286798477, 'behavior_loss': 0.2918993666768074, 'mean_batch': 5.071184873580933, 'min_batch': 5.045312118530274, 'max_batch': 5.079323959350586}
step: 14840 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 4.877331, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.726053249835968, 'actor_loss': -4.818502759933471, 'hyper_actor_loss': 0.036712102591991425, 'behavior_loss': 0.2683144509792328, 'mean_batch': 4.985005283355713, 'min_batch': 4.966234254837036, 'max_batch': 4.999603891372681}
step: 14850 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 2.1542842, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5955021262168885, 'actor_loss': -4.839111089706421, 'hyper_actor_loss': 0.036558644473552705, 'behavior_loss': 0.26659565716981887, 'mean_batch': 5.038875389099121, 'min_batch': 5.015557956695557, 'max_batch': 5.053015899658203}
step: 14860 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 3.8749053, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5751640796661377, 'actor_loss': -4.881513881683349, 'hyper_actor_loss': 0.036284264922142026, 'behavior_loss': 0.27666511833667756, 'mean_batch': 5.147197532653808, 'min_batch': 5.122430038452149, 'max_batch': 5.159499216079712}
step: 14870 @ episode report: {'average_total_reward': 10.631001, 'reward_variance': 3.7678692, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5770756363868714, 'actor_loss': -4.86361517906189, 'hyper_actor_loss': 0.03614366054534912, 'behavior_loss': 0.2758227810263634, 'mean_batch': 5.09958553314209, 'min_batch': 5.07856183052063, 'max_batch': 5.113828420639038}
step: 14880 @ episode report: {'average_total_reward': 10.687001, 'reward_variance': 2.138861, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1059778034687042, 'actor_loss': -4.83673062324524, 'hyper_actor_loss': 0.036058231443166736, 'behavior_loss': 0.27535525858402254, 'mean_batch': 5.02899808883667, 'min_batch': 5.0133891105651855, 'max_batch': 5.041357707977295}
step: 14890 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 6.143137, 'max_total_reward': 13.450001, 'min_total_reward': 4.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.067611074447632, 'actor_loss': -4.804598140716553, 'hyper_actor_loss': 0.03590970076620579, 'behavior_loss': 0.26735398471355437, 'mean_batch': 4.946017551422119, 'min_batch': 4.936119794845581, 'max_batch': 4.957669448852539}
step: 14900 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 4.6672015, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0161868929862976, 'actor_loss': -4.803625631332397, 'hyper_actor_loss': 0.035867085307836534, 'behavior_loss': 0.2726798474788666, 'mean_batch': 4.947303199768067, 'min_batch': 4.930023145675659, 'max_batch': 4.961949968338013}
step: 14910 @ episode report: {'average_total_reward': 10.854001, 'reward_variance': 2.2860646, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0097477793693543, 'actor_loss': -4.826240491867066, 'hyper_actor_loss': 0.035790979489684106, 'behavior_loss': 0.283476297557354, 'mean_batch': 5.006542062759399, 'min_batch': 4.983143091201782, 'max_batch': 5.020452260971069}
step: 14920 @ episode report: {'average_total_reward': 10.265, 'reward_variance': 1.9636446, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6724789619445801, 'actor_loss': -4.815661239624023, 'hyper_actor_loss': 0.03572217710316181, 'behavior_loss': 0.2623904928565025, 'mean_batch': 4.981759834289551, 'min_batch': 4.955426740646362, 'max_batch': 5.5188287734985355}
step: 14930 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 4.265869, 'max_total_reward': 12.34, 'min_total_reward': 4.46, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8078286826610566, 'actor_loss': -4.852338457107544, 'hyper_actor_loss': 0.03574984073638916, 'behavior_loss': 0.2698129490017891, 'mean_batch': 5.0849415302276615, 'min_batch': 5.036193370819092, 'max_batch': 5.162271022796631}
step: 14940 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 2.1524956, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0488603591918944, 'actor_loss': -4.807444620132446, 'hyper_actor_loss': 0.035589002817869184, 'behavior_loss': 0.28400626629590986, 'mean_batch': 4.962052822113037, 'min_batch': 4.934492301940918, 'max_batch': 4.981605291366577}
step: 14950 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 1.0954211, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8431935429573059, 'actor_loss': -4.7968419075012205, 'hyper_actor_loss': 0.03556092381477356, 'behavior_loss': 0.2652303144335747, 'mean_batch': 4.936767530441284, 'min_batch': 4.907289600372314, 'max_batch': 4.961858034133911}
step: 14960 @ episode report: {'average_total_reward': 10.863999, 'reward_variance': 4.5111833, 'max_total_reward': 14.559999, 'min_total_reward': 5.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.86945960521698, 'actor_loss': -4.815503978729248, 'hyper_actor_loss': 0.03549622260034084, 'behavior_loss': 0.27607392221689225, 'mean_batch': 4.9848216533660885, 'min_batch': 4.951399469375611, 'max_batch': 5.007737445831299}
step: 14970 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 3.547561, 'max_total_reward': 13.45, 'min_total_reward': 6.5699997, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4100101113319397, 'actor_loss': -4.839924287796021, 'hyper_actor_loss': 0.03537014797329903, 'behavior_loss': 0.2715585395693779, 'mean_batch': 5.049926233291626, 'min_batch': 5.008539009094238, 'max_batch': 5.064189910888672}
step: 14980 @ episode report: {'average_total_reward': 10.453001, 'reward_variance': 2.6276813, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5945352077484132, 'actor_loss': -4.870380449295044, 'hyper_actor_loss': 0.0353413887321949, 'behavior_loss': 0.28234008252620696, 'mean_batch': 5.132829046249389, 'min_batch': 5.0798783779144285, 'max_batch': 5.163490343093872}
step: 14990 @ episode report: {'average_total_reward': 11.774, 'reward_variance': 1.5290039, 'max_total_reward': 14.56, 'min_total_reward': 10.12, 'average_n_step': 12.5, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.673484468460083, 'actor_loss': -4.8375342845916744, 'hyper_actor_loss': 0.03533834032714367, 'behavior_loss': 0.2907353833317757, 'mean_batch': 5.0513307571411135, 'min_batch': 4.995264720916748, 'max_batch': 5.06930251121521}
step: 15000 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 1.188221, 'max_total_reward': 11.23, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3610992848873138, 'actor_loss': -4.823605394363403, 'hyper_actor_loss': 0.03533197157084942, 'behavior_loss': 0.26767055988311766, 'mean_batch': 5.022769451141357, 'min_batch': 4.95403904914856, 'max_batch': 5.051868867874146}
step: 15010 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 4.915685, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0108543753623964, 'actor_loss': -4.84985613822937, 'hyper_actor_loss': 0.03534382022917271, 'behavior_loss': 0.27476050704717636, 'mean_batch': 5.089161443710327, 'min_batch': 5.019405651092529, 'max_batch': 5.117198085784912}
step: 15020 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 9.159507, 'max_total_reward': 16.779999, 'min_total_reward': 5.6800003, 'average_n_step': 10.6, 'max_n_step': 17.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.791342842578888, 'actor_loss': -4.807631254196167, 'hyper_actor_loss': 0.03531251735985279, 'behavior_loss': 0.28430757820606234, 'mean_batch': 4.981519889831543, 'min_batch': 4.915883588790893, 'max_batch': 5.0177671909332275}
step: 15030 @ episode report: {'average_total_reward': 9.210001, 'reward_variance': 3.6681995, 'max_total_reward': 11.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8453654885292052, 'actor_loss': -4.819522953033447, 'hyper_actor_loss': 0.03520333170890808, 'behavior_loss': 0.27088779807090757, 'mean_batch': 5.007599687576294, 'min_batch': 4.948789167404175, 'max_batch': 5.033996105194092}
step: 15040 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 2.6617413, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7319531440734863, 'actor_loss': -4.820558071136475, 'hyper_actor_loss': 0.03513194397091866, 'behavior_loss': 0.2703459277749062, 'mean_batch': 5.006121444702148, 'min_batch': 4.955302810668945, 'max_batch': 5.025310087203979}
step: 15050 @ episode report: {'average_total_reward': 10.920001, 'reward_variance': 2.3971398, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7520481884479522, 'actor_loss': -4.830059242248535, 'hyper_actor_loss': 0.03511377237737179, 'behavior_loss': 0.282902429997921, 'mean_batch': 5.031925249099731, 'min_batch': 4.976998949050904, 'max_batch': 5.04929895401001}
step: 15060 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 1.534742, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7715441465377808, 'actor_loss': -4.816612005233765, 'hyper_actor_loss': 0.034967999532818796, 'behavior_loss': 0.27344425916671755, 'mean_batch': 4.993853330612183, 'min_batch': 4.947982835769653, 'max_batch': 5.019422483444214}
step: 15070 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.0220091, 'max_total_reward': 12.23, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5521601617336274, 'actor_loss': -4.843267965316772, 'hyper_actor_loss': 0.03491997942328453, 'behavior_loss': 0.2698902770876884, 'mean_batch': 5.061910772323609, 'min_batch': 5.013416290283203, 'max_batch': 5.086673355102539}
step: 15080 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 1.9292963, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.800960123538971, 'actor_loss': -4.852002191543579, 'hyper_actor_loss': 0.03491887785494328, 'behavior_loss': 0.2784227281808853, 'mean_batch': 5.085190773010254, 'min_batch': 5.034103345870972, 'max_batch': 5.106111860275268}
step: 15090 @ episode report: {'average_total_reward': 11.0980015, 'reward_variance': 3.959177, 'max_total_reward': 14.45, 'min_total_reward': 8.79, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5235533952713012, 'actor_loss': -4.8284650325775145, 'hyper_actor_loss': 0.03481316938996315, 'behavior_loss': 0.2851937472820282, 'mean_batch': 5.022008275985717, 'min_batch': 4.978852653503418, 'max_batch': 5.05627212524414}
step: 15100 @ episode report: {'average_total_reward': 9.832, 'reward_variance': 2.027456, 'max_total_reward': 13.45, 'min_total_reward': 8.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0479936003684998, 'actor_loss': -4.829854202270508, 'hyper_actor_loss': 0.03475722223520279, 'behavior_loss': 0.28312991857528685, 'mean_batch': 5.02267279624939, 'min_batch': 4.9851562023162845, 'max_batch': 5.044499349594116}
step: 15110 @ episode report: {'average_total_reward': 10.298999, 'reward_variance': 5.914389, 'max_total_reward': 13.450001, 'min_total_reward': 5.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8206487774848938, 'actor_loss': -4.809375953674317, 'hyper_actor_loss': 0.034850149601697925, 'behavior_loss': 0.2703196004033089, 'mean_batch': 4.971531534194947, 'min_batch': 4.934282970428467, 'max_batch': 4.999467420578003}
step: 15120 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 2.719284, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7474264919757843, 'actor_loss': -4.815840578079223, 'hyper_actor_loss': 0.03477539271116257, 'behavior_loss': 0.27542674988508226, 'mean_batch': 4.992918014526367, 'min_batch': 4.945041036605835, 'max_batch': 5.025856351852417}
step: 15130 @ episode report: {'average_total_reward': 10.531001, 'reward_variance': 1.5108092, 'max_total_reward': 12.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5288454473018647, 'actor_loss': -4.841109848022461, 'hyper_actor_loss': 0.03470965251326561, 'behavior_loss': 0.2815184220671654, 'mean_batch': 5.060289525985718, 'min_batch': 5.004126262664795, 'max_batch': 5.084399557113647}
step: 15140 @ episode report: {'average_total_reward': 10.409001, 'reward_variance': 2.4110494, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8809845447540283, 'actor_loss': -4.848394298553467, 'hyper_actor_loss': 0.03457373008131981, 'behavior_loss': 0.26629969030618666, 'mean_batch': 5.076131677627563, 'min_batch': 5.02506914138794, 'max_batch': 5.09385118484497}
step: 15150 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 2.9190445, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6354049503803254, 'actor_loss': -4.8206446170806885, 'hyper_actor_loss': 0.0344205804169178, 'behavior_loss': 0.26983230710029604, 'mean_batch': 5.005105018615723, 'min_batch': 4.9567399501800535, 'max_batch': 5.027906894683838}
step: 15160 @ episode report: {'average_total_reward': 8.933001, 'reward_variance': 2.8715806, 'max_total_reward': 12.23, 'min_total_reward': 5.57, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7943965673446656, 'actor_loss': -4.823962306976318, 'hyper_actor_loss': 0.03434525653719902, 'behavior_loss': 0.27690754234790804, 'mean_batch': 5.014116287231445, 'min_batch': 4.964275646209717, 'max_batch': 5.030119705200195}
step: 15170 @ episode report: {'average_total_reward': 9.400001, 'reward_variance': 5.3196416, 'max_total_reward': 14.56, 'min_total_reward': 6.46, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.429995226860046, 'actor_loss': -4.799640321731568, 'hyper_actor_loss': 0.03426012881100178, 'behavior_loss': 0.29381638020277023, 'mean_batch': 4.953334522247315, 'min_batch': 4.9048590660095215, 'max_batch': 4.979196310043335}
step: 15180 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 3.7779794, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8349961042404175, 'actor_loss': -4.762953519821167, 'hyper_actor_loss': 0.034376185759902, 'behavior_loss': 0.2795986980199814, 'mean_batch': 4.8662344455719, 'min_batch': 4.812443494796753, 'max_batch': 4.904731702804566}
step: 15190 @ episode report: {'average_total_reward': 8.777, 'reward_variance': 3.2087007, 'max_total_reward': 11.12, 'min_total_reward': 4.6800003, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7841113924980163, 'actor_loss': -4.816504287719726, 'hyper_actor_loss': 0.03437974490225315, 'behavior_loss': 0.28559642732143403, 'mean_batch': 4.998356199264526, 'min_batch': 4.943210220336914, 'max_batch': 5.02147912979126}
step: 15200 @ episode report: {'average_total_reward': 10.31, 'reward_variance': 3.9496799, 'max_total_reward': 14.23, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.10089750289917, 'actor_loss': -4.8126929759979244, 'hyper_actor_loss': 0.034444577246904376, 'behavior_loss': 0.2820037677884102, 'mean_batch': 4.991542625427246, 'min_batch': 4.9310875415802, 'max_batch': 5.034109163284302}
step: 15210 @ episode report: {'average_total_reward': 9.921, 'reward_variance': 1.6254892, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9590145111083985, 'actor_loss': -4.784373331069946, 'hyper_actor_loss': 0.03431744053959847, 'behavior_loss': 0.27310884445905687, 'mean_batch': 4.921489238739014, 'min_batch': 4.861404800415039, 'max_batch': 4.976824045181274}
step: 15220 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 3.9935856, 'max_total_reward': 15.56, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4888014554977418, 'actor_loss': -4.797985219955445, 'hyper_actor_loss': 0.03422020934522152, 'behavior_loss': 0.262239508330822, 'mean_batch': 4.961050367355346, 'min_batch': 4.8890846252441404, 'max_batch': 4.990615510940552}
step: 15230 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 2.3207011, 'max_total_reward': 13.12, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6499609708786012, 'actor_loss': -4.8597166538238525, 'hyper_actor_loss': 0.03383957780897617, 'behavior_loss': 0.277260060608387, 'mean_batch': 5.108981037139893, 'min_batch': 5.049574899673462, 'max_batch': 5.136018419265747}
step: 15240 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 4.490846, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8598844110965729, 'actor_loss': -4.823010015487671, 'hyper_actor_loss': 0.0337409257888794, 'behavior_loss': 0.26908870339393615, 'mean_batch': 5.012847900390625, 'min_batch': 4.961176824569702, 'max_batch': 5.074324607849121}
step: 15250 @ episode report: {'average_total_reward': 9.210001, 'reward_variance': 1.9850401, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4506334513425827, 'actor_loss': -4.834029722213745, 'hyper_actor_loss': 0.033894216641783714, 'behavior_loss': 0.2753941357135773, 'mean_batch': 5.095002555847168, 'min_batch': 4.935564994812012, 'max_batch': 6.5720844745635985}
step: 15260 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 3.8277802, 'max_total_reward': 13.01, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4859401822090148, 'actor_loss': -4.817360830307007, 'hyper_actor_loss': 0.033744340762495995, 'behavior_loss': 0.26326718032360075, 'mean_batch': 4.987704658508301, 'min_batch': 4.957877445220947, 'max_batch': 5.008319997787476}
step: 15270 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 3.9408212, 'max_total_reward': 14.559999, 'min_total_reward': 6.7900004, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7672885417938233, 'actor_loss': -4.849825668334961, 'hyper_actor_loss': 0.03353631943464279, 'behavior_loss': 0.27211110591888427, 'mean_batch': 5.067475461959839, 'min_batch': 5.040722274780274, 'max_batch': 5.115894317626953}
step: 15280 @ episode report: {'average_total_reward': 10.698001, 'reward_variance': 5.359997, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8024116516113282, 'actor_loss': -4.827696704864502, 'hyper_actor_loss': 0.03348090760409832, 'behavior_loss': 0.28447329103946684, 'mean_batch': 5.012086582183838, 'min_batch': 4.984909009933472, 'max_batch': 5.053281688690186}
step: 15290 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 3.3910244, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.625979208946228, 'actor_loss': -4.813521957397461, 'hyper_actor_loss': 0.03359919935464859, 'behavior_loss': 0.2600829377770424, 'mean_batch': 4.979767990112305, 'min_batch': 4.946683645248413, 'max_batch': 5.044762516021729}
step: 15300 @ episode report: {'average_total_reward': 9.91, 'reward_variance': 3.5959804, 'max_total_reward': 13.45, 'min_total_reward': 7.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5355387568473815, 'actor_loss': -4.857939004898071, 'hyper_actor_loss': 0.0335081048309803, 'behavior_loss': 0.26973946690559386, 'mean_batch': 5.0932541847229, 'min_batch': 5.0562256336212155, 'max_batch': 5.1716734886169435}
step: 15310 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 1.508264, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7229431927204133, 'actor_loss': -4.8551506996154785, 'hyper_actor_loss': 0.03333822414278984, 'behavior_loss': 0.2605855718255043, 'mean_batch': 5.084158945083618, 'min_batch': 5.051091241836548, 'max_batch': 5.173778676986695}
step: 15320 @ episode report: {'average_total_reward': 10.420001, 'reward_variance': 1.7886198, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7570077002048492, 'actor_loss': -4.816364574432373, 'hyper_actor_loss': 0.03337309062480927, 'behavior_loss': 0.2970662161707878, 'mean_batch': 4.9846056461334225, 'min_batch': 4.955906915664673, 'max_batch': 5.0691663265228275}
step: 15330 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 2.9397962, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9357575178146362, 'actor_loss': -4.805291700363159, 'hyper_actor_loss': 0.03354692719876766, 'behavior_loss': 0.26232142746448517, 'mean_batch': 4.957756376266479, 'min_batch': 4.9278481006622314, 'max_batch': 5.036839485168457}
step: 15340 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 3.5475605, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8036557257175445, 'actor_loss': -4.81614351272583, 'hyper_actor_loss': 0.033402415364980696, 'behavior_loss': 0.2605514287948608, 'mean_batch': 4.995878744125366, 'min_batch': 4.943595600128174, 'max_batch': 5.086461687088013}
step: 15350 @ episode report: {'average_total_reward': 9.132999, 'reward_variance': 2.8892207, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7900987148284913, 'actor_loss': -4.816635847091675, 'hyper_actor_loss': 0.033338329195976256, 'behavior_loss': 0.2787682592868805, 'mean_batch': 5.000282669067383, 'min_batch': 4.941664600372315, 'max_batch': 5.07659330368042}
step: 15360 @ episode report: {'average_total_reward': 10.842, 'reward_variance': 3.6822762, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5279569625854492, 'actor_loss': -4.8270955085754395, 'hyper_actor_loss': 0.033284739777445796, 'behavior_loss': 0.26494830250740053, 'mean_batch': 5.025763845443725, 'min_batch': 4.968341827392578, 'max_batch': 5.105123996734619}
step: 15370 @ episode report: {'average_total_reward': 10.309001, 'reward_variance': 1.4244292, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.838697212934494, 'actor_loss': -4.828826856613159, 'hyper_actor_loss': 0.03321512043476105, 'behavior_loss': 0.2742415234446526, 'mean_batch': 5.028629446029663, 'min_batch': 4.974103403091431, 'max_batch': 5.122572755813598}
step: 15380 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 5.573561, 'max_total_reward': 14.450001, 'min_total_reward': 6.6800003, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3646171808242797, 'actor_loss': -4.824289274215698, 'hyper_actor_loss': 0.033117708191275595, 'behavior_loss': 0.2829103469848633, 'mean_batch': 5.01943006515503, 'min_batch': 4.960828113555908, 'max_batch': 5.104272556304932}
step: 15390 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 4.89682, 'max_total_reward': 14.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5620629608631134, 'actor_loss': -4.876801443099976, 'hyper_actor_loss': 0.033291815966367724, 'behavior_loss': 0.2760996580123901, 'mean_batch': 5.152076530456543, 'min_batch': 5.093595170974732, 'max_batch': 5.229420232772827}
step: 15400 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 3.3628361, 'max_total_reward': 12.120001, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9776639223098755, 'actor_loss': -4.823694515228271, 'hyper_actor_loss': 0.03324367292225361, 'behavior_loss': 0.2707757905125618, 'mean_batch': 5.010446500778198, 'min_batch': 4.96727728843689, 'max_batch': 5.0789148807525635}
step: 15410 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 1.3058048, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4448448359966277, 'actor_loss': -4.823650169372558, 'hyper_actor_loss': 0.033106879144906995, 'behavior_loss': 0.26595524698495865, 'mean_batch': 5.007000589370728, 'min_batch': 4.970335197448731, 'max_batch': 5.070555877685547}
step: 15420 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 3.450025, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7042494416236877, 'actor_loss': -4.868370532989502, 'hyper_actor_loss': 0.03298627734184265, 'behavior_loss': 0.28397356271743773, 'mean_batch': 5.123197412490844, 'min_batch': 5.079202938079834, 'max_batch': 5.198873996734619}
step: 15430 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 3.0166092, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6118509948253632, 'actor_loss': -4.853019285202026, 'hyper_actor_loss': 0.033013975247740746, 'behavior_loss': 0.2718964546918869, 'mean_batch': 5.081545114517212, 'min_batch': 5.04286003112793, 'max_batch': 5.14449634552002}
step: 15440 @ episode report: {'average_total_reward': 9.210001, 'reward_variance': 4.2563004, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6772660613059998, 'actor_loss': -4.844911861419678, 'hyper_actor_loss': 0.03290594592690468, 'behavior_loss': 0.25849100649356843, 'mean_batch': 5.057249450683594, 'min_batch': 5.026155948638916, 'max_batch': 5.1324364185333256}
step: 15450 @ episode report: {'average_total_reward': 10.110001, 'reward_variance': 2.0270405, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6160649627447128, 'actor_loss': -4.840090322494507, 'hyper_actor_loss': 0.03275694139301777, 'behavior_loss': 0.2757954716682434, 'mean_batch': 5.043618059158325, 'min_batch': 5.015499639511108, 'max_batch': 5.1219385147094725}
step: 15460 @ episode report: {'average_total_reward': 11.075001, 'reward_variance': 3.5294845, 'max_total_reward': 14.559999, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0910928606987, 'actor_loss': -4.81919493675232, 'hyper_actor_loss': 0.03271923922002316, 'behavior_loss': 0.276440292596817, 'mean_batch': 4.989357233047485, 'min_batch': 4.965354633331299, 'max_batch': 5.05774450302124}
step: 15470 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 3.0697162, 'max_total_reward': 14.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0148548126220702, 'actor_loss': -4.803358364105224, 'hyper_actor_loss': 0.0327668983489275, 'behavior_loss': 0.2804232224822044, 'mean_batch': 4.9509295463562015, 'min_batch': 4.925089168548584, 'max_batch': 5.018461513519287}
step: 15480 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.7639633, 'max_total_reward': 12.339999, 'min_total_reward': 7.68, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.065571939945221, 'actor_loss': -4.803429031372071, 'hyper_actor_loss': 0.032803931087255475, 'behavior_loss': 0.2723044574260712, 'mean_batch': 4.959393930435181, 'min_batch': 4.9170678615570065, 'max_batch': 4.987952136993409}
step: 15490 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 4.343796, 'max_total_reward': 14.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.014127802848816, 'actor_loss': -4.772077560424805, 'hyper_actor_loss': 0.03266650587320328, 'behavior_loss': 0.25608952045440675, 'mean_batch': 4.8860327243804935, 'min_batch': 4.836927318572998, 'max_batch': 4.9176414012908936}
step: 15500 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 3.0624642, 'max_total_reward': 13.450001, 'min_total_reward': 6.57, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.638574767112732, 'actor_loss': -4.811055612564087, 'hyper_actor_loss': 0.03257836289703846, 'behavior_loss': 0.28489831686019895, 'mean_batch': 4.986506414413452, 'min_batch': 4.928396558761596, 'max_batch': 5.018256092071534}
step: 15510 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 3.3169658, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9677594512701035, 'actor_loss': -4.829635810852051, 'hyper_actor_loss': 0.03248271048069, 'behavior_loss': 0.28780216723680496, 'mean_batch': 5.0348790168762205, 'min_batch': 4.972171258926392, 'max_batch': 5.064882707595825}
step: 15520 @ episode report: {'average_total_reward': 11.164, 'reward_variance': 4.8826647, 'max_total_reward': 14.56, 'min_total_reward': 7.7899995, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7037091970443725, 'actor_loss': -4.812295055389404, 'hyper_actor_loss': 0.03270382322371006, 'behavior_loss': 0.2779048576951027, 'mean_batch': 4.989723062515258, 'min_batch': 4.930704498291016, 'max_batch': 5.018496990203857}
step: 15530 @ episode report: {'average_total_reward': 10.087999, 'reward_variance': 10.056055, 'max_total_reward': 13.34, 'min_total_reward': 1.9100001, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6815379500389098, 'actor_loss': -4.817148160934448, 'hyper_actor_loss': 0.03264995664358139, 'behavior_loss': 0.26249388307332994, 'mean_batch': 4.9968794822692875, 'min_batch': 4.947579956054687, 'max_batch': 5.023472929000855}
step: 15540 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 2.329165, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8205013155937195, 'actor_loss': -4.817361783981323, 'hyper_actor_loss': 0.0323508195579052, 'behavior_loss': 0.26588712483644483, 'mean_batch': 4.991112518310547, 'min_batch': 4.954345941543579, 'max_batch': 5.010148382186889}
step: 15550 @ episode report: {'average_total_reward': 9.998, 'reward_variance': 9.231716, 'max_total_reward': 12.340001, 'min_total_reward': 1.35, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6626480221748352, 'actor_loss': -4.837562322616577, 'hyper_actor_loss': 0.03228890188038349, 'behavior_loss': 0.284294331073761, 'mean_batch': 5.043261575698852, 'min_batch': 5.003225517272949, 'max_batch': 5.064326190948487}
step: 15560 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 4.590188, 'max_total_reward': 15.559999, 'min_total_reward': 6.7900004, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7400992512702942, 'actor_loss': -4.827932548522949, 'hyper_actor_loss': 0.03229960985481739, 'behavior_loss': 0.27506538331508634, 'mean_batch': 5.0144177913665775, 'min_batch': 4.983774566650391, 'max_batch': 5.0590588569641115}
step: 15570 @ episode report: {'average_total_reward': 11.397, 'reward_variance': 2.5471, 'max_total_reward': 14.34, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.428402352333069, 'actor_loss': -4.836936187744141, 'hyper_actor_loss': 0.03227778673171997, 'behavior_loss': 0.26904407888650894, 'mean_batch': 5.041362285614014, 'min_batch': 5.002024364471436, 'max_batch': 5.08143162727356}
step: 15580 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.9437613, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8458371460437775, 'actor_loss': -4.850794935226441, 'hyper_actor_loss': 0.03199034258723259, 'behavior_loss': 0.2663633406162262, 'mean_batch': 5.076449012756347, 'min_batch': 5.036705589294433, 'max_batch': 5.1621842861175535}
step: 15590 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 2.6107008, 'max_total_reward': 11.2300005, 'min_total_reward': 6.5699997, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7461268067359925, 'actor_loss': -4.817014455795288, 'hyper_actor_loss': 0.03198386281728745, 'behavior_loss': 0.2808283880352974, 'mean_batch': 4.990975379943848, 'min_batch': 4.952809906005859, 'max_batch': 5.055911684036255}
step: 15600 @ episode report: {'average_total_reward': 10.275999, 'reward_variance': 6.7944846, 'max_total_reward': 15.56, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8367160201072692, 'actor_loss': -4.807383632659912, 'hyper_actor_loss': 0.03198648877441883, 'behavior_loss': 0.28300233483314513, 'mean_batch': 4.9713410377502445, 'min_batch': 4.92466893196106, 'max_batch': 5.041147184371948}
step: 15610 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 5.0678215, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.2572437912225722, 'actor_loss': -4.846367931365966, 'hyper_actor_loss': 0.031940192356705664, 'behavior_loss': 0.26594034433364866, 'mean_batch': 5.066525840759278, 'min_batch': 5.0250880241394045, 'max_batch': 5.1228269100189205}
step: 15620 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 4.8613834, 'max_total_reward': 14.559999, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8764773279428482, 'actor_loss': -4.858862733840942, 'hyper_actor_loss': 0.03197166472673416, 'behavior_loss': 0.2827706798911095, 'mean_batch': 5.104610347747803, 'min_batch': 5.049953603744507, 'max_batch': 5.167581176757812}
step: 15630 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 4.317241, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4484472692012786, 'actor_loss': -4.8421595096588135, 'hyper_actor_loss': 0.03194410912692547, 'behavior_loss': 0.2717692941427231, 'mean_batch': 5.059670925140381, 'min_batch': 5.0100648403167725, 'max_batch': 5.158555412292481}
step: 15640 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 4.93263, 'max_total_reward': 13.34, 'min_total_reward': 5.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.205111563205719, 'actor_loss': -4.823375225067139, 'hyper_actor_loss': 0.03175320439040661, 'behavior_loss': 0.27557421922683717, 'mean_batch': 5.01119909286499, 'min_batch': 4.964605760574341, 'max_batch': 5.098322153091431}
step: 15650 @ episode report: {'average_total_reward': 9.987, 'reward_variance': 2.5477202, 'max_total_reward': 12.34, 'min_total_reward': 7.9000006, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6865406572818755, 'actor_loss': -4.791773939132691, 'hyper_actor_loss': 0.03167392984032631, 'behavior_loss': 0.27869623601436616, 'mean_batch': 4.927994060516357, 'min_batch': 4.891095733642578, 'max_batch': 5.01650767326355}
step: 15660 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 5.251139, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9535561561584474, 'actor_loss': -4.8132682800292965, 'hyper_actor_loss': 0.031730736047029494, 'behavior_loss': 0.2903640165925026, 'mean_batch': 4.983036851882934, 'min_batch': 4.94209246635437, 'max_batch': 5.072489309310913}
step: 15670 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 3.3229008, 'max_total_reward': 12.23, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8829550683498382, 'actor_loss': -4.814724540710449, 'hyper_actor_loss': 0.03173637315630913, 'behavior_loss': 0.2601228579878807, 'mean_batch': 4.985805797576904, 'min_batch': 4.946543741226196, 'max_batch': 5.061638736724854}
step: 15680 @ episode report: {'average_total_reward': 9.665, 'reward_variance': 5.298166, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.536818391084671, 'actor_loss': -4.825581884384155, 'hyper_actor_loss': 0.03164121322333813, 'behavior_loss': 0.29178579747676847, 'mean_batch': 5.013849496841431, 'min_batch': 4.9726259231567385, 'max_batch': 5.096338367462158}
step: 15690 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 2.0007415, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 12.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9262418627738953, 'actor_loss': -4.8304706573486325, 'hyper_actor_loss': 0.03173081614077091, 'behavior_loss': 0.28335817009210584, 'mean_batch': 5.026876020431518, 'min_batch': 4.9840521812438965, 'max_batch': 5.102240371704101}
step: 15700 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 2.1718812, 'max_total_reward': 13.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7907775044441223, 'actor_loss': -4.813107538223266, 'hyper_actor_loss': 0.03167518451809883, 'behavior_loss': 0.2821438670158386, 'mean_batch': 4.980774879455566, 'min_batch': 4.943541193008423, 'max_batch': 5.042626428604126}
step: 15710 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 1.9650295, 'max_total_reward': 12.340001, 'min_total_reward': 7.9000006, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8961355090141296, 'actor_loss': -4.818097019195557, 'hyper_actor_loss': 0.03159017562866211, 'behavior_loss': 0.27460172325372695, 'mean_batch': 4.992554092407227, 'min_batch': 4.956540298461914, 'max_batch': 5.048376512527466}
step: 15720 @ episode report: {'average_total_reward': 9.987, 'reward_variance': 6.075501, 'max_total_reward': 14.45, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4301738381385802, 'actor_loss': -4.810305404663086, 'hyper_actor_loss': 0.031494312733411786, 'behavior_loss': 0.26685039699077606, 'mean_batch': 4.967990684509277, 'min_batch': 4.942595195770264, 'max_batch': 5.0412805557250975}
step: 15730 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 6.585241, 'max_total_reward': 15.45, 'min_total_reward': 5.7900004, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4995419085025787, 'actor_loss': -4.887067699432373, 'hyper_actor_loss': 0.03131062835454941, 'behavior_loss': 0.27970428466796876, 'mean_batch': 5.163973045349121, 'min_batch': 5.13460521697998, 'max_batch': 5.245079231262207}
step: 15740 @ episode report: {'average_total_reward': 10.764001, 'reward_variance': 1.7810447, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9706432700157166, 'actor_loss': -4.848294019699097, 'hyper_actor_loss': 0.031096752919256686, 'behavior_loss': 0.256265726685524, 'mean_batch': 5.069895553588867, 'min_batch': 5.03141827583313, 'max_batch': 5.148422145843506}
step: 15750 @ episode report: {'average_total_reward': 9.698, 'reward_variance': 2.3884358, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8862077713012695, 'actor_loss': -4.787203931808472, 'hyper_actor_loss': 0.030970997363328933, 'behavior_loss': 0.27865583300590513, 'mean_batch': 4.920554494857788, 'min_batch': 4.876137399673462, 'max_batch': 4.980199670791626}
step: 15760 @ episode report: {'average_total_reward': 8.222, 'reward_variance': 2.7676768, 'max_total_reward': 10.120001, 'min_total_reward': 5.57, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5634065508842467, 'actor_loss': -4.806117963790894, 'hyper_actor_loss': 0.03101532645523548, 'behavior_loss': 0.27912478893995285, 'mean_batch': 4.971830558776856, 'min_batch': 4.918156147003174, 'max_batch': 5.013991832733154}
step: 15770 @ episode report: {'average_total_reward': 9.443001, 'reward_variance': 5.537282, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.205431544780731, 'actor_loss': -4.832235383987427, 'hyper_actor_loss': 0.031235224939882754, 'behavior_loss': 0.3035529851913452, 'mean_batch': 5.0374175071716305, 'min_batch': 4.9824525833129885, 'max_batch': 5.079883623123169}
step: 15780 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 6.016202, 'max_total_reward': 14.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7350006639957427, 'actor_loss': -4.804051446914673, 'hyper_actor_loss': 0.031527236104011536, 'behavior_loss': 0.27057250738143923, 'mean_batch': 4.963258409500122, 'min_batch': 4.916267156600952, 'max_batch': 5.014469957351684}
step: 15790 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 2.505565, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5693753778934478, 'actor_loss': -4.813117599487304, 'hyper_actor_loss': 0.031480972096323966, 'behavior_loss': 0.27843715250492096, 'mean_batch': 4.981294965744018, 'min_batch': 4.943094062805176, 'max_batch': 5.044629907608032}
step: 15800 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 4.659896, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9413249254226685, 'actor_loss': -4.8340537548065186, 'hyper_actor_loss': 0.031239526346325874, 'behavior_loss': 0.276681649684906, 'mean_batch': 5.0371932029724125, 'min_batch': 4.991656160354614, 'max_batch': 5.111512517929077}
step: 15810 @ episode report: {'average_total_reward': 9.566, 'reward_variance': 2.878965, 'max_total_reward': 14.120001, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9309453010559081, 'actor_loss': -4.8013848781585695, 'hyper_actor_loss': 0.03116086721420288, 'behavior_loss': 0.26748873591423034, 'mean_batch': 4.950577735900879, 'min_batch': 4.9158820629119875, 'max_batch': 5.019165086746216}
step: 15820 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 5.2480655, 'max_total_reward': 14.120001, 'min_total_reward': 6.7900004, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7583335876464843, 'actor_loss': -4.794605016708374, 'hyper_actor_loss': 0.031029772385954855, 'behavior_loss': 0.28833957612514494, 'mean_batch': 4.931484842300415, 'min_batch': 4.901471471786499, 'max_batch': 5.020794630050659}
step: 15830 @ episode report: {'average_total_reward': 10.409001, 'reward_variance': 2.9283092, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8617576003074645, 'actor_loss': -4.840750312805175, 'hyper_actor_loss': 0.031012776866555215, 'behavior_loss': 0.27559304386377337, 'mean_batch': 5.046574115753174, 'min_batch': 5.015998268127442, 'max_batch': 5.140313291549683}
step: 15840 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 2.559989, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6129441738128663, 'actor_loss': -4.825677108764649, 'hyper_actor_loss': 0.030852274410426615, 'behavior_loss': 0.28304601162672044, 'mean_batch': 5.006794071197509, 'min_batch': 4.980123472213745, 'max_batch': 5.129681396484375}
step: 15850 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.0834813, 'max_total_reward': 13.34, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8448148787021637, 'actor_loss': -4.832273054122925, 'hyper_actor_loss': 0.030838718079030512, 'behavior_loss': 0.2857341945171356, 'mean_batch': 5.0202052116394045, 'min_batch': 4.999635791778564, 'max_batch': 5.117462587356568}
step: 15860 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 4.4377756, 'max_total_reward': 12.12, 'min_total_reward': 5.68, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.729512196779251, 'actor_loss': -4.821760511398315, 'hyper_actor_loss': 0.030849796533584595, 'behavior_loss': 0.269290617108345, 'mean_batch': 4.999512672424316, 'min_batch': 4.9678315162658695, 'max_batch': 5.097691917419434}
step: 15870 @ episode report: {'average_total_reward': 9.877001, 'reward_variance': 1.6936013, 'max_total_reward': 12.34, 'min_total_reward': 7.4599996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.001252496242523, 'actor_loss': -4.80151252746582, 'hyper_actor_loss': 0.03094905652105808, 'behavior_loss': 0.28064112812280656, 'mean_batch': 4.951933574676514, 'min_batch': 4.9150676250457765, 'max_batch': 5.047602748870849}
step: 15880 @ episode report: {'average_total_reward': 9.722, 'reward_variance': 2.7784166, 'max_total_reward': 12.120001, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1498425960540772, 'actor_loss': -4.777698040008545, 'hyper_actor_loss': 0.030911949463188648, 'behavior_loss': 0.2908310413360596, 'mean_batch': 4.893953418731689, 'min_batch': 4.856228828430176, 'max_batch': 4.965916728973388}
step: 15890 @ episode report: {'average_total_reward': 11.542002, 'reward_variance': 0.7389561, 'max_total_reward': 13.2300005, 'min_total_reward': 10.12, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3498743653297425, 'actor_loss': -4.797671175003051, 'hyper_actor_loss': 0.03088680561631918, 'behavior_loss': 0.2547928363084793, 'mean_batch': 4.943313837051392, 'min_batch': 4.9052734375, 'max_batch': 5.0079038619995115}
step: 15900 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 2.6847084, 'max_total_reward': 12.339999, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.67257000207901, 'actor_loss': -4.857859659194946, 'hyper_actor_loss': 0.03056746646761894, 'behavior_loss': 0.2811670809984207, 'mean_batch': 5.098430633544922, 'min_batch': 5.050520515441894, 'max_batch': 5.142708826065063}
step: 15910 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 3.1602566, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7565391838550568, 'actor_loss': -4.840619134902954, 'hyper_actor_loss': 0.030376296304166318, 'behavior_loss': 0.26504205763339994, 'mean_batch': 5.055502462387085, 'min_batch': 5.006486225128174, 'max_batch': 5.086987686157227}
step: 15920 @ episode report: {'average_total_reward': 10.564, 'reward_variance': 3.157483, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7767032384872437, 'actor_loss': -4.807193803787231, 'hyper_actor_loss': 0.03026115372776985, 'behavior_loss': 0.2686131805181503, 'mean_batch': 4.976722335815429, 'min_batch': 4.91845121383667, 'max_batch': 5.014233255386353}
step: 15930 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 4.053516, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.822420859336853, 'actor_loss': -4.8028641700744625, 'hyper_actor_loss': 0.03016998991370201, 'behavior_loss': 0.29847882091999056, 'mean_batch': 4.965824270248413, 'min_batch': 4.9079090595245365, 'max_batch': 5.007397651672363}
step: 15940 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 1.4820998, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6789469122886658, 'actor_loss': -4.814447736740112, 'hyper_actor_loss': 0.030285611376166345, 'behavior_loss': 0.2630460664629936, 'mean_batch': 4.991585922241211, 'min_batch': 4.9395472526550295, 'max_batch': 5.058224439620972}
step: 15950 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.8882841, 'max_total_reward': 12.339999, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8420620441436768, 'actor_loss': -4.830836820602417, 'hyper_actor_loss': 0.030231977254152297, 'behavior_loss': 0.27298798263072965, 'mean_batch': 5.026057291030884, 'min_batch': 4.986646890640259, 'max_batch': 5.146924257278442}
step: 15960 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 3.3116963, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7899995, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8001265048980712, 'actor_loss': -4.817193555831909, 'hyper_actor_loss': 0.030243547074496745, 'behavior_loss': 0.2972491651773453, 'mean_batch': 4.986786556243897, 'min_batch': 4.957901811599731, 'max_batch': 5.051381540298462}
step: 15970 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 1.8012602, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2685389637947084, 'actor_loss': -4.776100492477417, 'hyper_actor_loss': 0.030340973846614362, 'behavior_loss': 0.28519839942455294, 'mean_batch': 4.892366647720337, 'min_batch': 4.850423097610474, 'max_batch': 4.931392002105713}
step: 15980 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 1.7028425, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8478618144989014, 'actor_loss': -4.7505295753479, 'hyper_actor_loss': 0.03048933334648609, 'behavior_loss': 0.2773653194308281, 'mean_batch': 4.830039024353027, 'min_batch': 4.788858127593994, 'max_batch': 4.8645079135894775}
step: 15990 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 4.551329, 'max_total_reward': 15.67, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.564789777994156, 'actor_loss': -4.824846982955933, 'hyper_actor_loss': 0.0302569730207324, 'behavior_loss': 0.2695294186472893, 'mean_batch': 5.005085134506226, 'min_batch': 4.978279113769531, 'max_batch': 5.039449882507324}
step: 16000 @ episode report: {'average_total_reward': 8.544001, 'reward_variance': 2.1077843, 'max_total_reward': 11.12, 'min_total_reward': 6.7900004, 'average_n_step': 9.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5049145638942718, 'actor_loss': -4.858704519271851, 'hyper_actor_loss': 0.030066623538732528, 'behavior_loss': 0.2874052822589874, 'mean_batch': 5.091349267959595, 'min_batch': 5.061797142028809, 'max_batch': 5.121683168411255}
step: 16010 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 2.8382008, 'max_total_reward': 12.34, 'min_total_reward': 5.7899995, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3997878432273865, 'actor_loss': -4.857710218429565, 'hyper_actor_loss': 0.030063563585281373, 'behavior_loss': 0.2711701259016991, 'mean_batch': 5.086869573593139, 'min_batch': 5.06123456954956, 'max_batch': 5.147323751449585}
step: 16020 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 3.5169654, 'max_total_reward': 11.2300005, 'min_total_reward': 4.68, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.780465292930603, 'actor_loss': -4.838505125045776, 'hyper_actor_loss': 0.029950040951371194, 'behavior_loss': 0.2856766939163208, 'mean_batch': 5.039694690704346, 'min_batch': 5.011502313613891, 'max_batch': 5.10572304725647}
step: 16030 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 2.1206603, 'max_total_reward': 12.339999, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.891495832800865, 'actor_loss': -4.820968770980835, 'hyper_actor_loss': 0.029910917580127715, 'behavior_loss': 0.27553280591964724, 'mean_batch': 4.998164176940918, 'min_batch': 4.965238237380982, 'max_batch': 5.059164333343506}
step: 16040 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 4.1193886, 'max_total_reward': 12.339999, 'min_total_reward': 5.68, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7069461226463318, 'actor_loss': -4.801967334747315, 'hyper_actor_loss': 0.02999346684664488, 'behavior_loss': 0.2764663591980934, 'mean_batch': 4.951298713684082, 'min_batch': 4.917894124984741, 'max_batch': 5.0284332752227785}
step: 16050 @ episode report: {'average_total_reward': 11.264002, 'reward_variance': 2.2774646, 'max_total_reward': 14.450001, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.696194350719452, 'actor_loss': -4.812794923782349, 'hyper_actor_loss': 0.029958704486489296, 'behavior_loss': 0.2778938949108124, 'mean_batch': 4.980584383010864, 'min_batch': 4.942243480682373, 'max_batch': 5.06019172668457}
step: 16060 @ episode report: {'average_total_reward': 10.109, 'reward_variance': 2.4897087, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6358354270458222, 'actor_loss': -4.835564756393433, 'hyper_actor_loss': 0.029930175840854646, 'behavior_loss': 0.2843939334154129, 'mean_batch': 5.038451528549194, 'min_batch': 4.998005056381226, 'max_batch': 5.134839248657227}
step: 16070 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 1.0725449, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6224735796451568, 'actor_loss': -4.838406610488891, 'hyper_actor_loss': 0.0299225689843297, 'behavior_loss': 0.2772598624229431, 'mean_batch': 5.040497589111328, 'min_batch': 5.010130882263184, 'max_batch': 5.131795835494995}
step: 16080 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 3.0287192, 'max_total_reward': 13.45, 'min_total_reward': 7.9000006, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5235408186912536, 'actor_loss': -4.8402464389801025, 'hyper_actor_loss': 0.029857146367430688, 'behavior_loss': 0.28392484188079836, 'mean_batch': 5.043956899642945, 'min_batch': 5.01591010093689, 'max_batch': 5.159258556365967}
step: 16090 @ episode report: {'average_total_reward': 8.722, 'reward_variance': 1.5784165, 'max_total_reward': 11.120001, 'min_total_reward': 6.6800003, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0314484238624573, 'actor_loss': -4.822240829467773, 'hyper_actor_loss': 0.029877459071576594, 'behavior_loss': 0.275999216735363, 'mean_batch': 4.997957372665406, 'min_batch': 4.9719473361969, 'max_batch': 5.126912307739258}
step: 16100 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 2.1631248, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8452669858932496, 'actor_loss': -4.804583787918091, 'hyper_actor_loss': 0.02991792857646942, 'behavior_loss': 0.2816238522529602, 'mean_batch': 4.956509447097778, 'min_batch': 4.925588369369507, 'max_batch': 5.110696458816529}
step: 16110 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 2.9021645, 'max_total_reward': 13.34, 'min_total_reward': 7.4599996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8439144253730775, 'actor_loss': -4.81624960899353, 'hyper_actor_loss': 0.029809124208986758, 'behavior_loss': 0.2806693121790886, 'mean_batch': 4.986889314651489, 'min_batch': 4.953044891357422, 'max_batch': 5.149779605865478}
step: 16120 @ episode report: {'average_total_reward': 9.1, 'reward_variance': 4.06092, 'max_total_reward': 12.340001, 'min_total_reward': 6.7900004, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7185206472873689, 'actor_loss': -4.819096422195434, 'hyper_actor_loss': 0.029836957156658173, 'behavior_loss': 0.2811340391635895, 'mean_batch': 4.990372180938721, 'min_batch': 4.963682413101196, 'max_batch': 5.133812189102173}
step: 16130 @ episode report: {'average_total_reward': 9.432, 'reward_variance': 3.3301163, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5043059229850768, 'actor_loss': -4.84280104637146, 'hyper_actor_loss': 0.029649958573281766, 'behavior_loss': 0.2560546398162842, 'mean_batch': 5.050498008728027, 'min_batch': 5.022336769104004, 'max_batch': 5.164977025985718}
step: 16140 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 1.4785159, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6726345896720887, 'actor_loss': -4.8393796443939205, 'hyper_actor_loss': 0.029466923512518405, 'behavior_loss': 0.28346704691648483, 'mean_batch': 5.038537836074829, 'min_batch': 5.017069101333618, 'max_batch': 5.116484785079956}
step: 16150 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.20682, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.850368320941925, 'actor_loss': -4.826364994049072, 'hyper_actor_loss': 0.029492817632853986, 'behavior_loss': 0.2812318027019501, 'mean_batch': 5.007431268692017, 'min_batch': 4.9828520774841305, 'max_batch': 5.103559255599976}
step: 16160 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 2.3839047, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.976418948173523, 'actor_loss': -4.815666913986206, 'hyper_actor_loss': 0.029556710831820966, 'behavior_loss': 0.2790332600474358, 'mean_batch': 4.9795783996582035, 'min_batch': 4.957415628433227, 'max_batch': 5.088260078430176}
step: 16170 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 3.037362, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8486716330051423, 'actor_loss': -4.803594160079956, 'hyper_actor_loss': 0.029420961253345014, 'behavior_loss': 0.2744064822793007, 'mean_batch': 4.948645305633545, 'min_batch': 4.928542566299439, 'max_batch': 5.043406867980957}
step: 16180 @ episode report: {'average_total_reward': 10.798001, 'reward_variance': 1.4845164, 'max_total_reward': 12.2300005, 'min_total_reward': 8.68, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.74230215549469, 'actor_loss': -4.815337991714477, 'hyper_actor_loss': 0.02949622832238674, 'behavior_loss': 0.27878462374210355, 'mean_batch': 4.977707433700561, 'min_batch': 4.957650995254516, 'max_batch': 5.049771118164062}
step: 16190 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 4.549165, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.643977054953575, 'actor_loss': -4.836451292037964, 'hyper_actor_loss': 0.02943812496960163, 'behavior_loss': 0.28637717962265014, 'mean_batch': 5.030360317230224, 'min_batch': 5.010478687286377, 'max_batch': 5.100740575790406}
step: 16200 @ episode report: {'average_total_reward': 9.221, 'reward_variance': 2.8453088, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.918392038345337, 'actor_loss': -4.833597230911255, 'hyper_actor_loss': 0.029452284052968025, 'behavior_loss': 0.27268572598695756, 'mean_batch': 5.022188425064087, 'min_batch': 5.004362773895264, 'max_batch': 5.100657939910889}
step: 16210 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 0.6020251, 'max_total_reward': 10.900001, 'min_total_reward': 7.9, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.835021448135376, 'actor_loss': -4.805543279647827, 'hyper_actor_loss': 0.029499837942421437, 'behavior_loss': 0.28287013322114946, 'mean_batch': 4.950751924514771, 'min_batch': 4.936048936843872, 'max_batch': 5.015707921981812}
step: 16220 @ episode report: {'average_total_reward': 9.544001, 'reward_variance': 0.7977842, 'max_total_reward': 11.120002, 'min_total_reward': 8.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9046254277229309, 'actor_loss': -4.806498432159424, 'hyper_actor_loss': 0.02941267341375351, 'behavior_loss': 0.2861690193414688, 'mean_batch': 4.954114484786987, 'min_batch': 4.937448596954345, 'max_batch': 4.9952808856964115}
step: 16230 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 3.150709, 'max_total_reward': 12.230001, 'min_total_reward': 6.7900004, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.890846785902977, 'actor_loss': -4.813300037384034, 'hyper_actor_loss': 0.029470271058380605, 'behavior_loss': 0.2822443976998329, 'mean_batch': 4.972204875946045, 'min_batch': 4.953032350540161, 'max_batch': 5.025564908981323}
step: 16240 @ episode report: {'average_total_reward': 9.022, 'reward_variance': 7.914036, 'max_total_reward': 13.45, 'min_total_reward': 2.46, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.742118239402771, 'actor_loss': -4.7952454566955565, 'hyper_actor_loss': 0.029450614377856253, 'behavior_loss': 0.29428971856832503, 'mean_batch': 4.928663063049316, 'min_batch': 4.907400798797608, 'max_batch': 4.99670443534851}
step: 16250 @ episode report: {'average_total_reward': 10.642001, 'reward_variance': 2.6452959, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8391558855772019, 'actor_loss': -4.808900213241577, 'hyper_actor_loss': 0.029441004619002342, 'behavior_loss': 0.2724505215883255, 'mean_batch': 4.963504076004028, 'min_batch': 4.939936923980713, 'max_batch': 5.020173358917236}
step: 16260 @ episode report: {'average_total_reward': 10.055, 'reward_variance': 2.124006, 'max_total_reward': 13.340001, 'min_total_reward': 7.5699997, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0001968443393707, 'actor_loss': -4.813695812225342, 'hyper_actor_loss': 0.029331190325319768, 'behavior_loss': 0.2711186587810516, 'mean_batch': 4.975603771209717, 'min_batch': 4.951639556884766, 'max_batch': 5.029972171783447}
step: 16270 @ episode report: {'average_total_reward': 9.143999, 'reward_variance': 2.3727648, 'max_total_reward': 12.34, 'min_total_reward': 6.57, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.334309810400009, 'actor_loss': -4.815236806869507, 'hyper_actor_loss': 0.02909852806478739, 'behavior_loss': 0.2748788699507713, 'mean_batch': 4.980379867553711, 'min_batch': 4.954619264602661, 'max_batch': 5.026074504852295}
step: 16280 @ episode report: {'average_total_reward': 11.064, 'reward_variance': 1.6607441, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5529683649539947, 'actor_loss': -4.865618085861206, 'hyper_actor_loss': 0.029011713154613972, 'behavior_loss': 0.28362893462181094, 'mean_batch': 5.115276861190796, 'min_batch': 5.0732049465179445, 'max_batch': 5.164117813110352}
step: 16290 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 5.447425, 'max_total_reward': 14.559999, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7590039134025575, 'actor_loss': -4.84672589302063, 'hyper_actor_loss': 0.029020474292337894, 'behavior_loss': 0.27244977802038195, 'mean_batch': 5.065629243850708, 'min_batch': 5.027191066741944, 'max_batch': 5.094993782043457}
step: 16300 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 2.2686455, 'max_total_reward': 12.2300005, 'min_total_reward': 6.569999, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.76540806889534, 'actor_loss': -4.796825361251831, 'hyper_actor_loss': 0.02906349953263998, 'behavior_loss': 0.2916510760784149, 'mean_batch': 4.94453125, 'min_batch': 4.899453592300415, 'max_batch': 4.970829677581787}
step: 16310 @ episode report: {'average_total_reward': 10.132, 'reward_variance': 1.6806759, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7124704480171205, 'actor_loss': -4.804182434082032, 'hyper_actor_loss': 0.02909921184182167, 'behavior_loss': 0.2815080150961876, 'mean_batch': 4.964388656616211, 'min_batch': 4.91583480834961, 'max_batch': 5.006321716308594}
step: 16320 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 3.5105202, 'max_total_reward': 13.01, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0360386967658997, 'actor_loss': -4.81214747428894, 'hyper_actor_loss': 0.029191591031849384, 'behavior_loss': 0.2874587655067444, 'mean_batch': 4.993167352676392, 'min_batch': 4.926586294174195, 'max_batch': 5.019958257675171}
step: 16330 @ episode report: {'average_total_reward': 8.655001, 'reward_variance': 3.3346448, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.842164796590805, 'actor_loss': -4.791072940826416, 'hyper_actor_loss': 0.02918949965387583, 'behavior_loss': 0.2831907197833061, 'mean_batch': 4.945925855636597, 'min_batch': 4.869934225082398, 'max_batch': 4.968564987182617}
step: 16340 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.1031017, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5327035307884216, 'actor_loss': -4.800114965438842, 'hyper_actor_loss': 0.02904418855905533, 'behavior_loss': 0.27633165270090104, 'mean_batch': 4.970389890670776, 'min_batch': 4.890023469924927, 'max_batch': 5.0004864692687985}
step: 16350 @ episode report: {'average_total_reward': 10.998001, 'reward_variance': 2.6124766, 'max_total_reward': 14.34, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6234932363033294, 'actor_loss': -4.833291339874267, 'hyper_actor_loss': 0.029022141359746456, 'behavior_loss': 0.28149920105934145, 'mean_batch': 5.058610153198242, 'min_batch': 4.966788864135742, 'max_batch': 5.095362997055053}
step: 16360 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.0265014, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9929720282554626, 'actor_loss': -4.832068729400635, 'hyper_actor_loss': 0.028929693438112736, 'behavior_loss': 0.28244571536779406, 'mean_batch': 5.055733585357666, 'min_batch': 4.963734769821167, 'max_batch': 5.089707899093628}
step: 16370 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 3.0272691, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5678594648838042, 'actor_loss': -4.787893867492675, 'hyper_actor_loss': 0.02880055960267782, 'behavior_loss': 0.2716832235455513, 'mean_batch': 4.9623407363891605, 'min_batch': 4.838417434692383, 'max_batch': 5.088609266281128}
step: 16380 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 4.957457, 'max_total_reward': 13.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.220237410068512, 'actor_loss': -4.789346027374267, 'hyper_actor_loss': 0.028653923794627188, 'behavior_loss': 0.2889436259865761, 'mean_batch': 4.988471412658692, 'min_batch': 4.8205952644348145, 'max_batch': 5.2691779136657715}
step: 16390 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 5.815789, 'max_total_reward': 14.45, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0247560024261473, 'actor_loss': -4.7470433712005615, 'hyper_actor_loss': 0.028651882708072663, 'behavior_loss': 0.2633999302983284, 'mean_batch': 4.870971965789795, 'min_batch': 4.731872606277466, 'max_batch': 5.177035808563232}
step: 16400 @ episode report: {'average_total_reward': 9.898001, 'reward_variance': 5.0546966, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6035509705543518, 'actor_loss': -4.79061598777771, 'hyper_actor_loss': 0.02859737817198038, 'behavior_loss': 0.28344554603099825, 'mean_batch': 5.002262306213379, 'min_batch': 4.813270139694214, 'max_batch': 5.426427602767944}
step: 16410 @ episode report: {'average_total_reward': 9.942999, 'reward_variance': 3.427121, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5909551799297332, 'actor_loss': -4.792776823043823, 'hyper_actor_loss': 0.028464832715690135, 'behavior_loss': 0.2759048044681549, 'mean_batch': 4.997415685653687, 'min_batch': 4.828045654296875, 'max_batch': 5.298244857788086}
step: 16420 @ episode report: {'average_total_reward': 11.497, 'reward_variance': 1.1984408, 'max_total_reward': 13.45, 'min_total_reward': 10.01, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6891489386558534, 'actor_loss': -4.781554937362671, 'hyper_actor_loss': 0.02837262023240328, 'behavior_loss': 0.2833404019474983, 'mean_batch': 4.962035465240478, 'min_batch': 4.80816011428833, 'max_batch': 5.27411470413208}
step: 16430 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 0.6929609, 'max_total_reward': 11.2300005, 'min_total_reward': 9.01, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6525794088840484, 'actor_loss': -4.811719560623169, 'hyper_actor_loss': 0.028346056304872035, 'behavior_loss': 0.2773804008960724, 'mean_batch': 5.034533500671387, 'min_batch': 4.884049415588379, 'max_batch': 5.1589148998260494}
step: 16440 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 4.226824, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.575428342819214, 'actor_loss': -4.813434696197509, 'hyper_actor_loss': 0.02841290831565857, 'behavior_loss': 0.28038752228021624, 'mean_batch': 5.029392290115356, 'min_batch': 4.8973935604095455, 'max_batch': 5.22952618598938}
step: 16450 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 2.9898763, 'max_total_reward': 13.450001, 'min_total_reward': 6.57, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.715540099143982, 'actor_loss': -4.795913362503052, 'hyper_actor_loss': 0.028421153873205186, 'behavior_loss': 0.27047375589609146, 'mean_batch': 4.982998847961426, 'min_batch': 4.857113552093506, 'max_batch': 5.041801929473877}
step: 16460 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 4.31208, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7959937691688537, 'actor_loss': -4.7938645362854, 'hyper_actor_loss': 0.028322541154921055, 'behavior_loss': 0.28138152658939364, 'mean_batch': 4.975726461410522, 'min_batch': 4.854251861572266, 'max_batch': 5.068855571746826}
step: 16470 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.7629294, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8886127054691315, 'actor_loss': -4.786462926864624, 'hyper_actor_loss': 0.028175945207476617, 'behavior_loss': 0.2855494752526283, 'mean_batch': 4.95851240158081, 'min_batch': 4.8352134227752686, 'max_batch': 5.052458715438843}
step: 16480 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 9.43604, 'max_total_reward': 13.450001, 'min_total_reward': 2.02, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6365948081016541, 'actor_loss': -4.79062180519104, 'hyper_actor_loss': 0.0282313022762537, 'behavior_loss': 0.2830889403820038, 'mean_batch': 4.965452718734741, 'min_batch': 4.848587846755981, 'max_batch': 5.097339200973511}
step: 16490 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 9.306509, 'max_total_reward': 13.34, 'min_total_reward': 2.02, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.719275438785553, 'actor_loss': -4.818982219696045, 'hyper_actor_loss': 0.028365999832749365, 'behavior_loss': 0.28056246489286424, 'mean_batch': 5.0394681930542, 'min_batch': 4.914810514450073, 'max_batch': 5.135815715789795}
step: 16500 @ episode report: {'average_total_reward': 8.8550005, 'reward_variance': 3.4610648, 'max_total_reward': 11.2300005, 'min_total_reward': 4.57, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4682965755462647, 'actor_loss': -4.816392421722412, 'hyper_actor_loss': 0.02826525643467903, 'behavior_loss': 0.2716021627187729, 'mean_batch': 5.029347372055054, 'min_batch': 4.911930656433105, 'max_batch': 5.107002687454224}
step: 16510 @ episode report: {'average_total_reward': 9.066, 'reward_variance': 2.2754836, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6068475127220154, 'actor_loss': -4.850231695175171, 'hyper_actor_loss': 0.028165513277053834, 'behavior_loss': 0.28478347659111025, 'mean_batch': 5.109777927398682, 'min_batch': 5.00110502243042, 'max_batch': 5.234691429138183}
step: 16520 @ episode report: {'average_total_reward': 9.433001, 'reward_variance': 0.736801, 'max_total_reward': 11.120001, 'min_total_reward': 7.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4628269374370575, 'actor_loss': -4.840078592300415, 'hyper_actor_loss': 0.028109555318951606, 'behavior_loss': 0.27701261192560195, 'mean_batch': 5.072634267807007, 'min_batch': 4.986724710464477, 'max_batch': 5.208310317993164}
step: 16530 @ episode report: {'average_total_reward': 7.912, 'reward_variance': 11.479155, 'max_total_reward': 11.2300005, 'min_total_reward': 0.9100001, 'average_n_step': 9.1, 'max_n_step': 12.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.825877833366394, 'actor_loss': -4.821753120422363, 'hyper_actor_loss': 0.02813765499740839, 'behavior_loss': 0.2748541206121445, 'mean_batch': 5.023802661895752, 'min_batch': 4.9439462184906, 'max_batch': 5.136722087860107}
step: 16540 @ episode report: {'average_total_reward': 7.3560004, 'reward_variance': 6.240244, 'max_total_reward': 9.01, 'min_total_reward': 1.13, 'average_n_step': 8.5, 'max_n_step': 10.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9264182925224305, 'actor_loss': -4.819057416915894, 'hyper_actor_loss': 0.02808445766568184, 'behavior_loss': 0.26774726510047914, 'mean_batch': 5.012548208236694, 'min_batch': 4.941583585739136, 'max_batch': 5.103391504287719}
step: 16550 @ episode report: {'average_total_reward': 8.8, 'reward_variance': 2.895461, 'max_total_reward': 11.120001, 'min_total_reward': 5.68, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7988711059093476, 'actor_loss': -4.818013906478882, 'hyper_actor_loss': 0.02810360174626112, 'behavior_loss': 0.28719044774770736, 'mean_batch': 5.0127006530761715, 'min_batch': 4.936248874664306, 'max_batch': 5.0923998832702635}
step: 16560 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 6.4777403, 'max_total_reward': 16.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5135336250066758, 'actor_loss': -4.820993661880493, 'hyper_actor_loss': 0.028196770697832108, 'behavior_loss': 0.2843332767486572, 'mean_batch': 5.026557111740113, 'min_batch': 4.937500238418579, 'max_batch': 5.2092362403869625}
step: 16570 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.753241, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8612206637859345, 'actor_loss': -4.841248655319214, 'hyper_actor_loss': 0.028251694329082967, 'behavior_loss': 0.27993202954530716, 'mean_batch': 5.087320613861084, 'min_batch': 4.978194618225098, 'max_batch': 5.176175880432129}
step: 16580 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 1.4121691, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6342826008796691, 'actor_loss': -4.825489902496338, 'hyper_actor_loss': 0.028213676437735556, 'behavior_loss': 0.2605085089802742, 'mean_batch': 5.045910120010376, 'min_batch': 4.9405677795410154, 'max_batch': 5.126355886459351}
step: 16590 @ episode report: {'average_total_reward': 9.41, 'reward_variance': 3.1750395, 'max_total_reward': 12.339999, 'min_total_reward': 5.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.88067284822464, 'actor_loss': -4.830367946624756, 'hyper_actor_loss': 0.028119344264268875, 'behavior_loss': 0.282232803106308, 'mean_batch': 5.048423528671265, 'min_batch': 4.962306261062622, 'max_batch': 5.141427373886108}
step: 16600 @ episode report: {'average_total_reward': 8.733, 'reward_variance': 4.2131004, 'max_total_reward': 11.23, 'min_total_reward': 4.6800003, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.586757594347, 'actor_loss': -4.84677734375, 'hyper_actor_loss': 0.02814797330647707, 'behavior_loss': 0.28804013729095457, 'mean_batch': 5.0843071937561035, 'min_batch': 5.009213876724243, 'max_batch': 5.183833980560303}
step: 16610 @ episode report: {'average_total_reward': 9.676001, 'reward_variance': 3.4283245, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9816767692565918, 'actor_loss': -4.849503040313721, 'hyper_actor_loss': 0.028359667770564555, 'behavior_loss': 0.28467300683259966, 'mean_batch': 5.083579969406128, 'min_batch': 5.0233917236328125, 'max_batch': 5.210540676116944}
step: 16620 @ episode report: {'average_total_reward': 8.666, 'reward_variance': 3.692284, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 9.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.890169584751129, 'actor_loss': -4.8076588153839115, 'hyper_actor_loss': 0.028399018011987208, 'behavior_loss': 0.29078069031238557, 'mean_batch': 4.9802666187286375, 'min_batch': 4.917212438583374, 'max_batch': 5.101399993896484}
step: 16630 @ episode report: {'average_total_reward': 8.933001, 'reward_variance': 4.328101, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5612607955932618, 'actor_loss': -4.820059204101563, 'hyper_actor_loss': 0.028577269986271858, 'behavior_loss': 0.2792308360338211, 'mean_batch': 5.013427829742431, 'min_batch': 4.946025276184082, 'max_batch': 5.209565448760986}
step: 16640 @ episode report: {'average_total_reward': 8.7560005, 'reward_variance': 2.5430446, 'max_total_reward': 12.120001, 'min_total_reward': 6.7899995, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0764935851097106, 'actor_loss': -4.846557855606079, 'hyper_actor_loss': 0.028527027741074563, 'behavior_loss': 0.280068838596344, 'mean_batch': 5.0956395149230955, 'min_batch': 4.996806812286377, 'max_batch': 5.321314477920533}
step: 16650 @ episode report: {'average_total_reward': 9.655001, 'reward_variance': 1.743705, 'max_total_reward': 12.12, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.593719059228897, 'actor_loss': -4.831944274902344, 'hyper_actor_loss': 0.028526679240167142, 'behavior_loss': 0.27508228421211245, 'mean_batch': 5.064919281005859, 'min_batch': 4.954019546508789, 'max_batch': 5.345376348495483}
step: 16660 @ episode report: {'average_total_reward': 8.433001, 'reward_variance': 2.5057414, 'max_total_reward': 11.2300005, 'min_total_reward': 6.68, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.00134881734848, 'actor_loss': -4.853826570510864, 'hyper_actor_loss': 0.02843123134225607, 'behavior_loss': 0.29769299030303953, 'mean_batch': 5.116787052154541, 'min_batch': 5.012216663360595, 'max_batch': 5.346975183486938}
step: 16670 @ episode report: {'average_total_reward': 10.332001, 'reward_variance': 4.278076, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6443248212337493, 'actor_loss': -4.83387188911438, 'hyper_actor_loss': 0.02851667385548353, 'behavior_loss': 0.2919677346944809, 'mean_batch': 5.064370965957641, 'min_batch': 4.964013671875, 'max_batch': 5.273135614395142}
step: 16680 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 1.6223211, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0030582308769227, 'actor_loss': -4.8311151504516605, 'hyper_actor_loss': 0.028718641586601736, 'behavior_loss': 0.28331647366285323, 'mean_batch': 5.048556518554688, 'min_batch': 4.9658363342285154, 'max_batch': 5.269283819198608}
step: 16690 @ episode report: {'average_total_reward': 8.056, 'reward_variance': 1.4882839, 'max_total_reward': 10.12, 'min_total_reward': 5.57, 'average_n_step': 9.2, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7278611660003662, 'actor_loss': -4.832422161102295, 'hyper_actor_loss': 0.028820532374083996, 'behavior_loss': 0.2976722478866577, 'mean_batch': 5.071834850311279, 'min_batch': 4.949571895599365, 'max_batch': 5.2766509532928465}
step: 16700 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 3.5487213, 'max_total_reward': 12.34, 'min_total_reward': 6.5699997, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.934704703092575, 'actor_loss': -4.842130470275879, 'hyper_actor_loss': 0.02890698201954365, 'behavior_loss': 0.2808306857943535, 'mean_batch': 5.094180345535278, 'min_batch': 4.975868129730225, 'max_batch': 5.299603033065796}
step: 16710 @ episode report: {'average_total_reward': 8.844, 'reward_variance': 3.0147443, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8455926537513734, 'actor_loss': -4.829945278167725, 'hyper_actor_loss': 0.02877012323588133, 'behavior_loss': 0.2822497308254242, 'mean_batch': 5.060069847106933, 'min_batch': 4.94870023727417, 'max_batch': 5.168189573287964}
step: 16720 @ episode report: {'average_total_reward': 8.2, 'reward_variance': 0.88325995, 'max_total_reward': 10.12, 'min_total_reward': 6.9, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.371598905324936, 'actor_loss': -4.842876958847046, 'hyper_actor_loss': 0.028703729249536993, 'behavior_loss': 0.2780256912112236, 'mean_batch': 5.096680927276611, 'min_batch': 4.977559185028076, 'max_batch': 5.284737300872803}
step: 16730 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 3.967662, 'max_total_reward': 12.2300005, 'min_total_reward': 4.5699997, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8554425358772277, 'actor_loss': -4.882114839553833, 'hyper_actor_loss': 0.028560189343988896, 'behavior_loss': 0.2708539843559265, 'mean_batch': 5.204398775100708, 'min_batch': 5.069172620773315, 'max_batch': 5.389279222488403}
step: 16740 @ episode report: {'average_total_reward': 8.555, 'reward_variance': 3.9683857, 'max_total_reward': 12.120001, 'min_total_reward': 5.6800003, 'average_n_step': 9.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6762873649597168, 'actor_loss': -4.840306520462036, 'hyper_actor_loss': 0.028479054011404513, 'behavior_loss': 0.28140382170677186, 'mean_batch': 5.084556531906128, 'min_batch': 4.976440382003784, 'max_batch': 5.195694160461426}
step: 16750 @ episode report: {'average_total_reward': 8.8, 'reward_variance': 1.9467199, 'max_total_reward': 10.120001, 'min_total_reward': 5.5700006, 'average_n_step': 9.9, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0649975657463076, 'actor_loss': -4.8374731063842775, 'hyper_actor_loss': 0.02844475004822016, 'behavior_loss': 0.2755118891596794, 'mean_batch': 5.067650079727173, 'min_batch': 4.978747463226318, 'max_batch': 5.131234407424927}
step: 16760 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 2.8175855, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.585902953147888, 'actor_loss': -4.83446888923645, 'hyper_actor_loss': 0.02840100843459368, 'behavior_loss': 0.27578877806663515, 'mean_batch': 5.057508420944214, 'min_batch': 4.97374119758606, 'max_batch': 5.10590968132019}
step: 16770 @ episode report: {'average_total_reward': 8.189, 'reward_variance': 1.9743096, 'max_total_reward': 10.120001, 'min_total_reward': 5.68, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.032180571556091, 'actor_loss': -4.851513814926148, 'hyper_actor_loss': 0.02840815745294094, 'behavior_loss': 0.2872790589928627, 'mean_batch': 5.09882550239563, 'min_batch': 5.018201398849487, 'max_batch': 5.147865152359008}
step: 16780 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 2.4745407, 'max_total_reward': 12.2300005, 'min_total_reward': 6.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.827018040418625, 'actor_loss': -4.823695468902588, 'hyper_actor_loss': 0.028450411185622214, 'behavior_loss': 0.27537826597690584, 'mean_batch': 5.026044225692749, 'min_batch': 4.951233434677124, 'max_batch': 5.065826082229615}
step: 16790 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 0.98325574, 'max_total_reward': 11.23, 'min_total_reward': 7.79, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6705004274845123, 'actor_loss': -4.841972780227661, 'hyper_actor_loss': 0.02842067591845989, 'behavior_loss': 0.27812086790800095, 'mean_batch': 5.06494107246399, 'min_batch': 5.003966999053955, 'max_batch': 5.1434472560882565}
step: 16800 @ episode report: {'average_total_reward': 8.766, 'reward_variance': 9.855784, 'max_total_reward': 13.45, 'min_total_reward': 2.24, 'average_n_step': 9.8, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7076570510864257, 'actor_loss': -4.867952585220337, 'hyper_actor_loss': 0.028462315164506435, 'behavior_loss': 0.28459544777870177, 'mean_batch': 5.1299385070800785, 'min_batch': 5.070410346984863, 'max_batch': 5.182474803924561}
step: 16810 @ episode report: {'average_total_reward': 9.244, 'reward_variance': 2.8484836, 'max_total_reward': 13.45, 'min_total_reward': 7.57, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7782734870910644, 'actor_loss': -4.874469518661499, 'hyper_actor_loss': 0.02848056610673666, 'behavior_loss': 0.2768960416316986, 'mean_batch': 5.143542003631592, 'min_batch': 5.090127325057983, 'max_batch': 5.215050745010376}
step: 16820 @ episode report: {'average_total_reward': 8.3, 'reward_variance': 1.4036801, 'max_total_reward': 10.01, 'min_total_reward': 5.79, 'average_n_step': 9.4, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.994594669342041, 'actor_loss': -4.850970125198364, 'hyper_actor_loss': 0.028538983874022962, 'behavior_loss': 0.28344355821609496, 'mean_batch': 5.086831331253052, 'min_batch': 5.027329397201538, 'max_batch': 5.199712324142456}
step: 16830 @ episode report: {'average_total_reward': 9.109999, 'reward_variance': 3.3447201, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.972902286052704, 'actor_loss': -4.832548046112061, 'hyper_actor_loss': 0.028644878417253494, 'behavior_loss': 0.2722796231508255, 'mean_batch': 5.040295267105103, 'min_batch': 4.981079864501953, 'max_batch': 5.1532371044158936}
step: 16840 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 4.1622972, 'max_total_reward': 12.34, 'min_total_reward': 4.5699997, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.094280833005905, 'actor_loss': -4.826739406585693, 'hyper_actor_loss': 0.028548802994191647, 'behavior_loss': 0.2905137002468109, 'mean_batch': 5.025023365020752, 'min_batch': 4.967280340194702, 'max_batch': 5.11009464263916}
step: 16850 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 5.054081, 'max_total_reward': 13.450001, 'min_total_reward': 5.57, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0006734251976015, 'actor_loss': -4.823002862930298, 'hyper_actor_loss': 0.02857121340930462, 'behavior_loss': 0.27293147295713427, 'mean_batch': 5.013082075119018, 'min_batch': 4.960526609420777, 'max_batch': 5.101451301574707}
step: 16860 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 3.9700813, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8623728632926941, 'actor_loss': -4.832077884674073, 'hyper_actor_loss': 0.028658990748226643, 'behavior_loss': 0.2910649746656418, 'mean_batch': 5.04379415512085, 'min_batch': 4.975370645523071, 'max_batch': 5.141221952438355}
step: 16870 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.9926455, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7966120839118958, 'actor_loss': -4.854707193374634, 'hyper_actor_loss': 0.028593905083835126, 'behavior_loss': 0.27230849117040634, 'mean_batch': 5.097838068008423, 'min_batch': 5.0352174758911135, 'max_batch': 5.201165962219238}
step: 16880 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 6.1683702, 'max_total_reward': 14.56, 'min_total_reward': 6.7900004, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9053847193717957, 'actor_loss': -4.842178153991699, 'hyper_actor_loss': 0.028459741920232772, 'behavior_loss': 0.28520617634058, 'mean_batch': 5.061438655853271, 'min_batch': 5.008394193649292, 'max_batch': 5.146197032928467}
step: 16890 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 4.174344, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7962762653827666, 'actor_loss': -4.817539691925049, 'hyper_actor_loss': 0.02852449119091034, 'behavior_loss': 0.2841015547513962, 'mean_batch': 4.999454736709595, 'min_batch': 4.9469895362854, 'max_batch': 5.087902498245239}
step: 16900 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 2.9087212, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.530008575320244, 'actor_loss': -4.869248628616333, 'hyper_actor_loss': 0.028483476489782333, 'behavior_loss': 0.2891741245985031, 'mean_batch': 5.143937778472901, 'min_batch': 5.063598775863648, 'max_batch': 5.251156759262085}
step: 16910 @ episode report: {'average_total_reward': 8.867001, 'reward_variance': 2.4300015, 'max_total_reward': 12.12, 'min_total_reward': 6.6800003, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4629236847162246, 'actor_loss': -4.900658416748047, 'hyper_actor_loss': 0.028710742853581904, 'behavior_loss': 0.280781552195549, 'mean_batch': 5.227013683319091, 'min_batch': 5.141862869262695, 'max_batch': 5.3456113815307615}
step: 16920 @ episode report: {'average_total_reward': 9.499, 'reward_variance': 0.584189, 'max_total_reward': 11.23, 'min_total_reward': 8.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.816368618607521, 'actor_loss': -4.868902778625488, 'hyper_actor_loss': 0.02857506610453129, 'behavior_loss': 0.2856921061873436, 'mean_batch': 5.154088306427002, 'min_batch': 5.0515354633331295, 'max_batch': 5.26276535987854}
step: 16930 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 1.117976, 'max_total_reward': 11.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.772636815905571, 'actor_loss': -4.834378576278686, 'hyper_actor_loss': 0.028588091768324376, 'behavior_loss': 0.2712674155831337, 'mean_batch': 5.06644196510315, 'min_batch': 4.964464378356934, 'max_batch': 5.172563886642456}
step: 16940 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 2.618657, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.831091618537903, 'actor_loss': -4.838283920288086, 'hyper_actor_loss': 0.02850278653204441, 'behavior_loss': 0.27455854415893555, 'mean_batch': 5.081017875671387, 'min_batch': 4.969682693481445, 'max_batch': 5.220285081863404}
step: 16950 @ episode report: {'average_total_reward': 9.988001, 'reward_variance': 4.2782373, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.628517311811447, 'actor_loss': -4.877637672424316, 'hyper_actor_loss': 0.0284012695774436, 'behavior_loss': 0.290942956507206, 'mean_batch': 5.177834224700928, 'min_batch': 5.072551584243774, 'max_batch': 5.31690526008606}
step: 16960 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 3.9511364, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1505305886268617, 'actor_loss': -4.844763898849488, 'hyper_actor_loss': 0.0285390792414546, 'behavior_loss': 0.28398519903421404, 'mean_batch': 5.0916729927062985, 'min_batch': 4.991976356506347, 'max_batch': 5.188072967529297}
step: 16970 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.5838649, 'max_total_reward': 12.12, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.811605978012085, 'actor_loss': -4.833254098892212, 'hyper_actor_loss': 0.02867945935577154, 'behavior_loss': 0.29756124764680864, 'mean_batch': 5.054076147079468, 'min_batch': 4.971190786361694, 'max_batch': 5.151324224472046}
step: 16980 @ episode report: {'average_total_reward': 10.409001, 'reward_variance': 2.2937896, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7909049987792969, 'actor_loss': -4.861360216140747, 'hyper_actor_loss': 0.02880752384662628, 'behavior_loss': 0.28095243573188783, 'mean_batch': 5.118369293212891, 'min_batch': 5.048505735397339, 'max_batch': 5.219277858734131}
step: 16990 @ episode report: {'average_total_reward': 11.83, 'reward_variance': 6.0902996, 'max_total_reward': 15.45, 'min_total_reward': 5.79, 'average_n_step': 12.6, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7672143459320069, 'actor_loss': -4.8615516185760494, 'hyper_actor_loss': 0.028685185313224792, 'behavior_loss': 0.26426963359117506, 'mean_batch': 5.132771158218384, 'min_batch': 5.035305023193359, 'max_batch': 5.235380744934082}
step: 17000 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 3.4530292, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8502915024757385, 'actor_loss': -4.85534896850586, 'hyper_actor_loss': 0.028604279831051828, 'behavior_loss': 0.28236610591411593, 'mean_batch': 5.117162132263184, 'min_batch': 5.019459915161133, 'max_batch': 5.2069145202636715}
step: 17010 @ episode report: {'average_total_reward': 9.888, 'reward_variance': 1.7515161, 'max_total_reward': 13.45, 'min_total_reward': 8.57, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8060214638710022, 'actor_loss': -4.838212347030639, 'hyper_actor_loss': 0.028632189705967905, 'behavior_loss': 0.27489528656005857, 'mean_batch': 5.0759584426879885, 'min_batch': 4.974210548400879, 'max_batch': 5.174750852584839}
step: 17020 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 3.2277966, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9851834297180175, 'actor_loss': -4.842451524734497, 'hyper_actor_loss': 0.02846008539199829, 'behavior_loss': 0.28837539851665495, 'mean_batch': 5.083403253555298, 'min_batch': 4.988001298904419, 'max_batch': 5.161620187759399}
step: 17030 @ episode report: {'average_total_reward': 10.410001, 'reward_variance': 1.5477802, 'max_total_reward': 12.340001, 'min_total_reward': 8.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8502768516540526, 'actor_loss': -4.8395833492279055, 'hyper_actor_loss': 0.02849131226539612, 'behavior_loss': 0.28388727754354476, 'mean_batch': 5.0733418464660645, 'min_batch': 4.98355507850647, 'max_batch': 5.179758787155151}
step: 17040 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.3706455, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9812296032905579, 'actor_loss': -4.83752064704895, 'hyper_actor_loss': 0.028462965600192548, 'behavior_loss': 0.27136273980140685, 'mean_batch': 5.0746715545654295, 'min_batch': 4.9719898223876955, 'max_batch': 5.147749710083008}
step: 17050 @ episode report: {'average_total_reward': 8.866, 'reward_variance': 3.8875644, 'max_total_reward': 12.340001, 'min_total_reward': 4.68, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6383516788482666, 'actor_loss': -4.848395729064942, 'hyper_actor_loss': 0.02843901813030243, 'behavior_loss': 0.2783506914973259, 'mean_batch': 5.102063131332398, 'min_batch': 4.999500036239624, 'max_batch': 5.176386928558349}
step: 17060 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 3.9858558, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7598656475543977, 'actor_loss': -4.873453950881958, 'hyper_actor_loss': 0.028366517461836337, 'behavior_loss': 0.2943368062376976, 'mean_batch': 5.1659482479095455, 'min_batch': 5.062867164611816, 'max_batch': 5.245115184783936}
step: 17070 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 0.5769444, 'max_total_reward': 11.2300005, 'min_total_reward': 9.009999, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0612587213516234, 'actor_loss': -4.843192291259766, 'hyper_actor_loss': 0.028259685821831228, 'behavior_loss': 0.2832970008254051, 'mean_batch': 5.083941030502319, 'min_batch': 4.991397094726563, 'max_batch': 5.1509991645812985}
step: 17080 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 2.1085012, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.092194902896881, 'actor_loss': -4.8156211376190186, 'hyper_actor_loss': 0.028640067763626577, 'behavior_loss': 0.2897320672869682, 'mean_batch': 5.006655359268189, 'min_batch': 4.930388402938843, 'max_batch': 5.064119291305542}
step: 17090 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.6367449, 'max_total_reward': 13.45, 'min_total_reward': 8.68, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0224605083465574, 'actor_loss': -4.816922760009765, 'hyper_actor_loss': 0.02844742015004158, 'behavior_loss': 0.2777748480439186, 'mean_batch': 5.012971878051758, 'min_batch': 4.9305860042572025, 'max_batch': 5.069086265563965}
step: 17100 @ episode report: {'average_total_reward': 9.532, 'reward_variance': 4.5411763, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7398568272590638, 'actor_loss': -4.828784990310669, 'hyper_actor_loss': 0.028446871787309647, 'behavior_loss': 0.2839809000492096, 'mean_batch': 5.039662790298462, 'min_batch': 4.96305627822876, 'max_batch': 5.0925819873809814}
step: 17110 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 4.005529, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.91464102268219, 'actor_loss': -4.849653816223144, 'hyper_actor_loss': 0.028320123627781867, 'behavior_loss': 0.28809245824813845, 'mean_batch': 5.099209833145141, 'min_batch': 5.008541917800903, 'max_batch': 5.161531925201416}
step: 17120 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 3.6023998, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.883368146419525, 'actor_loss': -4.837953996658325, 'hyper_actor_loss': 0.028378336131572722, 'behavior_loss': 0.2915515601634979, 'mean_batch': 5.06606125831604, 'min_batch': 4.982618093490601, 'max_batch': 5.159851026535034}
step: 17130 @ episode report: {'average_total_reward': 10.210001, 'reward_variance': 4.3588204, 'max_total_reward': 13.34, 'min_total_reward': 5.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8703782379627227, 'actor_loss': -4.84963436126709, 'hyper_actor_loss': 0.0284755589440465, 'behavior_loss': 0.27268418073654177, 'mean_batch': 5.095189046859741, 'min_batch': 5.012401866912842, 'max_batch': 5.152660942077636}
step: 17140 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 7.406925, 'max_total_reward': 13.2300005, 'min_total_reward': 3.46, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0032238721847535, 'actor_loss': -4.822669649124146, 'hyper_actor_loss': 0.02838178314268589, 'behavior_loss': 0.3037258476018906, 'mean_batch': 5.031319856643677, 'min_batch': 4.941149950027466, 'max_batch': 5.095425081253052}
step: 17150 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 3.2866848, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9388507604599, 'actor_loss': -4.8198024272918705, 'hyper_actor_loss': 0.02840667087584734, 'behavior_loss': 0.27843406349420546, 'mean_batch': 5.012951421737671, 'min_batch': 4.944882249832153, 'max_batch': 5.091821193695068}
step: 17160 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 2.9367557, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9261611580848694, 'actor_loss': -4.825178813934326, 'hyper_actor_loss': 0.028453056141734122, 'behavior_loss': 0.2729811370372772, 'mean_batch': 5.0295717239379885, 'min_batch': 4.955128335952759, 'max_batch': 5.087175941467285}
step: 17170 @ episode report: {'average_total_reward': 9.2439995, 'reward_variance': 2.5288036, 'max_total_reward': 12.2300005, 'min_total_reward': 6.680001, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0738223433494567, 'actor_loss': -4.841694498062134, 'hyper_actor_loss': 0.02825228814035654, 'behavior_loss': 0.29648766219615935, 'mean_batch': 5.0834245681762695, 'min_batch': 4.98431167602539, 'max_batch': 5.133940076828003}
step: 17180 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 2.2060657, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9339315295219421, 'actor_loss': -4.803707027435303, 'hyper_actor_loss': 0.028221599757671356, 'behavior_loss': 0.2803175300359726, 'mean_batch': 4.984217262268066, 'min_batch': 4.894217538833618, 'max_batch': 5.039381837844848}
step: 17190 @ episode report: {'average_total_reward': 8.766001, 'reward_variance': 6.0545435, 'max_total_reward': 11.23, 'min_total_reward': 2.3500001, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.944027054309845, 'actor_loss': -4.802361869812012, 'hyper_actor_loss': 0.028256801888346672, 'behavior_loss': 0.2846060410141945, 'mean_batch': 4.983752632141114, 'min_batch': 4.887976408004761, 'max_batch': 5.0261493682861325}
step: 17200 @ episode report: {'average_total_reward': 9.543, 'reward_variance': 4.67468, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6945526361465455, 'actor_loss': -4.834072303771973, 'hyper_actor_loss': 0.028081304766237734, 'behavior_loss': 0.2661992982029915, 'mean_batch': 5.0595314502716064, 'min_batch': 4.96987771987915, 'max_batch': 5.114262199401855}
step: 17210 @ episode report: {'average_total_reward': 8.611, 'reward_variance': 2.1743093, 'max_total_reward': 11.01, 'min_total_reward': 5.57, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9196277976036071, 'actor_loss': -4.836060905456543, 'hyper_actor_loss': 0.027753574959933757, 'behavior_loss': 0.26599692106246947, 'mean_batch': 5.055858325958252, 'min_batch': 4.983286333084107, 'max_batch': 5.114474058151245}
step: 17220 @ episode report: {'average_total_reward': 9.544001, 'reward_variance': 6.184703, 'max_total_reward': 13.23, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7211388885974883, 'actor_loss': -4.83183183670044, 'hyper_actor_loss': 0.027584923431277275, 'behavior_loss': 0.2949645683169365, 'mean_batch': 5.033417797088623, 'min_batch': 4.9843635082244875, 'max_batch': 5.084328556060791}
step: 17230 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 5.039485, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.509363266825676, 'actor_loss': -4.868657398223877, 'hyper_actor_loss': 0.027651821076869965, 'behavior_loss': 0.2738048166036606, 'mean_batch': 5.1333091259002686, 'min_batch': 5.070901489257812, 'max_batch': 5.185589981079102}
step: 17240 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 1.8818557, 'max_total_reward': 13.34, 'min_total_reward': 7.57, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.495199626684189, 'actor_loss': -4.870324230194091, 'hyper_actor_loss': 0.02760927937924862, 'behavior_loss': 0.2862406328320503, 'mean_batch': 5.138549041748047, 'min_batch': 5.074030923843384, 'max_batch': 5.219913578033447}
step: 17250 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.2110043, 'max_total_reward': 12.230001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5254396736621856, 'actor_loss': -4.869531679153442, 'hyper_actor_loss': 0.027605058811604976, 'behavior_loss': 0.2661069005727768, 'mean_batch': 5.138277816772461, 'min_batch': 5.0702043056488035, 'max_batch': 5.213642835617065}
step: 17260 @ episode report: {'average_total_reward': 10.542, 'reward_variance': 4.9014773, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6060574054718018, 'actor_loss': -4.872848272323608, 'hyper_actor_loss': 0.027392465621232986, 'behavior_loss': 0.27043401151895524, 'mean_batch': 5.14285945892334, 'min_batch': 5.082518291473389, 'max_batch': 5.247895908355713}
step: 17270 @ episode report: {'average_total_reward': 10.465, 'reward_variance': 4.8834257, 'max_total_reward': 13.340001, 'min_total_reward': 5.68, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4663980334997178, 'actor_loss': -4.8728346824646, 'hyper_actor_loss': 0.02712240144610405, 'behavior_loss': 0.273033994436264, 'mean_batch': 5.138974046707153, 'min_batch': 5.0862650871276855, 'max_batch': 5.233046960830689}
step: 17280 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 4.553417, 'max_total_reward': 14.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1115081191062925, 'actor_loss': -4.8819029331207275, 'hyper_actor_loss': 0.027192323841154574, 'behavior_loss': 0.27475323528051376, 'mean_batch': 5.162466526031494, 'min_batch': 5.109434413909912, 'max_batch': 5.2216040134429935}
step: 17290 @ episode report: {'average_total_reward': 10.11, 'reward_variance': 3.5544, 'max_total_reward': 12.01, 'min_total_reward': 5.46, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.761621505022049, 'actor_loss': -4.814422369003296, 'hyper_actor_loss': 0.027003826946020125, 'behavior_loss': 0.27289807945489886, 'mean_batch': 4.994734859466552, 'min_batch': 4.936513805389405, 'max_batch': 5.022805118560791}
step: 17300 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 1.7274818, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7600512742996215, 'actor_loss': -4.830317831039428, 'hyper_actor_loss': 0.027127116359770297, 'behavior_loss': 0.2770588085055351, 'mean_batch': 5.039957046508789, 'min_batch': 4.970667743682862, 'max_batch': 5.069743728637695}
step: 17310 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 4.463006, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6242820918560028, 'actor_loss': -4.8567524433135985, 'hyper_actor_loss': 0.02693107966333628, 'behavior_loss': 0.2782556042075157, 'mean_batch': 5.108290481567383, 'min_batch': 5.035224199295044, 'max_batch': 5.14260311126709}
step: 17320 @ episode report: {'average_total_reward': 8.7, 'reward_variance': 1.5480998, 'max_total_reward': 10.12, 'min_total_reward': 5.79, 'average_n_step': 9.8, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6540496349334717, 'actor_loss': -4.861321449279785, 'hyper_actor_loss': 0.026933605410158636, 'behavior_loss': 0.2662346810102463, 'mean_batch': 5.125473356246948, 'min_batch': 5.041302967071533, 'max_batch': 5.167802524566651}
step: 17330 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 2.3685453, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.693518614768982, 'actor_loss': -4.857284736633301, 'hyper_actor_loss': 0.02672588136047125, 'behavior_loss': 0.2676154151558876, 'mean_batch': 5.122184371948242, 'min_batch': 5.024231624603272, 'max_batch': 5.166424036026001}
step: 17340 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 3.4075418, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6714715719223023, 'actor_loss': -4.864173746109008, 'hyper_actor_loss': 0.02670672591775656, 'behavior_loss': 0.28770813941955564, 'mean_batch': 5.126314115524292, 'min_batch': 5.05486421585083, 'max_batch': 5.161333227157593}
step: 17350 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 3.7994606, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9043883979320526, 'actor_loss': -4.83879861831665, 'hyper_actor_loss': 0.026678833924233914, 'behavior_loss': 0.2880013436079025, 'mean_batch': 5.0628900051116945, 'min_batch': 4.990154981613159, 'max_batch': 5.100845146179199}
step: 17360 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 2.959376, 'max_total_reward': 13.34, 'min_total_reward': 6.68, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8925833523273468, 'actor_loss': -4.837603187561035, 'hyper_actor_loss': 0.02683127988129854, 'behavior_loss': 0.282750204205513, 'mean_batch': 5.062838745117188, 'min_batch': 4.984058141708374, 'max_batch': 5.102108430862427}
step: 17370 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 1.7948053, 'max_total_reward': 11.230001, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9347798585891725, 'actor_loss': -4.840602254867553, 'hyper_actor_loss': 0.026715164259076118, 'behavior_loss': 0.2807168960571289, 'mean_batch': 5.067419052124023, 'min_batch': 4.994482755661011, 'max_batch': 5.1008138179779055}
step: 17380 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 2.8399408, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6309403896331787, 'actor_loss': -4.8331849575042725, 'hyper_actor_loss': 0.026948976702988146, 'behavior_loss': 0.28587257117033005, 'mean_batch': 5.048882055282593, 'min_batch': 4.975814390182495, 'max_batch': 5.101711320877075}
step: 17390 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 3.3117805, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.877560591697693, 'actor_loss': -4.858897733688354, 'hyper_actor_loss': 0.02671305574476719, 'behavior_loss': 0.2789771109819412, 'mean_batch': 5.112394952774048, 'min_batch': 5.041993093490601, 'max_batch': 5.172684144973755}
step: 17400 @ episode report: {'average_total_reward': 10.720001, 'reward_variance': 1.0061002, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9997049212455749, 'actor_loss': -4.847218322753906, 'hyper_actor_loss': 0.026759857684373854, 'behavior_loss': 0.2901012241840363, 'mean_batch': 5.083089923858642, 'min_batch': 5.012335252761841, 'max_batch': 5.125909757614136}
step: 17410 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 2.1572814, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5295129060745238, 'actor_loss': -4.8147965431213375, 'hyper_actor_loss': 0.02677573598921299, 'behavior_loss': 0.28495771139860154, 'mean_batch': 5.003427362442016, 'min_batch': 4.929617786407471, 'max_batch': 5.0678300857543945}
step: 17420 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 3.2863624, 'max_total_reward': 13.340001, 'min_total_reward': 6.7899995, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.87622172832489, 'actor_loss': -4.874156093597412, 'hyper_actor_loss': 0.02658107578754425, 'behavior_loss': 0.26309930384159086, 'mean_batch': 5.1561079025268555, 'min_batch': 5.076305770874024, 'max_batch': 5.2523908615112305}
step: 17430 @ episode report: {'average_total_reward': 9.666, 'reward_variance': 1.2942839, 'max_total_reward': 11.23, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.914591097831726, 'actor_loss': -4.841126203536987, 'hyper_actor_loss': 0.02647577989846468, 'behavior_loss': 0.2814613595604897, 'mean_batch': 5.064642477035522, 'min_batch': 5.000115299224854, 'max_batch': 5.162149715423584}
step: 17440 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 3.3732247, 'max_total_reward': 11.2300005, 'min_total_reward': 4.57, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6593204736709595, 'actor_loss': -4.841155481338501, 'hyper_actor_loss': 0.026533797010779382, 'behavior_loss': 0.29151562303304673, 'mean_batch': 5.056930351257324, 'min_batch': 5.007730102539062, 'max_batch': 5.14239468574524}
step: 17450 @ episode report: {'average_total_reward': 10.132, 'reward_variance': 3.2518356, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6493164896965027, 'actor_loss': -4.876524925231934, 'hyper_actor_loss': 0.026611443050205706, 'behavior_loss': 0.27796711325645446, 'mean_batch': 5.146938180923462, 'min_batch': 5.0973358154296875, 'max_batch': 5.246920776367188}
step: 17460 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 5.2710094, 'max_total_reward': 12.34, 'min_total_reward': 4.5699997, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9540964484214782, 'actor_loss': -4.846219396591186, 'hyper_actor_loss': 0.02664343286305666, 'behavior_loss': 0.28041496872901917, 'mean_batch': 5.07275767326355, 'min_batch': 5.0177679538726805, 'max_batch': 5.185062742233276}
step: 17470 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 1.2613614, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6396638095378875, 'actor_loss': -4.853706645965576, 'hyper_actor_loss': 0.02674993947148323, 'behavior_loss': 0.27397053092718127, 'mean_batch': 5.094608020782471, 'min_batch': 5.033489751815796, 'max_batch': 5.248623418807983}
step: 17480 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 3.4920895, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.010976052284241, 'actor_loss': -4.858472204208374, 'hyper_actor_loss': 0.0266651077196002, 'behavior_loss': 0.27807149291038513, 'mean_batch': 5.103160953521728, 'min_batch': 5.049067592620849, 'max_batch': 5.218963956832885}
step: 17490 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 2.261444, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6174293279647827, 'actor_loss': -4.851034832000733, 'hyper_actor_loss': 0.026755044981837273, 'behavior_loss': 0.27905079424381257, 'mean_batch': 5.083375740051269, 'min_batch': 5.031068420410156, 'max_batch': 5.2106259822845455}
step: 17500 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 4.5287886, 'max_total_reward': 13.45, 'min_total_reward': 5.6800003, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8636919498443603, 'actor_loss': -4.865158891677856, 'hyper_actor_loss': 0.026596989296376706, 'behavior_loss': 0.28253224939107896, 'mean_batch': 5.12520956993103, 'min_batch': 5.06093430519104, 'max_batch': 5.220400953292847}
step: 17510 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 1.8644419, 'max_total_reward': 11.230001, 'min_total_reward': 6.7899995, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9859548687934876, 'actor_loss': -4.841809177398682, 'hyper_actor_loss': 0.026574268005788326, 'behavior_loss': 0.2829635888338089, 'mean_batch': 5.063830089569092, 'min_batch': 5.004165124893189, 'max_batch': 5.118638944625855}
step: 17520 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 5.255056, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.030167579650879, 'actor_loss': -4.821866464614868, 'hyper_actor_loss': 0.026675550267100334, 'behavior_loss': 0.26698714643716814, 'mean_batch': 5.007673740386963, 'min_batch': 4.960250759124756, 'max_batch': 5.036485481262207}
step: 17530 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 7.5360403, 'max_total_reward': 12.2300005, 'min_total_reward': 4.68, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8766792297363282, 'actor_loss': -4.8294957160949705, 'hyper_actor_loss': 0.0265001205727458, 'behavior_loss': 0.2759139880537987, 'mean_batch': 5.0264581680297855, 'min_batch': 4.979600191116333, 'max_batch': 5.062462234497071}
step: 17540 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 4.888424, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.943810760974884, 'actor_loss': -4.827534818649292, 'hyper_actor_loss': 0.026308026909828187, 'behavior_loss': 0.2707583487033844, 'mean_batch': 5.0313325881958, 'min_batch': 4.965032482147217, 'max_batch': 5.060573387145996}
step: 17550 @ episode report: {'average_total_reward': 8.788, 'reward_variance': 4.422595, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6935294032096864, 'actor_loss': -4.845706796646118, 'hyper_actor_loss': 0.02630276344716549, 'behavior_loss': 0.2737161561846733, 'mean_batch': 5.073896503448486, 'min_batch': 5.0138873100280765, 'max_batch': 5.109536790847779}
step: 17560 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 3.2386098, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9816282033920287, 'actor_loss': -4.846381950378418, 'hyper_actor_loss': 0.02642942275851965, 'behavior_loss': 0.29730999767780303, 'mean_batch': 5.070705795288086, 'min_batch': 5.020357942581176, 'max_batch': 5.107919406890869}
step: 17570 @ episode report: {'average_total_reward': 10.543, 'reward_variance': 4.5110006, 'max_total_reward': 14.34, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9510942459106446, 'actor_loss': -4.819761562347412, 'hyper_actor_loss': 0.02641045246273279, 'behavior_loss': 0.2722613841295242, 'mean_batch': 5.001364135742188, 'min_batch': 4.956063461303711, 'max_batch': 5.050181818008423}
step: 17580 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 4.670104, 'max_total_reward': 14.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.030645513534546, 'actor_loss': -4.815190553665161, 'hyper_actor_loss': 0.026572982780635357, 'behavior_loss': 0.29659861475229266, 'mean_batch': 4.9952805519104, 'min_batch': 4.939480543136597, 'max_batch': 5.0816771507263185}
step: 17590 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 2.1713557, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6267895072698593, 'actor_loss': -4.831892013549805, 'hyper_actor_loss': 0.026596186496317387, 'behavior_loss': 0.28294454514980316, 'mean_batch': 5.041460990905762, 'min_batch': 4.976942777633667, 'max_batch': 5.1218475818634035}
step: 17600 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.4179409, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9386844217777253, 'actor_loss': -4.849982786178589, 'hyper_actor_loss': 0.02662898525595665, 'behavior_loss': 0.2906515672802925, 'mean_batch': 5.0842005729675295, 'min_batch': 5.024937534332276, 'max_batch': 5.204317283630371}
step: 17610 @ episode report: {'average_total_reward': 8.633, 'reward_variance': 5.438641, 'max_total_reward': 11.009999, 'min_total_reward': 2.46, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8242879509925842, 'actor_loss': -4.828939437866211, 'hyper_actor_loss': 0.02671795804053545, 'behavior_loss': 0.2948539510369301, 'mean_batch': 5.026957845687866, 'min_batch': 4.976332283020019, 'max_batch': 5.113437557220459}
step: 17620 @ episode report: {'average_total_reward': 8.466001, 'reward_variance': 4.293104, 'max_total_reward': 10.12, 'min_total_reward': 3.5700002, 'average_n_step': 9.5, 'max_n_step': 11.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.061464083194733, 'actor_loss': -4.820588397979736, 'hyper_actor_loss': 0.026756147667765618, 'behavior_loss': 0.28151280283927915, 'mean_batch': 5.00264310836792, 'min_batch': 4.958897066116333, 'max_batch': 5.083008527755737}
step: 17630 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.3481889, 'max_total_reward': 13.45, 'min_total_reward': 7.9000006, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4450564503669738, 'actor_loss': -4.840980958938599, 'hyper_actor_loss': 0.02666983138769865, 'behavior_loss': 0.29149308800697327, 'mean_batch': 5.055377435684204, 'min_batch': 5.008612012863159, 'max_batch': 5.130745124816895}
step: 17640 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 2.1013253, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2407407641410826, 'actor_loss': -4.845962905883789, 'hyper_actor_loss': 0.026644300296902658, 'behavior_loss': 0.27276946157217025, 'mean_batch': 5.066371011734009, 'min_batch': 5.022819566726684, 'max_batch': 5.142821359634399}
step: 17650 @ episode report: {'average_total_reward': 8.643999, 'reward_variance': 8.249264, 'max_total_reward': 12.339999, 'min_total_reward': 1.13, 'average_n_step': 9.7, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.725555682182312, 'actor_loss': -4.785948848724365, 'hyper_actor_loss': 0.02649821136146784, 'behavior_loss': 0.29439527690410616, 'mean_batch': 4.909535884857178, 'min_batch': 4.881000947952271, 'max_batch': 4.943933343887329}
step: 17660 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 1.8348205, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.97816241979599, 'actor_loss': -4.834753227233887, 'hyper_actor_loss': 0.026461158134043216, 'behavior_loss': 0.2728003814816475, 'mean_batch': 5.033285427093506, 'min_batch': 4.9995441913604735, 'max_batch': 5.0685460567474365}
step: 17670 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 3.7284646, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5786726593971252, 'actor_loss': -4.855281114578247, 'hyper_actor_loss': 0.02631706018000841, 'behavior_loss': 0.28041303902864456, 'mean_batch': 5.08763542175293, 'min_batch': 5.048181629180908, 'max_batch': 5.11938886642456}
step: 17680 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 3.234789, 'max_total_reward': 14.45, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8971071362495422, 'actor_loss': -4.834146642684937, 'hyper_actor_loss': 0.026058058813214303, 'behavior_loss': 0.2765926331281662, 'mean_batch': 5.03495683670044, 'min_batch': 4.994446849822998, 'max_batch': 5.082626628875732}
step: 17690 @ episode report: {'average_total_reward': 10.509, 'reward_variance': 0.81840956, 'max_total_reward': 11.2300005, 'min_total_reward': 8.899999, 'average_n_step': 11.4, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9244791626930238, 'actor_loss': -4.8143308639526365, 'hyper_actor_loss': 0.026051563397049903, 'behavior_loss': 0.2955713003873825, 'mean_batch': 4.985693836212159, 'min_batch': 4.94470853805542, 'max_batch': 5.030513000488281}
step: 17700 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 5.1074896, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0171136617660523, 'actor_loss': -4.806427001953125, 'hyper_actor_loss': 0.02615271005779505, 'behavior_loss': 0.28470602780580523, 'mean_batch': 4.967012500762939, 'min_batch': 4.924240350723267, 'max_batch': 5.006272220611573}
step: 17710 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.883445, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.614221179485321, 'actor_loss': -4.8148383617401125, 'hyper_actor_loss': 0.026101842522621155, 'behavior_loss': 0.2688640132546425, 'mean_batch': 4.988584423065186, 'min_batch': 4.9444952487945555, 'max_batch': 5.030597591400147}
step: 17720 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 3.604501, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7219828605651855, 'actor_loss': -4.84650731086731, 'hyper_actor_loss': 0.0260282164439559, 'behavior_loss': 0.2742933988571167, 'mean_batch': 5.074036741256714, 'min_batch': 5.017512035369873, 'max_batch': 5.126821374893188}
step: 17730 @ episode report: {'average_total_reward': 9.910001, 'reward_variance': 3.6565003, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8398978769779206, 'actor_loss': -4.8306389331817625, 'hyper_actor_loss': 0.025795945897698402, 'behavior_loss': 0.28520787954330445, 'mean_batch': 5.036111688613891, 'min_batch': 4.975788974761963, 'max_batch': 5.116617345809937}
step: 17740 @ episode report: {'average_total_reward': 10.608999, 'reward_variance': 3.399549, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.042667257785797, 'actor_loss': -4.810225534439087, 'hyper_actor_loss': 0.02578522264957428, 'behavior_loss': 0.28250053972005845, 'mean_batch': 4.985243082046509, 'min_batch': 4.924932765960693, 'max_batch': 5.061841821670532}
step: 17750 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 4.5745616, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.156826615333557, 'actor_loss': -4.784426212310791, 'hyper_actor_loss': 0.02588115315884352, 'behavior_loss': 0.27674937546253203, 'mean_batch': 4.917271327972412, 'min_batch': 4.865826416015625, 'max_batch': 4.98381495475769}
step: 17760 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.7802246, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6127434074878693, 'actor_loss': -4.793092584609985, 'hyper_actor_loss': 0.02570297885686159, 'behavior_loss': 0.296789687871933, 'mean_batch': 4.939487934112549, 'min_batch': 4.886303424835205, 'max_batch': 5.009224081039429}
step: 17770 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 3.5449016, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.897255539894104, 'actor_loss': -4.829450082778931, 'hyper_actor_loss': 0.025710931792855263, 'behavior_loss': 0.2920221984386444, 'mean_batch': 5.028674697875976, 'min_batch': 4.977132558822632, 'max_batch': 5.08064374923706}
step: 17780 @ episode report: {'average_total_reward': 11.108, 'reward_variance': 2.7713163, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9802100777626037, 'actor_loss': -4.810700368881226, 'hyper_actor_loss': 0.025902549363672735, 'behavior_loss': 0.2923070877790451, 'mean_batch': 4.975631618499756, 'min_batch': 4.936847686767578, 'max_batch': 5.018468379974365}
step: 17790 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 4.3307204, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.790864259004593, 'actor_loss': -4.799996089935303, 'hyper_actor_loss': 0.025605645962059498, 'behavior_loss': 0.2688253954052925, 'mean_batch': 4.948959255218506, 'min_batch': 4.910567569732666, 'max_batch': 4.98948106765747}
step: 17800 @ episode report: {'average_total_reward': 9.543, 'reward_variance': 4.674682, 'max_total_reward': 14.56, 'min_total_reward': 6.7899995, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8419442892074585, 'actor_loss': -4.811603450775147, 'hyper_actor_loss': 0.02558415085077286, 'behavior_loss': 0.29781041741371156, 'mean_batch': 4.976756858825683, 'min_batch': 4.940094757080078, 'max_batch': 5.008137321472168}
step: 17810 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 5.0679007, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8835872650146483, 'actor_loss': -4.807205390930176, 'hyper_actor_loss': 0.025389282405376433, 'behavior_loss': 0.2785663574934006, 'mean_batch': 4.9668947696685795, 'min_batch': 4.9282002449035645, 'max_batch': 5.014131307601929}
step: 17820 @ episode report: {'average_total_reward': 9.178, 'reward_variance': 11.092616, 'max_total_reward': 12.34, 'min_total_reward': 0.58, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8987993359565736, 'actor_loss': -4.809684324264526, 'hyper_actor_loss': 0.025452447682619096, 'behavior_loss': 0.2813679128885269, 'mean_batch': 4.975354719161987, 'min_batch': 4.932017660140991, 'max_batch': 5.036998558044433}
step: 17830 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 0.95492935, 'max_total_reward': 12.12, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6454159498214722, 'actor_loss': -4.814528083801269, 'hyper_actor_loss': 0.02537019196897745, 'behavior_loss': 0.2867621198296547, 'mean_batch': 4.988194274902344, 'min_batch': 4.943226909637451, 'max_batch': 5.05032639503479}
step: 17840 @ episode report: {'average_total_reward': 8.789, 'reward_variance': 2.2186692, 'max_total_reward': 11.12, 'min_total_reward': 6.7899995, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.728388649225235, 'actor_loss': -4.826070785522461, 'hyper_actor_loss': 0.025407032668590547, 'behavior_loss': 0.28979586213827135, 'mean_batch': 5.016230678558349, 'min_batch': 4.9726427555084225, 'max_batch': 5.096578931808471}
step: 17850 @ episode report: {'average_total_reward': 9.743, 'reward_variance': 2.303801, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8214572250843049, 'actor_loss': -4.82458906173706, 'hyper_actor_loss': 0.025457866303622723, 'behavior_loss': 0.2900571644306183, 'mean_batch': 5.008928394317627, 'min_batch': 4.9726011753082275, 'max_batch': 5.090837287902832}
step: 17860 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.0533853, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8941807389259337, 'actor_loss': -4.797284555435181, 'hyper_actor_loss': 0.025419178418815136, 'behavior_loss': 0.2850879967212677, 'mean_batch': 4.938757133483887, 'min_batch': 4.907352113723755, 'max_batch': 5.0173828125}
step: 17870 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 3.6467006, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5393924325704575, 'actor_loss': -4.820735120773316, 'hyper_actor_loss': 0.025406141020357608, 'behavior_loss': 0.2934220552444458, 'mean_batch': 4.997842645645141, 'min_batch': 4.964573240280151, 'max_batch': 5.062500953674316}
step: 17880 @ episode report: {'average_total_reward': 10.265, 'reward_variance': 3.1004853, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4381137669086457, 'actor_loss': -4.849878358840942, 'hyper_actor_loss': 0.025422822311520578, 'behavior_loss': 0.2839640140533447, 'mean_batch': 5.073377990722657, 'min_batch': 5.0351399898529055, 'max_batch': 5.1405364036560055}
step: 17890 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 3.6400638, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3149775832891464, 'actor_loss': -4.8699719429016115, 'hyper_actor_loss': 0.025224603712558746, 'behavior_loss': 0.25891179889440535, 'mean_batch': 5.123982095718384, 'min_batch': 5.086562871932983, 'max_batch': 5.21036958694458}
step: 17900 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 2.2891417, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6957669854164124, 'actor_loss': -4.856387901306152, 'hyper_actor_loss': 0.024919206462800502, 'behavior_loss': 0.28998959213495257, 'mean_batch': 5.08870301246643, 'min_batch': 5.052831315994263, 'max_batch': 5.159140253067017}
step: 17910 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.4960413, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0492555260658265, 'actor_loss': -4.817901134490967, 'hyper_actor_loss': 0.024830393120646478, 'behavior_loss': 0.2567134737968445, 'mean_batch': 4.987523746490479, 'min_batch': 4.960816240310669, 'max_batch': 5.053377342224121}
step: 17920 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 1.3453157, 'max_total_reward': 11.23, 'min_total_reward': 6.6800003, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6180198669433594, 'actor_loss': -4.787466239929199, 'hyper_actor_loss': 0.024534430541098117, 'behavior_loss': 0.2730610728263855, 'mean_batch': 4.910395240783691, 'min_batch': 4.887554168701172, 'max_batch': 4.951824474334717}
step: 17930 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 6.987345, 'max_total_reward': 14.450001, 'min_total_reward': 6.680001, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8028238281607627, 'actor_loss': -4.83915638923645, 'hyper_actor_loss': 0.02441112119704485, 'behavior_loss': 0.27532679587602615, 'mean_batch': 5.042910099029541, 'min_batch': 5.011608982086182, 'max_batch': 5.092316389083862}
step: 17940 @ episode report: {'average_total_reward': 9.921, 'reward_variance': 3.6355891, 'max_total_reward': 12.34, 'min_total_reward': 6.57, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5913293600082397, 'actor_loss': -4.841551208496094, 'hyper_actor_loss': 0.024467083252966405, 'behavior_loss': 0.2755095139145851, 'mean_batch': 5.050164985656738, 'min_batch': 5.016283273696899, 'max_batch': 5.09638409614563}
step: 17950 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 2.6567245, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6069368064403533, 'actor_loss': -4.856854724884033, 'hyper_actor_loss': 0.024468185752630232, 'behavior_loss': 0.27183297276496887, 'mean_batch': 5.089589786529541, 'min_batch': 5.054218864440918, 'max_batch': 5.141270017623901}
step: 17960 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 2.7410402, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.665007269382477, 'actor_loss': -4.8441556930542, 'hyper_actor_loss': 0.024472372233867647, 'behavior_loss': 0.28635574877262115, 'mean_batch': 5.053531312942505, 'min_batch': 5.026078796386718, 'max_batch': 5.1243397235870365}
step: 17970 @ episode report: {'average_total_reward': 9.344, 'reward_variance': 1.5130638, 'max_total_reward': 11.12, 'min_total_reward': 6.7900004, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4352861762046814, 'actor_loss': -4.839882040023804, 'hyper_actor_loss': 0.024545338936150074, 'behavior_loss': 0.2827400639653206, 'mean_batch': 5.0441032409667965, 'min_batch': 5.014027070999146, 'max_batch': 5.1106178760528564}
step: 17980 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 6.44187, 'max_total_reward': 14.34, 'min_total_reward': 5.5699997, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6413764834403992, 'actor_loss': -4.868302059173584, 'hyper_actor_loss': 0.02448358554393053, 'behavior_loss': 0.27065120190382, 'mean_batch': 5.117136478424072, 'min_batch': 5.084876966476441, 'max_batch': 5.194332790374756}
step: 17990 @ episode report: {'average_total_reward': 9.565001, 'reward_variance': 3.3918056, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.088252329826355, 'actor_loss': -4.820556592941284, 'hyper_actor_loss': 0.024471809342503547, 'behavior_loss': 0.2853263258934021, 'mean_batch': 4.9929771900177, 'min_batch': 4.96889967918396, 'max_batch': 5.061143589019776}
step: 18000 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 3.6185882, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0097192406654356, 'actor_loss': -4.780843496322632, 'hyper_actor_loss': 0.024454062804579735, 'behavior_loss': 0.29674509167671204, 'mean_batch': 4.891126441955566, 'min_batch': 4.874346971511841, 'max_batch': 4.950910139083862}
step: 18010 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 6.8965654, 'max_total_reward': 12.34, 'min_total_reward': 2.13, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4739820957183838, 'actor_loss': -4.827550792694092, 'hyper_actor_loss': 0.02442444544285536, 'behavior_loss': 0.27682480961084366, 'mean_batch': 5.010799264907837, 'min_batch': 4.986027956008911, 'max_batch': 5.0545378684997555}
step: 18020 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 5.678602, 'max_total_reward': 12.230001, 'min_total_reward': 5.68, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8130088567733764, 'actor_loss': -4.863606977462768, 'hyper_actor_loss': 0.024369559250772, 'behavior_loss': 0.270183365046978, 'mean_batch': 5.103355407714844, 'min_batch': 5.074726247787476, 'max_batch': 5.156998348236084}
step: 18030 @ episode report: {'average_total_reward': 10.698001, 'reward_variance': 1.8249562, 'max_total_reward': 13.34, 'min_total_reward': 8.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5207069009542464, 'actor_loss': -4.844257259368897, 'hyper_actor_loss': 0.024267316050827503, 'behavior_loss': 0.29246857613325117, 'mean_batch': 5.053710889816284, 'min_batch': 5.026348686218261, 'max_batch': 5.099487400054931}
step: 18040 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 7.7603087, 'max_total_reward': 12.2300005, 'min_total_reward': 1.3500001, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2764193296432493, 'actor_loss': -4.815362644195557, 'hyper_actor_loss': 0.024213897809386254, 'behavior_loss': 0.2904369801282883, 'mean_batch': 4.979016065597534, 'min_batch': 4.95691065788269, 'max_batch': 5.028685760498047}
step: 18050 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 10.7589245, 'max_total_reward': 12.339999, 'min_total_reward': 1.3499999, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7465255975723266, 'actor_loss': -4.778417158126831, 'hyper_actor_loss': 0.024096829071640968, 'behavior_loss': 0.2684352248907089, 'mean_batch': 4.886768960952759, 'min_batch': 4.866932344436646, 'max_batch': 4.949619340896606}
step: 18060 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 8.496897, 'max_total_reward': 12.34, 'min_total_reward': 2.46, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9140421628952027, 'actor_loss': -4.823353481292725, 'hyper_actor_loss': 0.024068604223430157, 'behavior_loss': 0.2896590054035187, 'mean_batch': 5.000493049621582, 'min_batch': 4.974839591979981, 'max_batch': 5.055652904510498}
step: 18070 @ episode report: {'average_total_reward': 11.242, 'reward_variance': 2.2661562, 'max_total_reward': 14.2300005, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.773817205429077, 'actor_loss': -4.825983619689941, 'hyper_actor_loss': 0.02411914002150297, 'behavior_loss': 0.28511941730976104, 'mean_batch': 5.005137157440186, 'min_batch': 4.983232641220093, 'max_batch': 5.0689088821411135}
step: 18080 @ episode report: {'average_total_reward': 11.397, 'reward_variance': 7.7417, 'max_total_reward': 15.67, 'min_total_reward': 6.6800003, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.850089168548584, 'actor_loss': -4.810646629333496, 'hyper_actor_loss': 0.024067567847669124, 'behavior_loss': 0.28429972380399704, 'mean_batch': 4.966684293746948, 'min_batch': 4.945403957366944, 'max_batch': 4.999375200271606}
step: 18090 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 5.415536, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7325348734855652, 'actor_loss': -4.8178342342376705, 'hyper_actor_loss': 0.024013995565474032, 'behavior_loss': 0.2664130315184593, 'mean_batch': 4.986562299728393, 'min_batch': 4.96129264831543, 'max_batch': 5.036217069625854}
step: 18100 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 5.665689, 'max_total_reward': 13.45, 'min_total_reward': 4.68, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6109735190868377, 'actor_loss': -4.840122842788697, 'hyper_actor_loss': 0.023819048516452314, 'behavior_loss': 0.2826657846570015, 'mean_batch': 5.045528078079224, 'min_batch': 5.013749504089356, 'max_batch': 5.090151071548462}
step: 18110 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 3.474296, 'max_total_reward': 12.340001, 'min_total_reward': 5.57, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8756497204303741, 'actor_loss': -4.830745029449463, 'hyper_actor_loss': 0.023853613063693047, 'behavior_loss': 0.30049038529396055, 'mean_batch': 5.024213027954102, 'min_batch': 4.988028717041016, 'max_batch': 5.071755027770996}
step: 18120 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 1.8173258, 'max_total_reward': 12.230001, 'min_total_reward': 7.68, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5550575256347656, 'actor_loss': -4.817104530334473, 'hyper_actor_loss': 0.023782487958669662, 'behavior_loss': 0.290575236082077, 'mean_batch': 4.98822054862976, 'min_batch': 4.955974864959717, 'max_batch': 5.042969703674316}
step: 18130 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 4.2933216, 'max_total_reward': 14.56, 'min_total_reward': 7.5700006, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6295940399169921, 'actor_loss': -4.838124322891235, 'hyper_actor_loss': 0.024058124981820583, 'behavior_loss': 0.2699515551328659, 'mean_batch': 5.03996057510376, 'min_batch': 5.00924711227417, 'max_batch': 5.090547847747803}
step: 18140 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 5.332326, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.722943764925003, 'actor_loss': -4.83831467628479, 'hyper_actor_loss': 0.023801743425428866, 'behavior_loss': 0.27273343950510026, 'mean_batch': 5.04075345993042, 'min_batch': 5.009411144256592, 'max_batch': 5.096699237823486}
step: 18150 @ episode report: {'average_total_reward': 9.698999, 'reward_variance': 4.3251886, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7780355870723725, 'actor_loss': -4.81907172203064, 'hyper_actor_loss': 0.023658920638263227, 'behavior_loss': 0.27723240703344343, 'mean_batch': 4.9914130687713625, 'min_batch': 4.962586545944214, 'max_batch': 5.049451541900635}
step: 18160 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 9.49901, 'max_total_reward': 16.78, 'min_total_reward': 5.57, 'average_n_step': 10.6, 'max_n_step': 17.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5400892943143845, 'actor_loss': -4.827230310440063, 'hyper_actor_loss': 0.023609894327819347, 'behavior_loss': 0.2770302012562752, 'mean_batch': 5.012791156768799, 'min_batch': 4.981941747665405, 'max_batch': 5.0776914119720455}
step: 18170 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 2.2339644, 'max_total_reward': 12.339999, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6753312408924104, 'actor_loss': -4.858543252944946, 'hyper_actor_loss': 0.023446667194366454, 'behavior_loss': 0.2663843870162964, 'mean_batch': 5.096975898742675, 'min_batch': 5.055483627319336, 'max_batch': 5.166754722595215}
step: 18180 @ episode report: {'average_total_reward': 9.809999, 'reward_variance': 4.1146207, 'max_total_reward': 13.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3919446170330048, 'actor_loss': -4.856708908081055, 'hyper_actor_loss': 0.023344678059220313, 'behavior_loss': 0.2768800139427185, 'mean_batch': 5.089214563369751, 'min_batch': 5.053838062286377, 'max_batch': 5.163211536407471}
step: 18190 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 3.3771405, 'max_total_reward': 13.339999, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.222897636890411, 'actor_loss': -4.825578355789185, 'hyper_actor_loss': 0.0235082870349288, 'behavior_loss': 0.2845930740237236, 'mean_batch': 5.010988235473633, 'min_batch': 4.976053619384766, 'max_batch': 5.075201511383057}
step: 18200 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 3.058965, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6575948119163513, 'actor_loss': -4.798687076568603, 'hyper_actor_loss': 0.023442255333065987, 'behavior_loss': 0.2734308123588562, 'mean_batch': 4.944007015228271, 'min_batch': 4.909077835083008, 'max_batch': 5.0069962501525875}
step: 18210 @ episode report: {'average_total_reward': 9.566, 'reward_variance': 1.2125438, 'max_total_reward': 10.9, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0121756911277773, 'actor_loss': -4.81743893623352, 'hyper_actor_loss': 0.02348320297896862, 'behavior_loss': 0.2896605834364891, 'mean_batch': 4.992073631286621, 'min_batch': 4.953761100769043, 'max_batch': 5.0376317501068115}
step: 18220 @ episode report: {'average_total_reward': 9.910001, 'reward_variance': 2.6662002, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7377410531044006, 'actor_loss': -4.8217860698699955, 'hyper_actor_loss': 0.023415684700012207, 'behavior_loss': 0.27520228922367096, 'mean_batch': 5.000021886825562, 'min_batch': 4.967464303970337, 'max_batch': 5.039938688278198}
step: 18230 @ episode report: {'average_total_reward': 8.622, 'reward_variance': 2.3060763, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3580782771110536, 'actor_loss': -4.8385673522949215, 'hyper_actor_loss': 0.023290646076202393, 'behavior_loss': 0.2865500748157501, 'mean_batch': 5.045226812362671, 'min_batch': 5.006312561035156, 'max_batch': 5.085859537124634}
step: 18240 @ episode report: {'average_total_reward': 9.853999, 'reward_variance': 4.8184843, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5149266123771667, 'actor_loss': -4.8518167495727536, 'hyper_actor_loss': 0.023415783978998662, 'behavior_loss': 0.28775388598442075, 'mean_batch': 5.080563688278199, 'min_batch': 5.0377359867095945, 'max_batch': 5.12552285194397}
step: 18250 @ episode report: {'average_total_reward': 9.266, 'reward_variance': 3.7917037, 'max_total_reward': 13.45, 'min_total_reward': 7.6799994, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9614699542522431, 'actor_loss': -4.84622631072998, 'hyper_actor_loss': 0.023404851369559766, 'behavior_loss': 0.2687196359038353, 'mean_batch': 5.06543550491333, 'min_batch': 5.024693489074707, 'max_batch': 5.1161023616790775}
step: 18260 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 5.5949945, 'max_total_reward': 14.339999, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8114733934402465, 'actor_loss': -4.821444082260132, 'hyper_actor_loss': 0.023218586295843124, 'behavior_loss': 0.2665012046694756, 'mean_batch': 5.000211524963379, 'min_batch': 4.965585327148437, 'max_batch': 5.052481460571289}
step: 18270 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 3.1899638, 'max_total_reward': 13.23, 'min_total_reward': 6.68, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8165398955345153, 'actor_loss': -4.821833562850952, 'hyper_actor_loss': 0.023121773079037667, 'behavior_loss': 0.2721139922738075, 'mean_batch': 5.001662349700927, 'min_batch': 4.966047382354736, 'max_batch': 5.047571229934692}
step: 18280 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 11.570109, 'max_total_reward': 16.67, 'min_total_reward': 4.68, 'average_n_step': 10.0, 'max_n_step': 17.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.532923126220703, 'actor_loss': -4.823238325119019, 'hyper_actor_loss': 0.02298618983477354, 'behavior_loss': 0.2867340460419655, 'mean_batch': 5.0096453666687015, 'min_batch': 4.965154314041138, 'max_batch': 5.056619596481323}
step: 18290 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.5226812, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8090519845485686, 'actor_loss': -4.8515191078186035, 'hyper_actor_loss': 0.02307496629655361, 'behavior_loss': 0.29083892703056335, 'mean_batch': 5.085444545745849, 'min_batch': 5.031428241729737, 'max_batch': 5.133442211151123}
step: 18300 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 5.342725, 'max_total_reward': 13.2300005, 'min_total_reward': 4.68, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.674374783039093, 'actor_loss': -4.834062910079956, 'hyper_actor_loss': 0.02320427317172289, 'behavior_loss': 0.27364293932914735, 'mean_batch': 5.03806357383728, 'min_batch': 4.990870666503906, 'max_batch': 5.08561954498291}
step: 18310 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 3.094676, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0751580476760862, 'actor_loss': -4.8276654243469235, 'hyper_actor_loss': 0.0233447328209877, 'behavior_loss': 0.2863041922450066, 'mean_batch': 5.016174077987671, 'min_batch': 4.9806884765625, 'max_batch': 5.058648586273193}
step: 18320 @ episode report: {'average_total_reward': 10.432001, 'reward_variance': 4.6939964, 'max_total_reward': 13.34, 'min_total_reward': 5.7899995, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8411599159240724, 'actor_loss': -4.80665078163147, 'hyper_actor_loss': 0.023355050571262838, 'behavior_loss': 0.28162809610366824, 'mean_batch': 4.962438106536865, 'min_batch': 4.929887914657593, 'max_batch': 5.016529178619384}
step: 18330 @ episode report: {'average_total_reward': 10.266001, 'reward_variance': 2.132544, 'max_total_reward': 12.34, 'min_total_reward': 7.57, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0556658267974854, 'actor_loss': -4.787717628479004, 'hyper_actor_loss': 0.023352434299886225, 'behavior_loss': 0.27916910499334335, 'mean_batch': 4.914657258987427, 'min_batch': 4.884461688995361, 'max_batch': 4.9586399555206295}
step: 18340 @ episode report: {'average_total_reward': 8.866, 'reward_variance': 2.8578844, 'max_total_reward': 10.120001, 'min_total_reward': 4.6800003, 'average_n_step': 9.9, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8613214254379273, 'actor_loss': -4.794345951080322, 'hyper_actor_loss': 0.023350847885012627, 'behavior_loss': 0.2754189983010292, 'mean_batch': 4.931033277511597, 'min_batch': 4.900658226013183, 'max_batch': 4.978137445449829}
step: 18350 @ episode report: {'average_total_reward': 8.977, 'reward_variance': 2.9934812, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7512071967124938, 'actor_loss': -4.819739770889282, 'hyper_actor_loss': 0.023194354213774204, 'behavior_loss': 0.27933360636234283, 'mean_batch': 4.998495197296142, 'min_batch': 4.958843946456909, 'max_batch': 5.032670164108277}
step: 18360 @ episode report: {'average_total_reward': 8.900001, 'reward_variance': 2.1733603, 'max_total_reward': 11.12, 'min_total_reward': 6.9, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9059012055397033, 'actor_loss': -4.834010934829712, 'hyper_actor_loss': 0.023094834573566914, 'behavior_loss': 0.27871149182319643, 'mean_batch': 5.036921644210816, 'min_batch': 4.991713428497315, 'max_batch': 5.087573051452637}
step: 18370 @ episode report: {'average_total_reward': 8.988, 'reward_variance': 3.1565557, 'max_total_reward': 12.23, 'min_total_reward': 6.79, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.756781381368637, 'actor_loss': -4.808517169952393, 'hyper_actor_loss': 0.023124664463102816, 'behavior_loss': 0.2735753238201141, 'mean_batch': 4.969420623779297, 'min_batch': 4.932170057296753, 'max_batch': 5.005527639389038}
step: 18380 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 1.4717009, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.249241900444031, 'actor_loss': -4.795978593826294, 'hyper_actor_loss': 0.023379562608897685, 'behavior_loss': 0.296791797876358, 'mean_batch': 4.9432151317596436, 'min_batch': 4.896653938293457, 'max_batch': 4.972515058517456}
step: 18390 @ episode report: {'average_total_reward': 9.910001, 'reward_variance': 4.8256598, 'max_total_reward': 14.56, 'min_total_reward': 6.7900004, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7078679740428924, 'actor_loss': -4.7948027610778805, 'hyper_actor_loss': 0.02335690539330244, 'behavior_loss': 0.26957972496747973, 'mean_batch': 4.9383679866790775, 'min_batch': 4.895714282989502, 'max_batch': 4.968460750579834}
step: 18400 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 5.80682, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0989245653152464, 'actor_loss': -4.794464159011841, 'hyper_actor_loss': 0.0233155470341444, 'behavior_loss': 0.29212812781333924, 'mean_batch': 4.941408443450928, 'min_batch': 4.891041326522827, 'max_batch': 4.978718519210815}
step: 18410 @ episode report: {'average_total_reward': 9.799001, 'reward_variance': 1.6596291, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6242897450923919, 'actor_loss': -4.790759706497193, 'hyper_actor_loss': 0.023325487785041333, 'behavior_loss': 0.3006918579339981, 'mean_batch': 4.942978382110596, 'min_batch': 4.871810626983643, 'max_batch': 5.198348045349121}
step: 18420 @ episode report: {'average_total_reward': 9.111, 'reward_variance': 1.9353094, 'max_total_reward': 11.12, 'min_total_reward': 6.5699997, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8479992508888246, 'actor_loss': -4.8117786884307865, 'hyper_actor_loss': 0.023565272241830824, 'behavior_loss': 0.2784311205148697, 'mean_batch': 5.014060640335083, 'min_batch': 4.905211925506592, 'max_batch': 5.389691972732544}
step: 18430 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.0186355, 'max_total_reward': 12.339999, 'min_total_reward': 6.9000006, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8426972210407258, 'actor_loss': -4.798471689224243, 'hyper_actor_loss': 0.023320365510880948, 'behavior_loss': 0.28932704627513883, 'mean_batch': 4.956600761413574, 'min_batch': 4.895496940612793, 'max_batch': 5.028836488723755}
step: 18440 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.1775594, 'max_total_reward': 12.23, 'min_total_reward': 6.9000006, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6156692683696747, 'actor_loss': -4.800898885726928, 'hyper_actor_loss': 0.023432927764952184, 'behavior_loss': 0.28174304962158203, 'mean_batch': 4.960277271270752, 'min_batch': 4.903783750534058, 'max_batch': 5.0419121265411375}
step: 18450 @ episode report: {'average_total_reward': 10.664, 'reward_variance': 4.2444654, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.097734820842743, 'actor_loss': -4.809481477737426, 'hyper_actor_loss': 0.023273067735135555, 'behavior_loss': 0.2743010953068733, 'mean_batch': 4.977000331878662, 'min_batch': 4.929491424560547, 'max_batch': 5.05027027130127}
step: 18460 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 2.659889, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8410445213317872, 'actor_loss': -4.784329795837403, 'hyper_actor_loss': 0.023108549974858762, 'behavior_loss': 0.281490196287632, 'mean_batch': 4.917242765426636, 'min_batch': 4.865368890762329, 'max_batch': 4.9947096824646}
step: 18470 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 2.2589011, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5140570536255837, 'actor_loss': -4.801891803741455, 'hyper_actor_loss': 0.022891406342387198, 'behavior_loss': 0.2741085857152939, 'mean_batch': 4.96278486251831, 'min_batch': 4.906398773193359, 'max_batch': 5.034494113922119}
step: 18480 @ episode report: {'average_total_reward': 8.167, 'reward_variance': 1.4204412, 'max_total_reward': 10.01, 'min_total_reward': 6.6800003, 'average_n_step': 9.3, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7989998817443849, 'actor_loss': -4.823655414581299, 'hyper_actor_loss': 0.022839728370308877, 'behavior_loss': 0.27586364597082136, 'mean_batch': 5.014994716644287, 'min_batch': 4.961878919601441, 'max_batch': 5.090669441223144}
step: 18490 @ episode report: {'average_total_reward': 8.067, 'reward_variance': 2.9471009, 'max_total_reward': 11.12, 'min_total_reward': 4.6800003, 'average_n_step': 9.2, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4662522077560425, 'actor_loss': -4.822173166275024, 'hyper_actor_loss': 0.02281330246478319, 'behavior_loss': 0.28172212094068527, 'mean_batch': 5.007111597061157, 'min_batch': 4.962373971939087, 'max_batch': 5.07549352645874}
step: 18500 @ episode report: {'average_total_reward': 8.844, 'reward_variance': 1.2873837, 'max_total_reward': 11.01, 'min_total_reward': 6.6800003, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3891388088464738, 'actor_loss': -4.843435335159302, 'hyper_actor_loss': 0.022993033565580846, 'behavior_loss': 0.28634533286094666, 'mean_batch': 5.064479827880859, 'min_batch': 5.011619329452515, 'max_batch': 5.132026481628418}
step: 18510 @ episode report: {'average_total_reward': 10.275999, 'reward_variance': 3.2156434, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.411133849620819, 'actor_loss': -4.852705621719361, 'hyper_actor_loss': 0.023009323887526988, 'behavior_loss': 0.2871493071317673, 'mean_batch': 5.086220741271973, 'min_batch': 5.036598110198975, 'max_batch': 5.157826280593872}
step: 18520 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 5.9785895, 'max_total_reward': 14.56, 'min_total_reward': 5.6800003, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.063674473762512, 'actor_loss': -4.827665901184082, 'hyper_actor_loss': 0.023091326653957366, 'behavior_loss': 0.2908486917614937, 'mean_batch': 5.025261545181275, 'min_batch': 4.972030925750732, 'max_batch': 5.08042197227478}
step: 18530 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 8.642116, 'max_total_reward': 12.340001, 'min_total_reward': 1.35, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.802635705471039, 'actor_loss': -4.762321043014526, 'hyper_actor_loss': 0.023076341301202775, 'behavior_loss': 0.28722773790359496, 'mean_batch': 4.8606500148773195, 'min_batch': 4.814989471435547, 'max_batch': 4.925427484512329}
step: 18540 @ episode report: {'average_total_reward': 8.833, 'reward_variance': 4.1145005, 'max_total_reward': 12.119999, 'min_total_reward': 4.6800003, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7548648774623872, 'actor_loss': -4.797610187530518, 'hyper_actor_loss': 0.023140998929738997, 'behavior_loss': 0.2818993926048279, 'mean_batch': 4.952753067016602, 'min_batch': 4.895628595352173, 'max_batch': 5.020118522644043}
step: 18550 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 6.40292, 'max_total_reward': 13.45, 'min_total_reward': 4.6800003, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9619925498962403, 'actor_loss': -4.8191139698028564, 'hyper_actor_loss': 0.023123000003397464, 'behavior_loss': 0.2811390146613121, 'mean_batch': 5.006411027908325, 'min_batch': 4.947950458526611, 'max_batch': 5.081622982025147}
step: 18560 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 2.911141, 'max_total_reward': 11.23, 'min_total_reward': 5.68, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7086830139160156, 'actor_loss': -4.799623489379883, 'hyper_actor_loss': 0.022963439859449864, 'behavior_loss': 0.27966928780078887, 'mean_batch': 4.9536748886108395, 'min_batch': 4.904018115997315, 'max_batch': 5.024628734588623}
step: 18570 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 5.550729, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5820868968963624, 'actor_loss': -4.811316442489624, 'hyper_actor_loss': 0.022904036566615105, 'behavior_loss': 0.28521660566329954, 'mean_batch': 4.982224225997925, 'min_batch': 4.933352756500244, 'max_batch': 5.041506433486939}
step: 18580 @ episode report: {'average_total_reward': 8.488999, 'reward_variance': 5.677949, 'max_total_reward': 13.34, 'min_total_reward': 5.57, 'average_n_step': 9.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5900178611278535, 'actor_loss': -4.840692186355591, 'hyper_actor_loss': 0.022856665030121803, 'behavior_loss': 0.27000088393688204, 'mean_batch': 5.055707883834839, 'min_batch': 5.006514930725098, 'max_batch': 5.103280258178711}
step: 18590 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.633109, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6835704863071441, 'actor_loss': -4.844200277328492, 'hyper_actor_loss': 0.02290250901132822, 'behavior_loss': 0.27561421543359754, 'mean_batch': 5.067183303833008, 'min_batch': 5.012754154205322, 'max_batch': 5.146615266799927}
step: 18600 @ episode report: {'average_total_reward': 9.544001, 'reward_variance': 3.0859838, 'max_total_reward': 12.12, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8404404044151306, 'actor_loss': -4.8093774795532225, 'hyper_actor_loss': 0.022909803502261638, 'behavior_loss': 0.27745281159877777, 'mean_batch': 4.980977296829224, 'min_batch': 4.92501163482666, 'max_batch': 5.039471817016602}
step: 18610 @ episode report: {'average_total_reward': 9.110001, 'reward_variance': 3.7154605, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5828350603580474, 'actor_loss': -4.803512191772461, 'hyper_actor_loss': 0.02276389952749014, 'behavior_loss': 0.27669116854667664, 'mean_batch': 4.966224336624146, 'min_batch': 4.9107543468475345, 'max_batch': 5.044618606567383}
step: 18620 @ episode report: {'average_total_reward': 8.8220005, 'reward_variance': 12.768076, 'max_total_reward': 12.34, 'min_total_reward': 1.24, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0051054418087007, 'actor_loss': -4.8289892196655275, 'hyper_actor_loss': 0.022752968408167363, 'behavior_loss': 0.27408902943134306, 'mean_batch': 5.033242511749267, 'min_batch': 4.970448398590088, 'max_batch': 5.11415548324585}
step: 18630 @ episode report: {'average_total_reward': 9.443, 'reward_variance': 5.9498014, 'max_total_reward': 13.45, 'min_total_reward': 4.5699997, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5348797678947448, 'actor_loss': -4.810202932357788, 'hyper_actor_loss': 0.022983638383448125, 'behavior_loss': 0.2737004354596138, 'mean_batch': 4.983777761459351, 'min_batch': 4.926264047622681, 'max_batch': 5.0630326747894285}
step: 18640 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 2.1326842, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8474117517471313, 'actor_loss': -4.830903148651123, 'hyper_actor_loss': 0.022979915514588355, 'behavior_loss': 0.27421135604381563, 'mean_batch': 5.035690593719482, 'min_batch': 4.977441644668579, 'max_batch': 5.115533018112183}
step: 18650 @ episode report: {'average_total_reward': 9.198999, 'reward_variance': 7.0702887, 'max_total_reward': 13.45, 'min_total_reward': 5.4599996, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4235412061214447, 'actor_loss': -4.8283162117004395, 'hyper_actor_loss': 0.023211783915758132, 'behavior_loss': 0.27970927208662033, 'mean_batch': 5.030747890472412, 'min_batch': 4.9695065975189205, 'max_batch': 5.1126624584198}
step: 18660 @ episode report: {'average_total_reward': 7.6560006, 'reward_variance': 5.2028646, 'max_total_reward': 11.23, 'min_total_reward': 3.5700002, 'average_n_step': 8.8, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.510686457157135, 'actor_loss': -4.871712255477905, 'hyper_actor_loss': 0.02304290682077408, 'behavior_loss': 0.2800088539719582, 'mean_batch': 5.145793676376343, 'min_batch': 5.073938941955566, 'max_batch': 5.25138373374939}
step: 18670 @ episode report: {'average_total_reward': 7.9450006, 'reward_variance': 1.7869651, 'max_total_reward': 10.12, 'min_total_reward': 5.79, 'average_n_step': 9.1, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9418107926845551, 'actor_loss': -4.849827909469605, 'hyper_actor_loss': 0.02308398988097906, 'behavior_loss': 0.290943968296051, 'mean_batch': 5.090666151046753, 'min_batch': 5.018184518814087, 'max_batch': 5.188182592391968}
step: 18680 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 2.7306564, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0691335678100584, 'actor_loss': -4.763411903381348, 'hyper_actor_loss': 0.0231601245701313, 'behavior_loss': 0.2776237830519676, 'mean_batch': 4.865855312347412, 'min_batch': 4.8154431819915775, 'max_batch': 4.957929611206055}
step: 18690 @ episode report: {'average_total_reward': 7.4229994, 'reward_variance': 2.4524007, 'max_total_reward': 10.12, 'min_total_reward': 4.6800003, 'average_n_step': 8.6, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8963441610336305, 'actor_loss': -4.773708391189575, 'hyper_actor_loss': 0.0233289809897542, 'behavior_loss': 0.28949748128652575, 'mean_batch': 4.894536113739013, 'min_batch': 4.836622714996338, 'max_batch': 5.005201101303101}
step: 18700 @ episode report: {'average_total_reward': 7.8229995, 'reward_variance': 2.649581, 'max_total_reward': 11.23, 'min_total_reward': 5.68, 'average_n_step': 9.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.800513792037964, 'actor_loss': -4.846097707748413, 'hyper_actor_loss': 0.023455283232033254, 'behavior_loss': 0.2919468730688095, 'mean_batch': 5.078724813461304, 'min_batch': 5.011219215393067, 'max_batch': 5.199466037750244}
step: 18710 @ episode report: {'average_total_reward': 6.8580003, 'reward_variance': 7.1850967, 'max_total_reward': 11.01, 'min_total_reward': 1.8000002, 'average_n_step': 8.2, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1356787621974944, 'actor_loss': -4.820759057998657, 'hyper_actor_loss': 0.023663492500782014, 'behavior_loss': 0.290071876347065, 'mean_batch': 5.009869194030761, 'min_batch': 4.9531731605529785, 'max_batch': 5.095102691650391}
step: 18720 @ episode report: {'average_total_reward': 5.7590003, 'reward_variance': 6.2549086, 'max_total_reward': 9.01, 'min_total_reward': 2.13, 'average_n_step': 7.2, 'max_n_step': 10.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.871088021993637, 'actor_loss': -4.756013822555542, 'hyper_actor_loss': 0.02388541176915169, 'behavior_loss': 0.2821841731667519, 'mean_batch': 4.855414819717407, 'min_batch': 4.789857292175293, 'max_batch': 4.94168791770935}
step: 18730 @ episode report: {'average_total_reward': 4.7920003, 'reward_variance': 2.014496, 'max_total_reward': 6.9, 'min_total_reward': 2.3500001, 'average_n_step': 6.2, 'max_n_step': 8.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8061486899852752, 'actor_loss': -4.794410943984985, 'hyper_actor_loss': 0.023753257095813753, 'behavior_loss': 0.2917835831642151, 'mean_batch': 4.9520628452301025, 'min_batch': 4.880742597579956, 'max_batch': 5.032874250411988}
step: 18740 @ episode report: {'average_total_reward': 5.991, 'reward_variance': 6.245309, 'max_total_reward': 11.23, 'min_total_reward': 2.3500001, 'average_n_step': 7.3, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7711145520210265, 'actor_loss': -4.8333698272705075, 'hyper_actor_loss': 0.0236918518319726, 'behavior_loss': 0.2844653606414795, 'mean_batch': 5.052660989761352, 'min_batch': 4.973001003265381, 'max_batch': 5.137769746780395}
step: 18750 @ episode report: {'average_total_reward': 7.8, 'reward_variance': 7.1820807, 'max_total_reward': 12.34, 'min_total_reward': 3.5700002, 'average_n_step': 8.9, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.554986935853958, 'actor_loss': -4.819077110290527, 'hyper_actor_loss': 0.02363116480410099, 'behavior_loss': 0.300094211101532, 'mean_batch': 5.02224702835083, 'min_batch': 4.932105684280396, 'max_batch': 5.1055440425872805}
step: 18760 @ episode report: {'average_total_reward': 7.435, 'reward_variance': 7.066644, 'max_total_reward': 13.009999, 'min_total_reward': 3.5700002, 'average_n_step': 8.7, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6445498049259186, 'actor_loss': -4.818384027481079, 'hyper_actor_loss': 0.0237118573859334, 'behavior_loss': 0.2912849962711334, 'mean_batch': 5.019492244720459, 'min_batch': 4.931407403945923, 'max_batch': 5.125970506668091}
step: 18770 @ episode report: {'average_total_reward': 6.912, 'reward_variance': 5.8865757, 'max_total_reward': 11.12, 'min_total_reward': 3.5700002, 'average_n_step': 8.1, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6807892560958861, 'actor_loss': -4.82701473236084, 'hyper_actor_loss': 0.023708795383572578, 'behavior_loss': 0.2888126730918884, 'mean_batch': 5.043022012710571, 'min_batch': 4.95095591545105, 'max_batch': 5.14607982635498}
step: 18780 @ episode report: {'average_total_reward': 9.078001, 'reward_variance': 3.7394555, 'max_total_reward': 12.119999, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5404263615608216, 'actor_loss': -4.842406606674194, 'hyper_actor_loss': 0.023703569918870925, 'behavior_loss': 0.28681462854146955, 'mean_batch': 5.073287487030029, 'min_batch': 4.997743225097656, 'max_batch': 5.149823570251465}
step: 18790 @ episode report: {'average_total_reward': 8.911, 'reward_variance': 1.903609, 'max_total_reward': 11.9, 'min_total_reward': 6.79, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6344346463680268, 'actor_loss': -4.846912288665772, 'hyper_actor_loss': 0.023670262843370437, 'behavior_loss': 0.2795346036553383, 'mean_batch': 5.081805610656739, 'min_batch': 5.011882591247558, 'max_batch': 5.163553190231323}
step: 18800 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 2.3355694, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7631901979446412, 'actor_loss': -4.817563915252686, 'hyper_actor_loss': 0.023548613488674163, 'behavior_loss': 0.2930009126663208, 'mean_batch': 5.007826709747315, 'min_batch': 4.938909816741943, 'max_batch': 5.086403846740723}
step: 18810 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 3.3542244, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.934769582748413, 'actor_loss': -4.805148649215698, 'hyper_actor_loss': 0.023546200059354306, 'behavior_loss': 0.29119855016469953, 'mean_batch': 4.978715467453003, 'min_batch': 4.90640606880188, 'max_batch': 5.074637031555175}
step: 18820 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 3.2334378, 'max_total_reward': 13.450002, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6211960315704346, 'actor_loss': -4.8118627071380615, 'hyper_actor_loss': 0.0235084081068635, 'behavior_loss': 0.29265893548727034, 'mean_batch': 4.99819712638855, 'min_batch': 4.920243597030639, 'max_batch': 5.0790839195251465}
step: 18830 @ episode report: {'average_total_reward': 9.887, 'reward_variance': 3.3748012, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9398000121116639, 'actor_loss': -4.808013963699341, 'hyper_actor_loss': 0.023487270064651965, 'behavior_loss': 0.29371754080057144, 'mean_batch': 4.997164726257324, 'min_batch': 4.9024245262146, 'max_batch': 5.072759008407592}
step: 18840 @ episode report: {'average_total_reward': 9.987, 'reward_variance': 2.9186616, 'max_total_reward': 12.340001, 'min_total_reward': 7.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8695476412773133, 'actor_loss': -4.801491022109985, 'hyper_actor_loss': 0.023518101312220097, 'behavior_loss': 0.2825737327337265, 'mean_batch': 4.9767392635345455, 'min_batch': 4.890439748764038, 'max_batch': 5.0276233673095705}
step: 18850 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 2.4179006, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.74654678106308, 'actor_loss': -4.8013652801513675, 'hyper_actor_loss': 0.02333145961165428, 'behavior_loss': 0.2806940242648125, 'mean_batch': 4.97683801651001, 'min_batch': 4.889729022979736, 'max_batch': 5.020884418487549}
step: 18860 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 4.25053, 'max_total_reward': 12.34, 'min_total_reward': 6.57, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5274420022964477, 'actor_loss': -4.827764177322388, 'hyper_actor_loss': 0.02286022398620844, 'behavior_loss': 0.2697344943881035, 'mean_batch': 5.047416543960571, 'min_batch': 4.950446844100952, 'max_batch': 5.089679336547851}
step: 18870 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 1.5561764, 'max_total_reward': 12.2300005, 'min_total_reward': 7.68, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6840359300374985, 'actor_loss': -4.852152395248413, 'hyper_actor_loss': 0.022696507908403874, 'behavior_loss': 0.2897937625646591, 'mean_batch': 5.116850709915161, 'min_batch': 5.003736209869385, 'max_batch': 5.161502456665039}
step: 18880 @ episode report: {'average_total_reward': 9.099001, 'reward_variance': 5.8168488, 'max_total_reward': 13.45, 'min_total_reward': 4.6800003, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0148555040359497, 'actor_loss': -4.7922991752624515, 'hyper_actor_loss': 0.022633360512554646, 'behavior_loss': 0.3032114267349243, 'mean_batch': 4.963117885589599, 'min_batch': 4.859825086593628, 'max_batch': 5.0080602169036865}
step: 18890 @ episode report: {'average_total_reward': 9.844, 'reward_variance': 2.5584242, 'max_total_reward': 13.34, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6847339689731597, 'actor_loss': -4.773196029663086, 'hyper_actor_loss': 0.022753807343542577, 'behavior_loss': 0.28542437851428987, 'mean_batch': 4.906807231903076, 'min_batch': 4.8218996047973635, 'max_batch': 4.9471564292907715}
step: 18900 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 1.539109, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4118832409381867, 'actor_loss': -4.847194004058838, 'hyper_actor_loss': 0.02271805554628372, 'behavior_loss': 0.2847241163253784, 'mean_batch': 5.092661428451538, 'min_batch': 5.00335693359375, 'max_batch': 5.130060720443725}
step: 18910 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 4.109417, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7691479802131653, 'actor_loss': -4.859006357192993, 'hyper_actor_loss': 0.02263247761875391, 'behavior_loss': 0.2680119648575783, 'mean_batch': 5.119389247894287, 'min_batch': 5.0356762409210205, 'max_batch': 5.1615763187408445}
step: 18920 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 4.6133566, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8852725148200988, 'actor_loss': -4.817736053466797, 'hyper_actor_loss': 0.022358205169439316, 'behavior_loss': 0.2895278960466385, 'mean_batch': 5.009042453765869, 'min_batch': 4.938697433471679, 'max_batch': 5.038790655136109}
step: 18930 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 3.9414284, 'max_total_reward': 13.45, 'min_total_reward': 7.5700006, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9120262265205383, 'actor_loss': -4.778979969024658, 'hyper_actor_loss': 0.02245647758245468, 'behavior_loss': 0.303980153799057, 'mean_batch': 4.9165795803070065, 'min_batch': 4.840095853805542, 'max_batch': 4.948040008544922}
step: 18940 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 6.319236, 'max_total_reward': 15.67, 'min_total_reward': 7.46, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4728872537612916, 'actor_loss': -4.805957651138305, 'hyper_actor_loss': 0.02242646850645542, 'behavior_loss': 0.27707707285881045, 'mean_batch': 4.982215929031372, 'min_batch': 4.9073113918304445, 'max_batch': 5.011128997802734}
step: 18950 @ episode report: {'average_total_reward': 11.319, 'reward_variance': 1.7938099, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8230456113815308, 'actor_loss': -4.852639245986938, 'hyper_actor_loss': 0.022313900105655194, 'behavior_loss': 0.29245657920837403, 'mean_batch': 5.102194881439209, 'min_batch': 5.020627069473266, 'max_batch': 5.131926488876343}
step: 18960 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 5.93114, 'max_total_reward': 11.23, 'min_total_reward': 2.46, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6021212756633758, 'actor_loss': -4.8163234233856205, 'hyper_actor_loss': 0.02228606939315796, 'behavior_loss': 0.2890784353017807, 'mean_batch': 5.000275325775147, 'min_batch': 4.9402672290802006, 'max_batch': 5.023579788208008}
step: 18970 @ episode report: {'average_total_reward': 11.042, 'reward_variance': 5.305056, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.015226924419403, 'actor_loss': -4.8126991271972654, 'hyper_actor_loss': 0.02210390195250511, 'behavior_loss': 0.2821859985589981, 'mean_batch': 4.985242795944214, 'min_batch': 4.937104511260986, 'max_batch': 5.0071868896484375}
step: 18980 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 2.3964562, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.006456172466278, 'actor_loss': -4.789513301849365, 'hyper_actor_loss': 0.022131499089300632, 'behavior_loss': 0.29439121931791307, 'mean_batch': 4.92766227722168, 'min_batch': 4.880416679382324, 'max_batch': 4.9472984790802}
step: 18990 @ episode report: {'average_total_reward': 11.275, 'reward_variance': 5.334746, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0027072548866274, 'actor_loss': -4.793114805221558, 'hyper_actor_loss': 0.021956075541675092, 'behavior_loss': 0.28740011602640153, 'mean_batch': 4.9351222038269045, 'min_batch': 4.890610265731811, 'max_batch': 4.957803058624267}
step: 19000 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 3.9941611, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0194678902626038, 'actor_loss': -4.773083114624024, 'hyper_actor_loss': 0.02182487938553095, 'behavior_loss': 0.2743154510855675, 'mean_batch': 4.885684442520142, 'min_batch': 4.8421485900878904, 'max_batch': 4.9047853469848635}
step: 19010 @ episode report: {'average_total_reward': 9.333, 'reward_variance': 1.5210813, 'max_total_reward': 11.010001, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9305340051651, 'actor_loss': -4.791204214096069, 'hyper_actor_loss': 0.02160927951335907, 'behavior_loss': 0.27696982622146604, 'mean_batch': 4.927247095108032, 'min_batch': 4.8890422821044925, 'max_batch': 4.9473333835601805}
step: 19020 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 4.6112833, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8399969518184662, 'actor_loss': -4.807886362075806, 'hyper_actor_loss': 0.0215382969006896, 'behavior_loss': 0.29467610716819764, 'mean_batch': 4.972661828994751, 'min_batch': 4.925832986831665, 'max_batch': 4.99469518661499}
step: 19030 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 3.9974504, 'max_total_reward': 14.450001, 'min_total_reward': 7.9000006, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6451521635055542, 'actor_loss': -4.805871534347534, 'hyper_actor_loss': 0.021265950985252857, 'behavior_loss': 0.29572524428367614, 'mean_batch': 4.978551387786865, 'min_batch': 4.910155296325684, 'max_batch': 5.004331064224243}
step: 19040 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 1.9011214, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7655471950769424, 'actor_loss': -4.8056751728057865, 'hyper_actor_loss': 0.021257223561406136, 'behavior_loss': 0.28036135733127593, 'mean_batch': 4.973894882202148, 'min_batch': 4.913729238510132, 'max_batch': 5.006271076202393}
step: 19050 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 2.3161004, 'max_total_reward': 12.23, 'min_total_reward': 6.7899995, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.870541024208069, 'actor_loss': -4.804367589950561, 'hyper_actor_loss': 0.02129569984972477, 'behavior_loss': 0.2876039996743202, 'mean_batch': 4.973680019378662, 'min_batch': 4.907521486282349, 'max_batch': 5.002740335464478}
step: 19060 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 3.6017563, 'max_total_reward': 11.120001, 'min_total_reward': 5.6800003, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1026507377624513, 'actor_loss': -4.782781887054443, 'hyper_actor_loss': 0.02122466117143631, 'behavior_loss': 0.2990398794412613, 'mean_batch': 4.917450666427612, 'min_batch': 4.857739543914795, 'max_batch': 4.943242359161377}
step: 19070 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 4.166938, 'max_total_reward': 13.340001, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7603731989860534, 'actor_loss': -4.766332054138184, 'hyper_actor_loss': 0.021140890754759313, 'behavior_loss': 0.29183366149663925, 'mean_batch': 4.875385284423828, 'min_batch': 4.819684600830078, 'max_batch': 4.901470184326172}
step: 19080 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 2.7988012, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6304427981376648, 'actor_loss': -4.793965148925781, 'hyper_actor_loss': 0.02111606579273939, 'behavior_loss': 0.28682953864336014, 'mean_batch': 4.951541757583618, 'min_batch': 4.878578519821167, 'max_batch': 4.973150300979614}
step: 19090 @ episode report: {'average_total_reward': 10.4210005, 'reward_variance': 3.7429092, 'max_total_reward': 14.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7283079326152802, 'actor_loss': -4.818036460876465, 'hyper_actor_loss': 0.02095468621701002, 'behavior_loss': 0.28158562779426577, 'mean_batch': 5.010733938217163, 'min_batch': 4.93830041885376, 'max_batch': 5.03216962814331}
step: 19100 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.5322049, 'max_total_reward': 12.01, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5954569578170776, 'actor_loss': -4.815531826019287, 'hyper_actor_loss': 0.02084726970642805, 'behavior_loss': 0.28643494844436646, 'mean_batch': 5.0084620952606205, 'min_batch': 4.928269672393799, 'max_batch': 5.0274218082427975}
step: 19110 @ episode report: {'average_total_reward': 9.121, 'reward_variance': 2.0114095, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9504860758781433, 'actor_loss': -4.804792404174805, 'hyper_actor_loss': 0.02079505044966936, 'behavior_loss': 0.2894382536411285, 'mean_batch': 4.970924758911133, 'min_batch': 4.912353944778443, 'max_batch': 4.990910339355469}
step: 19120 @ episode report: {'average_total_reward': 10.62, 'reward_variance': 5.6006007, 'max_total_reward': 14.56, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0166232347488404, 'actor_loss': -4.768285608291626, 'hyper_actor_loss': 0.020618940703570843, 'behavior_loss': 0.2756838470697403, 'mean_batch': 4.878874254226685, 'min_batch': 4.825637531280518, 'max_batch': 4.898245525360108}
step: 19130 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 4.4629297, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7049698173999785, 'actor_loss': -4.777262830734253, 'hyper_actor_loss': 0.02056420762091875, 'behavior_loss': 0.2934539243578911, 'mean_batch': 4.897763919830322, 'min_batch': 4.850532484054566, 'max_batch': 4.913078260421753}
step: 19140 @ episode report: {'average_total_reward': 11.253, 'reward_variance': 4.7358217, 'max_total_reward': 14.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.824795424938202, 'actor_loss': -4.798726415634155, 'hyper_actor_loss': 0.0205248586833477, 'behavior_loss': 0.29630608707666395, 'mean_batch': 4.952313232421875, 'min_batch': 4.900982761383057, 'max_batch': 4.972476530075073}
step: 19150 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.567855, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.739302158355713, 'actor_loss': -4.79064793586731, 'hyper_actor_loss': 0.02065556701272726, 'behavior_loss': 0.293319371342659, 'mean_batch': 4.933481311798095, 'min_batch': 4.880122280120849, 'max_batch': 4.951279401779175}
step: 19160 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 3.8489213, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.930967664718628, 'actor_loss': -4.780337238311768, 'hyper_actor_loss': 0.020725170522928237, 'behavior_loss': 0.2989864856004715, 'mean_batch': 4.908180189132691, 'min_batch': 4.855069351196289, 'max_batch': 4.926174783706665}
step: 19170 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 1.9542843, 'max_total_reward': 12.23, 'min_total_reward': 7.7899995, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6357600212097168, 'actor_loss': -4.779092264175415, 'hyper_actor_loss': 0.020611528493463992, 'behavior_loss': 0.2931645825505257, 'mean_batch': 4.906027555465698, 'min_batch': 4.851150798797607, 'max_batch': 4.921800804138184}
step: 19180 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 2.8429809, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6204639673233032, 'actor_loss': -4.806512355804443, 'hyper_actor_loss': 0.020511823520064355, 'behavior_loss': 0.283792482316494, 'mean_batch': 4.982989406585693, 'min_batch': 4.908897447586059, 'max_batch': 5.002105331420898}
step: 19190 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.0778053, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5008749842643738, 'actor_loss': -4.824184083938599, 'hyper_actor_loss': 0.02023670859634876, 'behavior_loss': 0.2811576321721077, 'mean_batch': 5.035224485397339, 'min_batch': 4.9446745872497555, 'max_batch': 5.05826735496521}
step: 19200 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 3.0395358, 'max_total_reward': 13.34, 'min_total_reward': 8.68, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7352125763893127, 'actor_loss': -4.812481498718261, 'hyper_actor_loss': 0.02021041251718998, 'behavior_loss': 0.2855125665664673, 'mean_batch': 4.997453832626343, 'min_batch': 4.924186658859253, 'max_batch': 5.017385959625244}
step: 19210 @ episode report: {'average_total_reward': 9.655001, 'reward_variance': 2.9394848, 'max_total_reward': 12.2300005, 'min_total_reward': 5.5700006, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8833864212036133, 'actor_loss': -4.7893537998199465, 'hyper_actor_loss': 0.020015518739819528, 'behavior_loss': 0.29063969403505324, 'mean_batch': 4.934350204467774, 'min_batch': 4.872945117950439, 'max_batch': 4.951884984970093}
step: 19220 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 3.8687012, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3392887592315674, 'actor_loss': -4.803387546539307, 'hyper_actor_loss': 0.02000475861132145, 'behavior_loss': 0.28035099506378175, 'mean_batch': 4.96466178894043, 'min_batch': 4.911845874786377, 'max_batch': 4.983119773864746}
step: 19230 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 2.7413416, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7523872911930085, 'actor_loss': -4.81766266822815, 'hyper_actor_loss': 0.019811004959046842, 'behavior_loss': 0.2729577079415321, 'mean_batch': 5.0033856391906735, 'min_batch': 4.943733644485474, 'max_batch': 5.0222601890563965}
step: 19240 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 2.3536239, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8213157773017883, 'actor_loss': -4.806216382980347, 'hyper_actor_loss': 0.019616083800792695, 'behavior_loss': 0.285212017595768, 'mean_batch': 4.969297409057617, 'min_batch': 4.920976448059082, 'max_batch': 4.986608457565308}
step: 19250 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 3.9650815, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.886291253566742, 'actor_loss': -4.785649394989013, 'hyper_actor_loss': 0.019506957195699216, 'behavior_loss': 0.29106228053569794, 'mean_batch': 4.915399122238159, 'min_batch': 4.873671770095825, 'max_batch': 4.928785943984986}
step: 19260 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 2.6622293, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9440702080726624, 'actor_loss': -4.772045516967774, 'hyper_actor_loss': 0.01950929034501314, 'behavior_loss': 0.2975121259689331, 'mean_batch': 4.876269721984864, 'min_batch': 4.846365690231323, 'max_batch': 4.887337970733642}
step: 19270 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 3.2263882, 'max_total_reward': 14.559999, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4471445381641388, 'actor_loss': -4.7984936237335205, 'hyper_actor_loss': 0.019403508864343166, 'behavior_loss': 0.2961997866630554, 'mean_batch': 4.942418432235717, 'min_batch': 4.909823751449585, 'max_batch': 4.957530546188354}
step: 19280 @ episode report: {'average_total_reward': 11.353001, 'reward_variance': 1.6082809, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.898403239250183, 'actor_loss': -4.825465536117553, 'hyper_actor_loss': 0.019317693635821344, 'behavior_loss': 0.291623455286026, 'mean_batch': 5.013101530075073, 'min_batch': 4.972848701477051, 'max_batch': 5.029786014556885}
step: 19290 @ episode report: {'average_total_reward': 9.155001, 'reward_variance': 2.212485, 'max_total_reward': 11.2300005, 'min_total_reward': 6.5699997, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7814740061759948, 'actor_loss': -4.781704473495483, 'hyper_actor_loss': 0.019250045344233514, 'behavior_loss': 0.2655416876077652, 'mean_batch': 4.909859371185303, 'min_batch': 4.860061979293823, 'max_batch': 4.925941848754883}
step: 19300 @ episode report: {'average_total_reward': 9.232, 'reward_variance': 4.6861773, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9343582093715668, 'actor_loss': -4.786779356002808, 'hyper_actor_loss': 0.019035893864929675, 'behavior_loss': 0.2812975004315376, 'mean_batch': 4.9207117557525635, 'min_batch': 4.873906135559082, 'max_batch': 4.9347865104675295}
step: 19310 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.750697, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9762755036354065, 'actor_loss': -4.762603664398194, 'hyper_actor_loss': 0.018925503827631474, 'behavior_loss': 0.2905073404312134, 'mean_batch': 4.8565233707427975, 'min_batch': 4.82040433883667, 'max_batch': 4.866372299194336}
step: 19320 @ episode report: {'average_total_reward': 11.153, 'reward_variance': 3.3642209, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5552464604377747, 'actor_loss': -4.780039882659912, 'hyper_actor_loss': 0.01873049549758434, 'behavior_loss': 0.278016696870327, 'mean_batch': 4.901319313049316, 'min_batch': 4.860571002960205, 'max_batch': 4.913756561279297}
step: 19330 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 1.5556608, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9612971425056458, 'actor_loss': -4.805546855926513, 'hyper_actor_loss': 0.018754301592707634, 'behavior_loss': 0.2906609639525414, 'mean_batch': 4.968134832382202, 'min_batch': 4.918876695632934, 'max_batch': 4.984853792190552}
step: 19340 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 3.5728703, 'max_total_reward': 14.450001, 'min_total_reward': 7.68, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7389661073684692, 'actor_loss': -4.7877298355102536, 'hyper_actor_loss': 0.018629524484276773, 'behavior_loss': 0.28634303957223894, 'mean_batch': 4.924194622039795, 'min_batch': 4.875071716308594, 'max_batch': 4.938444137573242}
step: 19350 @ episode report: {'average_total_reward': 11.009, 'reward_variance': 1.92825, 'max_total_reward': 14.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6990273952484132, 'actor_loss': -4.780748987197876, 'hyper_actor_loss': 0.01849618796259165, 'behavior_loss': 0.2857097744941711, 'mean_batch': 4.90436806678772, 'min_batch': 4.8607110500335695, 'max_batch': 4.917233800888061}
step: 19360 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 3.2672257, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8056695222854615, 'actor_loss': -4.79776964187622, 'hyper_actor_loss': 0.018501428700983525, 'behavior_loss': 0.27508967369794846, 'mean_batch': 4.945086908340454, 'min_batch': 4.903454351425171, 'max_batch': 4.9587212085723875}
step: 19370 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 8.998776, 'max_total_reward': 14.56, 'min_total_reward': 2.2400002, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5446509838104248, 'actor_loss': -4.805411672592163, 'hyper_actor_loss': 0.018387128971517085, 'behavior_loss': 0.27197455018758776, 'mean_batch': 4.965154075622559, 'min_batch': 4.921106481552124, 'max_batch': 4.978999519348145}
step: 19380 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 3.9457366, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6240807890892028, 'actor_loss': -4.811204290390014, 'hyper_actor_loss': 0.01824381574988365, 'behavior_loss': 0.2884159699082375, 'mean_batch': 4.976657152175903, 'min_batch': 4.9382349967956545, 'max_batch': 4.990746927261353}
step: 19390 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 3.383065, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4520336925983428, 'actor_loss': -4.820772171020508, 'hyper_actor_loss': 0.01829756088554859, 'behavior_loss': 0.258710041642189, 'mean_batch': 5.003964185714722, 'min_batch': 4.9585589408874515, 'max_batch': 5.019712686538696}
step: 19400 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 3.8821702, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.954995059967041, 'actor_loss': -4.8073993682861325, 'hyper_actor_loss': 0.018190782330930234, 'behavior_loss': 0.28625466525554655, 'mean_batch': 4.967937755584717, 'min_batch': 4.928377151489258, 'max_batch': 4.981923294067383}
step: 19410 @ episode report: {'average_total_reward': 11.386, 'reward_variance': 3.4864845, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0187400817871093, 'actor_loss': -4.7738746166229244, 'hyper_actor_loss': 0.018040402233600615, 'behavior_loss': 0.3025472715497017, 'mean_batch': 4.883439826965332, 'min_batch': 4.848120498657226, 'max_batch': 4.900124883651733}
step: 19420 @ episode report: {'average_total_reward': 10.110001, 'reward_variance': 3.1200807, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5664578080177307, 'actor_loss': -4.7681739807128904, 'hyper_actor_loss': 0.018128363974392415, 'behavior_loss': 0.27627190500497817, 'mean_batch': 4.868614196777344, 'min_batch': 4.835362291336059, 'max_batch': 4.889570045471191}
step: 19430 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 1.1887763, 'max_total_reward': 11.120001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5056930303573608, 'actor_loss': -4.816185665130615, 'hyper_actor_loss': 0.018071491084992886, 'behavior_loss': 0.2783441796898842, 'mean_batch': 4.99424295425415, 'min_batch': 4.945599317550659, 'max_batch': 5.013311290740967}
step: 19440 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 3.7046082, 'max_total_reward': 13.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5024357795715333, 'actor_loss': -4.834795141220093, 'hyper_actor_loss': 0.018026737682521343, 'behavior_loss': 0.27996721118688583, 'mean_batch': 5.037703227996826, 'min_batch': 4.994836521148682, 'max_batch': 5.056558513641358}
step: 19450 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 2.80188, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6646756410598755, 'actor_loss': -4.815135526657104, 'hyper_actor_loss': 0.0178641140460968, 'behavior_loss': 0.2792386159300804, 'mean_batch': 4.988204860687256, 'min_batch': 4.946285963058472, 'max_batch': 5.01260666847229}
step: 19460 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 3.1891208, 'max_total_reward': 13.12, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.710699623823166, 'actor_loss': -4.795482110977173, 'hyper_actor_loss': 0.017870415560901166, 'behavior_loss': 0.2915839120745659, 'mean_batch': 4.938616228103638, 'min_batch': 4.898647594451904, 'max_batch': 4.960945177078247}
step: 19470 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 1.7978054, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7908108592033387, 'actor_loss': -4.800582218170166, 'hyper_actor_loss': 0.017648890055716036, 'behavior_loss': 0.2709522321820259, 'mean_batch': 4.953048324584961, 'min_batch': 4.909375715255737, 'max_batch': 4.975723600387573}
step: 19480 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 0.50216925, 'max_total_reward': 12.2300005, 'min_total_reward': 9.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.683230447769165, 'actor_loss': -4.791882181167603, 'hyper_actor_loss': 0.017579638212919236, 'behavior_loss': 0.28059301674366, 'mean_batch': 4.9308594226837155, 'min_batch': 4.888759517669678, 'max_batch': 4.961137056350708}
step: 19490 @ episode report: {'average_total_reward': 11.297, 'reward_variance': 2.861021, 'max_total_reward': 14.56, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7475200295448303, 'actor_loss': -4.796626996994019, 'hyper_actor_loss': 0.017423313297331332, 'behavior_loss': 0.2958088606595993, 'mean_batch': 4.9398651123046875, 'min_batch': 4.903009605407715, 'max_batch': 4.965496826171875}
step: 19500 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 1.9642448, 'max_total_reward': 12.230001, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.644490611553192, 'actor_loss': -4.816316938400268, 'hyper_actor_loss': 0.017556759342551232, 'behavior_loss': 0.28750909119844437, 'mean_batch': 4.985642528533935, 'min_batch': 4.954676723480224, 'max_batch': 4.998635768890381}
step: 19510 @ episode report: {'average_total_reward': 10.853002, 'reward_variance': 3.2188408, 'max_total_reward': 12.340001, 'min_total_reward': 6.4600005, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7815059959888457, 'actor_loss': -4.794071674346924, 'hyper_actor_loss': 0.017445831559598446, 'behavior_loss': 0.2796414226293564, 'mean_batch': 4.939696168899536, 'min_batch': 4.890773582458496, 'max_batch': 4.952079725265503}
step: 19520 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 1.8542207, 'max_total_reward': 12.23, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.678592473268509, 'actor_loss': -4.796701240539551, 'hyper_actor_loss': 0.017370361648499966, 'behavior_loss': 0.2874565526843071, 'mean_batch': 4.935888624191284, 'min_batch': 4.907344579696655, 'max_batch': 4.947556495666504}
step: 19530 @ episode report: {'average_total_reward': 10.099001, 'reward_variance': 2.547789, 'max_total_reward': 13.34, 'min_total_reward': 7.57, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4849886417388916, 'actor_loss': -4.818369913101196, 'hyper_actor_loss': 0.017198955826461314, 'behavior_loss': 0.29693531394004824, 'mean_batch': 4.991376447677612, 'min_batch': 4.959189796447754, 'max_batch': 5.004741621017456}
step: 19540 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 4.815404, 'max_total_reward': 15.56, 'min_total_reward': 7.57, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1572497725486754, 'actor_loss': -4.797174501419067, 'hyper_actor_loss': 0.017193998023867608, 'behavior_loss': 0.30258283019065857, 'mean_batch': 4.940526533126831, 'min_batch': 4.90552864074707, 'max_batch': 4.951307010650635}
step: 19550 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 4.9166613, 'max_total_reward': 13.34, 'min_total_reward': 4.57, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8345709562301635, 'actor_loss': -4.750936603546142, 'hyper_actor_loss': 0.017113654129207134, 'behavior_loss': 0.28060328513383864, 'mean_batch': 4.8294144630432125, 'min_batch': 4.791169548034668, 'max_batch': 4.839087677001953}
step: 19560 @ episode report: {'average_total_reward': 10.653, 'reward_variance': 4.818781, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8446544706821442, 'actor_loss': -4.789848041534424, 'hyper_actor_loss': 0.017006746865808962, 'behavior_loss': 0.27924361228942873, 'mean_batch': 4.926884698867798, 'min_batch': 4.882877445220947, 'max_batch': 4.939338684082031}
step: 19570 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.3075852, 'max_total_reward': 13.45, 'min_total_reward': 7.899999, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4058185935020446, 'actor_loss': -4.8123091697692875, 'hyper_actor_loss': 0.016896883957087994, 'behavior_loss': 0.2765702664852142, 'mean_batch': 4.989804935455322, 'min_batch': 4.930759477615356, 'max_batch': 5.003581953048706}
step: 19580 @ episode report: {'average_total_reward': 11.497001, 'reward_variance': 1.2424409, 'max_total_reward': 13.34, 'min_total_reward': 8.900001, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7648364901542664, 'actor_loss': -4.819147634506225, 'hyper_actor_loss': 0.016655020229518414, 'behavior_loss': 0.2766156643629074, 'mean_batch': 4.996532678604126, 'min_batch': 4.957840299606323, 'max_batch': 5.009256792068482}
step: 19590 @ episode report: {'average_total_reward': 11.097001, 'reward_variance': 4.9630823, 'max_total_reward': 15.560001, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.057714521884918, 'actor_loss': -4.788674831390381, 'hyper_actor_loss': 0.01654385980218649, 'behavior_loss': 0.28530188649892807, 'mean_batch': 4.914751243591309, 'min_batch': 4.889213800430298, 'max_batch': 4.924940776824951}
step: 19600 @ episode report: {'average_total_reward': 10.754001, 'reward_variance': 1.8102438, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7873841762542724, 'actor_loss': -4.760278129577637, 'hyper_actor_loss': 0.016429121047258376, 'behavior_loss': 0.2694979846477509, 'mean_batch': 4.848518991470337, 'min_batch': 4.817107248306274, 'max_batch': 4.922058963775635}
step: 19610 @ episode report: {'average_total_reward': 9.244, 'reward_variance': 2.531224, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.927872461080551, 'actor_loss': -4.779095125198364, 'hyper_actor_loss': 0.01628287322819233, 'behavior_loss': 0.2915685147047043, 'mean_batch': 4.909146499633789, 'min_batch': 4.847963953018189, 'max_batch': 4.947354078292847}
step: 19620 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 6.4119215, 'max_total_reward': 13.34, 'min_total_reward': 5.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5891318798065186, 'actor_loss': -4.7873763084411625, 'hyper_actor_loss': 0.016249624080955982, 'behavior_loss': 0.27867848724126815, 'mean_batch': 4.930411386489868, 'min_batch': 4.867252445220947, 'max_batch': 5.07387409210205}
step: 19630 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 5.0732417, 'max_total_reward': 14.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.658800059556961, 'actor_loss': -4.823198556900024, 'hyper_actor_loss': 0.016305325739085674, 'behavior_loss': 0.2670235842466354, 'mean_batch': 5.0183275699615475, 'min_batch': 4.95650086402893, 'max_batch': 5.089134263992309}
step: 19640 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 4.4553804, 'max_total_reward': 14.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6839019417762757, 'actor_loss': -4.795210981369019, 'hyper_actor_loss': 0.0161647729575634, 'behavior_loss': 0.28277997821569445, 'mean_batch': 4.945058679580688, 'min_batch': 4.891190528869629, 'max_batch': 4.959459733963013}
step: 19650 @ episode report: {'average_total_reward': 11.597, 'reward_variance': 3.9188225, 'max_total_reward': 14.450001, 'min_total_reward': 7.899999, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7573615908622742, 'actor_loss': -4.782754850387573, 'hyper_actor_loss': 0.016222776845097542, 'behavior_loss': 0.27984571903944017, 'mean_batch': 4.909385395050049, 'min_batch': 4.865505075454712, 'max_batch': 4.919707107543945}
step: 19660 @ episode report: {'average_total_reward': 11.209001, 'reward_variance': 4.4091682, 'max_total_reward': 14.339999, 'min_total_reward': 6.6800003, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5896922945976257, 'actor_loss': -4.809429883956909, 'hyper_actor_loss': 0.016144446842372418, 'behavior_loss': 0.29009670466184617, 'mean_batch': 4.97339358329773, 'min_batch': 4.932922840118408, 'max_batch': 4.985186529159546}
step: 19670 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 8.149261, 'max_total_reward': 13.23, 'min_total_reward': 4.57, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.698704469203949, 'actor_loss': -4.814281272888183, 'hyper_actor_loss': 0.01615496799349785, 'behavior_loss': 0.27205075323581696, 'mean_batch': 4.982344436645508, 'min_batch': 4.947848224639893, 'max_batch': 4.993403148651123}
step: 19680 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 2.8779652, 'max_total_reward': 12.339999, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7062920868396758, 'actor_loss': -4.795380783081055, 'hyper_actor_loss': 0.016037129424512388, 'behavior_loss': 0.29084784388542173, 'mean_batch': 4.930684566497803, 'min_batch': 4.906013488769531, 'max_batch': 4.938855600357056}
step: 19690 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.8146455, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7537532567977905, 'actor_loss': -4.79179015159607, 'hyper_actor_loss': 0.015901434421539306, 'behavior_loss': 0.28759652823209764, 'mean_batch': 4.921404218673706, 'min_batch': 4.897645139694214, 'max_batch': 4.929518127441407}
step: 19700 @ episode report: {'average_total_reward': 9.488, 'reward_variance': 2.7942364, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.647136241197586, 'actor_loss': -4.796979475021362, 'hyper_actor_loss': 0.01586828213185072, 'behavior_loss': 0.2819720610976219, 'mean_batch': 4.933338022232055, 'min_batch': 4.911244869232178, 'max_batch': 4.942748165130615}
step: 19710 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 1.476621, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5559110760688781, 'actor_loss': -4.819361352920533, 'hyper_actor_loss': 0.015858203545212744, 'behavior_loss': 0.29120908826589587, 'mean_batch': 4.986870050430298, 'min_batch': 4.968541431427002, 'max_batch': 5.001300096511841}
step: 19720 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 2.149844, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8603962063789368, 'actor_loss': -4.816819047927856, 'hyper_actor_loss': 0.015772511810064317, 'behavior_loss': 0.29080546647310257, 'mean_batch': 4.983689260482788, 'min_batch': 4.959077215194702, 'max_batch': 5.002595043182373}
step: 19730 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 1.799661, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4724143266677856, 'actor_loss': -4.790004062652588, 'hyper_actor_loss': 0.015726311691105367, 'behavior_loss': 0.2748443096876144, 'mean_batch': 4.92005877494812, 'min_batch': 4.890273475646973, 'max_batch': 4.952191734313965}
step: 19740 @ episode report: {'average_total_reward': 12.2300005, 'reward_variance': 3.439981, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 13.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8315268337726593, 'actor_loss': -4.805293130874634, 'hyper_actor_loss': 0.01561816008761525, 'behavior_loss': 0.28812204748392106, 'mean_batch': 4.958629751205445, 'min_batch': 4.9269716262817385, 'max_batch': 4.987663698196411}
step: 19750 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 2.9409559, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4033885598182678, 'actor_loss': -4.80525279045105, 'hyper_actor_loss': 0.01575046982616186, 'behavior_loss': 0.28144140988588334, 'mean_batch': 4.959833145141602, 'min_batch': 4.925664901733398, 'max_batch': 4.98570704460144}
step: 19760 @ episode report: {'average_total_reward': 11.608001, 'reward_variance': 1.6405756, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.532892143726349, 'actor_loss': -4.8316198825836185, 'hyper_actor_loss': 0.015572082530707122, 'behavior_loss': 0.2807262286543846, 'mean_batch': 5.029047632217408, 'min_batch': 4.987583208084106, 'max_batch': 5.1292243003845215}
step: 19770 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 2.2076457, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8932313203811646, 'actor_loss': -4.805757141113281, 'hyper_actor_loss': 0.015561816003173589, 'behavior_loss': 0.28372900038957594, 'mean_batch': 4.962134313583374, 'min_batch': 4.926049613952637, 'max_batch': 4.981390857696534}
step: 19780 @ episode report: {'average_total_reward': 11.1189995, 'reward_variance': 1.3429897, 'max_total_reward': 13.450001, 'min_total_reward': 10.119999, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8171813130378722, 'actor_loss': -4.770126581192017, 'hyper_actor_loss': 0.015566727798432111, 'behavior_loss': 0.2953043431043625, 'mean_batch': 4.876529598236084, 'min_batch': 4.836844110488892, 'max_batch': 4.8847887992858885}
step: 19790 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.7303848, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.330734097957611, 'actor_loss': -4.810178327560425, 'hyper_actor_loss': 0.015449348837137222, 'behavior_loss': 0.2650650292634964, 'mean_batch': 4.983473396301269, 'min_batch': 4.92726879119873, 'max_batch': 4.997739839553833}
step: 19800 @ episode report: {'average_total_reward': 11.075001, 'reward_variance': 3.4586449, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.594274067878723, 'actor_loss': -4.850513315200805, 'hyper_actor_loss': 0.01538110887631774, 'behavior_loss': 0.29678705632686614, 'mean_batch': 5.0858673572540285, 'min_batch': 5.025957727432251, 'max_batch': 5.104511451721192}
step: 19810 @ episode report: {'average_total_reward': 11.419001, 'reward_variance': 3.5421093, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9956150710582734, 'actor_loss': -4.7844939708709715, 'hyper_actor_loss': 0.015398013405501842, 'behavior_loss': 0.2878485232591629, 'mean_batch': 4.912845325469971, 'min_batch': 4.8714094161987305, 'max_batch': 4.924560070037842}
step: 19820 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 6.4274282, 'max_total_reward': 14.559999, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6617658853530883, 'actor_loss': -4.769013977050781, 'hyper_actor_loss': 0.01523330733180046, 'behavior_loss': 0.2722393721342087, 'mean_batch': 4.8775801181793215, 'min_batch': 4.830616617202759, 'max_batch': 4.891452264785767}
step: 19830 @ episode report: {'average_total_reward': 8.8880005, 'reward_variance': 13.547598, 'max_total_reward': 14.450001, 'min_total_reward': 1.24, 'average_n_step': 9.9, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.95562424659729, 'actor_loss': -4.8015515327453615, 'hyper_actor_loss': 0.015206305775791407, 'behavior_loss': 0.29029387831687925, 'mean_batch': 4.955303812026978, 'min_batch': 4.9118884086608885, 'max_batch': 4.966898632049561}
step: 19840 @ episode report: {'average_total_reward': 11.197, 'reward_variance': 4.9553595, 'max_total_reward': 15.669999, 'min_total_reward': 7.7899995, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6461883664131165, 'actor_loss': -4.800298261642456, 'hyper_actor_loss': 0.01509791361168027, 'behavior_loss': 0.2673078000545502, 'mean_batch': 4.954616689682007, 'min_batch': 4.90643539428711, 'max_batch': 4.96695384979248}
step: 19850 @ episode report: {'average_total_reward': 11.518999, 'reward_variance': 2.267149, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0559494256973267, 'actor_loss': -4.78874716758728, 'hyper_actor_loss': 0.015104999858886003, 'behavior_loss': 0.2900624990463257, 'mean_batch': 4.924418830871582, 'min_batch': 4.879873418807984, 'max_batch': 4.93500771522522}
step: 19860 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.469984, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8858484745025634, 'actor_loss': -4.757570886611939, 'hyper_actor_loss': 0.015121311228722335, 'behavior_loss': 0.27656242102384565, 'mean_batch': 4.835347366333008, 'min_batch': 4.817148113250733, 'max_batch': 4.85030083656311}
step: 19870 @ episode report: {'average_total_reward': 10.986, 'reward_variance': 2.4559236, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8089258909225463, 'actor_loss': -4.777859544754028, 'hyper_actor_loss': 0.015096502937376499, 'behavior_loss': 0.27887235283851625, 'mean_batch': 4.891578292846679, 'min_batch': 4.859458923339844, 'max_batch': 4.924130964279175}
step: 19880 @ episode report: {'average_total_reward': 11.186001, 'reward_variance': 3.6772041, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0294697999954225, 'actor_loss': -4.777740383148194, 'hyper_actor_loss': 0.014893581997603178, 'behavior_loss': 0.28011457473039625, 'mean_batch': 4.893586492538452, 'min_batch': 4.85691237449646, 'max_batch': 4.924840450286865}
step: 19890 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 1.0012163, 'max_total_reward': 12.23, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8392155051231385, 'actor_loss': -4.767343187332154, 'hyper_actor_loss': 0.014884971827268601, 'behavior_loss': 0.2819450080394745, 'mean_batch': 4.865858650207519, 'min_batch': 4.833932018280029, 'max_batch': 4.88475775718689}
step: 19900 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 5.330617, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8542854547500611, 'actor_loss': -4.764734983444214, 'hyper_actor_loss': 0.014759037643671036, 'behavior_loss': 0.2830394446849823, 'mean_batch': 4.8596141815185545, 'min_batch': 4.827542018890381, 'max_batch': 4.867960262298584}
step: 19910 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 2.9375606, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6218480587005615, 'actor_loss': -4.787571382522583, 'hyper_actor_loss': 0.014710527192801238, 'behavior_loss': 0.2723332718014717, 'mean_batch': 4.930573511123657, 'min_batch': 4.868081760406494, 'max_batch': 4.94223051071167}
step: 19920 @ episode report: {'average_total_reward': 8.8, 'reward_variance': 2.1735601, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7705400228500365, 'actor_loss': -4.794826936721802, 'hyper_actor_loss': 0.014701641164720058, 'behavior_loss': 0.29163787364959715, 'mean_batch': 4.951032590866089, 'min_batch': 4.8832536220550535, 'max_batch': 4.9641382694244385}
step: 19930 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 1.964941, 'max_total_reward': 13.340002, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4757318079471589, 'actor_loss': -4.793751335144043, 'hyper_actor_loss': 0.014729716163128615, 'behavior_loss': 0.26460654139518736, 'mean_batch': 4.952429389953613, 'min_batch': 4.876576709747314, 'max_batch': 4.966439247131348}
step: 19940 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 2.0365689, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9998367786407472, 'actor_loss': -4.783998823165893, 'hyper_actor_loss': 0.014649195224046707, 'behavior_loss': 0.28229871690273284, 'mean_batch': 4.9280322074890135, 'min_batch': 4.85330491065979, 'max_batch': 4.946551513671875}
step: 19950 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 3.9456697, 'max_total_reward': 14.450001, 'min_total_reward': 6.7900004, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9385798573493958, 'actor_loss': -4.751074600219726, 'hyper_actor_loss': 0.014566291123628616, 'behavior_loss': 0.2721740245819092, 'mean_batch': 4.835548400878906, 'min_batch': 4.785793113708496, 'max_batch': 4.852737331390381}
step: 19960 @ episode report: {'average_total_reward': 8.444, 'reward_variance': 7.8162446, 'max_total_reward': 11.2300005, 'min_total_reward': 1.24, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.808796763420105, 'actor_loss': -4.767749261856079, 'hyper_actor_loss': 0.014434204902499914, 'behavior_loss': 0.2830739378929138, 'mean_batch': 4.8786486148834225, 'min_batch': 4.823327207565308, 'max_batch': 4.896229934692383}
step: 19970 @ episode report: {'average_total_reward': 10.608999, 'reward_variance': 6.361431, 'max_total_reward': 15.560001, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.418013733625412, 'actor_loss': -4.8061802864074705, 'hyper_actor_loss': 0.014277448412030935, 'behavior_loss': 0.2759834125638008, 'mean_batch': 4.976886129379272, 'min_batch': 4.913448810577393, 'max_batch': 4.994694185256958}
step: 19980 @ episode report: {'average_total_reward': 11.509001, 'reward_variance': 2.3162894, 'max_total_reward': 13.45, 'min_total_reward': 8.679999, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6279513716697693, 'actor_loss': -4.811875295639038, 'hyper_actor_loss': 0.014276872016489505, 'behavior_loss': 0.27275075763463974, 'mean_batch': 4.989567661285401, 'min_batch': 4.92875566482544, 'max_batch': 5.006516981124878}
step: 19990 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 1.7257359, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.640705943107605, 'actor_loss': -4.7909997463226315, 'hyper_actor_loss': 0.014272253215312957, 'behavior_loss': 0.2851735919713974, 'mean_batch': 4.931576108932495, 'min_batch': 4.8837542057037355, 'max_batch': 4.947705698013306}
step: 20000 @ episode report: {'average_total_reward': 10.354, 'reward_variance': 3.7681625, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.783969235420227, 'actor_loss': -4.785905218124389, 'hyper_actor_loss': 0.014266553334891796, 'behavior_loss': 0.2823406830430031, 'mean_batch': 4.916867303848266, 'min_batch': 4.873416423797607, 'max_batch': 4.930197763442993}
step: 20010 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 0.6621841, 'max_total_reward': 11.2300005, 'min_total_reward': 9.01, 'average_n_step': 11.3, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7558594465255737, 'actor_loss': -4.782176923751831, 'hyper_actor_loss': 0.014283264707773923, 'behavior_loss': 0.28096415400505065, 'mean_batch': 4.90382490158081, 'min_batch': 4.868213510513305, 'max_batch': 4.92173752784729}
step: 20020 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 2.5176764, 'max_total_reward': 12.12, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8928658366203308, 'actor_loss': -4.789194345474243, 'hyper_actor_loss': 0.014162537734955549, 'behavior_loss': 0.26263168156147004, 'mean_batch': 4.918993234634399, 'min_batch': 4.88735556602478, 'max_batch': 4.94292197227478}
step: 20030 @ episode report: {'average_total_reward': 11.342001, 'reward_variance': 2.0756564, 'max_total_reward': 13.340001, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9789740920066834, 'actor_loss': -4.785300254821777, 'hyper_actor_loss': 0.014129707310348748, 'behavior_loss': 0.263395231962204, 'mean_batch': 4.9111274719238285, 'min_batch': 4.876228761672974, 'max_batch': 4.932676029205322}
step: 20040 @ episode report: {'average_total_reward': 11.342, 'reward_variance': 2.3781755, 'max_total_reward': 13.34, 'min_total_reward': 8.68, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5693181931972504, 'actor_loss': -4.77076678276062, 'hyper_actor_loss': 0.013901690114289522, 'behavior_loss': 0.26714389622211454, 'mean_batch': 4.882082986831665, 'min_batch': 4.834430885314942, 'max_batch': 4.898748254776001}
step: 20050 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 7.851729, 'max_total_reward': 14.56, 'min_total_reward': 3.5700002, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.878126460313797, 'actor_loss': -4.799014329910278, 'hyper_actor_loss': 0.013787390757352113, 'behavior_loss': 0.2637911975383759, 'mean_batch': 4.951297473907471, 'min_batch': 4.90343542098999, 'max_batch': 4.965869188308716}
step: 20060 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 4.7799897, 'max_total_reward': 11.2300005, 'min_total_reward': 3.5700002, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.829041463136673, 'actor_loss': -4.780206298828125, 'hyper_actor_loss': 0.01372375013306737, 'behavior_loss': 0.26947121024131776, 'mean_batch': 4.908027029037475, 'min_batch': 4.854473114013672, 'max_batch': 4.921572923660278}
step: 20070 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 6.796904, 'max_total_reward': 13.12, 'min_total_reward': 3.5700002, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7592366218566895, 'actor_loss': -4.780133438110352, 'hyper_actor_loss': 0.013707944191992283, 'behavior_loss': 0.27659232914447784, 'mean_batch': 4.906867980957031, 'min_batch': 4.855272912979126, 'max_batch': 4.920458459854126}
step: 20080 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 1.9690403, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6156792879104613, 'actor_loss': -4.778965091705322, 'hyper_actor_loss': 0.013701284863054752, 'behavior_loss': 0.2874915346503258, 'mean_batch': 4.908682870864868, 'min_batch': 4.847782230377197, 'max_batch': 4.924206018447876}
step: 20090 @ episode report: {'average_total_reward': 11.43, 'reward_variance': 2.87062, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9309284090995789, 'actor_loss': -4.773352098464966, 'hyper_actor_loss': 0.013708154577761889, 'behavior_loss': 0.2894218981266022, 'mean_batch': 4.900733423233032, 'min_batch': 4.828496694564819, 'max_batch': 4.920357942581177}
step: 20100 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 3.101829, 'max_total_reward': 13.23, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5162412345409393, 'actor_loss': -4.784000301361084, 'hyper_actor_loss': 0.01384517913684249, 'behavior_loss': 0.26366971880197526, 'mean_batch': 4.928271532058716, 'min_batch': 4.853269243240357, 'max_batch': 4.948192691802978}
step: 20110 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 3.0946238, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6679217338562011, 'actor_loss': -4.805322694778442, 'hyper_actor_loss': 0.013802206330001354, 'behavior_loss': 0.2637243211269379, 'mean_batch': 4.984125185012817, 'min_batch': 4.901914072036743, 'max_batch': 5.005161476135254}
step: 20120 @ episode report: {'average_total_reward': 9.942999, 'reward_variance': 5.08344, 'max_total_reward': 13.23, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4797368049621582, 'actor_loss': -4.796052408218384, 'hyper_actor_loss': 0.013757037557661533, 'behavior_loss': 0.2787078216671944, 'mean_batch': 4.955769348144531, 'min_batch': 4.884481430053711, 'max_batch': 4.975334119796753}
step: 20130 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.2237804, 'max_total_reward': 13.23, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9585216820240021, 'actor_loss': -4.799589014053344, 'hyper_actor_loss': 0.013652656693011522, 'behavior_loss': 0.27312919199466706, 'mean_batch': 4.9651471138000485, 'min_batch': 4.892598056793213, 'max_batch': 4.983997392654419}
step: 20140 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 5.25083, 'max_total_reward': 12.339999, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.68440842628479, 'actor_loss': -4.758844947814941, 'hyper_actor_loss': 0.013567131944000721, 'behavior_loss': 0.2788903251290321, 'mean_batch': 4.855103158950806, 'min_batch': 4.803703022003174, 'max_batch': 4.883979272842407}
step: 20150 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 8.80839, 'max_total_reward': 14.56, 'min_total_reward': 5.68, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.910849279165268, 'actor_loss': -4.768412399291992, 'hyper_actor_loss': 0.01358546931296587, 'behavior_loss': 0.2792026624083519, 'mean_batch': 4.879516124725342, 'min_batch': 4.8255946159362795, 'max_batch': 4.907642221450805}
step: 20160 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 1.3183088, 'max_total_reward': 13.12, 'min_total_reward': 9.01, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.07069137096405, 'actor_loss': -4.773026943206787, 'hyper_actor_loss': 0.013496041297912598, 'behavior_loss': 0.278521928191185, 'mean_batch': 4.89209303855896, 'min_batch': 4.835440540313721, 'max_batch': 4.9116912364959715}
step: 20170 @ episode report: {'average_total_reward': 11.364, 'reward_variance': 2.9291837, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8632169246673584, 'actor_loss': -4.760469579696656, 'hyper_actor_loss': 0.01350121907889843, 'behavior_loss': 0.28245277255773543, 'mean_batch': 4.8555091381072994, 'min_batch': 4.8110586643219, 'max_batch': 4.873885202407837}
step: 20180 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 2.488535, 'max_total_reward': 13.34, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7805884778499603, 'actor_loss': -4.761605167388916, 'hyper_actor_loss': 0.013497599959373474, 'behavior_loss': 0.2722096562385559, 'mean_batch': 4.85811562538147, 'min_batch': 4.813952350616455, 'max_batch': 4.8692333698272705}
step: 20190 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 2.304385, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.664056372642517, 'actor_loss': -4.7898341655731205, 'hyper_actor_loss': 0.013490942306816578, 'behavior_loss': 0.269708476960659, 'mean_batch': 4.929338693618774, 'min_batch': 4.880294466018677, 'max_batch': 4.940225076675415}
step: 20200 @ episode report: {'average_total_reward': 10.287, 'reward_variance': 2.5935214, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9686607122421265, 'actor_loss': -4.790268754959106, 'hyper_actor_loss': 0.013323758356273174, 'behavior_loss': 0.26942766904830934, 'mean_batch': 4.933278274536133, 'min_batch': 4.878566789627075, 'max_batch': 4.948581647872925}
step: 20210 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 5.967721, 'max_total_reward': 15.56, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6965466737747192, 'actor_loss': -4.758217096328735, 'hyper_actor_loss': 0.013224298972636462, 'behavior_loss': 0.2708934500813484, 'mean_batch': 4.8552710056304935, 'min_batch': 4.8004594326019285, 'max_batch': 4.876575613021851}
step: 20220 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 2.1737757, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.490062952041626, 'actor_loss': -4.784568881988525, 'hyper_actor_loss': 0.01317188311368227, 'behavior_loss': 0.26580192893743515, 'mean_batch': 4.9190796375274655, 'min_batch': 4.864936971664429, 'max_batch': 4.933878564834595}
step: 20230 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 7.434809, 'max_total_reward': 12.23, 'min_total_reward': 2.3500001, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8542763948440553, 'actor_loss': -4.79620590209961, 'hyper_actor_loss': 0.013149242661893368, 'behavior_loss': 0.2746300041675568, 'mean_batch': 4.949249505996704, 'min_batch': 4.891671180725098, 'max_batch': 4.963977718353272}
step: 20240 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 2.7877612, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.709314799308777, 'actor_loss': -4.786690998077392, 'hyper_actor_loss': 0.013143027760088443, 'behavior_loss': 0.278837189078331, 'mean_batch': 4.919571304321289, 'min_batch': 4.874577426910401, 'max_batch': 4.9307139873504635}
step: 20250 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 2.9654596, 'max_total_reward': 12.339999, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.587571954727173, 'actor_loss': -4.787731266021728, 'hyper_actor_loss': 0.013083001226186752, 'behavior_loss': 0.2775412410497665, 'mean_batch': 4.919359636306763, 'min_batch': 4.879845476150512, 'max_batch': 4.929048204421997}
step: 20260 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 3.2119236, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7261135697364807, 'actor_loss': -4.806661319732666, 'hyper_actor_loss': 0.013089934550225734, 'behavior_loss': 0.27533355355262756, 'mean_batch': 4.965977334976197, 'min_batch': 4.9264472961425785, 'max_batch': 4.975668096542359}
step: 20270 @ episode report: {'average_total_reward': 11.497, 'reward_variance': 3.2919014, 'max_total_reward': 15.67, 'min_total_reward': 9.009999, 'average_n_step': 12.3, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7981874704360963, 'actor_loss': -4.787687969207764, 'hyper_actor_loss': 0.01313435398042202, 'behavior_loss': 0.28385390937328336, 'mean_batch': 4.925155591964722, 'min_batch': 4.873997640609741, 'max_batch': 4.9347004890441895}
step: 20280 @ episode report: {'average_total_reward': 11.275001, 'reward_variance': 4.344425, 'max_total_reward': 13.450001, 'min_total_reward': 6.680001, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0524071216583253, 'actor_loss': -4.761082935333252, 'hyper_actor_loss': 0.013091364502906799, 'behavior_loss': 0.28616823554039, 'mean_batch': 4.852802371978759, 'min_batch': 4.816849851608277, 'max_batch': 4.860178852081299}
step: 20290 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 4.123921, 'max_total_reward': 12.34, 'min_total_reward': 6.680001, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6591586589813232, 'actor_loss': -4.758544826507569, 'hyper_actor_loss': 0.0130294025875628, 'behavior_loss': 0.26745923757553103, 'mean_batch': 4.846334171295166, 'min_batch': 4.81103401184082, 'max_batch': 4.856260585784912}
step: 20300 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.3946362, 'max_total_reward': 12.34, 'min_total_reward': 6.5700006, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.630467015504837, 'actor_loss': -4.790860891342163, 'hyper_actor_loss': 0.012984642293304205, 'behavior_loss': 0.25401891469955445, 'mean_batch': 4.950291347503662, 'min_batch': 4.864711332321167, 'max_batch': 4.968369817733764}
step: 20310 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.1922755, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.586836701631546, 'actor_loss': -4.798439931869507, 'hyper_actor_loss': 0.012865168787539006, 'behavior_loss': 0.2742320880293846, 'mean_batch': 4.966165256500244, 'min_batch': 4.885990810394287, 'max_batch': 4.98840103149414}
step: 20320 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 8.3248415, 'max_total_reward': 12.2300005, 'min_total_reward': 2.46, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5277550935745239, 'actor_loss': -4.8013896465301515, 'hyper_actor_loss': 0.012895031645894051, 'behavior_loss': 0.2553922563791275, 'mean_batch': 4.967816972732544, 'min_batch': 4.898773193359375, 'max_batch': 4.98908052444458}
step: 20330 @ episode report: {'average_total_reward': 11.020001, 'reward_variance': 6.47228, 'max_total_reward': 14.56, 'min_total_reward': 5.57, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4421852827072144, 'actor_loss': -4.816140079498291, 'hyper_actor_loss': 0.012829309608787299, 'behavior_loss': 0.26594880074262617, 'mean_batch': 5.002922821044922, 'min_batch': 4.936658239364624, 'max_batch': 5.019701147079468}
step: 20340 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 0.83504933, 'max_total_reward': 11.2300005, 'min_total_reward': 8.790001, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7724276781082153, 'actor_loss': -4.810022258758545, 'hyper_actor_loss': 0.012683225888758897, 'behavior_loss': 0.2707299754023552, 'mean_batch': 4.988677930831909, 'min_batch': 4.9205934524536135, 'max_batch': 4.998984479904175}
step: 20350 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 4.1891356, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9604329347610474, 'actor_loss': -4.776394176483154, 'hyper_actor_loss': 0.0126794190146029, 'behavior_loss': 0.2733423113822937, 'mean_batch': 4.901032161712647, 'min_batch': 4.843005132675171, 'max_batch': 4.910663747787476}
step: 20360 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.210705, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5466660618782044, 'actor_loss': -4.762626457214355, 'hyper_actor_loss': 0.012637929804623128, 'behavior_loss': 0.2742236390709877, 'mean_batch': 4.86468620300293, 'min_batch': 4.812592792510986, 'max_batch': 4.87758059501648}
step: 20370 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 4.14272, 'max_total_reward': 13.23, 'min_total_reward': 5.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.1632454007864, 'actor_loss': -4.824022674560547, 'hyper_actor_loss': 0.012573637440800667, 'behavior_loss': 0.2584843158721924, 'mean_batch': 5.020739889144897, 'min_batch': 4.958711099624634, 'max_batch': 5.033218765258789}
step: 20380 @ episode report: {'average_total_reward': 9.698001, 'reward_variance': 6.553157, 'max_total_reward': 13.450001, 'min_total_reward': 5.7899995, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7765995562076569, 'actor_loss': -4.85916953086853, 'hyper_actor_loss': 0.012502439692616463, 'behavior_loss': 0.2774654790759087, 'mean_batch': 5.099755907058716, 'min_batch': 5.05610408782959, 'max_batch': 5.113890314102173}
step: 20390 @ episode report: {'average_total_reward': 11.297001, 'reward_variance': 0.3479811, 'max_total_reward': 12.34, 'min_total_reward': 10.12, 'average_n_step': 12.1, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.92162264585495, 'actor_loss': -4.790410470962525, 'hyper_actor_loss': 0.012537924386560918, 'behavior_loss': 0.2659895524382591, 'mean_batch': 4.930061960220337, 'min_batch': 4.882593202590942, 'max_batch': 4.938890409469605}
step: 20400 @ episode report: {'average_total_reward': 10.875002, 'reward_variance': 5.518525, 'max_total_reward': 14.56, 'min_total_reward': 5.57, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9999479174613952, 'actor_loss': -4.74753851890564, 'hyper_actor_loss': 0.012497289199382066, 'behavior_loss': 0.2896472722291946, 'mean_batch': 4.815935277938843, 'min_batch': 4.7883587837219235, 'max_batch': 4.821932458877564}
step: 20410 @ episode report: {'average_total_reward': 11.031, 'reward_variance': 0.76896864, 'max_total_reward': 12.34, 'min_total_reward': 10.01, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8660825431346892, 'actor_loss': -4.766134929656983, 'hyper_actor_loss': 0.012536809034645557, 'behavior_loss': 0.28851099461317065, 'mean_batch': 4.864192771911621, 'min_batch': 4.830124616622925, 'max_batch': 4.871379661560058}
step: 20420 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 6.4194603, 'max_total_reward': 13.340001, 'min_total_reward': 4.68, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6755815207958222, 'actor_loss': -4.793263626098633, 'hyper_actor_loss': 0.012415849883109332, 'behavior_loss': 0.2752890929579735, 'mean_batch': 4.9326762676239015, 'min_batch': 4.893696117401123, 'max_batch': 4.9410919666290285}
step: 20430 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 2.9813762, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5166876792907715, 'actor_loss': -4.809080791473389, 'hyper_actor_loss': 0.012419154308736325, 'behavior_loss': 0.2787238910794258, 'mean_batch': 4.976218843460083, 'min_batch': 4.928208303451538, 'max_batch': 4.985993146896362}
step: 20440 @ episode report: {'average_total_reward': 11.042, 'reward_variance': 4.9345174, 'max_total_reward': 14.450001, 'min_total_reward': 6.57, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4667027056217194, 'actor_loss': -4.822108888626099, 'hyper_actor_loss': 0.012455080822110175, 'behavior_loss': 0.27752224206924436, 'mean_batch': 5.01768159866333, 'min_batch': 4.951559019088745, 'max_batch': 5.02966341972351}
step: 20450 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.2762618, 'max_total_reward': 12.12, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6541724443435668, 'actor_loss': -4.817354297637939, 'hyper_actor_loss': 0.012361352797597647, 'behavior_loss': 0.2653679341077805, 'mean_batch': 4.999919462203979, 'min_batch': 4.945640325546265, 'max_batch': 5.012138843536377}
step: 20460 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 5.413844, 'max_total_reward': 12.34, 'min_total_reward': 5.5699997, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4195779860019684, 'actor_loss': -4.8161077976226805, 'hyper_actor_loss': 0.012249070499092341, 'behavior_loss': 0.28495468348264696, 'mean_batch': 4.991337871551513, 'min_batch': 4.94790210723877, 'max_batch': 5.016090726852417}
step: 20470 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 6.678649, 'max_total_reward': 14.56, 'min_total_reward': 5.5699997, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5672203302383423, 'actor_loss': -4.825272750854492, 'hyper_actor_loss': 0.012290345411747694, 'behavior_loss': 0.26865217089653015, 'mean_batch': 5.019549369812012, 'min_batch': 4.965393114089966, 'max_batch': 5.069759559631348}
step: 20480 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 4.096529, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0201088309288027, 'actor_loss': -4.796684598922729, 'hyper_actor_loss': 0.012251455616205931, 'behavior_loss': 0.2812958911061287, 'mean_batch': 4.947096920013427, 'min_batch': 4.89646954536438, 'max_batch': 4.998400640487671}
step: 20490 @ episode report: {'average_total_reward': 10.543001, 'reward_variance': 2.3886814, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6406207144260407, 'actor_loss': -4.772100734710693, 'hyper_actor_loss': 0.012282297387719155, 'behavior_loss': 0.27732532024383544, 'mean_batch': 4.8809364318847654, 'min_batch': 4.842096948623658, 'max_batch': 4.923961544036866}
step: 20500 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 3.6765163, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7253778517246245, 'actor_loss': -4.8191725730896, 'hyper_actor_loss': 0.01224297722801566, 'behavior_loss': 0.2745838388800621, 'mean_batch': 4.999545001983643, 'min_batch': 4.955089712142945, 'max_batch': 5.029466342926026}
step: 20510 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 4.498686, 'max_total_reward': 13.450001, 'min_total_reward': 6.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7541659355163575, 'actor_loss': -4.81881890296936, 'hyper_actor_loss': 0.012183570768684149, 'behavior_loss': 0.28201538473367693, 'mean_batch': 4.994653558731079, 'min_batch': 4.958118915557861, 'max_batch': 5.019458055496216}
step: 20520 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 2.9336958, 'max_total_reward': 11.12, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7735869109630584, 'actor_loss': -4.789520120620727, 'hyper_actor_loss': 0.012155075278133153, 'behavior_loss': 0.2858361840248108, 'mean_batch': 4.922250747680664, 'min_batch': 4.885723972320557, 'max_batch': 4.9538171768188475}
step: 20530 @ episode report: {'average_total_reward': 9.276999, 'reward_variance': 4.360321, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6545697093009948, 'actor_loss': -4.794536924362182, 'hyper_actor_loss': 0.01207552244886756, 'behavior_loss': 0.26996002197265623, 'mean_batch': 4.935119915008545, 'min_batch': 4.897522830963135, 'max_batch': 4.970404243469238}
step: 20540 @ episode report: {'average_total_reward': 10.264999, 'reward_variance': 2.4685838, 'max_total_reward': 12.339999, 'min_total_reward': 6.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4887827277183532, 'actor_loss': -4.828009557723999, 'hyper_actor_loss': 0.011919408105313778, 'behavior_loss': 0.2585803508758545, 'mean_batch': 5.018443012237549, 'min_batch': 4.980227327346801, 'max_batch': 5.049702548980713}
step: 20550 @ episode report: {'average_total_reward': 10.221, 'reward_variance': 5.7827687, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4304898381233215, 'actor_loss': -4.839152050018311, 'hyper_actor_loss': 0.011874450836330652, 'behavior_loss': 0.2610832467675209, 'mean_batch': 5.04835352897644, 'min_batch': 5.006085014343261, 'max_batch': 5.070719289779663}
step: 20560 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 4.7844963, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.705982118844986, 'actor_loss': -4.8324603080749515, 'hyper_actor_loss': 0.011745558120310307, 'behavior_loss': 0.2642251119017601, 'mean_batch': 5.026501798629761, 'min_batch': 4.994368982315064, 'max_batch': 5.0403038501739506}
step: 20570 @ episode report: {'average_total_reward': 11.63, 'reward_variance': 1.7429405, 'max_total_reward': 13.340001, 'min_total_reward': 9.01, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9745365679264069, 'actor_loss': -4.8094103813171385, 'hyper_actor_loss': 0.011753470823168754, 'behavior_loss': 0.2759074494242668, 'mean_batch': 4.964900302886963, 'min_batch': 4.941116094589233, 'max_batch': 4.977495813369751}
step: 20580 @ episode report: {'average_total_reward': 10.265, 'reward_variance': 1.3511246, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8019824385643006, 'actor_loss': -4.773568201065063, 'hyper_actor_loss': 0.011745566409081221, 'behavior_loss': 0.2743308648467064, 'mean_batch': 4.87697319984436, 'min_batch': 4.853042459487915, 'max_batch': 4.9029412269592285}
step: 20590 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 2.1468563, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8002615571022034, 'actor_loss': -4.795151948928833, 'hyper_actor_loss': 0.011793335713446141, 'behavior_loss': 0.27197353094816207, 'mean_batch': 4.932595157623291, 'min_batch': 4.903067016601563, 'max_batch': 4.9615864753723145}
step: 20600 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 4.756444, 'max_total_reward': 14.45, 'min_total_reward': 5.6800003, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.520419216156006, 'actor_loss': -4.8126500129699705, 'hyper_actor_loss': 0.011734483391046524, 'behavior_loss': 0.2687471777200699, 'mean_batch': 4.974951601028442, 'min_batch': 4.9472362995147705, 'max_batch': 5.001990699768067}
step: 20610 @ episode report: {'average_total_reward': 9.110001, 'reward_variance': 3.9863002, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9865525901317596, 'actor_loss': -4.829965257644654, 'hyper_actor_loss': 0.01174506600946188, 'behavior_loss': 0.2799159109592438, 'mean_batch': 5.0216748237609865, 'min_batch': 4.986738061904907, 'max_batch': 5.059278535842895}
step: 20620 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 7.7492766, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5577587127685546, 'actor_loss': -4.787868022918701, 'hyper_actor_loss': 0.011668342631310225, 'behavior_loss': 0.27207748889923095, 'mean_batch': 4.910520601272583, 'min_batch': 4.88933162689209, 'max_batch': 4.941370677947998}
step: 20630 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 2.928709, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6947881519794463, 'actor_loss': -4.817196083068848, 'hyper_actor_loss': 0.011695937439799308, 'behavior_loss': 0.28581652194261553, 'mean_batch': 4.987989377975464, 'min_batch': 4.956798696517945, 'max_batch': 5.030422019958496}
step: 20640 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 3.2851405, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.70793496966362, 'actor_loss': -4.831203031539917, 'hyper_actor_loss': 0.011729019880294799, 'behavior_loss': 0.2551357164978981, 'mean_batch': 5.024899578094482, 'min_batch': 4.989640712738037, 'max_batch': 5.0720587253570555}
step: 20650 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 3.4103694, 'max_total_reward': 14.339999, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8631125807762146, 'actor_loss': -4.801420736312866, 'hyper_actor_loss': 0.011607504170387983, 'behavior_loss': 0.290794338285923, 'mean_batch': 4.948754835128784, 'min_batch': 4.917941999435425, 'max_batch': 4.9914507389068605}
step: 20660 @ episode report: {'average_total_reward': 8.978, 'reward_variance': 0.81843597, 'max_total_reward': 10.12, 'min_total_reward': 7.79, 'average_n_step': 10.1, 'max_n_step': 11.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5111987352371217, 'actor_loss': -4.798932838439941, 'hyper_actor_loss': 0.011578442715108394, 'behavior_loss': 0.2533318355679512, 'mean_batch': 4.9473217010498045, 'min_batch': 4.907176303863525, 'max_batch': 4.982009363174439}
step: 20670 @ episode report: {'average_total_reward': 9.544001, 'reward_variance': 3.6157653, 'max_total_reward': 13.34, 'min_total_reward': 7.68, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5367586374282838, 'actor_loss': -4.834319591522217, 'hyper_actor_loss': 0.011540875583887101, 'behavior_loss': 0.28566754460334776, 'mean_batch': 5.036894369125366, 'min_batch': 4.9932976245880125, 'max_batch': 5.055463647842407}
step: 20680 @ episode report: {'average_total_reward': 10.942001, 'reward_variance': 1.217156, 'max_total_reward': 13.12, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6934418678283691, 'actor_loss': -4.825132083892822, 'hyper_actor_loss': 0.011455944553017617, 'behavior_loss': 0.25695142298936846, 'mean_batch': 5.013212108612061, 'min_batch': 4.9710112571716305, 'max_batch': 5.027864742279053}
step: 20690 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 2.7990608, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7664023518562317, 'actor_loss': -4.796128034591675, 'hyper_actor_loss': 0.011404188070446252, 'behavior_loss': 0.2679669141769409, 'mean_batch': 4.936075496673584, 'min_batch': 4.904413175582886, 'max_batch': 4.951709365844726}
step: 20700 @ episode report: {'average_total_reward': 8.844, 'reward_variance': 3.2855842, 'max_total_reward': 12.2300005, 'min_total_reward': 6.57, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3550986796617508, 'actor_loss': -4.823681974411011, 'hyper_actor_loss': 0.011371641512960195, 'behavior_loss': 0.27683204412460327, 'mean_batch': 5.006662321090698, 'min_batch': 4.970614051818847, 'max_batch': 5.01966347694397}
step: 20710 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 2.8643613, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9052427053451537, 'actor_loss': -4.848362064361572, 'hyper_actor_loss': 0.011377849336713552, 'behavior_loss': 0.2849264472723007, 'mean_batch': 5.076890850067139, 'min_batch': 5.024081611633301, 'max_batch': 5.097343587875367}
step: 20720 @ episode report: {'average_total_reward': 10.332001, 'reward_variance': 3.5511353, 'max_total_reward': 13.45, 'min_total_reward': 7.68, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6420844495296478, 'actor_loss': -4.802765226364135, 'hyper_actor_loss': 0.01138148084282875, 'behavior_loss': 0.2796354994177818, 'mean_batch': 4.965032529830933, 'min_batch': 4.908330059051513, 'max_batch': 4.991958427429199}
step: 20730 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 2.4426847, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.0533679366111754, 'actor_loss': -4.835458421707154, 'hyper_actor_loss': 0.011429694294929505, 'behavior_loss': 0.2703538775444031, 'mean_batch': 5.0454686164855955, 'min_batch': 4.991161632537842, 'max_batch': 5.075232458114624}
step: 20740 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 2.6965404, 'max_total_reward': 14.45, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.117390203475952, 'actor_loss': -4.853485202789306, 'hyper_actor_loss': 0.01138562373816967, 'behavior_loss': 0.29181350469589235, 'mean_batch': 5.095298480987549, 'min_batch': 5.031959295272827, 'max_batch': 5.132589721679688}
step: 20750 @ episode report: {'average_total_reward': 9.566, 'reward_variance': 10.401545, 'max_total_reward': 13.340001, 'min_total_reward': 1.0200001, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8172810196876525, 'actor_loss': -4.79722032546997, 'hyper_actor_loss': 0.011413245648145675, 'behavior_loss': 0.26279537975788114, 'mean_batch': 4.9509984970092775, 'min_batch': 4.89498872756958, 'max_batch': 5.003991746902466}
step: 20760 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 3.0746617, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7060086250305175, 'actor_loss': -4.788845825195312, 'hyper_actor_loss': 0.011390031408518552, 'behavior_loss': 0.2882859230041504, 'mean_batch': 4.926497554779052, 'min_batch': 4.878283929824829, 'max_batch': 4.989962911605835}
step: 20770 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 1.6341689, 'max_total_reward': 11.12, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7486594557762145, 'actor_loss': -4.826821660995483, 'hyper_actor_loss': 0.011407252121716737, 'behavior_loss': 0.2725962623953819, 'mean_batch': 5.022659254074097, 'min_batch': 4.9700343132019045, 'max_batch': 5.090542888641357}
step: 20780 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 2.304585, 'max_total_reward': 13.120001, 'min_total_reward': 7.899999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.42760688662529, 'actor_loss': -4.832887125015259, 'hyper_actor_loss': 0.011429811641573907, 'behavior_loss': 0.27689298391342165, 'mean_batch': 5.037289476394653, 'min_batch': 4.985801458358765, 'max_batch': 5.105450963973999}
step: 20790 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 3.1252618, 'max_total_reward': 12.23, 'min_total_reward': 5.7899995, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6238780319690704, 'actor_loss': -4.85844464302063, 'hyper_actor_loss': 0.011387842800468206, 'behavior_loss': 0.2570198193192482, 'mean_batch': 5.101612377166748, 'min_batch': 5.050335311889649, 'max_batch': 5.166193628311158}
step: 20800 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 2.228041, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7453781604766845, 'actor_loss': -4.827095651626587, 'hyper_actor_loss': 0.011326161120086909, 'behavior_loss': 0.28194359689950943, 'mean_batch': 5.018066787719727, 'min_batch': 4.976113891601562, 'max_batch': 5.087004137039185}
step: 20810 @ episode report: {'average_total_reward': 10.186999, 'reward_variance': 2.1437607, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6756959855556488, 'actor_loss': -4.8197883605957035, 'hyper_actor_loss': 0.011339386459439993, 'behavior_loss': 0.27538591623306274, 'mean_batch': 4.9967827796936035, 'min_batch': 4.960770082473755, 'max_batch': 5.057903146743774}
step: 20820 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 4.6433043, 'max_total_reward': 13.23, 'min_total_reward': 6.57, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6366652488708495, 'actor_loss': -4.825525331497192, 'hyper_actor_loss': 0.011205751169472932, 'behavior_loss': 0.2790471151471138, 'mean_batch': 5.016973209381104, 'min_batch': 4.969225168228149, 'max_batch': 5.070949983596802}
step: 20830 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 3.8827248, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.940430724620819, 'actor_loss': -4.8100768566131595, 'hyper_actor_loss': 0.011257381550967694, 'behavior_loss': 0.2853052169084549, 'mean_batch': 4.974250316619873, 'min_batch': 4.93510479927063, 'max_batch': 5.015342712402344}
step: 20840 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.3089967, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8623776197433473, 'actor_loss': -4.807414531707764, 'hyper_actor_loss': 0.01123024420812726, 'behavior_loss': 0.28138734996318815, 'mean_batch': 4.968207693099975, 'min_batch': 4.9279077529907225, 'max_batch': 5.001055431365967}
step: 20850 @ episode report: {'average_total_reward': 8.776999, 'reward_variance': 2.9598606, 'max_total_reward': 11.23, 'min_total_reward': 5.7900004, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7485459446907043, 'actor_loss': -4.814303255081176, 'hyper_actor_loss': 0.011258249916136265, 'behavior_loss': 0.25224210023880006, 'mean_batch': 4.987075901031494, 'min_batch': 4.943232822418213, 'max_batch': 5.018283843994141}
step: 20860 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 2.4295297, 'max_total_reward': 14.56, 'min_total_reward': 9.009999, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6040184259414674, 'actor_loss': -4.841531276702881, 'hyper_actor_loss': 0.011175150517374277, 'behavior_loss': 0.25921015441417694, 'mean_batch': 5.0613140106201175, 'min_batch': 5.005280160903931, 'max_batch': 5.091132402420044}
step: 20870 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.3879056, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4141494274139403, 'actor_loss': -4.8430037021636965, 'hyper_actor_loss': 0.01107781296595931, 'behavior_loss': 0.2797375231981277, 'mean_batch': 5.065876007080078, 'min_batch': 5.008051872253418, 'max_batch': 5.087205314636231}
step: 20880 @ episode report: {'average_total_reward': 9.455, 'reward_variance': 1.7617056, 'max_total_reward': 11.12, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9555635303258896, 'actor_loss': -4.841019535064698, 'hyper_actor_loss': 0.01110637942329049, 'behavior_loss': 0.27152699381113055, 'mean_batch': 5.058098030090332, 'min_batch': 5.005979537963867, 'max_batch': 5.073759317398071}
step: 20890 @ episode report: {'average_total_reward': 9.566, 'reward_variance': 1.5007443, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.933712327480316, 'actor_loss': -4.793534994125366, 'hyper_actor_loss': 0.011002364475280047, 'behavior_loss': 0.2675923764705658, 'mean_batch': 4.933409786224365, 'min_batch': 4.8944704055786135, 'max_batch': 4.9528180122375485}
step: 20900 @ episode report: {'average_total_reward': 10.431002, 'reward_variance': 5.354889, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7639197409152985, 'actor_loss': -4.79333987236023, 'hyper_actor_loss': 0.01103966562077403, 'behavior_loss': 0.27213768661022186, 'mean_batch': 4.932893466949463, 'min_batch': 4.8940423965454105, 'max_batch': 4.9638340950012205}
step: 20910 @ episode report: {'average_total_reward': 9.066, 'reward_variance': 5.9592643, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5893624424934387, 'actor_loss': -4.84399733543396, 'hyper_actor_loss': 0.01108674043789506, 'behavior_loss': 0.27787192165851593, 'mean_batch': 5.061666822433471, 'min_batch': 5.017312288284302, 'max_batch': 5.100589799880981}
step: 20920 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 3.2483006, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1057695388793944, 'actor_loss': -4.831575155258179, 'hyper_actor_loss': 0.011061320453882218, 'behavior_loss': 0.28097841143608093, 'mean_batch': 5.03330249786377, 'min_batch': 4.983599233627319, 'max_batch': 5.070625972747803}
step: 20930 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 2.3091285, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6623670518398286, 'actor_loss': -4.793371391296387, 'hyper_actor_loss': 0.011005509365350007, 'behavior_loss': 0.26199164241552353, 'mean_batch': 4.940803527832031, 'min_batch': 4.88618574142456, 'max_batch': 4.982114458084107}
step: 20940 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 4.523423, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.468488973379135, 'actor_loss': -4.832335090637207, 'hyper_actor_loss': 0.010995631478726864, 'behavior_loss': 0.2859084278345108, 'mean_batch': 5.035633230209351, 'min_batch': 4.984812164306641, 'max_batch': 5.060186195373535}
step: 20950 @ episode report: {'average_total_reward': 8.622, 'reward_variance': 8.454677, 'max_total_reward': 12.2300005, 'min_total_reward': 1.13, 'average_n_step': 9.7, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1978468179702757, 'actor_loss': -4.819604206085205, 'hyper_actor_loss': 0.011107410117983819, 'behavior_loss': 0.2826709449291229, 'mean_batch': 5.003614854812622, 'min_batch': 4.953431415557861, 'max_batch': 5.022960948944092}
step: 20960 @ episode report: {'average_total_reward': 9.888, 'reward_variance': 5.039936, 'max_total_reward': 15.34, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8971164226531982, 'actor_loss': -4.788518714904785, 'hyper_actor_loss': 0.011039215046912432, 'behavior_loss': 0.2760609433054924, 'mean_batch': 4.921131563186646, 'min_batch': 4.881971645355224, 'max_batch': 4.940736484527588}
step: 20970 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 8.188089, 'max_total_reward': 13.340001, 'min_total_reward': 5.6800003, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0123666882514955, 'actor_loss': -4.790873861312866, 'hyper_actor_loss': 0.011066817585378886, 'behavior_loss': 0.2761898756027222, 'mean_batch': 4.924574375152588, 'min_batch': 4.890025615692139, 'max_batch': 4.948398494720459}
step: 20980 @ episode report: {'average_total_reward': 11.209002, 'reward_variance': 1.6840084, 'max_total_reward': 12.34, 'min_total_reward': 7.680001, 'average_n_step': 12.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5531422913074493, 'actor_loss': -4.808459806442261, 'hyper_actor_loss': 0.011049960553646088, 'behavior_loss': 0.26634959131479263, 'mean_batch': 4.9652200698852536, 'min_batch': 4.936237001419068, 'max_batch': 4.9834836483001705}
step: 20990 @ episode report: {'average_total_reward': 9.698999, 'reward_variance': 1.9659485, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6415020942687988, 'actor_loss': -4.857497882843018, 'hyper_actor_loss': 0.010979299061000347, 'behavior_loss': 0.28272455334663393, 'mean_batch': 5.09194598197937, 'min_batch': 5.055165815353393, 'max_batch': 5.10544719696045}
step: 21000 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 4.4869413, 'max_total_reward': 13.45, 'min_total_reward': 5.5699997, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.736828863620758, 'actor_loss': -4.8356410503387455, 'hyper_actor_loss': 0.010951659921556712, 'behavior_loss': 0.25454215705394745, 'mean_batch': 5.032557821273803, 'min_batch': 5.004313945770264, 'max_batch': 5.044290781021118}
step: 21010 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.536224, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.64505295753479, 'actor_loss': -4.823642158508301, 'hyper_actor_loss': 0.010875615570694209, 'behavior_loss': 0.2651955187320709, 'mean_batch': 5.0046196460723875, 'min_batch': 4.972152233123779, 'max_batch': 5.020429086685181}
step: 21020 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 3.4108047, 'max_total_reward': 12.340001, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5429775357246398, 'actor_loss': -4.8328996181488035, 'hyper_actor_loss': 0.010813639499247074, 'behavior_loss': 0.26673998683691025, 'mean_batch': 5.0270530700683596, 'min_batch': 4.995934629440308, 'max_batch': 5.044894409179688}
step: 21030 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 0.87334377, 'max_total_reward': 12.23, 'min_total_reward': 9.009999, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7633784890174866, 'actor_loss': -4.84344515800476, 'hyper_actor_loss': 0.010754388477653264, 'behavior_loss': 0.2749530032277107, 'mean_batch': 5.051303577423096, 'min_batch': 5.024669742584228, 'max_batch': 5.064536428451538}
step: 21040 @ episode report: {'average_total_reward': 10.386999, 'reward_variance': 5.485263, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7907932162284852, 'actor_loss': -4.833045291900635, 'hyper_actor_loss': 0.010773080959916114, 'behavior_loss': 0.286625312268734, 'mean_batch': 5.024043178558349, 'min_batch': 4.999773216247559, 'max_batch': 5.040603446960449}
step: 21050 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 1.7332767, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.083026099205017, 'actor_loss': -4.798670482635498, 'hyper_actor_loss': 0.01076965294778347, 'behavior_loss': 0.26781788319349287, 'mean_batch': 4.937210416793823, 'min_batch': 4.9157774448394775, 'max_batch': 4.956191301345825}
step: 21060 @ episode report: {'average_total_reward': 8.844, 'reward_variance': 4.7493634, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.06401983499527, 'actor_loss': -4.764742374420166, 'hyper_actor_loss': 0.010683651734143495, 'behavior_loss': 0.2779659628868103, 'mean_batch': 4.8553938388824465, 'min_batch': 4.831834888458252, 'max_batch': 4.870987796783448}
step: 21070 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 1.2476351, 'max_total_reward': 13.339999, 'min_total_reward': 9.010001, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.787719291448593, 'actor_loss': -4.804277658462524, 'hyper_actor_loss': 0.010760828480124473, 'behavior_loss': 0.26162864863872526, 'mean_batch': 4.958228397369385, 'min_batch': 4.92303614616394, 'max_batch': 4.97387809753418}
step: 21080 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 2.3172698, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6563597202301026, 'actor_loss': -4.834504556655884, 'hyper_actor_loss': 0.010670337360352278, 'behavior_loss': 0.269834403693676, 'mean_batch': 5.0382835388183596, 'min_batch': 4.992840766906738, 'max_batch': 5.055338573455811}
step: 21090 @ episode report: {'average_total_reward': 11.02, 'reward_variance': 3.3715599, 'max_total_reward': 14.559999, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8301139175891876, 'actor_loss': -4.806435918807983, 'hyper_actor_loss': 0.010643347259610891, 'behavior_loss': 0.2728621229529381, 'mean_batch': 4.972093391418457, 'min_batch': 4.919374704360962, 'max_batch': 4.98852014541626}
step: 21100 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 2.014545, 'max_total_reward': 11.900001, 'min_total_reward': 6.7900004, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5130815863609315, 'actor_loss': -4.8168477535247805, 'hyper_actor_loss': 0.010522151179611684, 'behavior_loss': 0.2710420325398445, 'mean_batch': 5.002389574050904, 'min_batch': 4.940841865539551, 'max_batch': 5.0232429027557375}
step: 21110 @ episode report: {'average_total_reward': 8.966001, 'reward_variance': 6.392464, 'max_total_reward': 14.45, 'min_total_reward': 5.79, 'average_n_step': 10.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3653809070587157, 'actor_loss': -4.852168798446655, 'hyper_actor_loss': 0.010609190817922354, 'behavior_loss': 0.2838011994957924, 'mean_batch': 5.096799373626709, 'min_batch': 5.0234778881072994, 'max_batch': 5.119036245346069}
step: 21120 @ episode report: {'average_total_reward': 9.577001, 'reward_variance': 3.965922, 'max_total_reward': 12.230001, 'min_total_reward': 5.68, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9487354040145874, 'actor_loss': -4.822435760498047, 'hyper_actor_loss': 0.010534735023975372, 'behavior_loss': 0.26361401528120043, 'mean_batch': 5.021101284027099, 'min_batch': 4.950146484375, 'max_batch': 5.04674506187439}
step: 21130 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 2.4661365, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3244606733322144, 'actor_loss': -4.806328916549683, 'hyper_actor_loss': 0.010453324392437935, 'behavior_loss': 0.27313980311155317, 'mean_batch': 4.975374937057495, 'min_batch': 4.915786457061768, 'max_batch': 4.997065496444702}
step: 21140 @ episode report: {'average_total_reward': 10.442, 'reward_variance': 4.409875, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7783186078071593, 'actor_loss': -4.8552947521209715, 'hyper_actor_loss': 0.010535398498177528, 'behavior_loss': 0.2767991155385971, 'mean_batch': 5.096809577941895, 'min_batch': 5.039184331893921, 'max_batch': 5.119083309173584}
step: 21150 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 7.24207, 'max_total_reward': 13.45, 'min_total_reward': 3.57, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.857421338558197, 'actor_loss': -4.830106639862061, 'hyper_actor_loss': 0.010447460785508155, 'behavior_loss': 0.2792923510074615, 'mean_batch': 5.030442571640014, 'min_batch': 4.978872489929199, 'max_batch': 5.054387187957763}
step: 21160 @ episode report: {'average_total_reward': 11.009001, 'reward_variance': 3.4971886, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3208368688821792, 'actor_loss': -4.8123143196105955, 'hyper_actor_loss': 0.010397049132734537, 'behavior_loss': 0.2536585196852684, 'mean_batch': 4.983724546432495, 'min_batch': 4.936832141876221, 'max_batch': 5.003372049331665}
step: 21170 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 4.7932653, 'max_total_reward': 14.450001, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6415314972400665, 'actor_loss': -4.864775514602661, 'hyper_actor_loss': 0.010376894380897284, 'behavior_loss': 0.25838801115751264, 'mean_batch': 5.123187637329101, 'min_batch': 5.061115884780884, 'max_batch': 5.142234945297242}
step: 21180 @ episode report: {'average_total_reward': 9.943, 'reward_variance': 4.0687013, 'max_total_reward': 14.450001, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.023413521051407, 'actor_loss': -4.858122158050537, 'hyper_actor_loss': 0.010286513902246951, 'behavior_loss': 0.26387605369091033, 'mean_batch': 5.102992725372315, 'min_batch': 5.0476408958435055, 'max_batch': 5.122995090484619}
step: 21190 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 5.323262, 'max_total_reward': 13.340001, 'min_total_reward': 4.68, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5364673376083373, 'actor_loss': -4.807107543945312, 'hyper_actor_loss': 0.010259206406772137, 'behavior_loss': 0.26017303466796876, 'mean_batch': 4.962504243850708, 'min_batch': 4.932089519500733, 'max_batch': 5.004781818389892}
step: 21200 @ episode report: {'average_total_reward': 11.575001, 'reward_variance': 1.8823849, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7822058618068695, 'actor_loss': -4.828427076339722, 'hyper_actor_loss': 0.010163354687392712, 'behavior_loss': 0.27466260492801664, 'mean_batch': 5.018879652023315, 'min_batch': 4.981898498535156, 'max_batch': 5.071969318389892}
step: 21210 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 4.0897613, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8388789653778077, 'actor_loss': -4.830227851867676, 'hyper_actor_loss': 0.01016850145533681, 'behavior_loss': 0.2755980134010315, 'mean_batch': 5.021747493743897, 'min_batch': 4.987921094894409, 'max_batch': 5.062925100326538}
step: 21220 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 5.4573565, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9670626401901246, 'actor_loss': -4.805585241317749, 'hyper_actor_loss': 0.010189932119101287, 'behavior_loss': 0.27207873910665514, 'mean_batch': 4.959302377700806, 'min_batch': 4.927797651290893, 'max_batch': 5.001332759857178}
step: 21230 @ episode report: {'average_total_reward': 10.742002, 'reward_variance': 3.5921566, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0688069581985475, 'actor_loss': -4.798909759521484, 'hyper_actor_loss': 0.010206233523786069, 'behavior_loss': 0.28247173577547074, 'mean_batch': 4.940275764465332, 'min_batch': 4.9138054847717285, 'max_batch': 4.979718399047852}
step: 21240 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 7.5850806, 'max_total_reward': 13.450001, 'min_total_reward': 6.7899995, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8403434038162232, 'actor_loss': -4.804580354690552, 'hyper_actor_loss': 0.010140580870211125, 'behavior_loss': 0.2727588668465614, 'mean_batch': 4.958147430419922, 'min_batch': 4.923974561691284, 'max_batch': 5.006405448913574}
step: 21250 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 0.736801, 'max_total_reward': 12.120001, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.110581946372986, 'actor_loss': -4.815729093551636, 'hyper_actor_loss': 0.010300060268491507, 'behavior_loss': 0.2794897869229317, 'mean_batch': 4.98894190788269, 'min_batch': 4.948424816131592, 'max_batch': 5.03868408203125}
step: 21260 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 6.828865, 'max_total_reward': 13.450001, 'min_total_reward': 4.68, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.914980697631836, 'actor_loss': -4.780950450897217, 'hyper_actor_loss': 0.010370205249637365, 'behavior_loss': 0.29774418771266936, 'mean_batch': 4.900787401199341, 'min_batch': 4.86526780128479, 'max_batch': 4.954349660873413}
step: 21270 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.0007808, 'max_total_reward': 12.2300005, 'min_total_reward': 7.68, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9653445482254028, 'actor_loss': -4.783917760848999, 'hyper_actor_loss': 0.010357924923300742, 'behavior_loss': 0.2663012444972992, 'mean_batch': 4.906907844543457, 'min_batch': 4.873693227767944, 'max_batch': 4.946292543411255}
step: 21280 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 1.4605837, 'max_total_reward': 12.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7541505575180054, 'actor_loss': -4.812435150146484, 'hyper_actor_loss': 0.010324564669281245, 'behavior_loss': 0.27288578301668165, 'mean_batch': 4.978701496124268, 'min_batch': 4.942315101623535, 'max_batch': 5.014032506942749}
step: 21290 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 1.8103037, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4245245993137359, 'actor_loss': -4.839305782318116, 'hyper_actor_loss': 0.010219427291303873, 'behavior_loss': 0.2831253856420517, 'mean_batch': 5.048721981048584, 'min_batch': 5.006639862060547, 'max_batch': 5.078436040878296}
step: 21300 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 3.0232968, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7073615074157715, 'actor_loss': -4.832925271987915, 'hyper_actor_loss': 0.01027574073523283, 'behavior_loss': 0.27756383568048476, 'mean_batch': 5.033987998962402, 'min_batch': 4.989397573471069, 'max_batch': 5.057909393310547}
step: 21310 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 3.0219052, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4941085189580918, 'actor_loss': -4.823093032836914, 'hyper_actor_loss': 0.0102589744143188, 'behavior_loss': 0.2648721769452095, 'mean_batch': 5.013175106048584, 'min_batch': 4.961002492904663, 'max_batch': 5.032507801055909}
step: 21320 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 3.9354215, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.641235637664795, 'actor_loss': -4.8509557247161865, 'hyper_actor_loss': 0.010181673802435398, 'behavior_loss': 0.2721033975481987, 'mean_batch': 5.08922438621521, 'min_batch': 5.024855041503907, 'max_batch': 5.107522630691529}
step: 21330 @ episode report: {'average_total_reward': 10.431001, 'reward_variance': 6.5672097, 'max_total_reward': 14.450001, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8466373205184936, 'actor_loss': -4.811337089538574, 'hyper_actor_loss': 0.010057936236262322, 'behavior_loss': 0.2668940111994743, 'mean_batch': 5.005819511413574, 'min_batch': 4.910333061218262, 'max_batch': 5.025884485244751}
step: 21340 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 1.1553596, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6763551831245422, 'actor_loss': -4.812681436538696, 'hyper_actor_loss': 0.010144140385091305, 'behavior_loss': 0.2779763966798782, 'mean_batch': 4.991065788269043, 'min_batch': 4.931284379959107, 'max_batch': 5.009027528762817}
step: 21350 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 2.9491167, 'max_total_reward': 14.56, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6872759699821471, 'actor_loss': -4.824922275543213, 'hyper_actor_loss': 0.010147805605083705, 'behavior_loss': 0.27052321583032607, 'mean_batch': 5.025213050842285, 'min_batch': 4.9580854892730715, 'max_batch': 5.0443521499633786}
step: 21360 @ episode report: {'average_total_reward': 11.541, 'reward_variance': 3.4055297, 'max_total_reward': 14.56, 'min_total_reward': 9.009999, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3483762443065643, 'actor_loss': -4.849811792373657, 'hyper_actor_loss': 0.010198970697820187, 'behavior_loss': 0.25352238714694975, 'mean_batch': 5.085159492492676, 'min_batch': 5.0233605861663815, 'max_batch': 5.118770408630371}
step: 21370 @ episode report: {'average_total_reward': 11.1310005, 'reward_variance': 2.8017087, 'max_total_reward': 15.56, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8323172092437745, 'actor_loss': -4.857862043380737, 'hyper_actor_loss': 0.010100688599050046, 'behavior_loss': 0.263028147816658, 'mean_batch': 5.102320766448974, 'min_batch': 5.046807909011841, 'max_batch': 5.143526697158814}
step: 21380 @ episode report: {'average_total_reward': 10.553999, 'reward_variance': 2.6048837, 'max_total_reward': 13.23, 'min_total_reward': 7.57, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.879171621799469, 'actor_loss': -4.814408302307129, 'hyper_actor_loss': 0.00998253533616662, 'behavior_loss': 0.2839363545179367, 'mean_batch': 4.988041543960572, 'min_batch': 4.942849349975586, 'max_batch': 5.01727991104126}
step: 21390 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 4.6442814, 'max_total_reward': 13.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5887491047382354, 'actor_loss': -4.8146223545074465, 'hyper_actor_loss': 0.010035388451069594, 'behavior_loss': 0.2716324806213379, 'mean_batch': 4.988646078109741, 'min_batch': 4.943328189849853, 'max_batch': 5.003421926498413}
step: 21400 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 6.4786005, 'max_total_reward': 13.450001, 'min_total_reward': 4.68, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8117982983589171, 'actor_loss': -4.840527486801148, 'hyper_actor_loss': 0.010010773781687021, 'behavior_loss': 0.27193930745124817, 'mean_batch': 5.0519767761230465, 'min_batch': 5.009367799758911, 'max_batch': 5.063412284851074}
step: 21410 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.3974855, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6998606503009797, 'actor_loss': -4.823667764663696, 'hyper_actor_loss': 0.009929959196597338, 'behavior_loss': 0.27801828384399413, 'mean_batch': 5.001629066467285, 'min_batch': 4.975244760513306, 'max_batch': 5.015288591384888}
step: 21420 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.8147435, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8047781825065612, 'actor_loss': -4.8174418926239015, 'hyper_actor_loss': 0.009942107088863849, 'behavior_loss': 0.29331178963184357, 'mean_batch': 4.983756065368652, 'min_batch': 4.962040138244629, 'max_batch': 4.999217319488525}
step: 21430 @ episode report: {'average_total_reward': 11.564, 'reward_variance': 2.2303238, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6366430997848511, 'actor_loss': -4.846154594421387, 'hyper_actor_loss': 0.009946447610855103, 'behavior_loss': 0.2712306663393974, 'mean_batch': 5.056649541854858, 'min_batch': 5.033162069320679, 'max_batch': 5.076195955276489}
step: 21440 @ episode report: {'average_total_reward': 11.331001, 'reward_variance': 2.803929, 'max_total_reward': 15.67, 'min_total_reward': 9.79, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.087504506111145, 'actor_loss': -4.825600242614746, 'hyper_actor_loss': 0.009939535707235336, 'behavior_loss': 0.2683084517717361, 'mean_batch': 5.008385276794433, 'min_batch': 4.978804063796997, 'max_batch': 5.032207012176514}
step: 21450 @ episode report: {'average_total_reward': 10.321001, 'reward_variance': 2.0902686, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8382027208805085, 'actor_loss': -4.773252201080322, 'hyper_actor_loss': 0.009942658431828021, 'behavior_loss': 0.26465936601161955, 'mean_batch': 4.882601165771485, 'min_batch': 4.8462378025054935, 'max_batch': 4.901676893234253}
step: 21460 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 1.4143243, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8313026905059815, 'actor_loss': -4.8371522426605225, 'hyper_actor_loss': 0.009830516111105681, 'behavior_loss': 0.26783859431743623, 'mean_batch': 5.035984182357788, 'min_batch': 5.0085851669311525, 'max_batch': 5.05617938041687}
step: 21470 @ episode report: {'average_total_reward': 11.231, 'reward_variance': 3.1288695, 'max_total_reward': 15.67, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.023985981941223, 'actor_loss': -4.8253209590911865, 'hyper_actor_loss': 0.009842597786337138, 'behavior_loss': 0.2752727523446083, 'mean_batch': 5.011271047592163, 'min_batch': 4.974091053009033, 'max_batch': 5.035742950439453}
step: 21480 @ episode report: {'average_total_reward': 10.864001, 'reward_variance': 4.9017043, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.477252906560898, 'actor_loss': -4.796668148040771, 'hyper_actor_loss': 0.009735641907900572, 'behavior_loss': 0.2633814483880997, 'mean_batch': 4.9451375007629395, 'min_batch': 4.898198175430298, 'max_batch': 4.975287675857544}
step: 21490 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 0.7988288, 'max_total_reward': 12.34, 'min_total_reward': 10.01, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6216736078262328, 'actor_loss': -4.847124671936035, 'hyper_actor_loss': 0.009793282579630613, 'behavior_loss': 0.28311065286397935, 'mean_batch': 5.079458379745484, 'min_batch': 5.0153998851776125, 'max_batch': 5.102047157287598}
step: 21500 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 4.730581, 'max_total_reward': 14.45, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4815816044807435, 'actor_loss': -4.863900566101075, 'hyper_actor_loss': 0.009736967273056507, 'behavior_loss': 0.27205644100904464, 'mean_batch': 5.124103975296021, 'min_batch': 5.055695724487305, 'max_batch': 5.144553089141846}
step: 21510 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 6.9796867, 'max_total_reward': 15.670001, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.630926513671875, 'actor_loss': -4.835049772262574, 'hyper_actor_loss': 0.009698025789111853, 'behavior_loss': 0.2643544226884842, 'mean_batch': 5.05476016998291, 'min_batch': 4.97942042350769, 'max_batch': 5.076168155670166}
step: 21520 @ episode report: {'average_total_reward': 10.664, 'reward_variance': 2.665844, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.2442286431789398, 'actor_loss': -4.840305662155151, 'hyper_actor_loss': 0.009693577885627747, 'behavior_loss': 0.27208577245473864, 'mean_batch': 5.069253444671631, 'min_batch': 4.991631317138672, 'max_batch': 5.087739658355713}
step: 21530 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 3.5897365, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8723221302032471, 'actor_loss': -4.861317110061646, 'hyper_actor_loss': 0.009643950965255499, 'behavior_loss': 0.2789748594164848, 'mean_batch': 5.124421072006226, 'min_batch': 5.042459726333618, 'max_batch': 5.1385509967803955}
step: 21540 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 4.000795, 'max_total_reward': 14.339999, 'min_total_reward': 8.68, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6538537621498108, 'actor_loss': -4.819565343856811, 'hyper_actor_loss': 0.009628902934491635, 'behavior_loss': 0.2663212239742279, 'mean_batch': 5.012682104110718, 'min_batch': 4.944088411331177, 'max_batch': 5.026268196105957}
step: 21550 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.3043046, 'max_total_reward': 13.2300005, 'min_total_reward': 8.790001, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7609310805797578, 'actor_loss': -4.832484912872315, 'hyper_actor_loss': 0.009630974754691124, 'behavior_loss': 0.276457254588604, 'mean_batch': 5.044684219360351, 'min_batch': 4.976597929000855, 'max_batch': 5.0583672523498535}
step: 21560 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 2.9966407, 'max_total_reward': 13.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8115236401557921, 'actor_loss': -4.840020799636841, 'hyper_actor_loss': 0.009631363954395056, 'behavior_loss': 0.27409448325634, 'mean_batch': 5.0495024681091305, 'min_batch': 5.00933804512024, 'max_batch': 5.061359310150147}
step: 21570 @ episode report: {'average_total_reward': 11.597001, 'reward_variance': 3.137981, 'max_total_reward': 14.45, 'min_total_reward': 9.01, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8965580940246582, 'actor_loss': -4.821893739700317, 'hyper_actor_loss': 0.00963048031553626, 'behavior_loss': 0.2726651981472969, 'mean_batch': 4.99812331199646, 'min_batch': 4.969890832901001, 'max_batch': 5.012176513671875}
step: 21580 @ episode report: {'average_total_reward': 11.264001, 'reward_variance': 4.282924, 'max_total_reward': 15.67, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7572704315185548, 'actor_loss': -4.807266187667847, 'hyper_actor_loss': 0.009548859670758247, 'behavior_loss': 0.28208511471748354, 'mean_batch': 4.9693845272064205, 'min_batch': 4.926040554046631, 'max_batch': 4.994498443603516}
step: 21590 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 4.3623996, 'max_total_reward': 15.67, 'min_total_reward': 6.9000006, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.529350256919861, 'actor_loss': -4.831645774841308, 'hyper_actor_loss': 0.009523609187453985, 'behavior_loss': 0.28277214169502257, 'mean_batch': 5.038863754272461, 'min_batch': 4.9781811237335205, 'max_batch': 5.059009265899658}
step: 21600 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 4.683266, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4458307087421418, 'actor_loss': -4.8726202011108395, 'hyper_actor_loss': 0.009485859703272582, 'behavior_loss': 0.26141014099121096, 'mean_batch': 5.1465002536773685, 'min_batch': 5.077767086029053, 'max_batch': 5.166824769973755}
step: 21610 @ episode report: {'average_total_reward': 9.577001, 'reward_variance': 4.0002213, 'max_total_reward': 13.450001, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6911704897880555, 'actor_loss': -4.8636962890625, 'hyper_actor_loss': 0.009521647449582815, 'behavior_loss': 0.2687957689166069, 'mean_batch': 5.125324487686157, 'min_batch': 5.053529977798462, 'max_batch': 5.145637369155883}
step: 21620 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 3.499316, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5243762016296387, 'actor_loss': -4.849192333221436, 'hyper_actor_loss': 0.009411701932549477, 'behavior_loss': 0.2690825641155243, 'mean_batch': 5.083906888961792, 'min_batch': 5.021243238449097, 'max_batch': 5.103572654724121}
step: 21630 @ episode report: {'average_total_reward': 11.264, 'reward_variance': 5.290604, 'max_total_reward': 15.67, 'min_total_reward': 6.9, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8331108808517456, 'actor_loss': -4.843640327453613, 'hyper_actor_loss': 0.009420400205999612, 'behavior_loss': 0.2930418223142624, 'mean_batch': 5.059908199310303, 'min_batch': 5.017186307907105, 'max_batch': 5.081488800048828}
step: 21640 @ episode report: {'average_total_reward': 11.064, 'reward_variance': 3.2440047, 'max_total_reward': 13.45, 'min_total_reward': 6.899999, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7392199754714965, 'actor_loss': -4.836513042449951, 'hyper_actor_loss': 0.00945011069998145, 'behavior_loss': 0.2694525718688965, 'mean_batch': 5.035891675949097, 'min_batch': 5.005234098434448, 'max_batch': 5.060249519348145}
step: 21650 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 4.3498955, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5768769145011903, 'actor_loss': -4.855824899673462, 'hyper_actor_loss': 0.009420467540621758, 'behavior_loss': 0.2838947534561157, 'mean_batch': 5.083238744735718, 'min_batch': 5.055368185043335, 'max_batch': 5.125637769699097}
step: 21660 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 5.452841, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8682535886764526, 'actor_loss': -4.836753797531128, 'hyper_actor_loss': 0.009487636107951402, 'behavior_loss': 0.28681049346923826, 'mean_batch': 5.034984922409057, 'min_batch': 5.00755934715271, 'max_batch': 5.090841150283813}
step: 21670 @ episode report: {'average_total_reward': 9.455, 'reward_variance': 4.760525, 'max_total_reward': 12.34, 'min_total_reward': 5.4600005, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4534151554107666, 'actor_loss': -4.842440223693847, 'hyper_actor_loss': 0.009465462155640125, 'behavior_loss': 0.2656807154417038, 'mean_batch': 5.050620174407959, 'min_batch': 5.0205076217651365, 'max_batch': 5.112555456161499}
step: 21680 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 3.2347457, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7551018834114074, 'actor_loss': -4.874573135375977, 'hyper_actor_loss': 0.009449954237788915, 'behavior_loss': 0.2531271934509277, 'mean_batch': 5.140140104293823, 'min_batch': 5.093976306915283, 'max_batch': 5.222974109649658}
step: 21690 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 4.1816645, 'max_total_reward': 13.45, 'min_total_reward': 5.6799994, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8400647222995759, 'actor_loss': -4.85374608039856, 'hyper_actor_loss': 0.009322954528033733, 'behavior_loss': 0.26716685593128203, 'mean_batch': 5.090038633346557, 'min_batch': 5.038108491897583, 'max_batch': 5.177448797225952}
step: 21700 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 6.7197967, 'max_total_reward': 14.450001, 'min_total_reward': 4.57, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7686066031455994, 'actor_loss': -4.83838038444519, 'hyper_actor_loss': 0.009231069684028625, 'behavior_loss': 0.26673439145088196, 'mean_batch': 5.0484860897064205, 'min_batch': 5.002073097229004, 'max_batch': 5.130473995208741}
step: 21710 @ episode report: {'average_total_reward': 10.986, 'reward_variance': 4.6050844, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.2240427613258362, 'actor_loss': -4.8538023948669435, 'hyper_actor_loss': 0.00927717937156558, 'behavior_loss': 0.2611701741814613, 'mean_batch': 5.089768409729004, 'min_batch': 5.038884782791138, 'max_batch': 5.175721168518066}
step: 21720 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 5.1137443, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7339558184146882, 'actor_loss': -4.88750901222229, 'hyper_actor_loss': 0.009236753825098276, 'behavior_loss': 0.26745121330022814, 'mean_batch': 5.180452919006347, 'min_batch': 5.120124244689942, 'max_batch': 5.272086429595947}
step: 21730 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 4.848749, 'max_total_reward': 14.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8701864302158355, 'actor_loss': -4.860685253143311, 'hyper_actor_loss': 0.009165316727012396, 'behavior_loss': 0.251212839782238, 'mean_batch': 5.106375646591187, 'min_batch': 5.057137584686279, 'max_batch': 5.174630212783813}
step: 21740 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 2.9994593, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6877235293388366, 'actor_loss': -4.830214977264404, 'hyper_actor_loss': 0.009166277758777142, 'behavior_loss': 0.27299941778182985, 'mean_batch': 5.023479461669922, 'min_batch': 4.986108779907227, 'max_batch': 5.0739298343658445}
step: 21750 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 1.5264962, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.600199806690216, 'actor_loss': -4.8558512210845945, 'hyper_actor_loss': 0.009104192350059747, 'behavior_loss': 0.24878496378660203, 'mean_batch': 5.088607692718506, 'min_batch': 5.050193214416504, 'max_batch': 5.1262922286987305}
step: 21760 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 1.4708054, 'max_total_reward': 12.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0091073155403136, 'actor_loss': -4.857071495056152, 'hyper_actor_loss': 0.009081409499049186, 'behavior_loss': 0.27363934069871904, 'mean_batch': 5.093740367889405, 'min_batch': 5.051338338851929, 'max_batch': 5.13568115234375}
step: 21770 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 4.5184207, 'max_total_reward': 13.45, 'min_total_reward': 4.6800003, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9164130747318269, 'actor_loss': -4.84018874168396, 'hyper_actor_loss': 0.00916341645643115, 'behavior_loss': 0.272113573551178, 'mean_batch': 5.050856590270996, 'min_batch': 5.008791875839234, 'max_batch': 5.092767953872681}
step: 21780 @ episode report: {'average_total_reward': 10.875, 'reward_variance': 2.761486, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7567785263061524, 'actor_loss': -4.829572343826294, 'hyper_actor_loss': 0.00909995948895812, 'behavior_loss': 0.2639618396759033, 'mean_batch': 5.023245859146118, 'min_batch': 4.983140373229981, 'max_batch': 5.041610336303711}
step: 21790 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 3.1847687, 'max_total_reward': 14.45, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7064809918403625, 'actor_loss': -4.8544886112213135, 'hyper_actor_loss': 0.009093731828033923, 'behavior_loss': 0.26129329204559326, 'mean_batch': 5.090154790878296, 'min_batch': 5.041883897781372, 'max_batch': 5.106916713714599}
step: 21800 @ episode report: {'average_total_reward': 9.821, 'reward_variance': 3.0125291, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0953579902648927, 'actor_loss': -4.839243698120117, 'hyper_actor_loss': 0.0091169866733253, 'behavior_loss': 0.2759713053703308, 'mean_batch': 5.045351982116699, 'min_batch': 5.009968042373657, 'max_batch': 5.06577696800232}
step: 21810 @ episode report: {'average_total_reward': 8.511, 'reward_variance': 6.34903, 'max_total_reward': 11.120001, 'min_total_reward': 3.46, 'average_n_step': 9.6, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7230885982513429, 'actor_loss': -4.822303771972656, 'hyper_actor_loss': 0.009102177154272795, 'behavior_loss': 0.2759342983365059, 'mean_batch': 5.000617504119873, 'min_batch': 4.969525098800659, 'max_batch': 5.033497381210327}
step: 21820 @ episode report: {'average_total_reward': 9.544, 'reward_variance': 1.8736643, 'max_total_reward': 12.34, 'min_total_reward': 7.57, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9414520859718323, 'actor_loss': -4.855723428726196, 'hyper_actor_loss': 0.009081129357218743, 'behavior_loss': 0.27014908343553545, 'mean_batch': 5.085560369491577, 'min_batch': 5.0524821281433105, 'max_batch': 5.125502729415894}
step: 21830 @ episode report: {'average_total_reward': 11.153002, 'reward_variance': 5.277463, 'max_total_reward': 14.56, 'min_total_reward': 7.7899995, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6836614966392518, 'actor_loss': -4.844735383987427, 'hyper_actor_loss': 0.00899352291598916, 'behavior_loss': 0.2693404763936996, 'mean_batch': 5.064576482772827, 'min_batch': 5.017993831634522, 'max_batch': 5.1155928611755375}
step: 21840 @ episode report: {'average_total_reward': 10.986, 'reward_variance': 4.993385, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.984094226360321, 'actor_loss': -4.843925428390503, 'hyper_actor_loss': 0.008957187365740537, 'behavior_loss': 0.27570030093193054, 'mean_batch': 5.063306665420532, 'min_batch': 5.015215921401977, 'max_batch': 5.125239849090576}
step: 21850 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 3.2578158, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6673667669296264, 'actor_loss': -4.828477382659912, 'hyper_actor_loss': 0.009012064710259438, 'behavior_loss': 0.2704330697655678, 'mean_batch': 5.026516437530518, 'min_batch': 4.974484920501709, 'max_batch': 5.087009716033935}
step: 21860 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 1.6272558, 'max_total_reward': 12.12, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5303764939308167, 'actor_loss': -4.872941732406616, 'hyper_actor_loss': 0.009053086582571267, 'behavior_loss': 0.25645848363637924, 'mean_batch': 5.1488929271698, 'min_batch': 5.077535820007324, 'max_batch': 5.222465181350708}
step: 21870 @ episode report: {'average_total_reward': 11.031, 'reward_variance': 10.266729, 'max_total_reward': 16.67, 'min_total_reward': 4.68, 'average_n_step': 11.9, 'max_n_step': 17.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.3759508639574052, 'actor_loss': -4.899460029602051, 'hyper_actor_loss': 0.009046140592545271, 'behavior_loss': 0.2822085335850716, 'mean_batch': 5.21263370513916, 'min_batch': 5.149698543548584, 'max_batch': 5.299222230911255}
step: 21880 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 1.6641004, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5571886897087097, 'actor_loss': -4.870176696777344, 'hyper_actor_loss': 0.009030101355165243, 'behavior_loss': 0.25773118883371354, 'mean_batch': 5.131099891662598, 'min_batch': 5.080667400360108, 'max_batch': 5.227423095703125}
step: 21890 @ episode report: {'average_total_reward': 10.642001, 'reward_variance': 1.5792964, 'max_total_reward': 12.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5960421323776246, 'actor_loss': -4.869974374771118, 'hyper_actor_loss': 0.009046930633485318, 'behavior_loss': 0.25021522790193557, 'mean_batch': 5.131511449813843, 'min_batch': 5.07912540435791, 'max_batch': 5.216521406173706}
step: 21900 @ episode report: {'average_total_reward': 10.509, 'reward_variance': 15.1376095, 'max_total_reward': 15.67, 'min_total_reward': 0.13, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 2.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6807266831398011, 'actor_loss': -4.872739696502686, 'hyper_actor_loss': 0.009001701604574919, 'behavior_loss': 0.2564896896481514, 'mean_batch': 5.142396736145019, 'min_batch': 5.082429265975952, 'max_batch': 5.237755870819091}
step: 21910 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 2.9814212, 'max_total_reward': 13.12, 'min_total_reward': 7.7899995, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6942225873470307, 'actor_loss': -4.876264953613282, 'hyper_actor_loss': 0.00888849264010787, 'behavior_loss': 0.2613990858197212, 'mean_batch': 5.147920370101929, 'min_batch': 5.094893884658814, 'max_batch': 5.234256601333618}
step: 21920 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 3.3743, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8092143058776855, 'actor_loss': -4.870681428909302, 'hyper_actor_loss': 0.008937965705990791, 'behavior_loss': 0.2768025204539299, 'mean_batch': 5.1363753318786625, 'min_batch': 5.078000593185425, 'max_batch': 5.2187152862548825}
step: 21930 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 1.486456, 'max_total_reward': 12.23, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.574595308303833, 'actor_loss': -4.857323026657104, 'hyper_actor_loss': 0.00887909224256873, 'behavior_loss': 0.25939645767211916, 'mean_batch': 5.099566555023193, 'min_batch': 5.046696186065674, 'max_batch': 5.187228775024414}
step: 21940 @ episode report: {'average_total_reward': 10.875001, 'reward_variance': 4.930425, 'max_total_reward': 15.67, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7240552306175232, 'actor_loss': -4.8785511493682865, 'hyper_actor_loss': 0.008925869502127171, 'behavior_loss': 0.2547312259674072, 'mean_batch': 5.161120986938476, 'min_batch': 5.093505239486694, 'max_batch': 5.2278666496276855}
step: 21950 @ episode report: {'average_total_reward': 8.8550005, 'reward_variance': 1.5117056, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.683642613887787, 'actor_loss': -4.889542531967163, 'hyper_actor_loss': 0.008868169318884612, 'behavior_loss': 0.2644760742783546, 'mean_batch': 5.181884765625, 'min_batch': 5.129137086868286, 'max_batch': 5.23360047340393}
step: 21960 @ episode report: {'average_total_reward': 11.118999, 'reward_variance': 4.2536097, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6636234998703003, 'actor_loss': -4.860292720794678, 'hyper_actor_loss': 0.008791436161845922, 'behavior_loss': 0.26973722577095033, 'mean_batch': 5.11209135055542, 'min_batch': 5.04943618774414, 'max_batch': 5.154286050796509}
step: 21970 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 6.4494286, 'max_total_reward': 14.559999, 'min_total_reward': 6.68, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5971217453479767, 'actor_loss': -4.862343454360962, 'hyper_actor_loss': 0.008836707286536693, 'behavior_loss': 0.2660249561071396, 'mean_batch': 5.11658239364624, 'min_batch': 5.055345821380615, 'max_batch': 5.183819150924682}
step: 21980 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 4.7404203, 'max_total_reward': 14.45, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.269734811782837, 'actor_loss': -4.875289678573608, 'hyper_actor_loss': 0.008818888571113348, 'behavior_loss': 0.2633970618247986, 'mean_batch': 5.151537704467773, 'min_batch': 5.086544942855835, 'max_batch': 5.218970727920532}
step: 21990 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 2.861896, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4457803606986999, 'actor_loss': -4.84426474571228, 'hyper_actor_loss': 0.008680483791977167, 'behavior_loss': 0.2591847121715546, 'mean_batch': 5.073389959335327, 'min_batch': 5.006969213485718, 'max_batch': 5.149294328689575}
step: 22000 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 3.7114816, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5076791286468505, 'actor_loss': -4.893477249145508, 'hyper_actor_loss': 0.008616004511713982, 'behavior_loss': 0.267130634188652, 'mean_batch': 5.195220565795898, 'min_batch': 5.136377668380737, 'max_batch': 5.272620820999146}
step: 22010 @ episode report: {'average_total_reward': 9.144, 'reward_variance': 5.2272844, 'max_total_reward': 12.34, 'min_total_reward': 3.46, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.623310375213623, 'actor_loss': -4.919818115234375, 'hyper_actor_loss': 0.008565194625407457, 'behavior_loss': 0.2608680158853531, 'mean_batch': 5.265631628036499, 'min_batch': 5.20275239944458, 'max_batch': 5.33055305480957}
step: 22020 @ episode report: {'average_total_reward': 9.8880005, 'reward_variance': 2.7589974, 'max_total_reward': 13.120001, 'min_total_reward': 6.5699997, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6842024147510528, 'actor_loss': -4.881631088256836, 'hyper_actor_loss': 0.008649419713765382, 'behavior_loss': 0.2768586978316307, 'mean_batch': 5.1713782787323, 'min_batch': 5.099121999740601, 'max_batch': 5.217196750640869}
step: 22030 @ episode report: {'average_total_reward': 9.799001, 'reward_variance': 10.34285, 'max_total_reward': 13.120001, 'min_total_reward': 1.02, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9697809100151062, 'actor_loss': -4.838950777053833, 'hyper_actor_loss': 0.008690811134874821, 'behavior_loss': 0.28145077973604204, 'mean_batch': 5.054092788696289, 'min_batch': 4.99955005645752, 'max_batch': 5.086551904678345}
step: 22040 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 3.0531247, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7062136054039, 'actor_loss': -4.855094575881958, 'hyper_actor_loss': 0.008683701138943433, 'behavior_loss': 0.26015338897705076, 'mean_batch': 5.097918272018433, 'min_batch': 5.03729510307312, 'max_batch': 5.132025814056396}
step: 22050 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 3.9333358, 'max_total_reward': 13.12, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.719905173778534, 'actor_loss': -4.883914422988892, 'hyper_actor_loss': 0.008641800098121166, 'behavior_loss': 0.276170215010643, 'mean_batch': 5.171694326400757, 'min_batch': 5.1104084014892575, 'max_batch': 5.212077045440674}
step: 22060 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 2.0854955, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7373258590698242, 'actor_loss': -4.899214267730713, 'hyper_actor_loss': 0.00855559790506959, 'behavior_loss': 0.2576640695333481, 'mean_batch': 5.216453933715821, 'min_batch': 5.144716119766235, 'max_batch': 5.258359336853028}
step: 22070 @ episode report: {'average_total_reward': 10.408999, 'reward_variance': 2.313568, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.75269056558609, 'actor_loss': -4.878101348876953, 'hyper_actor_loss': 0.008517622761428357, 'behavior_loss': 0.2578009024262428, 'mean_batch': 5.169263887405395, 'min_batch': 5.083286714553833, 'max_batch': 5.201042413711548}
step: 22080 @ episode report: {'average_total_reward': 9.466001, 'reward_variance': 3.1683638, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7970927000045775, 'actor_loss': -4.854673767089844, 'hyper_actor_loss': 0.008433865290135146, 'behavior_loss': 0.26084574609994887, 'mean_batch': 5.105407428741455, 'min_batch': 5.02759313583374, 'max_batch': 5.1283180713653564}
step: 22090 @ episode report: {'average_total_reward': 10.509, 'reward_variance': 4.002289, 'max_total_reward': 14.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.027900779247284, 'actor_loss': -4.8528166770935055, 'hyper_actor_loss': 0.008319510985165835, 'behavior_loss': 0.2724539011716843, 'mean_batch': 5.104617881774902, 'min_batch': 5.019036436080933, 'max_batch': 5.1303167819976805}
step: 22100 @ episode report: {'average_total_reward': 9.898001, 'reward_variance': 5.1814365, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7739493787288665, 'actor_loss': -4.8522546768188475, 'hyper_actor_loss': 0.008403573092073202, 'behavior_loss': 0.2692083761096001, 'mean_batch': 5.094324016571045, 'min_batch': 5.026335382461548, 'max_batch': 5.132431268692017}
step: 22110 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 1.8799248, 'max_total_reward': 12.230001, 'min_total_reward': 7.9000006, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9211417078971862, 'actor_loss': -4.870054483413696, 'hyper_actor_loss': 0.00830372804775834, 'behavior_loss': 0.2771290555596352, 'mean_batch': 5.138661336898804, 'min_batch': 5.072459745407104, 'max_batch': 5.200740718841553}
step: 22120 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 7.473306, 'max_total_reward': 14.560001, 'min_total_reward': 4.68, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8402282118797302, 'actor_loss': -4.8631140232086185, 'hyper_actor_loss': 0.008437470439821482, 'behavior_loss': 0.2730358690023422, 'mean_batch': 5.115664625167847, 'min_batch': 5.060026216506958, 'max_batch': 5.168394947052002}
step: 22130 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 1.9172693, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6662998974323273, 'actor_loss': -4.873869276046753, 'hyper_actor_loss': 0.008413295540958644, 'behavior_loss': 0.274365046620369, 'mean_batch': 5.147664976119995, 'min_batch': 5.082968616485596, 'max_batch': 5.1872889518737795}
step: 22140 @ episode report: {'average_total_reward': 10.01, 'reward_variance': 2.5077808, 'max_total_reward': 13.120001, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7668439701199532, 'actor_loss': -4.885875940322876, 'hyper_actor_loss': 0.008488435018807649, 'behavior_loss': 0.27242832630872726, 'mean_batch': 5.1806785583496096, 'min_batch': 5.111577653884888, 'max_batch': 5.25290732383728}
step: 22150 @ episode report: {'average_total_reward': 9.155001, 'reward_variance': 12.471505, 'max_total_reward': 13.34, 'min_total_reward': 1.13, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6205861747264863, 'actor_loss': -4.895204687118531, 'hyper_actor_loss': 0.008429658878594638, 'behavior_loss': 0.2605449348688126, 'mean_batch': 5.207190322875976, 'min_batch': 5.133195447921753, 'max_batch': 5.313627529144287}
step: 22160 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 5.4282165, 'max_total_reward': 12.23, 'min_total_reward': 3.5699997, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.697129774093628, 'actor_loss': -4.897956705093383, 'hyper_actor_loss': 0.008521033730357886, 'behavior_loss': 0.2595897540450096, 'mean_batch': 5.227458715438843, 'min_batch': 5.127708816528321, 'max_batch': 5.4376373291015625}
step: 22170 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 1.894664, 'max_total_reward': 13.34, 'min_total_reward': 8.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.409040904045105, 'actor_loss': -4.89020299911499, 'hyper_actor_loss': 0.008448975719511509, 'behavior_loss': 0.2676969259977341, 'mean_batch': 5.188397026062011, 'min_batch': 5.126123762130737, 'max_batch': 5.217387056350708}
step: 22180 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 5.733201, 'max_total_reward': 12.23, 'min_total_reward': 4.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7046617209911346, 'actor_loss': -4.918861675262451, 'hyper_actor_loss': 0.008345304615795612, 'behavior_loss': 0.24831908345222473, 'mean_batch': 5.2770027160644535, 'min_batch': 5.186631536483764, 'max_batch': 5.314565896987915}
step: 22190 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 1.7404763, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4026483595371246, 'actor_loss': -4.906707763671875, 'hyper_actor_loss': 0.008274308405816555, 'behavior_loss': 0.2633796870708466, 'mean_batch': 5.238260793685913, 'min_batch': 5.1618259906768795, 'max_batch': 5.273915243148804}
step: 22200 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 3.964716, 'max_total_reward': 14.559999, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0740153431892394, 'actor_loss': -4.889226961135864, 'hyper_actor_loss': 0.008215015660971403, 'behavior_loss': 0.2732647076249123, 'mean_batch': 5.192044734954834, 'min_batch': 5.117770195007324, 'max_batch': 5.232357120513916}
step: 22210 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.8266443, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0933165192604064, 'actor_loss': -4.851770639419556, 'hyper_actor_loss': 0.008260505553334952, 'behavior_loss': 0.2697854429483414, 'mean_batch': 5.099945783615112, 'min_batch': 5.018613195419311, 'max_batch': 5.150098276138306}
step: 22220 @ episode report: {'average_total_reward': 10.997, 'reward_variance': 2.1891208, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1879390597343447, 'actor_loss': -4.853693532943725, 'hyper_actor_loss': 0.008262657467275858, 'behavior_loss': 0.2762193024158478, 'mean_batch': 5.100094652175903, 'min_batch': 5.02789945602417, 'max_batch': 5.155335760116577}
step: 22230 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 5.09546, 'max_total_reward': 14.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8868082761764526, 'actor_loss': -4.860757064819336, 'hyper_actor_loss': 0.00838347217068076, 'behavior_loss': 0.28107111155986786, 'mean_batch': 5.130622863769531, 'min_batch': 5.033505439758301, 'max_batch': 5.184779930114746}
step: 22240 @ episode report: {'average_total_reward': 10.265, 'reward_variance': 3.4201653, 'max_total_reward': 13.340001, 'min_total_reward': 6.5699997, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.096046566963196, 'actor_loss': -4.88625922203064, 'hyper_actor_loss': 0.008479208685457706, 'behavior_loss': 0.27574770897626877, 'mean_batch': 5.183332633972168, 'min_batch': 5.110942125320435, 'max_batch': 5.230052757263183}
step: 22250 @ episode report: {'average_total_reward': 9.454, 'reward_variance': 1.0349638, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9054870188236237, 'actor_loss': -4.867625761032104, 'hyper_actor_loss': 0.008598574623465537, 'behavior_loss': 0.2539206087589264, 'mean_batch': 5.143800115585327, 'min_batch': 5.055105209350586, 'max_batch': 5.20805983543396}
step: 22260 @ episode report: {'average_total_reward': 10.154, 'reward_variance': 4.6708245, 'max_total_reward': 15.45, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7944365620613099, 'actor_loss': -4.89516863822937, 'hyper_actor_loss': 0.008502430841326713, 'behavior_loss': 0.2586140751838684, 'mean_batch': 5.214734792709351, 'min_batch': 5.125886154174805, 'max_batch': 5.3269110202789305}
step: 22270 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.7666812, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6352125644683837, 'actor_loss': -4.878907060623169, 'hyper_actor_loss': 0.008371390122920274, 'behavior_loss': 0.27288089841604235, 'mean_batch': 5.177540683746338, 'min_batch': 5.079326105117798, 'max_batch': 5.2609610080719}
step: 22280 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.8922896, 'max_total_reward': 12.340001, 'min_total_reward': 6.68, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7764811038970947, 'actor_loss': -4.885072660446167, 'hyper_actor_loss': 0.008338768687099218, 'behavior_loss': 0.2719766855239868, 'mean_batch': 5.185833215713501, 'min_batch': 5.102492094039917, 'max_batch': 5.270475196838379}
step: 22290 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 5.641341, 'max_total_reward': 14.56, 'min_total_reward': 5.68, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.143787908554077, 'actor_loss': -4.863813400268555, 'hyper_actor_loss': 0.00839347904548049, 'behavior_loss': 0.264160218834877, 'mean_batch': 5.135849475860596, 'min_batch': 5.044207191467285, 'max_batch': 5.19580044746399}
step: 22300 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 4.39701, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7093065142631532, 'actor_loss': -4.85210108757019, 'hyper_actor_loss': 0.008389145229011774, 'behavior_loss': 0.2901847675442696, 'mean_batch': 5.107692289352417, 'min_batch': 5.012557888031006, 'max_batch': 5.170649814605713}
step: 22310 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 1.3319966, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0692237257957458, 'actor_loss': -4.892543649673462, 'hyper_actor_loss': 0.00838395832106471, 'behavior_loss': 0.25574994683265684, 'mean_batch': 5.2019730567932125, 'min_batch': 5.124750852584839, 'max_batch': 5.2528739929199215}
step: 22320 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 1.332876, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.041787302494049, 'actor_loss': -4.864417171478271, 'hyper_actor_loss': 0.008321199379861356, 'behavior_loss': 0.2751375287771225, 'mean_batch': 5.133013200759888, 'min_batch': 5.049674367904663, 'max_batch': 5.188576316833496}
step: 22330 @ episode report: {'average_total_reward': 8.532999, 'reward_variance': 2.955141, 'max_total_reward': 11.23, 'min_total_reward': 5.6800003, 'average_n_step': 9.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1741172909736632, 'actor_loss': -4.838967418670654, 'hyper_actor_loss': 0.00830348376184702, 'behavior_loss': 0.27780354470014573, 'mean_batch': 5.067278242111206, 'min_batch': 4.9864765167236325, 'max_batch': 5.126204776763916}
step: 22340 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 4.7296762, 'max_total_reward': 13.450001, 'min_total_reward': 5.46, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8273817300796509, 'actor_loss': -4.855515718460083, 'hyper_actor_loss': 0.008424952998757363, 'behavior_loss': 0.27312680035829545, 'mean_batch': 5.112362861633301, 'min_batch': 5.025037240982056, 'max_batch': 5.153191375732422}
step: 22350 @ episode report: {'average_total_reward': 8.622, 'reward_variance': 8.042157, 'max_total_reward': 13.340001, 'min_total_reward': 2.35, 'average_n_step': 9.7, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.091081404685974, 'actor_loss': -4.872572612762451, 'hyper_actor_loss': 0.008321513049304485, 'behavior_loss': 0.2522240921854973, 'mean_batch': 5.159045314788818, 'min_batch': 5.065262222290039, 'max_batch': 5.215646457672119}
step: 22360 @ episode report: {'average_total_reward': 11.020001, 'reward_variance': 4.01334, 'max_total_reward': 13.450001, 'min_total_reward': 7.57, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.200415790081024, 'actor_loss': -4.852185487747192, 'hyper_actor_loss': 0.008261576853692531, 'behavior_loss': 0.2740050718188286, 'mean_batch': 5.1085066318511965, 'min_batch': 5.012086629867554, 'max_batch': 5.160835456848145}
step: 22370 @ episode report: {'average_total_reward': 9.210001, 'reward_variance': 4.207461, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8334012031555176, 'actor_loss': -4.8341552257537845, 'hyper_actor_loss': 0.008271657302975655, 'behavior_loss': 0.28188377767801287, 'mean_batch': 5.065430736541748, 'min_batch': 4.964446353912353, 'max_batch': 5.121446895599365}
step: 22380 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 4.637941, 'max_total_reward': 14.45, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8491738617420197, 'actor_loss': -4.871982622146606, 'hyper_actor_loss': 0.008308604080229997, 'behavior_loss': 0.2665769264101982, 'mean_batch': 5.161794757843017, 'min_batch': 5.059675550460815, 'max_batch': 5.227137708663941}
step: 22390 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 2.5569406, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3992411971092222, 'actor_loss': -4.865350580215454, 'hyper_actor_loss': 0.00829260153695941, 'behavior_loss': 0.27373061031103135, 'mean_batch': 5.154506254196167, 'min_batch': 5.033831930160522, 'max_batch': 5.2342547416687015}
step: 22400 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.1471014, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.879524254798889, 'actor_loss': -4.822915649414062, 'hyper_actor_loss': 0.00834598932415247, 'behavior_loss': 0.259893536567688, 'mean_batch': 5.047927808761597, 'min_batch': 4.926156234741211, 'max_batch': 5.1569243431091305}
step: 22410 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 2.0451417, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4006027042865754, 'actor_loss': -4.911113357543945, 'hyper_actor_loss': 0.008450261503458022, 'behavior_loss': 0.26952213048934937, 'mean_batch': 5.297294855117798, 'min_batch': 5.127784872055054, 'max_batch': 5.404527854919434}
step: 22420 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 2.7311287, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5337958633899689, 'actor_loss': -4.935052013397216, 'hyper_actor_loss': 0.008404229767620564, 'behavior_loss': 0.2551943242549896, 'mean_batch': 5.364735746383667, 'min_batch': 5.185707855224609, 'max_batch': 5.460408449172974}
step: 22430 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 2.2915616, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8035895764827727, 'actor_loss': -4.883415222167969, 'hyper_actor_loss': 0.00838475115597248, 'behavior_loss': 0.27358976304531096, 'mean_batch': 5.200634098052978, 'min_batch': 5.07979941368103, 'max_batch': 5.2940685749053955}
step: 22440 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 2.4577363, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8727866291999817, 'actor_loss': -4.858908700942993, 'hyper_actor_loss': 0.008314795419573784, 'behavior_loss': 0.2589794993400574, 'mean_batch': 5.136905908584595, 'min_batch': 5.018150281906128, 'max_batch': 5.204644298553466}
step: 22450 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 5.060341, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9161528289318084, 'actor_loss': -4.871874523162842, 'hyper_actor_loss': 0.008235258422791958, 'behavior_loss': 0.25376915037631986, 'mean_batch': 5.165872955322266, 'min_batch': 5.05492844581604, 'max_batch': 5.260204029083252}
step: 22460 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.9477487, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7637456417083741, 'actor_loss': -4.88930377960205, 'hyper_actor_loss': 0.008213830925524235, 'behavior_loss': 0.26679217368364333, 'mean_batch': 5.210522699356079, 'min_batch': 5.099938201904297, 'max_batch': 5.3142846584320065}
step: 22470 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 1.6195452, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4318088591098785, 'actor_loss': -4.928569746017456, 'hyper_actor_loss': 0.008134269434958697, 'behavior_loss': 0.2608299136161804, 'mean_batch': 5.326702451705932, 'min_batch': 5.188462543487549, 'max_batch': 5.436627435684204}
step: 22480 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.269524, 'max_total_reward': 12.339999, 'min_total_reward': 6.68, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7270732402801514, 'actor_loss': -4.938453006744385, 'hyper_actor_loss': 0.008166561648249627, 'behavior_loss': 0.2685742422938347, 'mean_batch': 5.347382259368897, 'min_batch': 5.219612455368042, 'max_batch': 5.436911487579346}
step: 22490 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 1.250056, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1710797786712646, 'actor_loss': -4.887723112106324, 'hyper_actor_loss': 0.008311109896749259, 'behavior_loss': 0.29746028780937195, 'mean_batch': 5.212187767028809, 'min_batch': 5.090514659881592, 'max_batch': 5.3001221179962155}
step: 22500 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.0429153, 'max_total_reward': 13.45, 'min_total_reward': 7.9000006, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7433581709861756, 'actor_loss': -4.863559246063232, 'hyper_actor_loss': 0.008508606906980276, 'behavior_loss': 0.26423081010580063, 'mean_batch': 5.160745573043823, 'min_batch': 5.018709707260132, 'max_batch': 5.2744384765625}
step: 22510 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 1.428189, 'max_total_reward': 11.01, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.402001643180847, 'actor_loss': -4.942387580871582, 'hyper_actor_loss': 0.00858424548059702, 'behavior_loss': 0.26409351229667666, 'mean_batch': 5.358597993850708, 'min_batch': 5.229709577560425, 'max_batch': 5.455844593048096}
step: 22520 @ episode report: {'average_total_reward': 8.089001, 'reward_variance': 8.250929, 'max_total_reward': 10.120001, 'min_total_reward': 0.13, 'average_n_step': 9.2, 'max_n_step': 11.0, 'min_n_step': 2.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0476445078849794, 'actor_loss': -4.948521566390991, 'hyper_actor_loss': 0.00855015655979514, 'behavior_loss': 0.2663349390029907, 'mean_batch': 5.3728835105896, 'min_batch': 5.248326206207276, 'max_batch': 5.475947523117066}
step: 22530 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 5.153305, 'max_total_reward': 14.45, 'min_total_reward': 5.68, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2987802267074584, 'actor_loss': -4.877175903320312, 'hyper_actor_loss': 0.008544284757226706, 'behavior_loss': 0.27024907171726226, 'mean_batch': 5.173506355285644, 'min_batch': 5.07452540397644, 'max_batch': 5.291477060317993}
step: 22540 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 4.970422, 'max_total_reward': 14.56, 'min_total_reward': 5.68, 'average_n_step': 10.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8634287357330321, 'actor_loss': -4.8617760181427006, 'hyper_actor_loss': 0.008570610359311105, 'behavior_loss': 0.252120777964592, 'mean_batch': 5.1437633514404295, 'min_batch': 5.025894832611084, 'max_batch': 5.275172328948974}
step: 22550 @ episode report: {'average_total_reward': 10.798001, 'reward_variance': 3.4584966, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.017557656764984, 'actor_loss': -4.932296943664551, 'hyper_actor_loss': 0.008512977696955203, 'behavior_loss': 0.2599215194582939, 'mean_batch': 5.337210273742675, 'min_batch': 5.197650718688965, 'max_batch': 5.457632303237915}
step: 22560 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 5.427156, 'max_total_reward': 13.450001, 'min_total_reward': 5.6800003, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.944823145866394, 'actor_loss': -4.901477670669555, 'hyper_actor_loss': 0.008487896993756294, 'behavior_loss': 0.258086596429348, 'mean_batch': 5.245063781738281, 'min_batch': 5.128383016586303, 'max_batch': 5.380058908462525}
step: 22570 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 2.570876, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9219143748283387, 'actor_loss': -4.880571508407593, 'hyper_actor_loss': 0.008515522629022599, 'behavior_loss': 0.274263060092926, 'mean_batch': 5.191393136978149, 'min_batch': 5.074063396453857, 'max_batch': 5.318501091003418}
step: 22580 @ episode report: {'average_total_reward': 10.608999, 'reward_variance': 7.06679, 'max_total_reward': 14.56, 'min_total_reward': 5.68, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5060836017131805, 'actor_loss': -4.93731722831726, 'hyper_actor_loss': 0.008600603230297566, 'behavior_loss': 0.2771807610988617, 'mean_batch': 5.352500247955322, 'min_batch': 5.209335422515869, 'max_batch': 5.460956192016601}
step: 22590 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 9.309616, 'max_total_reward': 13.23, 'min_total_reward': 2.13, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.238749647140503, 'actor_loss': -4.936583232879639, 'hyper_actor_loss': 0.00867962595075369, 'behavior_loss': 0.2897384762763977, 'mean_batch': 5.3579634666442875, 'min_batch': 5.200741577148437, 'max_batch': 5.495597171783447}
step: 22600 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 3.041441, 'max_total_reward': 12.12, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9128661692142486, 'actor_loss': -4.886778163909912, 'hyper_actor_loss': 0.008812485076487065, 'behavior_loss': 0.2648774743080139, 'mean_batch': 5.208395338058471, 'min_batch': 5.089090824127197, 'max_batch': 5.322712755203247}
step: 22610 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 1.246269, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8934760391712189, 'actor_loss': -4.895521020889282, 'hyper_actor_loss': 0.008861979935318232, 'behavior_loss': 0.2824976846575737, 'mean_batch': 5.235503435134888, 'min_batch': 5.107156085968017, 'max_batch': 5.329127454757691}
step: 22620 @ episode report: {'average_total_reward': 9.098999, 'reward_variance': 7.1072683, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8757205367088319, 'actor_loss': -4.925859451293945, 'hyper_actor_loss': 0.008972834516316652, 'behavior_loss': 0.2724070444703102, 'mean_batch': 5.315234088897705, 'min_batch': 5.185669660568237, 'max_batch': 5.428235054016113}
step: 22630 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.6052647, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3064462184906005, 'actor_loss': -4.914362859725952, 'hyper_actor_loss': 0.00891176788136363, 'behavior_loss': 0.2618589624762535, 'mean_batch': 5.283546018600464, 'min_batch': 5.157281351089478, 'max_batch': 5.410401248931885}
step: 22640 @ episode report: {'average_total_reward': 10.354, 'reward_variance': 5.117324, 'max_total_reward': 14.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6040193796157838, 'actor_loss': -4.902431583404541, 'hyper_actor_loss': 0.00889634359627962, 'behavior_loss': 0.27731439620256426, 'mean_batch': 5.262360334396362, 'min_batch': 5.116646432876587, 'max_batch': 5.388542652130127}
step: 22650 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 2.291001, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.143648087978363, 'actor_loss': -4.937142419815063, 'hyper_actor_loss': 0.008993962593376637, 'behavior_loss': 0.27525835037231444, 'mean_batch': 5.354033422470093, 'min_batch': 5.206428289413452, 'max_batch': 5.480541324615478}
step: 22660 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 2.9743001, 'max_total_reward': 12.12, 'min_total_reward': 6.5699997, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.811099684238434, 'actor_loss': -4.917405986785889, 'hyper_actor_loss': 0.009121354762464761, 'behavior_loss': 0.271780726313591, 'mean_batch': 5.294121646881104, 'min_batch': 5.162307977676392, 'max_batch': 5.409894895553589}
step: 22670 @ episode report: {'average_total_reward': 9.011, 'reward_variance': 4.7214084, 'max_total_reward': 12.12, 'min_total_reward': 5.6800003, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.4874216139316558, 'actor_loss': -4.934380578994751, 'hyper_actor_loss': 0.009075290989130735, 'behavior_loss': 0.2719670936465263, 'mean_batch': 5.340796375274659, 'min_batch': 5.205019140243531, 'max_batch': 5.455426406860352}
step: 22680 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.9213164, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8152646660804748, 'actor_loss': -4.965151739120484, 'hyper_actor_loss': 0.008977222535759211, 'behavior_loss': 0.2551067963242531, 'mean_batch': 5.426803779602051, 'min_batch': 5.282447576522827, 'max_batch': 5.528976106643677}
step: 22690 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.6339042, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6456953942775727, 'actor_loss': -4.9415717124938965, 'hyper_actor_loss': 0.008981443382799626, 'behavior_loss': 0.25653988420963286, 'mean_batch': 5.35576229095459, 'min_batch': 5.227726697921753, 'max_batch': 5.465713310241699}
step: 22700 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 5.663844, 'max_total_reward': 14.56, 'min_total_reward': 5.7900004, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6627966940402985, 'actor_loss': -4.960543632507324, 'hyper_actor_loss': 0.008922786731272937, 'behavior_loss': 0.25718674808740616, 'mean_batch': 5.399919652938843, 'min_batch': 5.284302473068237, 'max_batch': 5.491364002227783}
step: 22710 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 4.106656, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9988909482955932, 'actor_loss': -4.952496194839478, 'hyper_actor_loss': 0.008874054346233607, 'behavior_loss': 0.27046460956335067, 'mean_batch': 5.375668573379516, 'min_batch': 5.26562614440918, 'max_batch': 5.4553608894348145}
step: 22720 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 2.7955356, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7833785176277162, 'actor_loss': -4.915042352676392, 'hyper_actor_loss': 0.00888196611776948, 'behavior_loss': 0.2679703965783119, 'mean_batch': 5.276092052459717, 'min_batch': 5.1677659034729, 'max_batch': 5.363898849487304}
step: 22730 @ episode report: {'average_total_reward': 10.964001, 'reward_variance': 3.6059635, 'max_total_reward': 14.450001, 'min_total_reward': 7.790001, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1810476899147035, 'actor_loss': -4.937201738357544, 'hyper_actor_loss': 0.008966033719480038, 'behavior_loss': 0.2610501408576965, 'mean_batch': 5.346336841583252, 'min_batch': 5.214130067825318, 'max_batch': 5.444487524032593}
step: 22740 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 4.7692766, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.050891637802124, 'actor_loss': -4.911035585403442, 'hyper_actor_loss': 0.008923293184489011, 'behavior_loss': 0.27310405671596527, 'mean_batch': 5.26918625831604, 'min_batch': 5.1541379451751705, 'max_batch': 5.369531440734863}
step: 22750 @ episode report: {'average_total_reward': 9.765, 'reward_variance': 3.3590653, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6660293817520142, 'actor_loss': -4.9396192073822025, 'hyper_actor_loss': 0.008976257964968681, 'behavior_loss': 0.26281667649745943, 'mean_batch': 5.361805725097656, 'min_batch': 5.212212610244751, 'max_batch': 5.462394428253174}
step: 22760 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 5.9559016, 'max_total_reward': 15.56, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.772634255886078, 'actor_loss': -4.991434717178345, 'hyper_actor_loss': 0.009076496679335832, 'behavior_loss': 0.27147939056158066, 'mean_batch': 5.5241701126098635, 'min_batch': 5.327579164505005, 'max_batch': 5.619788980484008}
step: 22770 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 2.7605367, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8748434364795685, 'actor_loss': -4.964531660079956, 'hyper_actor_loss': 0.009217244200408458, 'behavior_loss': 0.26213472336530685, 'mean_batch': 5.4205115795135494, 'min_batch': 5.28539457321167, 'max_batch': 5.520239734649659}
step: 22780 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 2.03262, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2464762806892393, 'actor_loss': -4.939288759231568, 'hyper_actor_loss': 0.009249326959252357, 'behavior_loss': 0.25840628445148467, 'mean_batch': 5.371293306350708, 'min_batch': 5.200685262680054, 'max_batch': 5.489277410507202}
step: 22790 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 4.686582, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0489458441734314, 'actor_loss': -4.9484189510345455, 'hyper_actor_loss': 0.009255615994334221, 'behavior_loss': 0.25170862674713135, 'mean_batch': 5.405907821655274, 'min_batch': 5.214994287490844, 'max_batch': 5.532149982452393}
step: 22800 @ episode report: {'average_total_reward': 8.911, 'reward_variance': 6.4178896, 'max_total_reward': 11.120001, 'min_total_reward': 2.13, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6373194217681886, 'actor_loss': -4.98492693901062, 'hyper_actor_loss': 0.009184919856488704, 'behavior_loss': 0.27075165361166, 'mean_batch': 5.505756521224976, 'min_batch': 5.310824346542359, 'max_batch': 5.644735288619995}
step: 22810 @ episode report: {'average_total_reward': 8.989, 'reward_variance': 7.246929, 'max_total_reward': 12.2300005, 'min_total_reward': 2.13, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8215271174907683, 'actor_loss': -5.000805759429932, 'hyper_actor_loss': 0.009358069207519294, 'behavior_loss': 0.27359371930360793, 'mean_batch': 5.561229419708252, 'min_batch': 5.341996669769287, 'max_batch': 5.698255491256714}
step: 22820 @ episode report: {'average_total_reward': 10.720001, 'reward_variance': 3.1286213, 'max_total_reward': 13.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0878385305404663, 'actor_loss': -4.953202724456787, 'hyper_actor_loss': 0.009562304336577654, 'behavior_loss': 0.26689249724149705, 'mean_batch': 5.393916988372803, 'min_batch': 5.251644277572632, 'max_batch': 5.516030740737915}
step: 22830 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 2.8331769, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9676131367683412, 'actor_loss': -4.932234764099121, 'hyper_actor_loss': 0.009691944066435098, 'behavior_loss': 0.2672691121697426, 'mean_batch': 5.343255710601807, 'min_batch': 5.191287040710449, 'max_batch': 5.45747561454773}
step: 22840 @ episode report: {'average_total_reward': 9.155001, 'reward_variance': 2.4463851, 'max_total_reward': 11.23, 'min_total_reward': 5.7900004, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1868493974208834, 'actor_loss': -4.965304851531982, 'hyper_actor_loss': 0.009702741540968418, 'behavior_loss': 0.27147037982940675, 'mean_batch': 5.4425005435943605, 'min_batch': 5.267990589141846, 'max_batch': 5.574882125854492}
step: 22850 @ episode report: {'average_total_reward': 11.408, 'reward_variance': 1.8980961, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.14203804731369, 'actor_loss': -4.943260431289673, 'hyper_actor_loss': 0.009861009567975998, 'behavior_loss': 0.2582115888595581, 'mean_batch': 5.388455581665039, 'min_batch': 5.204766511917114, 'max_batch': 5.5323262214660645}
step: 22860 @ episode report: {'average_total_reward': 9.821, 'reward_variance': 3.7445292, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8588617324829102, 'actor_loss': -4.960582304000854, 'hyper_actor_loss': 0.009888587892055512, 'behavior_loss': 0.27927918285131453, 'mean_batch': 5.433204412460327, 'min_batch': 5.252343559265137, 'max_batch': 5.573910522460937}
step: 22870 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 1.6343695, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9433907628059388, 'actor_loss': -5.016565418243408, 'hyper_actor_loss': 0.010044742282480002, 'behavior_loss': 0.269721981883049, 'mean_batch': 5.60410623550415, 'min_batch': 5.385411500930786, 'max_batch': 5.767791700363159}
step: 22880 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 1.5446198, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9972154259681703, 'actor_loss': -4.937314081192016, 'hyper_actor_loss': 0.010311126243323088, 'behavior_loss': 0.2802779346704483, 'mean_batch': 5.37092661857605, 'min_batch': 5.191688394546508, 'max_batch': 5.491661834716797}
step: 22890 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.4094844, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.858188271522522, 'actor_loss': -4.952865171432495, 'hyper_actor_loss': 0.01037212461233139, 'behavior_loss': 0.2757877245545387, 'mean_batch': 5.39716911315918, 'min_batch': 5.246979427337647, 'max_batch': 5.494269275665284}
step: 22900 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 6.1208053, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8977371424436569, 'actor_loss': -4.981364822387695, 'hyper_actor_loss': 0.010258115082979202, 'behavior_loss': 0.262436543405056, 'mean_batch': 5.468914127349853, 'min_batch': 5.327395963668823, 'max_batch': 5.556493425369263}
step: 22910 @ episode report: {'average_total_reward': 9.542999, 'reward_variance': 3.7693214, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5805434584617615, 'actor_loss': -4.967074394226074, 'hyper_actor_loss': 0.010049742553383112, 'behavior_loss': 0.2735994264483452, 'mean_batch': 5.427611923217773, 'min_batch': 5.29176173210144, 'max_batch': 5.499871730804443}
step: 22920 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.5066962, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7369791746139527, 'actor_loss': -4.98190393447876, 'hyper_actor_loss': 0.009960939362645149, 'behavior_loss': 0.2614112988114357, 'mean_batch': 5.471996641159057, 'min_batch': 5.327294778823853, 'max_batch': 5.547443485260009}
step: 22930 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 2.3099968, 'max_total_reward': 13.010001, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1631599187850954, 'actor_loss': -4.960360336303711, 'hyper_actor_loss': 0.009685271978378296, 'behavior_loss': 0.2661000207066536, 'mean_batch': 5.4145886421203615, 'min_batch': 5.269103908538819, 'max_batch': 5.479391717910767}
step: 22940 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.707789, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0643441915512084, 'actor_loss': -4.922807693481445, 'hyper_actor_loss': 0.009777924232184886, 'behavior_loss': 0.27544140070676804, 'mean_batch': 5.312569189071655, 'min_batch': 5.172291326522827, 'max_batch': 5.374073839187622}
step: 22950 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.880324, 'max_total_reward': 12.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7974308133125305, 'actor_loss': -4.956827020645141, 'hyper_actor_loss': 0.00973449982702732, 'behavior_loss': 0.2604562878608704, 'mean_batch': 5.398190927505493, 'min_batch': 5.266624593734742, 'max_batch': 5.484499311447143}
step: 22960 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 1.945796, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.369535517692566, 'actor_loss': -4.958415508270264, 'hyper_actor_loss': 0.009654527250677346, 'behavior_loss': 0.25579228699207307, 'mean_batch': 5.4081462860107425, 'min_batch': 5.26522912979126, 'max_batch': 5.490805006027221}
step: 22970 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 1.7858846, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.017194926738739, 'actor_loss': -4.9394683837890625, 'hyper_actor_loss': 0.009408909548074006, 'behavior_loss': 0.25919620543718336, 'mean_batch': 5.353242635726929, 'min_batch': 5.2191509246826175, 'max_batch': 5.444043254852295}
step: 22980 @ episode report: {'average_total_reward': 9.744, 'reward_variance': 2.254385, 'max_total_reward': 13.450001, 'min_total_reward': 7.6799994, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9979054808616639, 'actor_loss': -4.95617151260376, 'hyper_actor_loss': 0.009473623894155025, 'behavior_loss': 0.26228470355272293, 'mean_batch': 5.395240259170532, 'min_batch': 5.265784406661988, 'max_batch': 5.490251588821411}
step: 22990 @ episode report: {'average_total_reward': 10.398, 'reward_variance': 6.0998554, 'max_total_reward': 14.34, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2981816291809083, 'actor_loss': -4.948369121551513, 'hyper_actor_loss': 0.009435424022376538, 'behavior_loss': 0.25851901322603227, 'mean_batch': 5.385862255096436, 'min_batch': 5.234081554412842, 'max_batch': 5.477970695495605}
step: 23000 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 3.1694608, 'max_total_reward': 14.34, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.655443924665451, 'actor_loss': -4.976738929748535, 'hyper_actor_loss': 0.009396569523960351, 'behavior_loss': 0.2476811647415161, 'mean_batch': 5.455520486831665, 'min_batch': 5.3168481349945065, 'max_batch': 5.577150058746338}
step: 23010 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 4.770237, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5866963267326355, 'actor_loss': -5.017489099502564, 'hyper_actor_loss': 0.00940874284133315, 'behavior_loss': 0.25276303142309187, 'mean_batch': 5.606411409378052, 'min_batch': 5.38806300163269, 'max_batch': 5.719877052307129}
step: 23020 @ episode report: {'average_total_reward': 9.099001, 'reward_variance': 9.227369, 'max_total_reward': 14.45, 'min_total_reward': 4.5699997, 'average_n_step': 10.1, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9402970552444458, 'actor_loss': -4.996386528015137, 'hyper_actor_loss': 0.009551879577338695, 'behavior_loss': 0.27661109566688535, 'mean_batch': 5.523357725143432, 'min_batch': 5.354984283447266, 'max_batch': 5.642649936676025}
step: 23030 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 5.293888, 'max_total_reward': 13.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1380555987358094, 'actor_loss': -4.967944765090943, 'hyper_actor_loss': 0.009903514944016933, 'behavior_loss': 0.2814183905720711, 'mean_batch': 5.433718347549439, 'min_batch': 5.29036955833435, 'max_batch': 5.543727540969849}
step: 23040 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 2.2280686, 'max_total_reward': 11.23, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.137962794303894, 'actor_loss': -4.966976594924927, 'hyper_actor_loss': 0.010106686968356371, 'behavior_loss': 0.26913347095251083, 'mean_batch': 5.447634887695313, 'min_batch': 5.271956157684326, 'max_batch': 5.558923530578613}
step: 23050 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 1.6290646, 'max_total_reward': 13.45, 'min_total_reward': 10.009999, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0803549766540526, 'actor_loss': -4.979449653625489, 'hyper_actor_loss': 0.010187255498021842, 'behavior_loss': 0.26817782670259477, 'mean_batch': 5.487755060195923, 'min_batch': 5.299027633666992, 'max_batch': 5.601655292510986}
step: 23060 @ episode report: {'average_total_reward': 10.964001, 'reward_variance': 1.8394436, 'max_total_reward': 14.559999, 'min_total_reward': 10.12, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.969200813770294, 'actor_loss': -4.974745655059815, 'hyper_actor_loss': 0.010254854708909989, 'behavior_loss': 0.27240743637084963, 'mean_batch': 5.486637687683105, 'min_batch': 5.275322675704956, 'max_batch': 5.620532035827637}
step: 23070 @ episode report: {'average_total_reward': 11.1310005, 'reward_variance': 2.7213895, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.522981071472168, 'actor_loss': -4.992356252670288, 'hyper_actor_loss': 0.010283791180700063, 'behavior_loss': 0.2643453136086464, 'mean_batch': 5.549109745025635, 'min_batch': 5.30994176864624, 'max_batch': 5.853710651397705}
step: 23080 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 3.4938407, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.173924648761749, 'actor_loss': -4.9483559131622314, 'hyper_actor_loss': 0.010217109695076942, 'behavior_loss': 0.26596929877996445, 'mean_batch': 5.404347467422485, 'min_batch': 5.21608943939209, 'max_batch': 5.563415813446045}
step: 23090 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 4.367662, 'max_total_reward': 13.340001, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1376748025417327, 'actor_loss': -4.990765333175659, 'hyper_actor_loss': 0.010179454553872347, 'behavior_loss': 0.28567345440387726, 'mean_batch': 5.528212213516236, 'min_batch': 5.320163917541504, 'max_batch': 5.71848874092102}
step: 23100 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 4.6427813, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.520549464225769, 'actor_loss': -4.977497339248657, 'hyper_actor_loss': 0.010374846681952477, 'behavior_loss': 0.2693882405757904, 'mean_batch': 5.506493473052979, 'min_batch': 5.271192359924316, 'max_batch': 5.717532062530518}
step: 23110 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 3.1608205, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.121675395965576, 'actor_loss': -4.9465772151947025, 'hyper_actor_loss': 0.010319590754806995, 'behavior_loss': 0.25506795644760133, 'mean_batch': 5.396368455886841, 'min_batch': 5.214515686035156, 'max_batch': 5.539585113525391}
step: 23120 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 1.8262447, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0395834267139437, 'actor_loss': -4.9942296028137205, 'hyper_actor_loss': 0.01016432149335742, 'behavior_loss': 0.2735594317317009, 'mean_batch': 5.525587797164917, 'min_batch': 5.341054964065552, 'max_batch': 5.698692989349365}
step: 23130 @ episode report: {'average_total_reward': 10.764, 'reward_variance': 6.6654434, 'max_total_reward': 13.45, 'min_total_reward': 4.68, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9993767142295837, 'actor_loss': -4.999319458007813, 'hyper_actor_loss': 0.01035582171753049, 'behavior_loss': 0.2935596346855164, 'mean_batch': 5.531232643127441, 'min_batch': 5.3628973960876465, 'max_batch': 5.694407033920288}
step: 23140 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 2.9825363, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0234623312950135, 'actor_loss': -4.9949414253234865, 'hyper_actor_loss': 0.010575956292450428, 'behavior_loss': 0.27531692385673523, 'mean_batch': 5.521097660064697, 'min_batch': 5.349208402633667, 'max_batch': 5.672011852264404}
step: 23150 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 1.1951253, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.168082869052887, 'actor_loss': -4.981171751022339, 'hyper_actor_loss': 0.010826548468321562, 'behavior_loss': 0.27167067527770994, 'mean_batch': 5.503870820999145, 'min_batch': 5.292752885818482, 'max_batch': 5.708204936981201}
step: 23160 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 5.867759, 'max_total_reward': 16.779999, 'min_total_reward': 7.8999996, 'average_n_step': 11.7, 'max_n_step': 17.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2055020570755004, 'actor_loss': -4.993253135681153, 'hyper_actor_loss': 0.010498659778386354, 'behavior_loss': 0.26096324175596236, 'mean_batch': 5.533506631851196, 'min_batch': 5.3283463478088375, 'max_batch': 5.674851512908935}
step: 23170 @ episode report: {'average_total_reward': 11.774, 'reward_variance': 7.196662, 'max_total_reward': 16.779999, 'min_total_reward': 7.9, 'average_n_step': 12.5, 'max_n_step': 17.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2235382795333862, 'actor_loss': -4.985459423065185, 'hyper_actor_loss': 0.010179698932915926, 'behavior_loss': 0.2576043099164963, 'mean_batch': 5.501248407363891, 'min_batch': 5.317818689346313, 'max_batch': 5.6247230052948}
step: 23180 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 3.8803554, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.313958775997162, 'actor_loss': -4.9696753978729244, 'hyper_actor_loss': 0.00985872931778431, 'behavior_loss': 0.26283026188611985, 'mean_batch': 5.446139287948609, 'min_batch': 5.287461853027343, 'max_batch': 5.569496440887451}
step: 23190 @ episode report: {'average_total_reward': 10.974999, 'reward_variance': 4.3277445, 'max_total_reward': 15.67, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2182044863700865, 'actor_loss': -4.959966516494751, 'hyper_actor_loss': 0.009776816982775927, 'behavior_loss': 0.25783700346946714, 'mean_batch': 5.416193056106567, 'min_batch': 5.265395450592041, 'max_batch': 5.535360097885132}
step: 23200 @ episode report: {'average_total_reward': 10.841999, 'reward_variance': 3.306696, 'max_total_reward': 14.559999, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8119785845279694, 'actor_loss': -4.994812965393066, 'hyper_actor_loss': 0.009727973584085703, 'behavior_loss': 0.2537221938371658, 'mean_batch': 5.522199726104736, 'min_batch': 5.347814893722534, 'max_batch': 5.630202531814575}
step: 23210 @ episode report: {'average_total_reward': 10.210001, 'reward_variance': 10.28258, 'max_total_reward': 13.34, 'min_total_reward': 1.13, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6268021941184996, 'actor_loss': -5.004104566574097, 'hyper_actor_loss': 0.009578089788556099, 'behavior_loss': 0.25393613427877426, 'mean_batch': 5.538238859176635, 'min_batch': 5.382472848892212, 'max_batch': 5.634693288803101}
step: 23220 @ episode report: {'average_total_reward': 9.832, 'reward_variance': 3.0082965, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9355020403862, 'actor_loss': -4.946313667297363, 'hyper_actor_loss': 0.009398997202515602, 'behavior_loss': 0.2669429093599319, 'mean_batch': 5.3833324909210205, 'min_batch': 5.225718927383423, 'max_batch': 5.491895151138306}
step: 23230 @ episode report: {'average_total_reward': 10.830999, 'reward_variance': 3.2796695, 'max_total_reward': 14.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2111594438552857, 'actor_loss': -4.991756534576416, 'hyper_actor_loss': 0.009397451300173998, 'behavior_loss': 0.2552513524889946, 'mean_batch': 5.511409616470337, 'min_batch': 5.341843795776367, 'max_batch': 5.614747858047485}
step: 23240 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 4.1248455, 'max_total_reward': 14.56, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7656593918800354, 'actor_loss': -5.005303144454956, 'hyper_actor_loss': 0.009287361428141594, 'behavior_loss': 0.25917514860630037, 'mean_batch': 5.565496778488159, 'min_batch': 5.361868572235108, 'max_batch': 5.687360620498657}
step: 23250 @ episode report: {'average_total_reward': 10.853, 'reward_variance': 3.5603223, 'max_total_reward': 14.560001, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9528733015060424, 'actor_loss': -5.003665828704834, 'hyper_actor_loss': 0.009111134521663188, 'behavior_loss': 0.2697509303689003, 'mean_batch': 5.55663537979126, 'min_batch': 5.361654901504517, 'max_batch': 5.665345335006714}
step: 23260 @ episode report: {'average_total_reward': 9.221001, 'reward_variance': 5.6558285, 'max_total_reward': 11.2300005, 'min_total_reward': 3.5700002, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4643508076667784, 'actor_loss': -4.999036407470703, 'hyper_actor_loss': 0.009044724795967341, 'behavior_loss': 0.2505274027585983, 'mean_batch': 5.552732324600219, 'min_batch': 5.340597486495971, 'max_batch': 5.653323602676392}
step: 23270 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 4.541962, 'max_total_reward': 15.670001, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.945137631893158, 'actor_loss': -4.968166399002075, 'hyper_actor_loss': 0.008961433917284012, 'behavior_loss': 0.26749545633792876, 'mean_batch': 5.444730472564697, 'min_batch': 5.280998802185058, 'max_batch': 5.544316577911377}
step: 23280 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 4.2804003, 'max_total_reward': 13.34, 'min_total_reward': 5.57, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0825525403022764, 'actor_loss': -4.997075080871582, 'hyper_actor_loss': 0.008965625241398812, 'behavior_loss': 0.2731246054172516, 'mean_batch': 5.537035799026489, 'min_batch': 5.345398902893066, 'max_batch': 5.638557624816895}
step: 23290 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 2.495676, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0048646450042726, 'actor_loss': -4.990663766860962, 'hyper_actor_loss': 0.00890232203528285, 'behavior_loss': 0.26723531931638717, 'mean_batch': 5.50487871170044, 'min_batch': 5.341999149322509, 'max_batch': 5.603706550598145}
step: 23300 @ episode report: {'average_total_reward': 11.009, 'reward_variance': 2.9629683, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8067050457000733, 'actor_loss': -5.000668907165528, 'hyper_actor_loss': 0.008958104811608792, 'behavior_loss': 0.2686819538474083, 'mean_batch': 5.553170299530029, 'min_batch': 5.348975610733032, 'max_batch': 5.67543044090271}
step: 23310 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 3.9119847, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8630804061889648, 'actor_loss': -5.0409996032714846, 'hyper_actor_loss': 0.00899320300668478, 'behavior_loss': 0.2627538800239563, 'mean_batch': 5.662603282928467, 'min_batch': 5.461454629898071, 'max_batch': 5.781547784805298}
step: 23320 @ episode report: {'average_total_reward': 10.453, 'reward_variance': 3.6133606, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9643098652362823, 'actor_loss': -4.974577617645264, 'hyper_actor_loss': 0.008921328652650117, 'behavior_loss': 0.2663551926612854, 'mean_batch': 5.462065076828003, 'min_batch': 5.298635578155517, 'max_batch': 5.553018617630005}
step: 23330 @ episode report: {'average_total_reward': 10.798001, 'reward_variance': 2.4336562, 'max_total_reward': 13.450001, 'min_total_reward': 8.46, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.092083740234375, 'actor_loss': -4.976971960067749, 'hyper_actor_loss': 0.008695298712700606, 'behavior_loss': 0.24768491387367247, 'mean_batch': 5.462853860855103, 'min_batch': 5.310035133361817, 'max_batch': 5.559179639816284}
step: 23340 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 3.093621, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9320358514785767, 'actor_loss': -5.018554639816284, 'hyper_actor_loss': 0.008652567118406295, 'behavior_loss': 0.2515826180577278, 'mean_batch': 5.611839962005615, 'min_batch': 5.389035177230835, 'max_batch': 5.732008361816407}
step: 23350 @ episode report: {'average_total_reward': 8.988001, 'reward_variance': 4.1737165, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4351347923278808, 'actor_loss': -4.995153427124023, 'hyper_actor_loss': 0.008464501798152923, 'behavior_loss': 0.2728414833545685, 'mean_batch': 5.543266105651855, 'min_batch': 5.329779005050659, 'max_batch': 5.652384424209595}
step: 23360 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 3.0751405, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5003169417381286, 'actor_loss': -4.976737070083618, 'hyper_actor_loss': 0.008464767877012492, 'behavior_loss': 0.2948134422302246, 'mean_batch': 5.497454977035522, 'min_batch': 5.275627946853637, 'max_batch': 5.601782989501953}
step: 23370 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 3.8244004, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2101548433303835, 'actor_loss': -4.974889755249023, 'hyper_actor_loss': 0.008681348990648985, 'behavior_loss': 0.26876471787691114, 'mean_batch': 5.481694316864013, 'min_batch': 5.280749082565308, 'max_batch': 5.580537986755371}
step: 23380 @ episode report: {'average_total_reward': 9.311, 'reward_variance': 1.9717491, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.235187864303589, 'actor_loss': -4.976738834381104, 'hyper_actor_loss': 0.008687723986804485, 'behavior_loss': 0.2630788281559944, 'mean_batch': 5.499778318405151, 'min_batch': 5.273079538345337, 'max_batch': 5.607697248458862}
step: 23390 @ episode report: {'average_total_reward': 11.0199995, 'reward_variance': 4.9865003, 'max_total_reward': 14.34, 'min_total_reward': 6.68, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.133133566379547, 'actor_loss': -4.986995029449463, 'hyper_actor_loss': 0.008609185460954905, 'behavior_loss': 0.28063818961381914, 'mean_batch': 5.517585802078247, 'min_batch': 5.310296154022216, 'max_batch': 5.627657222747803}
step: 23400 @ episode report: {'average_total_reward': 11.153001, 'reward_variance': 3.9501011, 'max_total_reward': 15.559999, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8652429580688477, 'actor_loss': -4.993892097473145, 'hyper_actor_loss': 0.008501330111175775, 'behavior_loss': 0.27291402518749236, 'mean_batch': 5.548949241638184, 'min_batch': 5.316932916641235, 'max_batch': 5.663854789733887}
step: 23410 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 3.989661, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0499207019805907, 'actor_loss': -5.023168134689331, 'hyper_actor_loss': 0.008374548982828856, 'behavior_loss': 0.27016863524913787, 'mean_batch': 5.61422815322876, 'min_batch': 5.411112260818482, 'max_batch': 5.734580993652344}
step: 23420 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 5.499302, 'max_total_reward': 14.450001, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7508490800857544, 'actor_loss': -5.016108465194702, 'hyper_actor_loss': 0.008369189128279686, 'behavior_loss': 0.27018930166959765, 'mean_batch': 5.594242143630981, 'min_batch': 5.392262983322143, 'max_batch': 5.698387289047242}
step: 23430 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 3.0516448, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.41904274225235, 'actor_loss': -4.990015935897827, 'hyper_actor_loss': 0.008322025276720523, 'behavior_loss': 0.27758643329143523, 'mean_batch': 5.523523902893066, 'min_batch': 5.320990371704101, 'max_batch': 5.63346643447876}
step: 23440 @ episode report: {'average_total_reward': 11.231001, 'reward_variance': 2.1139288, 'max_total_reward': 13.34, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.553129732608795, 'actor_loss': -4.962879323959351, 'hyper_actor_loss': 0.00840155864134431, 'behavior_loss': 0.27041355818510054, 'mean_batch': 5.4407586574554445, 'min_batch': 5.257045841217041, 'max_batch': 5.571633815765381}
step: 23450 @ episode report: {'average_total_reward': 12.095999, 'reward_variance': 2.7267635, 'max_total_reward': 15.669999, 'min_total_reward': 10.01, 'average_n_step': 12.8, 'max_n_step': 16.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2769696712493896, 'actor_loss': -4.9819653034210205, 'hyper_actor_loss': 0.008471742831170559, 'behavior_loss': 0.2659865230321884, 'mean_batch': 5.510818576812744, 'min_batch': 5.290235280990601, 'max_batch': 5.751550102233887}
step: 23460 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 3.5315595, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4363158345222473, 'actor_loss': -4.997550916671753, 'hyper_actor_loss': 0.008316248562186957, 'behavior_loss': 0.28497844338417055, 'mean_batch': 5.540664768218994, 'min_batch': 5.344351053237915, 'max_batch': 5.82638258934021}
step: 23470 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 5.4890046, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.259823966026306, 'actor_loss': -4.960182332992554, 'hyper_actor_loss': 0.008328057639300824, 'behavior_loss': 0.275475712120533, 'mean_batch': 5.445401620864868, 'min_batch': 5.238461446762085, 'max_batch': 5.776006507873535}
step: 23480 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 3.9974504, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.803517907857895, 'actor_loss': -4.996889114379883, 'hyper_actor_loss': 0.00825537396594882, 'behavior_loss': 0.2580863550305367, 'mean_batch': 5.527531099319458, 'min_batch': 5.354291677474976, 'max_batch': 5.665056943893433}
step: 23490 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 0.895744, 'max_total_reward': 10.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.0, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1805651009082796, 'actor_loss': -5.018435001373291, 'hyper_actor_loss': 0.008248504251241684, 'behavior_loss': 0.2817700728774071, 'mean_batch': 5.592776775360107, 'min_batch': 5.406254577636719, 'max_batch': 5.744531059265137}
step: 23500 @ episode report: {'average_total_reward': 9.998, 'reward_variance': 5.755195, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.257127231359482, 'actor_loss': -4.973704862594604, 'hyper_actor_loss': 0.008090824913233518, 'behavior_loss': 0.2653235957026482, 'mean_batch': 5.456826782226562, 'min_batch': 5.298502349853516, 'max_batch': 5.560405683517456}
step: 23510 @ episode report: {'average_total_reward': 11.075, 'reward_variance': 1.3385452, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0284053087234497, 'actor_loss': -4.983276510238648, 'hyper_actor_loss': 0.00813279952853918, 'behavior_loss': 0.2587726071476936, 'mean_batch': 5.486956167221069, 'min_batch': 5.320171880722046, 'max_batch': 5.672497987747192}
step: 23520 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 1.897341, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6607929944992066, 'actor_loss': -5.0674971580505375, 'hyper_actor_loss': 0.008167188335210084, 'behavior_loss': 0.2616123542189598, 'mean_batch': 5.7979662895202635, 'min_batch': 5.478251838684082, 'max_batch': 6.208084058761597}
step: 23530 @ episode report: {'average_total_reward': 11.919, 'reward_variance': 1.6099488, 'max_total_reward': 14.56, 'min_total_reward': 10.01, 'average_n_step': 12.7, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.07110458612442, 'actor_loss': -4.997789001464843, 'hyper_actor_loss': 0.008282953593879937, 'behavior_loss': 0.26549440771341326, 'mean_batch': 5.536109828948975, 'min_batch': 5.350826406478882, 'max_batch': 5.714084243774414}
step: 23540 @ episode report: {'average_total_reward': 10.631, 'reward_variance': 4.6560698, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1070885062217712, 'actor_loss': -4.973674011230469, 'hyper_actor_loss': 0.008370149228721858, 'behavior_loss': 0.268365877866745, 'mean_batch': 5.453803014755249, 'min_batch': 5.301258325576782, 'max_batch': 5.532217121124267}
step: 23550 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 3.9539056, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6868583798408507, 'actor_loss': -4.9595154285430905, 'hyper_actor_loss': 0.008195218723267316, 'behavior_loss': 0.2493493527173996, 'mean_batch': 5.416975355148315, 'min_batch': 5.262722301483154, 'max_batch': 5.496747779846191}
step: 23560 @ episode report: {'average_total_reward': 10.309001, 'reward_variance': 5.0010495, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.162371838092804, 'actor_loss': -4.947446680068969, 'hyper_actor_loss': 0.00815663430839777, 'behavior_loss': 0.259792697429657, 'mean_batch': 5.384227609634399, 'min_batch': 5.230941677093506, 'max_batch': 5.455315256118775}
step: 23570 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 2.7398803, 'max_total_reward': 12.34, 'min_total_reward': 6.790001, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.5042518079280853, 'actor_loss': -5.010032749176025, 'hyper_actor_loss': 0.008107787184417247, 'behavior_loss': 0.26248064637184143, 'mean_batch': 5.562118864059448, 'min_batch': 5.391984987258911, 'max_batch': 5.638410234451294}
step: 23580 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 7.229968, 'max_total_reward': 15.56, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8114696979522704, 'actor_loss': -5.060714054107666, 'hyper_actor_loss': 0.008029498811811208, 'behavior_loss': 0.2703573822975159, 'mean_batch': 5.705550575256348, 'min_batch': 5.528378343582153, 'max_batch': 5.79951810836792}
step: 23590 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.81011, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.57721586227417, 'actor_loss': -4.973329496383667, 'hyper_actor_loss': 0.007987534860149026, 'behavior_loss': 0.2654395267367363, 'mean_batch': 5.4433001518249515, 'min_batch': 5.311834001541138, 'max_batch': 5.522282409667969}
step: 23600 @ episode report: {'average_total_reward': 9.01, 'reward_variance': 3.51062, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.352761423587799, 'actor_loss': -4.918329954147339, 'hyper_actor_loss': 0.008217625506222247, 'behavior_loss': 0.2871673434972763, 'mean_batch': 5.318596076965332, 'min_batch': 5.145158433914185, 'max_batch': 5.391638326644897}
step: 23610 @ episode report: {'average_total_reward': 9.787001, 'reward_variance': 3.5913613, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9271039128303529, 'actor_loss': -4.998552417755127, 'hyper_actor_loss': 0.008423561044037343, 'behavior_loss': 0.25393244475126264, 'mean_batch': 5.515183925628662, 'min_batch': 5.375048065185547, 'max_batch': 5.5990324974060055}
step: 23620 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 3.3690238, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.281131458282471, 'actor_loss': -5.016796207427978, 'hyper_actor_loss': 0.008446185663342477, 'behavior_loss': 0.2650128498673439, 'mean_batch': 5.573846292495728, 'min_batch': 5.4160808563232425, 'max_batch': 5.652804374694824}
step: 23630 @ episode report: {'average_total_reward': 10.154, 'reward_variance': 5.5612454, 'max_total_reward': 14.450001, 'min_total_reward': 5.7899995, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.829089605808258, 'actor_loss': -4.977198362350464, 'hyper_actor_loss': 0.008416103292256593, 'behavior_loss': 0.265866157412529, 'mean_batch': 5.450652837753296, 'min_batch': 5.323028802871704, 'max_batch': 5.5285180568695065}
step: 23640 @ episode report: {'average_total_reward': 10.887001, 'reward_variance': 1.5303812, 'max_total_reward': 13.34, 'min_total_reward': 8.68, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.428157591819763, 'actor_loss': -4.991729259490967, 'hyper_actor_loss': 0.00839022183790803, 'behavior_loss': 0.28567447513341904, 'mean_batch': 5.487276792526245, 'min_batch': 5.364841794967651, 'max_batch': 5.569227266311645}
step: 23650 @ episode report: {'average_total_reward': 11.375001, 'reward_variance': 3.8104854, 'max_total_reward': 15.56, 'min_total_reward': 8.9, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9252916872501373, 'actor_loss': -4.971661949157715, 'hyper_actor_loss': 0.008571370039135218, 'behavior_loss': 0.27774953097105026, 'mean_batch': 5.431726741790771, 'min_batch': 5.312067365646362, 'max_batch': 5.508015871047974}
step: 23660 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 3.3141162, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9002809703350068, 'actor_loss': -4.99340033531189, 'hyper_actor_loss': 0.008669336792081594, 'behavior_loss': 0.2802103698253632, 'mean_batch': 5.503008031845093, 'min_batch': 5.358538866043091, 'max_batch': 5.584674215316772}
step: 23670 @ episode report: {'average_total_reward': 11.608, 'reward_variance': 2.6262562, 'max_total_reward': 14.450001, 'min_total_reward': 8.79, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.20958526134491, 'actor_loss': -5.020443725585937, 'hyper_actor_loss': 0.00884649297222495, 'behavior_loss': 0.27983942478895185, 'mean_batch': 5.587119293212891, 'min_batch': 5.422564888000489, 'max_batch': 5.6737633228302}
step: 23680 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 2.222004, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8936955809593201, 'actor_loss': -4.999395084381104, 'hyper_actor_loss': 0.008876440022140742, 'behavior_loss': 0.28354726880788805, 'mean_batch': 5.527339601516724, 'min_batch': 5.367112636566162, 'max_batch': 5.613455104827881}
step: 23690 @ episode report: {'average_total_reward': 9.998001, 'reward_variance': 3.6861558, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.308600103855133, 'actor_loss': -5.00551962852478, 'hyper_actor_loss': 0.00898123299703002, 'behavior_loss': 0.2654338896274567, 'mean_batch': 5.543204641342163, 'min_batch': 5.384578609466553, 'max_batch': 5.637771463394165}
step: 23700 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 2.1054444, 'max_total_reward': 13.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9152813673019409, 'actor_loss': -5.007202959060669, 'hyper_actor_loss': 0.00886693811044097, 'behavior_loss': 0.260586217045784, 'mean_batch': 5.555368280410766, 'min_batch': 5.382050275802612, 'max_batch': 5.652223062515259}
step: 23710 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.380629, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.09638090133667, 'actor_loss': -5.059248399734497, 'hyper_actor_loss': 0.008871544990688563, 'behavior_loss': 0.2744927182793617, 'mean_batch': 5.709341955184937, 'min_batch': 5.516512680053711, 'max_batch': 5.80865888595581}
step: 23720 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 2.8069568, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2521323442459105, 'actor_loss': -5.020389747619629, 'hyper_actor_loss': 0.008724002074450255, 'behavior_loss': 0.2637171044945717, 'mean_batch': 5.589549541473389, 'min_batch': 5.420464420318604, 'max_batch': 5.678948545455933}
step: 23730 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 2.231657, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.215387237071991, 'actor_loss': -5.013457441329956, 'hyper_actor_loss': 0.00860913647338748, 'behavior_loss': 0.266153521835804, 'mean_batch': 5.5422896385192875, 'min_batch': 5.428294563293457, 'max_batch': 5.622940921783448}
step: 23740 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 4.4011617, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0759015321731566, 'actor_loss': -5.027054929733277, 'hyper_actor_loss': 0.008506732434034348, 'behavior_loss': 0.2718635395169258, 'mean_batch': 5.5909370422363285, 'min_batch': 5.454717397689819, 'max_batch': 5.6678825378417965}
step: 23750 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 2.740364, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4877808690071106, 'actor_loss': -5.026319408416748, 'hyper_actor_loss': 0.008618076052516698, 'behavior_loss': 0.27005971074104307, 'mean_batch': 5.57874321937561, 'min_batch': 5.4626439094543455, 'max_batch': 5.654390621185303}
step: 23760 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.76546, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.182060980796814, 'actor_loss': -4.981024646759034, 'hyper_actor_loss': 0.008686615619808435, 'behavior_loss': 0.2684468537569046, 'mean_batch': 5.458965015411377, 'min_batch': 5.33528208732605, 'max_batch': 5.538540267944336}
step: 23770 @ episode report: {'average_total_reward': 9.222, 'reward_variance': 3.062936, 'max_total_reward': 12.12, 'min_total_reward': 6.6800003, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2657870650291443, 'actor_loss': -4.9897480487823485, 'hyper_actor_loss': 0.008642346691340208, 'behavior_loss': 0.2768791183829308, 'mean_batch': 5.487329530715942, 'min_batch': 5.354230546951294, 'max_batch': 5.56617431640625}
step: 23780 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.393845, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7899995, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6271448373794555, 'actor_loss': -5.006479930877686, 'hyper_actor_loss': 0.008583288919180632, 'behavior_loss': 0.27767149209976194, 'mean_batch': 5.541013526916504, 'min_batch': 5.391842317581177, 'max_batch': 5.624897575378418}
step: 23790 @ episode report: {'average_total_reward': 8.555, 'reward_variance': 9.062887, 'max_total_reward': 13.450001, 'min_total_reward': 2.35, 'average_n_step': 9.6, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.127957117557526, 'actor_loss': -4.986931467056275, 'hyper_actor_loss': 0.008662948198616505, 'behavior_loss': 0.2621580436825752, 'mean_batch': 5.476349639892578, 'min_batch': 5.349819898605347, 'max_batch': 5.551505899429321}
step: 23800 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 4.9145103, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1620821714401246, 'actor_loss': -5.011797189712524, 'hyper_actor_loss': 0.008669826108962298, 'behavior_loss': 0.2760629117488861, 'mean_batch': 5.546966600418091, 'min_batch': 5.4147868156433105, 'max_batch': 5.621776962280274}
step: 23810 @ episode report: {'average_total_reward': 11.375001, 'reward_variance': 3.7933254, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8897000551223755, 'actor_loss': -5.018075609207154, 'hyper_actor_loss': 0.008710080105811358, 'behavior_loss': 0.261098051071167, 'mean_batch': 5.575771522521973, 'min_batch': 5.420641279220581, 'max_batch': 5.666821050643921}
step: 23820 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 1.9951248, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5650185346603394, 'actor_loss': -5.009805727005005, 'hyper_actor_loss': 0.008745887223631144, 'behavior_loss': 0.2783463880419731, 'mean_batch': 5.545422840118408, 'min_batch': 5.405736255645752, 'max_batch': 5.631801271438599}
step: 23830 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 4.205104, 'max_total_reward': 14.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.293916845321655, 'actor_loss': -4.978494596481323, 'hyper_actor_loss': 0.008860305044800043, 'behavior_loss': 0.2751189023256302, 'mean_batch': 5.462654972076416, 'min_batch': 5.318159437179565, 'max_batch': 5.5482100486755375}
step: 23840 @ episode report: {'average_total_reward': 10.976001, 'reward_variance': 2.162824, 'max_total_reward': 13.23, 'min_total_reward': 8.57, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8344698667526245, 'actor_loss': -5.0151866436004635, 'hyper_actor_loss': 0.00904622133821249, 'behavior_loss': 0.2683269202709198, 'mean_batch': 5.5670722961425785, 'min_batch': 5.413978576660156, 'max_batch': 5.655761289596557}
step: 23850 @ episode report: {'average_total_reward': 10.176, 'reward_variance': 3.2510636, 'max_total_reward': 12.12, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.175363302230835, 'actor_loss': -5.043924236297608, 'hyper_actor_loss': 0.009111408703029155, 'behavior_loss': 0.2710611119866371, 'mean_batch': 5.65551528930664, 'min_batch': 5.484184789657593, 'max_batch': 5.754806900024414}
step: 23860 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.3801258, 'max_total_reward': 13.120001, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.449912595748901, 'actor_loss': -5.018261432647705, 'hyper_actor_loss': 0.00910339094698429, 'behavior_loss': 0.26353361904621125, 'mean_batch': 5.5757239818572994, 'min_batch': 5.421845960617065, 'max_batch': 5.673946571350098}
step: 23870 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 4.92356, 'max_total_reward': 14.339999, 'min_total_reward': 6.57, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3940519452095033, 'actor_loss': -4.997972297668457, 'hyper_actor_loss': 0.009238539077341557, 'behavior_loss': 0.25792312175035476, 'mean_batch': 5.519651412963867, 'min_batch': 5.36684136390686, 'max_batch': 5.608370304107666}
step: 23880 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 2.1030245, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.982039111852646, 'actor_loss': -5.01517653465271, 'hyper_actor_loss': 0.009235283359885216, 'behavior_loss': 0.25944321900606154, 'mean_batch': 5.567324781417847, 'min_batch': 5.413321208953858, 'max_batch': 5.660038995742798}
step: 23890 @ episode report: {'average_total_reward': 11.253, 'reward_variance': 4.0799227, 'max_total_reward': 14.450001, 'min_total_reward': 7.7899995, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6562223732471466, 'actor_loss': -5.052615356445313, 'hyper_actor_loss': 0.009248272143304348, 'behavior_loss': 0.27852323800325396, 'mean_batch': 5.669105052947998, 'min_batch': 5.518932294845581, 'max_batch': 5.760064744949341}
step: 23900 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 4.020426, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1109835147857665, 'actor_loss': -5.067118167877197, 'hyper_actor_loss': 0.009299022331833839, 'behavior_loss': 0.2632329538464546, 'mean_batch': 5.725412178039551, 'min_batch': 5.544569253921509, 'max_batch': 5.825111389160156}
step: 23910 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 4.73619, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6485207438468934, 'actor_loss': -5.037559270858765, 'hyper_actor_loss': 0.009290638752281666, 'behavior_loss': 0.26141109615564345, 'mean_batch': 5.629251623153687, 'min_batch': 5.474852085113525, 'max_batch': 5.723177099227906}
step: 23920 @ episode report: {'average_total_reward': 10.098001, 'reward_variance': 3.876236, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.990995502471924, 'actor_loss': -5.06277060508728, 'hyper_actor_loss': 0.009153351187705994, 'behavior_loss': 0.28305855840444566, 'mean_batch': 5.699633502960205, 'min_batch': 5.545296907424927, 'max_batch': 5.7967335224151615}
step: 23930 @ episode report: {'average_total_reward': 9.554, 'reward_variance': 4.739524, 'max_total_reward': 14.45, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1728832006454466, 'actor_loss': -5.032665014266968, 'hyper_actor_loss': 0.009231258928775788, 'behavior_loss': 0.2662334606051445, 'mean_batch': 5.615106296539307, 'min_batch': 5.461886978149414, 'max_batch': 5.704095983505249}
step: 23940 @ episode report: {'average_total_reward': 11.186, 'reward_variance': 2.862264, 'max_total_reward': 14.45, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8773963689804076, 'actor_loss': -5.034282493591308, 'hyper_actor_loss': 0.009338828548789025, 'behavior_loss': 0.2705369099974632, 'mean_batch': 5.622387027740478, 'min_batch': 5.463897609710694, 'max_batch': 5.710790014266967}
step: 23950 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 5.06587, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0922742009162905, 'actor_loss': -5.057826519012451, 'hyper_actor_loss': 0.009360161703079939, 'behavior_loss': 0.26065448224544524, 'mean_batch': 5.68929877281189, 'min_batch': 5.528035879135132, 'max_batch': 5.786845397949219}
step: 23960 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 5.9265, 'max_total_reward': 13.45, 'min_total_reward': 5.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.070462113618851, 'actor_loss': -5.058320188522339, 'hyper_actor_loss': 0.009455815609544515, 'behavior_loss': 0.2572991088032722, 'mean_batch': 5.694764280319214, 'min_batch': 5.525375699996948, 'max_batch': 5.80077223777771}
step: 23970 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 5.4608397, 'max_total_reward': 14.559999, 'min_total_reward': 6.57, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7477557063102722, 'actor_loss': -5.076873445510865, 'hyper_actor_loss': 0.009446698240935802, 'behavior_loss': 0.27872899621725084, 'mean_batch': 5.761292743682861, 'min_batch': 5.564222383499145, 'max_batch': 5.915887546539307}
step: 23980 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 1.4858642, 'max_total_reward': 11.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1151314258575438, 'actor_loss': -5.093791246414185, 'hyper_actor_loss': 0.009588003065437079, 'behavior_loss': 0.2669268861413002, 'mean_batch': 5.8103820323944095, 'min_batch': 5.611100530624389, 'max_batch': 5.921109914779663}
step: 23990 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 5.37905, 'max_total_reward': 12.340001, 'min_total_reward': 4.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2835480332374574, 'actor_loss': -5.052448558807373, 'hyper_actor_loss': 0.009709572419524193, 'behavior_loss': 0.2510432332754135, 'mean_batch': 5.692841243743897, 'min_batch': 5.495087766647339, 'max_batch': 5.799217271804809}
step: 24000 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 3.4910417, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2197957396507264, 'actor_loss': -5.078612422943115, 'hyper_actor_loss': 0.00949214855208993, 'behavior_loss': 0.25817469507455826, 'mean_batch': 5.77296290397644, 'min_batch': 5.5630035400390625, 'max_batch': 5.900914716720581}
step: 24010 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 3.2311885, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.45320086479187, 'actor_loss': -5.08018651008606, 'hyper_actor_loss': 0.009342106711119413, 'behavior_loss': 0.2695834755897522, 'mean_batch': 5.783196306228637, 'min_batch': 5.561273765563965, 'max_batch': 5.919832038879394}
step: 24020 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 4.1656647, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0056068122386934, 'actor_loss': -5.075024366378784, 'hyper_actor_loss': 0.009481672663241625, 'behavior_loss': 0.2766201674938202, 'mean_batch': 5.772161197662354, 'min_batch': 5.543290424346924, 'max_batch': 5.90030083656311}
step: 24030 @ episode report: {'average_total_reward': 8.966001, 'reward_variance': 8.612665, 'max_total_reward': 12.23, 'min_total_reward': 1.24, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9439212560653687, 'actor_loss': -5.095664310455322, 'hyper_actor_loss': 0.009520500618964433, 'behavior_loss': 0.2625865891575813, 'mean_batch': 5.838206672668457, 'min_batch': 5.594879055023194, 'max_batch': 5.99036021232605}
step: 24040 @ episode report: {'average_total_reward': 10.687001, 'reward_variance': 1.0090814, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4503637313842774, 'actor_loss': -5.064592170715332, 'hyper_actor_loss': 0.009491650201380254, 'behavior_loss': 0.2676768109202385, 'mean_batch': 5.724629068374634, 'min_batch': 5.531379318237304, 'max_batch': 5.838284921646118}
step: 24050 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.2729652, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.338187521696091, 'actor_loss': -5.0379640579223635, 'hyper_actor_loss': 0.009431347157806158, 'behavior_loss': 0.2720950573682785, 'mean_batch': 5.64397554397583, 'min_batch': 5.462787628173828, 'max_batch': 5.748373556137085}
step: 24060 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 1.8352363, 'max_total_reward': 12.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3216378927230834, 'actor_loss': -5.04094614982605, 'hyper_actor_loss': 0.009552700631320476, 'behavior_loss': 0.2843543812632561, 'mean_batch': 5.645256757736206, 'min_batch': 5.477898740768433, 'max_batch': 5.737163734436035}
step: 24070 @ episode report: {'average_total_reward': 10.442001, 'reward_variance': 5.346717, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.910202944278717, 'actor_loss': -5.063196754455566, 'hyper_actor_loss': 0.00971303479745984, 'behavior_loss': 0.26366041898727416, 'mean_batch': 5.713636875152588, 'min_batch': 5.53443546295166, 'max_batch': 5.818601417541504}
step: 24080 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.5970297, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3103912651538847, 'actor_loss': -5.075543594360352, 'hyper_actor_loss': 0.009774366114288568, 'behavior_loss': 0.2629286840558052, 'mean_batch': 5.747351026535034, 'min_batch': 5.57044243812561, 'max_batch': 5.84858455657959}
step: 24090 @ episode report: {'average_total_reward': 10.408999, 'reward_variance': 7.4615493, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0446980476379393, 'actor_loss': -5.066531991958618, 'hyper_actor_loss': 0.009646396897733212, 'behavior_loss': 0.28692135214805603, 'mean_batch': 5.715195226669311, 'min_batch': 5.551175117492676, 'max_batch': 5.800241470336914}
step: 24100 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 3.7634606, 'max_total_reward': 14.450001, 'min_total_reward': 7.9000006, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0393724918365477, 'actor_loss': -5.082582616806031, 'hyper_actor_loss': 0.009719808027148247, 'behavior_loss': 0.25120375454425814, 'mean_batch': 5.771447372436524, 'min_batch': 5.586215877532959, 'max_batch': 5.864623355865478}
step: 24110 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 1.8304895, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.325620412826538, 'actor_loss': -5.070869588851929, 'hyper_actor_loss': 0.009644344914704561, 'behavior_loss': 0.25248630344867706, 'mean_batch': 5.737837076187134, 'min_batch': 5.553122663497925, 'max_batch': 5.839028406143188}
step: 24120 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 4.188724, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9904658317565918, 'actor_loss': -5.070500183105469, 'hyper_actor_loss': 0.009485203493386506, 'behavior_loss': 0.26116075962781904, 'mean_batch': 5.743334627151489, 'min_batch': 5.545869636535644, 'max_batch': 5.83843297958374}
step: 24130 @ episode report: {'average_total_reward': 8.411, 'reward_variance': 4.397129, 'max_total_reward': 11.2300005, 'min_total_reward': 4.68, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.280923902988434, 'actor_loss': -5.073059034347534, 'hyper_actor_loss': 0.009486219938844442, 'behavior_loss': 0.27299712002277376, 'mean_batch': 5.721018266677857, 'min_batch': 5.581777667999267, 'max_batch': 5.8172327995300295}
step: 24140 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 6.745681, 'max_total_reward': 13.450001, 'min_total_reward': 4.68, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1168787717819213, 'actor_loss': -5.041518449783325, 'hyper_actor_loss': 0.009491519723087549, 'behavior_loss': 0.2656919062137604, 'mean_batch': 5.651782703399658, 'min_batch': 5.474641227722168, 'max_batch': 5.7602873802185055}
step: 24150 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 4.8338556, 'max_total_reward': 12.23, 'min_total_reward': 4.57, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1888860940933226, 'actor_loss': -5.055937910079956, 'hyper_actor_loss': 0.009342917706817389, 'behavior_loss': 0.26570071578025817, 'mean_batch': 5.67740421295166, 'min_batch': 5.529077434539795, 'max_batch': 5.7584062099456785}
step: 24160 @ episode report: {'average_total_reward': 9.688, 'reward_variance': 5.419356, 'max_total_reward': 13.12, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0066679239273073, 'actor_loss': -5.0794209957122805, 'hyper_actor_loss': 0.009508780110627413, 'behavior_loss': 0.26697106957435607, 'mean_batch': 5.753078413009644, 'min_batch': 5.586537408828735, 'max_batch': 5.869401311874389}
step: 24170 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 4.95463, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.485638564825058, 'actor_loss': -5.096474313735962, 'hyper_actor_loss': 0.009745157696306706, 'behavior_loss': 0.2522138372063637, 'mean_batch': 5.800369596481323, 'min_batch': 5.635836172103882, 'max_batch': 5.908211660385132}
step: 24180 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.9314759, 'max_total_reward': 12.23, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.58209969997406, 'actor_loss': -5.089608144760132, 'hyper_actor_loss': 0.009756192937493325, 'behavior_loss': 0.28918883204460144, 'mean_batch': 5.786194658279419, 'min_batch': 5.61144642829895, 'max_batch': 5.909187126159668}
step: 24190 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 3.4381695, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.234360063076019, 'actor_loss': -5.023997449874878, 'hyper_actor_loss': 0.00996337430551648, 'behavior_loss': 0.2633914351463318, 'mean_batch': 5.592954301834107, 'min_batch': 5.436401081085205, 'max_batch': 5.707168912887573}
step: 24200 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 3.7426815, 'max_total_reward': 13.450001, 'min_total_reward': 7.7899995, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6844367250800132, 'actor_loss': -5.090021562576294, 'hyper_actor_loss': 0.01016220860183239, 'behavior_loss': 0.2759808823466301, 'mean_batch': 5.792774295806884, 'min_batch': 5.608501529693603, 'max_batch': 5.900710773468018}
step: 24210 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 2.513105, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0009552001953126, 'actor_loss': -5.141798782348633, 'hyper_actor_loss': 0.010262807458639145, 'behavior_loss': 0.27415345460176466, 'mean_batch': 5.94914231300354, 'min_batch': 5.74966287612915, 'max_batch': 6.065233755111694}
step: 24220 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 3.4191291, 'max_total_reward': 12.23, 'min_total_reward': 5.7899995, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.191612219810486, 'actor_loss': -5.070916700363159, 'hyper_actor_loss': 0.010331059247255326, 'behavior_loss': 0.2675461694598198, 'mean_batch': 5.7305295944213865, 'min_batch': 5.560946321487426, 'max_batch': 5.833129215240478}
step: 24230 @ episode report: {'average_total_reward': 9.565001, 'reward_variance': 7.707685, 'max_total_reward': 12.34, 'min_total_reward': 3.5700002, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2741665959358217, 'actor_loss': -5.071021795272827, 'hyper_actor_loss': 0.010425027552992105, 'behavior_loss': 0.27359006106853484, 'mean_batch': 5.736548852920532, 'min_batch': 5.555359125137329, 'max_batch': 5.844708967208862}
step: 24240 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 2.0474854, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.835815852880478, 'actor_loss': -5.0878321647644045, 'hyper_actor_loss': 0.010611456260085106, 'behavior_loss': 0.2576802209019661, 'mean_batch': 5.783579778671265, 'min_batch': 5.603696632385254, 'max_batch': 5.894586706161499}
step: 24250 @ episode report: {'average_total_reward': 9.455, 'reward_variance': 1.6521248, 'max_total_reward': 12.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7935820788145065, 'actor_loss': -5.141874027252197, 'hyper_actor_loss': 0.010709298215806485, 'behavior_loss': 0.2508694902062416, 'mean_batch': 5.930160665512085, 'min_batch': 5.768622589111328, 'max_batch': 6.0459880352020265}
step: 24260 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 2.496041, 'max_total_reward': 12.12, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2486123561859133, 'actor_loss': -5.109887361526489, 'hyper_actor_loss': 0.010539316292852163, 'behavior_loss': 0.26560966968536376, 'mean_batch': 5.848223924636841, 'min_batch': 5.665648508071899, 'max_batch': 5.951215839385986}
step: 24270 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 4.1157765, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.09757684469223, 'actor_loss': -5.0828746318817135, 'hyper_actor_loss': 0.01097209146246314, 'behavior_loss': 0.2578058496117592, 'mean_batch': 5.755834484100342, 'min_batch': 5.602924346923828, 'max_batch': 5.893134069442749}
step: 24280 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 5.88601, 'max_total_reward': 15.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.009499955177307, 'actor_loss': -5.129695558547974, 'hyper_actor_loss': 0.011336559243500233, 'behavior_loss': 0.2679425925016403, 'mean_batch': 5.901057338714599, 'min_batch': 5.7269350528717045, 'max_batch': 6.091219902038574}
step: 24290 @ episode report: {'average_total_reward': 8.877001, 'reward_variance': 1.8912013, 'max_total_reward': 11.01, 'min_total_reward': 6.9, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7394125878810882, 'actor_loss': -5.1353894710540775, 'hyper_actor_loss': 0.011583870090544224, 'behavior_loss': 0.2789190739393234, 'mean_batch': 5.92723708152771, 'min_batch': 5.733965492248535, 'max_batch': 6.0951779842376705}
step: 24300 @ episode report: {'average_total_reward': 9.332001, 'reward_variance': 1.943256, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3624072909355163, 'actor_loss': -5.129590129852295, 'hyper_actor_loss': 0.012105891294777394, 'behavior_loss': 0.2733977124094963, 'mean_batch': 5.900026178359985, 'min_batch': 5.727131128311157, 'max_batch': 6.053004932403565}
step: 24310 @ episode report: {'average_total_reward': 9.799001, 'reward_variance': 3.73573, 'max_total_reward': 13.2300005, 'min_total_reward': 6.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2399894118309023, 'actor_loss': -5.100279140472412, 'hyper_actor_loss': 0.012668506801128387, 'behavior_loss': 0.2680522248148918, 'mean_batch': 5.805223989486694, 'min_batch': 5.652490615844727, 'max_batch': 5.940120363235474}
step: 24320 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 2.2417843, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7215060949325562, 'actor_loss': -5.07642092704773, 'hyper_actor_loss': 0.012739870976656676, 'behavior_loss': 0.26783923953771593, 'mean_batch': 5.745456027984619, 'min_batch': 5.576673555374145, 'max_batch': 5.877937269210816}
step: 24330 @ episode report: {'average_total_reward': 9.666, 'reward_variance': 3.8828042, 'max_total_reward': 13.340001, 'min_total_reward': 7.68, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.318583333492279, 'actor_loss': -5.087283658981323, 'hyper_actor_loss': 0.012884756736457347, 'behavior_loss': 0.2641687497496605, 'mean_batch': 5.779602861404419, 'min_batch': 5.604475021362305, 'max_batch': 5.9222499370574955}
step: 24340 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 4.099049, 'max_total_reward': 13.12, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3414979934692384, 'actor_loss': -5.114970541000366, 'hyper_actor_loss': 0.013054798264056445, 'behavior_loss': 0.2582661032676697, 'mean_batch': 5.865648317337036, 'min_batch': 5.6770570278167725, 'max_batch': 5.989132404327393}
step: 24350 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 1.3001837, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.361235558986664, 'actor_loss': -5.101973581314087, 'hyper_actor_loss': 0.0131983058527112, 'behavior_loss': 0.2596207082271576, 'mean_batch': 5.82822961807251, 'min_batch': 5.639833116531372, 'max_batch': 5.960203504562378}
step: 24360 @ episode report: {'average_total_reward': 8.966001, 'reward_variance': 5.4848847, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.094791316986084, 'actor_loss': -5.124615001678467, 'hyper_actor_loss': 0.013518299162387847, 'behavior_loss': 0.2643006771802902, 'mean_batch': 5.881414127349854, 'min_batch': 5.717076301574707, 'max_batch': 6.043660306930542}
step: 24370 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 1.4009491, 'max_total_reward': 12.2300005, 'min_total_reward': 9.009999, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.376697063446045, 'actor_loss': -5.132111406326294, 'hyper_actor_loss': 0.01367351897060871, 'behavior_loss': 0.27145499885082247, 'mean_batch': 5.906727647781372, 'min_batch': 5.735330867767334, 'max_batch': 6.068843603134155}
step: 24380 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 3.6581893, 'max_total_reward': 13.450001, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.256630063056946, 'actor_loss': -5.103302621841431, 'hyper_actor_loss': 0.014172362629324198, 'behavior_loss': 0.2679740086197853, 'mean_batch': 5.850885725021362, 'min_batch': 5.625696277618408, 'max_batch': 5.993201398849488}
step: 24390 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 4.963109, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.347404932975769, 'actor_loss': -5.126411247253418, 'hyper_actor_loss': 0.014486185368150472, 'behavior_loss': 0.27708351612091064, 'mean_batch': 5.908055400848388, 'min_batch': 5.701334714889526, 'max_batch': 6.092375040054321}
step: 24400 @ episode report: {'average_total_reward': 8.045, 'reward_variance': 4.803426, 'max_total_reward': 10.120001, 'min_total_reward': 3.35, 'average_n_step': 9.2, 'max_n_step': 11.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4275488793849944, 'actor_loss': -5.137324810028076, 'hyper_actor_loss': 0.015005520917475224, 'behavior_loss': 0.28143556863069535, 'mean_batch': 5.941805171966553, 'min_batch': 5.731067419052124, 'max_batch': 6.12092924118042}
step: 24410 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 5.79889, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3615417003631594, 'actor_loss': -5.107406663894653, 'hyper_actor_loss': 0.015212127938866615, 'behavior_loss': 0.27975998967885973, 'mean_batch': 5.854118680953979, 'min_batch': 5.645553779602051, 'max_batch': 6.050007486343384}
step: 24420 @ episode report: {'average_total_reward': 8.255, 'reward_variance': 5.818425, 'max_total_reward': 13.45, 'min_total_reward': 5.6800003, 'average_n_step': 9.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.044373834133148, 'actor_loss': -5.1095000267028805, 'hyper_actor_loss': 0.01494370074942708, 'behavior_loss': 0.2610011652112007, 'mean_batch': 5.847117567062378, 'min_batch': 5.664417171478272, 'max_batch': 6.043047618865967}
step: 24430 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 2.3727243, 'max_total_reward': 12.23, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3709339678287504, 'actor_loss': -5.157808303833008, 'hyper_actor_loss': 0.014538493379950524, 'behavior_loss': 0.26445996165275576, 'mean_batch': 6.003462171554565, 'min_batch': 5.789846897125244, 'max_batch': 6.203813266754151}
step: 24440 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 2.6965563, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4040912210941316, 'actor_loss': -5.12184772491455, 'hyper_actor_loss': 0.014483115170150995, 'behavior_loss': 0.29274008572101595, 'mean_batch': 5.882550144195557, 'min_batch': 5.700129413604737, 'max_batch': 6.044557332992554}
step: 24450 @ episode report: {'average_total_reward': 10.709002, 'reward_variance': 4.8632097, 'max_total_reward': 14.450001, 'min_total_reward': 6.57, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.826439070701599, 'actor_loss': -5.110211992263794, 'hyper_actor_loss': 0.014973557367920876, 'behavior_loss': 0.2729253932833672, 'mean_batch': 5.857885503768921, 'min_batch': 5.657630109786988, 'max_batch': 6.085897636413574}
step: 24460 @ episode report: {'average_total_reward': 9.099001, 'reward_variance': 4.089489, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0356362581253054, 'actor_loss': -5.129315567016602, 'hyper_actor_loss': 0.015071421302855015, 'behavior_loss': 0.26186780631542206, 'mean_batch': 5.919254350662231, 'min_batch': 5.707406139373779, 'max_batch': 6.174334907531739}
step: 24470 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 5.925628, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6242827415466308, 'actor_loss': -5.160191535949707, 'hyper_actor_loss': 0.015074806753546, 'behavior_loss': 0.2822976365685463, 'mean_batch': 6.008514261245727, 'min_batch': 5.798496961593628, 'max_batch': 6.284867525100708}
step: 24480 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 4.8508296, 'max_total_reward': 14.450001, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.153808557987213, 'actor_loss': -5.122310733795166, 'hyper_actor_loss': 0.015530276857316495, 'behavior_loss': 0.26508208066225053, 'mean_batch': 5.904484558105469, 'min_batch': 5.681380748748779, 'max_batch': 6.199182748794556}
step: 24490 @ episode report: {'average_total_reward': 8.555, 'reward_variance': 3.0803852, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 9.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.60585241317749, 'actor_loss': -5.136102628707886, 'hyper_actor_loss': 0.015628861729055643, 'behavior_loss': 0.27722394168376924, 'mean_batch': 5.940177965164184, 'min_batch': 5.7256505489349365, 'max_batch': 6.293516540527344}
step: 24500 @ episode report: {'average_total_reward': 8.733, 'reward_variance': 2.005421, 'max_total_reward': 11.01, 'min_total_reward': 6.79, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2006983160972595, 'actor_loss': -5.170946836471558, 'hyper_actor_loss': 0.015975389815866946, 'behavior_loss': 0.26769846528768537, 'mean_batch': 6.13056526184082, 'min_batch': 5.745242071151734, 'max_batch': 6.537354135513306}
step: 24510 @ episode report: {'average_total_reward': 8.622, 'reward_variance': 6.5682764, 'max_total_reward': 11.2300005, 'min_total_reward': 3.46, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.644464612007141, 'actor_loss': -5.150119209289551, 'hyper_actor_loss': 0.016185220517218112, 'behavior_loss': 0.2724283128976822, 'mean_batch': 6.01030707359314, 'min_batch': 5.738818645477295, 'max_batch': 6.398480939865112}
step: 24520 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 3.2557697, 'max_total_reward': 13.340001, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4066434264183045, 'actor_loss': -5.109988069534301, 'hyper_actor_loss': 0.016103364154696466, 'behavior_loss': 0.26965632736682893, 'mean_batch': 5.880941724777221, 'min_batch': 5.634297943115234, 'max_batch': 6.1976264953613285}
step: 24530 @ episode report: {'average_total_reward': 8.810999, 'reward_variance': 2.8182282, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3263939023017883, 'actor_loss': -5.1711037158966064, 'hyper_actor_loss': 0.016194200422614814, 'behavior_loss': 0.27740619629621505, 'mean_batch': 6.0730123043060305, 'min_batch': 5.800535345077515, 'max_batch': 6.592436933517456}
step: 24540 @ episode report: {'average_total_reward': 8.644, 'reward_variance': 6.350544, 'max_total_reward': 13.34, 'min_total_reward': 4.6800003, 'average_n_step': 9.7, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8983856797218324, 'actor_loss': -5.201939535140991, 'hyper_actor_loss': 0.016804919764399528, 'behavior_loss': 0.26637343019247056, 'mean_batch': 6.17978458404541, 'min_batch': 5.878469753265381, 'max_batch': 6.611058950424194}
step: 24550 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 2.631189, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.095142650604248, 'actor_loss': -5.204941654205323, 'hyper_actor_loss': 0.016881407238543034, 'behavior_loss': 0.2699341535568237, 'mean_batch': 6.198913192749023, 'min_batch': 5.877869939804077, 'max_batch': 6.637311840057373}
step: 24560 @ episode report: {'average_total_reward': 8.811, 'reward_variance': 5.6414704, 'max_total_reward': 11.2300005, 'min_total_reward': 3.24, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7644359707832336, 'actor_loss': -5.178046941757202, 'hyper_actor_loss': 0.016984162293374537, 'behavior_loss': 0.27474247962236403, 'mean_batch': 6.117153787612915, 'min_batch': 5.798471355438233, 'max_batch': 6.57680721282959}
step: 24570 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 7.585917, 'max_total_reward': 13.45, 'min_total_reward': 3.57, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.6600859403610229, 'actor_loss': -5.179667186737061, 'hyper_actor_loss': 0.01688336431980133, 'behavior_loss': 0.2745078757405281, 'mean_batch': 6.099685907363892, 'min_batch': 5.824985361099243, 'max_batch': 6.439341592788696}
step: 24580 @ episode report: {'average_total_reward': 6.7350006, 'reward_variance': 7.8832054, 'max_total_reward': 10.12, 'min_total_reward': 2.3500001, 'average_n_step': 8.0, 'max_n_step': 11.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.701243555545807, 'actor_loss': -5.17754430770874, 'hyper_actor_loss': 0.016932546347379684, 'behavior_loss': 0.2755091592669487, 'mean_batch': 6.068244218826294, 'min_batch': 5.842570972442627, 'max_batch': 6.373379421234131}
step: 24590 @ episode report: {'average_total_reward': 11.042002, 'reward_variance': 9.520837, 'max_total_reward': 15.56, 'min_total_reward': 3.5700002, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0101242661476135, 'actor_loss': -5.1488807678222654, 'hyper_actor_loss': 0.016997596994042397, 'behavior_loss': 0.2679430514574051, 'mean_batch': 5.981237411499023, 'min_batch': 5.759665441513062, 'max_batch': 6.262987995147705}
step: 24600 @ episode report: {'average_total_reward': 10.231001, 'reward_variance': 6.86897, 'max_total_reward': 15.67, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.055990827083588, 'actor_loss': -5.195350265502929, 'hyper_actor_loss': 0.016697717271745204, 'behavior_loss': 0.2774960890412331, 'mean_batch': 6.131001663208008, 'min_batch': 5.8860626220703125, 'max_batch': 6.324672222137451}
step: 24610 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 6.9924636, 'max_total_reward': 13.45, 'min_total_reward': 5.6800003, 'average_n_step': 10.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6046337127685546, 'actor_loss': -5.1834330558776855, 'hyper_actor_loss': 0.01638049427419901, 'behavior_loss': 0.27825015485286714, 'mean_batch': 6.085877752304077, 'min_batch': 5.859488773345947, 'max_batch': 6.290367889404297}
step: 24620 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 4.7927766, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3507081031799317, 'actor_loss': -5.14579291343689, 'hyper_actor_loss': 0.016356431134045123, 'behavior_loss': 0.27923007756471635, 'mean_batch': 5.966087341308594, 'min_batch': 5.756243181228638, 'max_batch': 6.195363140106201}
step: 24630 @ episode report: {'average_total_reward': 10.320001, 'reward_variance': 1.2433605, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5843361496925352, 'actor_loss': -5.157300662994385, 'hyper_actor_loss': 0.016487874649465085, 'behavior_loss': 0.2812209740281105, 'mean_batch': 6.018156242370606, 'min_batch': 5.772645282745361, 'max_batch': 6.356150531768799}
step: 24640 @ episode report: {'average_total_reward': 9.997999, 'reward_variance': 6.8896165, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.456444638967514, 'actor_loss': -5.18372597694397, 'hyper_actor_loss': 0.01622294243425131, 'behavior_loss': 0.27612552493810655, 'mean_batch': 6.098052501678467, 'min_batch': 5.849422454833984, 'max_batch': 6.461233234405517}
step: 24650 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 6.1585298, 'max_total_reward': 14.450001, 'min_total_reward': 5.7900004, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.173597276210785, 'actor_loss': -5.1962450504302975, 'hyper_actor_loss': 0.016246356070041656, 'behavior_loss': 0.2750345662236214, 'mean_batch': 6.157103967666626, 'min_batch': 5.866353845596313, 'max_batch': 6.499050855636597}
step: 24660 @ episode report: {'average_total_reward': 8.655001, 'reward_variance': 6.271905, 'max_total_reward': 12.23, 'min_total_reward': 4.6800003, 'average_n_step': 9.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7392861247062683, 'actor_loss': -5.208979654312134, 'hyper_actor_loss': 0.015967884473502635, 'behavior_loss': 0.27383525520563123, 'mean_batch': 6.202129316329956, 'min_batch': 5.898678350448608, 'max_batch': 6.600223636627197}
step: 24670 @ episode report: {'average_total_reward': 10.432, 'reward_variance': 3.747057, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5821592688560484, 'actor_loss': -5.184468221664429, 'hyper_actor_loss': 0.015847296640276908, 'behavior_loss': 0.28044775128364563, 'mean_batch': 6.113734722137451, 'min_batch': 5.838814115524292, 'max_batch': 6.4637425422668455}
step: 24680 @ episode report: {'average_total_reward': 10.4210005, 'reward_variance': 1.2593294, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.457953763008118, 'actor_loss': -5.165021228790283, 'hyper_actor_loss': 0.01571793369948864, 'behavior_loss': 0.2494231343269348, 'mean_batch': 6.046194362640381, 'min_batch': 5.790362215042114, 'max_batch': 6.409997749328613}
step: 24690 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 4.836276, 'max_total_reward': 15.56, 'min_total_reward': 6.6800003, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.995873546600342, 'actor_loss': -5.18603744506836, 'hyper_actor_loss': 0.015303243603557348, 'behavior_loss': 0.2704570725560188, 'mean_batch': 6.124884843826294, 'min_batch': 5.837163591384888, 'max_batch': 6.497898149490356}
step: 24700 @ episode report: {'average_total_reward': 10.653, 'reward_variance': 8.200041, 'max_total_reward': 16.67, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.7890868663787842, 'actor_loss': -5.204850816726685, 'hyper_actor_loss': 0.015302530117332935, 'behavior_loss': 0.26703078001737596, 'mean_batch': 6.186526966094971, 'min_batch': 5.889691305160523, 'max_batch': 6.599142265319824}
step: 24710 @ episode report: {'average_total_reward': 10.874999, 'reward_variance': 4.337485, 'max_total_reward': 14.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4329011261463167, 'actor_loss': -5.266127300262451, 'hyper_actor_loss': 0.015504411794245243, 'behavior_loss': 0.2742659136652946, 'mean_batch': 6.412827444076538, 'min_batch': 6.040224838256836, 'max_batch': 6.85477991104126}
step: 24720 @ episode report: {'average_total_reward': 9.766001, 'reward_variance': 9.195205, 'max_total_reward': 12.34, 'min_total_reward': 1.58, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3410282492637635, 'actor_loss': -5.203833055496216, 'hyper_actor_loss': 0.01578999953344464, 'behavior_loss': 0.27410883605480196, 'mean_batch': 6.148831701278686, 'min_batch': 5.919565296173095, 'max_batch': 6.484880542755127}
step: 24730 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 3.5080485, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1385524928569795, 'actor_loss': -5.185365533828735, 'hyper_actor_loss': 0.01610200759023428, 'behavior_loss': 0.2591103598475456, 'mean_batch': 6.074107456207275, 'min_batch': 5.882361316680909, 'max_batch': 6.335537147521973}
step: 24740 @ episode report: {'average_total_reward': 10.653001, 'reward_variance': 1.7176406, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.584389019012451, 'actor_loss': -5.203454828262329, 'hyper_actor_loss': 0.01568455146625638, 'behavior_loss': 0.27550770044326783, 'mean_batch': 6.126262855529785, 'min_batch': 5.9384125709533695, 'max_batch': 6.3424272537231445}
step: 24750 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 5.1535497, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3952165722846983, 'actor_loss': -5.180218076705932, 'hyper_actor_loss': 0.01552947899326682, 'behavior_loss': 0.276101741194725, 'mean_batch': 6.054632186889648, 'min_batch': 5.8706504821777346, 'max_batch': 6.316882610321045}
step: 24760 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 5.539244, 'max_total_reward': 13.45, 'min_total_reward': 4.68, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.009797823429108, 'actor_loss': -5.203884696960449, 'hyper_actor_loss': 0.015341551788151265, 'behavior_loss': 0.26375037878751756, 'mean_batch': 6.13343768119812, 'min_batch': 5.934380435943604, 'max_batch': 6.447311067581177}
step: 24770 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 1.7274816, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.494045877456665, 'actor_loss': -5.217829704284668, 'hyper_actor_loss': 0.015224030613899231, 'behavior_loss': 0.2769010543823242, 'mean_batch': 6.1796403408050535, 'min_batch': 5.972484683990478, 'max_batch': 6.492902851104736}
step: 24780 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 5.6008453, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.530940532684326, 'actor_loss': -5.174467945098877, 'hyper_actor_loss': 0.014896969310939312, 'behavior_loss': 0.25687316358089446, 'mean_batch': 6.032668542861939, 'min_batch': 5.858317089080811, 'max_batch': 6.172808361053467}
step: 24790 @ episode report: {'average_total_reward': 9.887, 'reward_variance': 12.8852825, 'max_total_reward': 14.56, 'min_total_reward': 1.13, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.641254338622093, 'actor_loss': -5.156558227539063, 'hyper_actor_loss': 0.014786245580762625, 'behavior_loss': 0.27531006634235383, 'mean_batch': 5.962984895706176, 'min_batch': 5.821547174453736, 'max_batch': 6.051087856292725}
step: 24800 @ episode report: {'average_total_reward': 10.709001, 'reward_variance': 2.867429, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.691636300086975, 'actor_loss': -5.15548095703125, 'hyper_actor_loss': 0.014359925128519534, 'behavior_loss': 0.26166012436151503, 'mean_batch': 5.964112997055054, 'min_batch': 5.814229297637939, 'max_batch': 6.050168991088867}
step: 24810 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 10.31053, 'max_total_reward': 12.339999, 'min_total_reward': 0.90999997, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6287940084934234, 'actor_loss': -5.17085599899292, 'hyper_actor_loss': 0.014301176927983762, 'behavior_loss': 0.28108444064855576, 'mean_batch': 6.009965324401856, 'min_batch': 5.859244918823242, 'max_batch': 6.098102045059204}
step: 24820 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 1.7674496, 'max_total_reward': 12.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4117115080356597, 'actor_loss': -5.154753160476685, 'hyper_actor_loss': 0.014144793804734945, 'behavior_loss': 0.28101884573698044, 'mean_batch': 5.973690176010132, 'min_batch': 5.800878095626831, 'max_batch': 6.069045209884644}
step: 24830 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 3.5839648, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.342162585258484, 'actor_loss': -5.178620147705078, 'hyper_actor_loss': 0.013999419193714857, 'behavior_loss': 0.2509005174040794, 'mean_batch': 6.038817834854126, 'min_batch': 5.876865291595459, 'max_batch': 6.133520078659058}
step: 24840 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 1.4958245, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6844404578208922, 'actor_loss': -5.1578452587127686, 'hyper_actor_loss': 0.013738602492958307, 'behavior_loss': 0.2848493576049805, 'mean_batch': 5.984370422363281, 'min_batch': 5.80824990272522, 'max_batch': 6.082958745956421}
step: 24850 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 4.091067, 'max_total_reward': 14.450002, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7488394141197205, 'actor_loss': -5.113209676742554, 'hyper_actor_loss': 0.013498914241790772, 'behavior_loss': 0.2749266251921654, 'mean_batch': 5.844120693206787, 'min_batch': 5.6880138397216795, 'max_batch': 5.93736572265625}
step: 24860 @ episode report: {'average_total_reward': 11.031, 'reward_variance': 6.1635695, 'max_total_reward': 15.67, 'min_total_reward': 7.7900004, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.489768439531326, 'actor_loss': -5.154399108886719, 'hyper_actor_loss': 0.013507225550711155, 'behavior_loss': 0.2670812219381332, 'mean_batch': 5.98376784324646, 'min_batch': 5.789237689971924, 'max_batch': 6.081951904296875}
step: 24870 @ episode report: {'average_total_reward': 10.098, 'reward_variance': 2.6661358, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2199804067611693, 'actor_loss': -5.170846796035766, 'hyper_actor_loss': 0.013262773305177689, 'behavior_loss': 0.26433411836624143, 'mean_batch': 6.042799949645996, 'min_batch': 5.827434539794922, 'max_batch': 6.164269304275512}
step: 24880 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 1.9884812, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2921162247657776, 'actor_loss': -5.18083176612854, 'hyper_actor_loss': 0.012850880809128284, 'behavior_loss': 0.2652724593877792, 'mean_batch': 6.081421709060669, 'min_batch': 5.848656749725341, 'max_batch': 6.189810752868652}
step: 24890 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 4.4695807, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0882726907730103, 'actor_loss': -5.150436115264893, 'hyper_actor_loss': 0.012615873385220766, 'behavior_loss': 0.26828999221324923, 'mean_batch': 5.977753210067749, 'min_batch': 5.7718476295471195, 'max_batch': 6.083765172958374}
step: 24900 @ episode report: {'average_total_reward': 10.931, 'reward_variance': 3.766529, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.805917227268219, 'actor_loss': -5.159339952468872, 'hyper_actor_loss': 0.012706874962896108, 'behavior_loss': 0.29314457923173903, 'mean_batch': 5.999807691574096, 'min_batch': 5.8019843101501465, 'max_batch': 6.1050725936889645}
step: 24910 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 6.9271226, 'max_total_reward': 13.45, 'min_total_reward': 5.4599996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0906053125858306, 'actor_loss': -5.137185335159302, 'hyper_actor_loss': 0.013175403978675605, 'behavior_loss': 0.27171054780483245, 'mean_batch': 5.9281562805175785, 'min_batch': 5.743369817733765, 'max_batch': 6.028926420211792}
step: 24920 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 2.5785205, 'max_total_reward': 11.900001, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2539047718048097, 'actor_loss': -5.169734764099121, 'hyper_actor_loss': 0.013076188135892152, 'behavior_loss': 0.2772118791937828, 'mean_batch': 6.038542985916138, 'min_batch': 5.825220394134521, 'max_batch': 6.145874977111816}
step: 24930 @ episode report: {'average_total_reward': 9.565001, 'reward_variance': 4.2043257, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0639641523361205, 'actor_loss': -5.1912171840667725, 'hyper_actor_loss': 0.012844408582895993, 'behavior_loss': 0.2800172492861748, 'mean_batch': 6.10149564743042, 'min_batch': 5.890041255950928, 'max_batch': 6.218399333953857}
step: 24940 @ episode report: {'average_total_reward': 10.098001, 'reward_variance': 3.3321362, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.706673300266266, 'actor_loss': -5.1583044052124025, 'hyper_actor_loss': 0.012694718595594168, 'behavior_loss': 0.2688700959086418, 'mean_batch': 6.008222818374634, 'min_batch': 5.788115549087524, 'max_batch': 6.12443356513977}
step: 24950 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 2.8186407, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.366202640533447, 'actor_loss': -5.142738723754883, 'hyper_actor_loss': 0.012343806494027377, 'behavior_loss': 0.2709726870059967, 'mean_batch': 5.953194618225098, 'min_batch': 5.751131200790406, 'max_batch': 6.070487117767334}
step: 24960 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 1.4594243, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5625693917274477, 'actor_loss': -5.159217405319214, 'hyper_actor_loss': 0.012385922390967608, 'behavior_loss': 0.29195176213979723, 'mean_batch': 6.002552223205567, 'min_batch': 5.7986513614654545, 'max_batch': 6.115657234191895}
step: 24970 @ episode report: {'average_total_reward': 10.5199995, 'reward_variance': 3.1726198, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1802346289157866, 'actor_loss': -5.140745353698731, 'hyper_actor_loss': 0.012465120572596789, 'behavior_loss': 0.2621213346719742, 'mean_batch': 5.944471645355224, 'min_batch': 5.748160171508789, 'max_batch': 6.053493595123291}
step: 24980 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 2.7769814, 'max_total_reward': 13.34, 'min_total_reward': 6.68, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7748616695404054, 'actor_loss': -5.150843477249145, 'hyper_actor_loss': 0.01253180978819728, 'behavior_loss': 0.27301567047834396, 'mean_batch': 5.968809127807617, 'min_batch': 5.782730531692505, 'max_batch': 6.0805951118469235}
step: 24990 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 2.9790366, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2939656496047975, 'actor_loss': -5.14898190498352, 'hyper_actor_loss': 0.012364034261554479, 'behavior_loss': 0.2887115806341171, 'mean_batch': 5.9630004405975345, 'min_batch': 5.777709341049194, 'max_batch': 6.074510192871093}
step: 25000 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 3.2677085, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.40591539144516, 'actor_loss': -5.174081230163575, 'hyper_actor_loss': 0.012388892658054828, 'behavior_loss': 0.2851650550961494, 'mean_batch': 6.040384292602539, 'min_batch': 5.848459053039551, 'max_batch': 6.163347053527832}
step: 25010 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.8432488, 'max_total_reward': 13.23, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0157247126102447, 'actor_loss': -5.163652181625366, 'hyper_actor_loss': 0.012424270436167718, 'behavior_loss': 0.2618410989642143, 'mean_batch': 6.033366107940674, 'min_batch': 5.794734525680542, 'max_batch': 6.149790906906128}
step: 25020 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 2.416161, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.662009596824646, 'actor_loss': -5.166527509689331, 'hyper_actor_loss': 0.012419478874653578, 'behavior_loss': 0.2850178018212318, 'mean_batch': 6.0163679122924805, 'min_batch': 5.8277984142303465, 'max_batch': 6.143227672576904}
step: 25030 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 3.884065, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6068387389183045, 'actor_loss': -5.11791615486145, 'hyper_actor_loss': 0.012455944903194904, 'behavior_loss': 0.2756503537297249, 'mean_batch': 5.856975746154785, 'min_batch': 5.702658557891846, 'max_batch': 5.982908725738525}
step: 25040 @ episode report: {'average_total_reward': 11.020001, 'reward_variance': 1.7099806, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3638100028038025, 'actor_loss': -5.155904006958008, 'hyper_actor_loss': 0.012428800854831935, 'behavior_loss': 0.2654772013425827, 'mean_batch': 5.99781231880188, 'min_batch': 5.784644842147827, 'max_batch': 6.126285123825073}
step: 25050 @ episode report: {'average_total_reward': 8.866, 'reward_variance': 4.133985, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.655812847614288, 'actor_loss': -5.182857513427734, 'hyper_actor_loss': 0.012305866274982692, 'behavior_loss': 0.2607097774744034, 'mean_batch': 6.077810573577881, 'min_batch': 5.863890361785889, 'max_batch': 6.221976089477539}
step: 25060 @ episode report: {'average_total_reward': 9.388, 'reward_variance': 6.5956154, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3941476464271547, 'actor_loss': -5.154677104949951, 'hyper_actor_loss': 0.012307007890194654, 'behavior_loss': 0.28372451215982436, 'mean_batch': 5.9983312606811525, 'min_batch': 5.776394176483154, 'max_batch': 6.142586421966553}
step: 25070 @ episode report: {'average_total_reward': 9.977, 'reward_variance': 1.0931612, 'max_total_reward': 11.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.720417654514313, 'actor_loss': -5.15668683052063, 'hyper_actor_loss': 0.012371648754924535, 'behavior_loss': 0.28920145630836486, 'mean_batch': 6.011046600341797, 'min_batch': 5.775691366195678, 'max_batch': 6.146805191040039}
step: 25080 @ episode report: {'average_total_reward': 10.82, 'reward_variance': 2.2642999, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.316525799036026, 'actor_loss': -5.1540649890899655, 'hyper_actor_loss': 0.01256992993876338, 'behavior_loss': 0.26270572394132613, 'mean_batch': 6.0040747165679935, 'min_batch': 5.7673173427581785, 'max_batch': 6.160178279876709}
step: 25090 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 2.6120365, 'max_total_reward': 13.01, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6108495593070984, 'actor_loss': -5.1677751541137695, 'hyper_actor_loss': 0.012378188781440258, 'behavior_loss': 0.27580209374427794, 'mean_batch': 6.032749366760254, 'min_batch': 5.819160985946655, 'max_batch': 6.1850080490112305}
step: 25100 @ episode report: {'average_total_reward': 9.655001, 'reward_variance': 12.896785, 'max_total_reward': 14.45, 'min_total_reward': 0.8, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4727630019187927, 'actor_loss': -5.133692359924316, 'hyper_actor_loss': 0.012020924594253302, 'behavior_loss': 0.2598700925707817, 'mean_batch': 5.924136686325073, 'min_batch': 5.7273375511169435, 'max_batch': 6.092107343673706}
step: 25110 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 4.442537, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.167189133167267, 'actor_loss': -5.168585348129272, 'hyper_actor_loss': 0.011887245438992977, 'behavior_loss': 0.27649548649787903, 'mean_batch': 6.059258651733399, 'min_batch': 5.798843479156494, 'max_batch': 6.255926275253296}
step: 25120 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.5795236, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.556224226951599, 'actor_loss': -5.191277980804443, 'hyper_actor_loss': 0.011913300026208162, 'behavior_loss': 0.264904148876667, 'mean_batch': 6.1196869850158695, 'min_batch': 5.8729856491088865, 'max_batch': 6.367700910568237}
step: 25130 @ episode report: {'average_total_reward': 10.653002, 'reward_variance': 2.4789011, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.342591714859009, 'actor_loss': -5.155667781829834, 'hyper_actor_loss': 0.012009596545249223, 'behavior_loss': 0.2622964680194855, 'mean_batch': 6.011064672470093, 'min_batch': 5.77018780708313, 'max_batch': 6.2674366474151615}
step: 25140 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 8.436961, 'max_total_reward': 12.340001, 'min_total_reward': 2.13, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0733307123184206, 'actor_loss': -5.19135103225708, 'hyper_actor_loss': 0.011997317336499691, 'behavior_loss': 0.2711756840348244, 'mean_batch': 6.121265840530396, 'min_batch': 5.872148609161377, 'max_batch': 6.397033071517944}
step: 25150 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 1.1832559, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6165393233299254, 'actor_loss': -5.16819920539856, 'hyper_actor_loss': 0.012096906919032336, 'behavior_loss': 0.27722614258527756, 'mean_batch': 6.050377082824707, 'min_batch': 5.805188941955566, 'max_batch': 6.304306507110596}
step: 25160 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.9903245, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.541863626241684, 'actor_loss': -5.175069856643677, 'hyper_actor_loss': 0.012159164529293776, 'behavior_loss': 0.27195010930299757, 'mean_batch': 6.068183374404907, 'min_batch': 5.827870893478393, 'max_batch': 6.358532381057739}
step: 25170 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 4.0628567, 'max_total_reward': 14.120001, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.840400147438049, 'actor_loss': -5.192869186401367, 'hyper_actor_loss': 0.012309600412845612, 'behavior_loss': 0.2904427915811539, 'mean_batch': 6.123732185363769, 'min_batch': 5.8783793449401855, 'max_batch': 6.452285432815552}
step: 25180 @ episode report: {'average_total_reward': 8.977, 'reward_variance': 3.908321, 'max_total_reward': 12.01, 'min_total_reward': 5.6800003, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9326050519943236, 'actor_loss': -5.1514520168304445, 'hyper_actor_loss': 0.012681282125413418, 'behavior_loss': 0.2637771889567375, 'mean_batch': 6.010483884811402, 'min_batch': 5.7462170124053955, 'max_batch': 6.3215244770050045}
step: 25190 @ episode report: {'average_total_reward': 9.554001, 'reward_variance': 3.4051044, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.757984125614166, 'actor_loss': -5.187073373794556, 'hyper_actor_loss': 0.01293382616713643, 'behavior_loss': 0.26139461547136306, 'mean_batch': 6.13239598274231, 'min_batch': 5.836982727050781, 'max_batch': 6.475529623031616}
step: 25200 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 4.030961, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1567430973052977, 'actor_loss': -5.174065780639649, 'hyper_actor_loss': 0.012795554753392935, 'behavior_loss': 0.25464524179697035, 'mean_batch': 6.087312841415406, 'min_batch': 5.80509581565857, 'max_batch': 6.3884134769439695}
step: 25210 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 5.577202, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3696898221969604, 'actor_loss': -5.137604379653931, 'hyper_actor_loss': 0.012655637599527836, 'behavior_loss': 0.25628590434789655, 'mean_batch': 5.966099071502685, 'min_batch': 5.709709405899048, 'max_batch': 6.220122671127319}
step: 25220 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 1.7425693, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.228525286912918, 'actor_loss': -5.209074783325195, 'hyper_actor_loss': 0.012398591358214616, 'behavior_loss': 0.2833414524793625, 'mean_batch': 6.184318780899048, 'min_batch': 5.916104412078857, 'max_batch': 6.463201904296875}
step: 25230 @ episode report: {'average_total_reward': 9.344, 'reward_variance': 4.896726, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3074453473091125, 'actor_loss': -5.242274618148803, 'hyper_actor_loss': 0.012648919876664878, 'behavior_loss': 0.267579385638237, 'mean_batch': 6.317028760910034, 'min_batch': 5.987396907806397, 'max_batch': 6.72535457611084}
step: 25240 @ episode report: {'average_total_reward': 8.877001, 'reward_variance': 6.578021, 'max_total_reward': 11.2300005, 'min_total_reward': 3.5700002, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.805289900302887, 'actor_loss': -5.189924240112305, 'hyper_actor_loss': 0.012738239858299494, 'behavior_loss': 0.2617778554558754, 'mean_batch': 6.132059621810913, 'min_batch': 5.853582859039307, 'max_batch': 6.518789768218994}
step: 25250 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 1.806069, 'max_total_reward': 11.2300005, 'min_total_reward': 6.680001, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1924588203430178, 'actor_loss': -5.164325189590454, 'hyper_actor_loss': 0.012682025320827961, 'behavior_loss': 0.2709654524922371, 'mean_batch': 6.018300771713257, 'min_batch': 5.813026237487793, 'max_batch': 6.3416869163513185}
step: 25260 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.6900811, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.512515437602997, 'actor_loss': -5.198011827468872, 'hyper_actor_loss': 0.012734292540699244, 'behavior_loss': 0.27574586123228073, 'mean_batch': 6.108717584609986, 'min_batch': 5.923204040527343, 'max_batch': 6.43330340385437}
step: 25270 @ episode report: {'average_total_reward': 10.009001, 'reward_variance': 1.5894091, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.714587676525116, 'actor_loss': -5.160093688964844, 'hyper_actor_loss': 0.012895382381975651, 'behavior_loss': 0.2587867692112923, 'mean_batch': 5.984108400344849, 'min_batch': 5.821733856201172, 'max_batch': 6.280419635772705}
step: 25280 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 3.6626573, 'max_total_reward': 13.340001, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.209195864200592, 'actor_loss': -5.16970911026001, 'hyper_actor_loss': 0.012767378240823746, 'behavior_loss': 0.26804032027721403, 'mean_batch': 6.001995944976807, 'min_batch': 5.860487699508667, 'max_batch': 6.190463638305664}
step: 25290 @ episode report: {'average_total_reward': 10.431002, 'reward_variance': 2.3734295, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.9967491388320924, 'actor_loss': -5.202515029907227, 'hyper_actor_loss': 0.012746130116283894, 'behavior_loss': 0.27474561184644697, 'mean_batch': 6.103865242004394, 'min_batch': 5.954624032974243, 'max_batch': 6.329756736755371}
step: 25300 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 1.8162893, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.203647714853287, 'actor_loss': -5.19896183013916, 'hyper_actor_loss': 0.01268736319616437, 'behavior_loss': 0.28445911705493926, 'mean_batch': 6.092374658584594, 'min_batch': 5.944757175445557, 'max_batch': 6.291562223434449}
step: 25310 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 2.5413415, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.556288421154022, 'actor_loss': -5.141710948944092, 'hyper_actor_loss': 0.01277817515656352, 'behavior_loss': 0.28145229518413545, 'mean_batch': 5.90776743888855, 'min_batch': 5.7897392272949215, 'max_batch': 6.084134101867676}
step: 25320 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 3.5390408, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.852279615402222, 'actor_loss': -5.108879613876343, 'hyper_actor_loss': 0.01282840659841895, 'behavior_loss': 0.2795800745487213, 'mean_batch': 5.819461011886597, 'min_batch': 5.687334108352661, 'max_batch': 5.980518579483032}
step: 25330 @ episode report: {'average_total_reward': 10.120001, 'reward_variance': 3.2813606, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.921838474273682, 'actor_loss': -5.135321617126465, 'hyper_actor_loss': 0.012742486968636512, 'behavior_loss': 0.2750088945031166, 'mean_batch': 5.8931413173675535, 'min_batch': 5.76675271987915, 'max_batch': 6.01839656829834}
step: 25340 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 5.6059046, 'max_total_reward': 12.119999, 'min_total_reward': 4.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.712133193016052, 'actor_loss': -5.124847888946533, 'hyper_actor_loss': 0.01280131945386529, 'behavior_loss': 0.2614609718322754, 'mean_batch': 5.878004026412964, 'min_batch': 5.721481800079346, 'max_batch': 6.043239974975586}
step: 25350 @ episode report: {'average_total_reward': 9.676001, 'reward_variance': 7.897784, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.084572768211365, 'actor_loss': -5.137665557861328, 'hyper_actor_loss': 0.012801862880587577, 'behavior_loss': 0.2903025969862938, 'mean_batch': 5.9145606517791744, 'min_batch': 5.759945440292358, 'max_batch': 6.108876276016235}
step: 25360 @ episode report: {'average_total_reward': 8.877001, 'reward_variance': 0.6252013, 'max_total_reward': 10.120001, 'min_total_reward': 7.79, 'average_n_step': 9.9, 'max_n_step': 11.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.368896359205246, 'actor_loss': -5.192982387542725, 'hyper_actor_loss': 0.012888317182660102, 'behavior_loss': 0.2657595410943031, 'mean_batch': 6.089648818969726, 'min_batch': 5.9119391441345215, 'max_batch': 6.308870267868042}
step: 25370 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 3.1660056, 'max_total_reward': 14.450001, 'min_total_reward': 7.5699997, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.762956953048706, 'actor_loss': -5.13847017288208, 'hyper_actor_loss': 0.012844225950539112, 'behavior_loss': 0.2673018917441368, 'mean_batch': 5.932491207122803, 'min_batch': 5.747255754470825, 'max_batch': 6.12252459526062}
step: 25380 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 2.1512961, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2564549684524535, 'actor_loss': -5.1140752792358395, 'hyper_actor_loss': 0.012813625484704971, 'behavior_loss': 0.2733093187212944, 'mean_batch': 5.851076555252075, 'min_batch': 5.686114549636841, 'max_batch': 6.084818315505982}
step: 25390 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 4.2073417, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4943238854408265, 'actor_loss': -5.119580364227295, 'hyper_actor_loss': 0.012753532454371452, 'behavior_loss': 0.28029453158378603, 'mean_batch': 5.8901489734649655, 'min_batch': 5.680107450485229, 'max_batch': 6.188525152206421}
step: 25400 @ episode report: {'average_total_reward': 8.4, 'reward_variance': 2.7454598, 'max_total_reward': 10.12, 'min_total_reward': 4.57, 'average_n_step': 9.5, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7367926836013794, 'actor_loss': -5.164383172988892, 'hyper_actor_loss': 0.012945857364684343, 'behavior_loss': 0.2848473325371742, 'mean_batch': 6.025766277313233, 'min_batch': 5.8062464714050295, 'max_batch': 6.351172399520874}
step: 25410 @ episode report: {'average_total_reward': 10.465001, 'reward_variance': 1.8069046, 'max_total_reward': 12.2300005, 'min_total_reward': 8.570001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.573205089569092, 'actor_loss': -5.1562567234039305, 'hyper_actor_loss': 0.013101513776928187, 'behavior_loss': 0.2721349895000458, 'mean_batch': 6.022595071792603, 'min_batch': 5.762221622467041, 'max_batch': 6.447658491134644}
step: 25420 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.9526844, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3468730568885805, 'actor_loss': -5.151414442062378, 'hyper_actor_loss': 0.013328935671597718, 'behavior_loss': 0.28095383048057554, 'mean_batch': 6.008837032318115, 'min_batch': 5.747597932815552, 'max_batch': 6.370163822174073}
step: 25430 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 6.46176, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.27728328704834, 'actor_loss': -5.201225709915161, 'hyper_actor_loss': 0.013440989423543215, 'behavior_loss': 0.2671107530593872, 'mean_batch': 6.16947603225708, 'min_batch': 5.88427357673645, 'max_batch': 6.580524492263794}
step: 25440 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 5.6178455, 'max_total_reward': 13.34, 'min_total_reward': 4.46, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2061861157417297, 'actor_loss': -5.177604532241821, 'hyper_actor_loss': 0.013554759044200181, 'behavior_loss': 0.27421188801527024, 'mean_batch': 6.104539489746093, 'min_batch': 5.8082973003387455, 'max_batch': 6.471802806854248}
step: 25450 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 1.6885192, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4536041736602785, 'actor_loss': -5.1347798824310305, 'hyper_actor_loss': 0.013631271943449975, 'behavior_loss': 0.26971239745616915, 'mean_batch': 5.951450634002685, 'min_batch': 5.707363271713257, 'max_batch': 6.218892765045166}
step: 25460 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 2.6986203, 'max_total_reward': 14.45, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1847147583961486, 'actor_loss': -5.199774169921875, 'hyper_actor_loss': 0.013608646765351295, 'behavior_loss': 0.2519163966178894, 'mean_batch': 6.134767818450928, 'min_batch': 5.908969068527222, 'max_batch': 6.413690090179443}
step: 25470 @ episode report: {'average_total_reward': 10.598, 'reward_variance': 5.202117, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5097394585609436, 'actor_loss': -5.2032705783844, 'hyper_actor_loss': 0.013426669221371413, 'behavior_loss': 0.27294598817825316, 'mean_batch': 6.16611909866333, 'min_batch': 5.899247407913208, 'max_batch': 6.420987987518311}
step: 25480 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 1.9893891, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7899995, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7433409452438355, 'actor_loss': -5.168556451797485, 'hyper_actor_loss': 0.013561437837779522, 'behavior_loss': 0.2790149450302124, 'mean_batch': 6.038652133941651, 'min_batch': 5.818254184722901, 'max_batch': 6.306349992752075}
step: 25490 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 2.661776, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6800938129425047, 'actor_loss': -5.1714451789855955, 'hyper_actor_loss': 0.013687565363943577, 'behavior_loss': 0.26852797865867617, 'mean_batch': 6.0519561767578125, 'min_batch': 5.822301292419434, 'max_batch': 6.361499786376953}
step: 25500 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 6.165945, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4371261477470396, 'actor_loss': -5.20374174118042, 'hyper_actor_loss': 0.013895135745406151, 'behavior_loss': 0.2746395394206047, 'mean_batch': 6.1545978546142575, 'min_batch': 5.912943363189697, 'max_batch': 6.464425325393677}
step: 25510 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 6.2704086, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5752943754196167, 'actor_loss': -5.190339136123657, 'hyper_actor_loss': 0.013878860604017973, 'behavior_loss': 0.26408980786800385, 'mean_batch': 6.124439287185669, 'min_batch': 5.863229370117187, 'max_batch': 6.450976610183716}
step: 25520 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 2.028136, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.615726411342621, 'actor_loss': -5.211126756668091, 'hyper_actor_loss': 0.014024809561669826, 'behavior_loss': 0.2793794125318527, 'mean_batch': 6.198878908157349, 'min_batch': 5.914349937438965, 'max_batch': 6.5591777801513675}
step: 25530 @ episode report: {'average_total_reward': 9.687, 'reward_variance': 3.9051812, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.545985746383667, 'actor_loss': -5.198291349411011, 'hyper_actor_loss': 0.01405841913074255, 'behavior_loss': 0.2826504737138748, 'mean_batch': 6.1640270233154295, 'min_batch': 5.8718376636505125, 'max_batch': 6.553564739227295}
step: 25540 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.6220045, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0141320705413817, 'actor_loss': -5.19327826499939, 'hyper_actor_loss': 0.014073629677295686, 'behavior_loss': 0.2580052688717842, 'mean_batch': 6.133053588867187, 'min_batch': 5.872171831130982, 'max_batch': 6.447832489013672}
step: 25550 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 4.9309816, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8875768184661865, 'actor_loss': -5.209870958328247, 'hyper_actor_loss': 0.01383662996813655, 'behavior_loss': 0.2685375675559044, 'mean_batch': 6.17722978591919, 'min_batch': 5.927576494216919, 'max_batch': 6.390712881088257}
step: 25560 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 6.0213246, 'max_total_reward': 13.45, 'min_total_reward': 4.5699997, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6037636399269104, 'actor_loss': -5.19086537361145, 'hyper_actor_loss': 0.013438054453581571, 'behavior_loss': 0.27178100794553756, 'mean_batch': 6.106305742263794, 'min_batch': 5.883538722991943, 'max_batch': 6.298966693878174}
step: 25570 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 1.3477799, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5639671325683593, 'actor_loss': -5.170750617980957, 'hyper_actor_loss': 0.013443881925195456, 'behavior_loss': 0.2601015716791153, 'mean_batch': 6.059122133255005, 'min_batch': 5.811189794540406, 'max_batch': 6.243014764785767}
step: 25580 @ episode report: {'average_total_reward': 8.544001, 'reward_variance': 3.0983043, 'max_total_reward': 12.2300005, 'min_total_reward': 6.57, 'average_n_step': 9.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.460330009460449, 'actor_loss': -5.198454999923706, 'hyper_actor_loss': 0.013431138545274734, 'behavior_loss': 0.26969394385814666, 'mean_batch': 6.139430713653565, 'min_batch': 5.896514415740967, 'max_batch': 6.3849310874938965}
step: 25590 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 3.3477216, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7758002877235413, 'actor_loss': -5.217851400375366, 'hyper_actor_loss': 0.013601535651832818, 'behavior_loss': 0.27980717867612837, 'mean_batch': 6.193855142593383, 'min_batch': 5.958989524841309, 'max_batch': 6.417268323898315}
step: 25600 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 2.1500778, 'max_total_reward': 13.340001, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.355667841434479, 'actor_loss': -5.206225728988647, 'hyper_actor_loss': 0.013688342738896608, 'behavior_loss': 0.2753838986158371, 'mean_batch': 6.172982549667358, 'min_batch': 5.910065984725952, 'max_batch': 6.461876916885376}
step: 25610 @ episode report: {'average_total_reward': 11.408, 'reward_variance': 4.518096, 'max_total_reward': 15.45, 'min_total_reward': 6.9, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3562097191810607, 'actor_loss': -5.230586385726928, 'hyper_actor_loss': 0.013816749211400747, 'behavior_loss': 0.2581350728869438, 'mean_batch': 6.230098724365234, 'min_batch': 6.000187826156616, 'max_batch': 6.412151336669922}
step: 25620 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 10.857438, 'max_total_reward': 14.559999, 'min_total_reward': 4.6800003, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.555000960826874, 'actor_loss': -5.211039638519287, 'hyper_actor_loss': 0.013478840887546539, 'behavior_loss': 0.26460181921720505, 'mean_batch': 6.171124982833862, 'min_batch': 5.940402603149414, 'max_batch': 6.374296760559082}
step: 25630 @ episode report: {'average_total_reward': 10.330999, 'reward_variance': 3.0404694, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2783017635345457, 'actor_loss': -5.212917280197144, 'hyper_actor_loss': 0.013446350861340762, 'behavior_loss': 0.2792664498090744, 'mean_batch': 6.1550452709198, 'min_batch': 5.966969347000122, 'max_batch': 6.340839910507202}
step: 25640 @ episode report: {'average_total_reward': 10.709, 'reward_variance': 7.03699, 'max_total_reward': 16.67, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6442283570766447, 'actor_loss': -5.209228372573852, 'hyper_actor_loss': 0.01322182361036539, 'behavior_loss': 0.2671411082148552, 'mean_batch': 6.169942951202392, 'min_batch': 5.93072657585144, 'max_batch': 6.327881097793579}
step: 25650 @ episode report: {'average_total_reward': 9.655001, 'reward_variance': 1.3463261, 'max_total_reward': 12.230001, 'min_total_reward': 8.57, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0688449859619142, 'actor_loss': -5.194232320785522, 'hyper_actor_loss': 0.01339882891625166, 'behavior_loss': 0.2804268360137939, 'mean_batch': 6.124137258529663, 'min_batch': 5.8861888408660885, 'max_batch': 6.291562509536743}
step: 25660 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 2.6790404, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1247150182723997, 'actor_loss': -5.202510786056519, 'hyper_actor_loss': 0.013550028391182422, 'behavior_loss': 0.2729360044002533, 'mean_batch': 6.1394952774047855, 'min_batch': 5.920925045013428, 'max_batch': 6.315200853347778}
step: 25670 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 3.554137, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9299622178077698, 'actor_loss': -5.242642068862915, 'hyper_actor_loss': 0.013690989464521408, 'behavior_loss': 0.27416708022356034, 'mean_batch': 6.276271200180053, 'min_batch': 6.028965187072754, 'max_batch': 6.497625637054443}
step: 25680 @ episode report: {'average_total_reward': 10.542, 'reward_variance': 2.0665364, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5605526983737947, 'actor_loss': -5.214101839065552, 'hyper_actor_loss': 0.013610711973160505, 'behavior_loss': 0.2567296579480171, 'mean_batch': 6.1854012966156, 'min_batch': 5.944768476486206, 'max_batch': 6.440572261810303}
step: 25690 @ episode report: {'average_total_reward': 10.209002, 'reward_variance': 4.877589, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.576856219768524, 'actor_loss': -5.231720495223999, 'hyper_actor_loss': 0.013275927864015102, 'behavior_loss': 0.2808439314365387, 'mean_batch': 6.23662748336792, 'min_batch': 6.000584506988526, 'max_batch': 6.48372106552124}
step: 25700 @ episode report: {'average_total_reward': 10.687, 'reward_variance': 3.2000206, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4067803382873536, 'actor_loss': -5.2064714431762695, 'hyper_actor_loss': 0.013474710192531348, 'behavior_loss': 0.2777403950691223, 'mean_batch': 6.172968482971191, 'min_batch': 5.911385631561279, 'max_batch': 6.430854415893554}
step: 25710 @ episode report: {'average_total_reward': 8.589, 'reward_variance': 1.2973284, 'max_total_reward': 11.009999, 'min_total_reward': 6.9, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5130900502204896, 'actor_loss': -5.241498756408691, 'hyper_actor_loss': 0.013714091386646032, 'behavior_loss': 0.27843789756298065, 'mean_batch': 6.265946292877198, 'min_batch': 6.031280517578125, 'max_batch': 6.505458927154541}
step: 25720 @ episode report: {'average_total_reward': 10.886, 'reward_variance': 5.800484, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8086193799972534, 'actor_loss': -5.203463172912597, 'hyper_actor_loss': 0.013780974596738816, 'behavior_loss': 0.27137586027383803, 'mean_batch': 6.154852390289307, 'min_batch': 5.911100625991821, 'max_batch': 6.3938117027282715}
step: 25730 @ episode report: {'average_total_reward': 11.031001, 'reward_variance': 2.3207493, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3684463024139406, 'actor_loss': -5.211402893066406, 'hyper_actor_loss': 0.013527894113212823, 'behavior_loss': 0.2726044073700905, 'mean_batch': 6.192656803131103, 'min_batch': 5.921961116790771, 'max_batch': 6.447673034667969}
step: 25740 @ episode report: {'average_total_reward': 11.109, 'reward_variance': 5.3831706, 'max_total_reward': 14.450001, 'min_total_reward': 7.68, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.644959235191345, 'actor_loss': -5.207037878036499, 'hyper_actor_loss': 0.013509394507855177, 'behavior_loss': 0.2718525558710098, 'mean_batch': 6.160064744949341, 'min_batch': 5.927200794219971, 'max_batch': 6.376835870742798}
step: 25750 @ episode report: {'average_total_reward': 10.731, 'reward_variance': 2.523769, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4800487518310548, 'actor_loss': -5.1940842628479, 'hyper_actor_loss': 0.013333065249025822, 'behavior_loss': 0.26054736226797104, 'mean_batch': 6.116794204711914, 'min_batch': 5.892357540130615, 'max_batch': 6.254275703430176}
step: 25760 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 3.602129, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6396977305412292, 'actor_loss': -5.203988552093506, 'hyper_actor_loss': 0.013213634584099054, 'behavior_loss': 0.2801112920045853, 'mean_batch': 6.131200695037842, 'min_batch': 5.936889362335205, 'max_batch': 6.289663505554199}
step: 25770 @ episode report: {'average_total_reward': 8.833, 'reward_variance': 9.572681, 'max_total_reward': 12.34, 'min_total_reward': 2.24, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6551976203918457, 'actor_loss': -5.191191291809082, 'hyper_actor_loss': 0.013040845468640327, 'behavior_loss': 0.2760489761829376, 'mean_batch': 6.1051473140716555, 'min_batch': 5.886834239959716, 'max_batch': 6.269709348678589}
step: 25780 @ episode report: {'average_total_reward': 11.386, 'reward_variance': 2.5228038, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1328866720199584, 'actor_loss': -5.157265853881836, 'hyper_actor_loss': 0.013030989747494458, 'behavior_loss': 0.2788181215524673, 'mean_batch': 5.9892291069030765, 'min_batch': 5.800232791900635, 'max_batch': 6.103561067581177}
step: 25790 @ episode report: {'average_total_reward': 11.319, 'reward_variance': 2.5819097, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3766402125358583, 'actor_loss': -5.164264154434204, 'hyper_actor_loss': 0.013152383733540773, 'behavior_loss': 0.260928675532341, 'mean_batch': 6.011419105529785, 'min_batch': 5.819640302658081, 'max_batch': 6.156671810150146}
step: 25800 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 2.0041964, 'max_total_reward': 11.2300005, 'min_total_reward': 6.68, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.625054568052292, 'actor_loss': -5.208282947540283, 'hyper_actor_loss': 0.013040236756205558, 'behavior_loss': 0.26568165272474287, 'mean_batch': 6.14856538772583, 'min_batch': 5.945507192611695, 'max_batch': 6.363718938827515}
step: 25810 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.738536, 'max_total_reward': 12.23, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3535255074501036, 'actor_loss': -5.2070455074310305, 'hyper_actor_loss': 0.012687722221016884, 'behavior_loss': 0.2587829276919365, 'mean_batch': 6.147568273544311, 'min_batch': 5.939197778701782, 'max_batch': 6.324483203887939}
step: 25820 @ episode report: {'average_total_reward': 11.275001, 'reward_variance': 4.224745, 'max_total_reward': 15.45, 'min_total_reward': 6.6800003, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5438040018081667, 'actor_loss': -5.19540810585022, 'hyper_actor_loss': 0.012470307666808367, 'behavior_loss': 0.26257291734218596, 'mean_batch': 6.119892168045044, 'min_batch': 5.897095155715943, 'max_batch': 6.2791577816009525}
step: 25830 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 2.7497408, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7999771356582643, 'actor_loss': -5.172472763061523, 'hyper_actor_loss': 0.012398541439324617, 'behavior_loss': 0.26695228517055514, 'mean_batch': 6.047185182571411, 'min_batch': 5.832728147506714, 'max_batch': 6.1798694133758545}
step: 25840 @ episode report: {'average_total_reward': 11.0199995, 'reward_variance': 5.469659, 'max_total_reward': 14.45, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.183725380897522, 'actor_loss': -5.190205717086792, 'hyper_actor_loss': 0.012451645638793706, 'behavior_loss': 0.26135680377483367, 'mean_batch': 6.102048444747925, 'min_batch': 5.883990621566772, 'max_batch': 6.236484050750732}
step: 25850 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 1.466809, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.597615456581116, 'actor_loss': -5.221558427810669, 'hyper_actor_loss': 0.01238975515589118, 'behavior_loss': 0.26556438356637957, 'mean_batch': 6.208723449707032, 'min_batch': 5.966710472106934, 'max_batch': 6.382414484024048}
step: 25860 @ episode report: {'average_total_reward': 8.633, 'reward_variance': 2.527801, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.701352035999298, 'actor_loss': -5.1932713985443115, 'hyper_actor_loss': 0.012463808339089156, 'behavior_loss': 0.2631485566496849, 'mean_batch': 6.123900890350342, 'min_batch': 5.880795574188232, 'max_batch': 6.257557725906372}
step: 25870 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 2.4980838, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7453471064567565, 'actor_loss': -5.192571544647217, 'hyper_actor_loss': 0.012768239062279464, 'behavior_loss': 0.26232890635728834, 'mean_batch': 6.111010265350342, 'min_batch': 5.88919849395752, 'max_batch': 6.24674916267395}
step: 25880 @ episode report: {'average_total_reward': 10.465001, 'reward_variance': 1.1919647, 'max_total_reward': 12.12, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6610673546791075, 'actor_loss': -5.2071301460266115, 'hyper_actor_loss': 0.012938337959349155, 'behavior_loss': 0.2621215686202049, 'mean_batch': 6.160646867752075, 'min_batch': 5.927048301696777, 'max_batch': 6.293872833251953}
step: 25890 @ episode report: {'average_total_reward': 9.443001, 'reward_variance': 2.1826615, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.578772711753845, 'actor_loss': -5.235241985321045, 'hyper_actor_loss': 0.01274314457550645, 'behavior_loss': 0.26191688179969785, 'mean_batch': 6.2494182109832765, 'min_batch': 6.0095664978027346, 'max_batch': 6.3735082149505615}
step: 25900 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 3.6755497, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.749169874191284, 'actor_loss': -5.205970621109008, 'hyper_actor_loss': 0.012765047140419483, 'behavior_loss': 0.2869737982749939, 'mean_batch': 6.168170690536499, 'min_batch': 5.913687992095947, 'max_batch': 6.303295087814331}
step: 25910 @ episode report: {'average_total_reward': 9.898001, 'reward_variance': 3.0344965, 'max_total_reward': 12.34, 'min_total_reward': 5.7899995, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.80381236076355, 'actor_loss': -5.191667652130127, 'hyper_actor_loss': 0.013065544608980417, 'behavior_loss': 0.2735517591238022, 'mean_batch': 6.121132659912109, 'min_batch': 5.874079275131225, 'max_batch': 6.271465539932251}
step: 25920 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 3.1790357, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2009416103363035, 'actor_loss': -5.218738842010498, 'hyper_actor_loss': 0.013286598306149245, 'behavior_loss': 0.2720589369535446, 'mean_batch': 6.196799898147583, 'min_batch': 5.961338663101197, 'max_batch': 6.318856906890869}
step: 25930 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.6220093, 'max_total_reward': 12.12, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.319338345527649, 'actor_loss': -5.197286796569824, 'hyper_actor_loss': 0.013322925474494696, 'behavior_loss': 0.2711402505636215, 'mean_batch': 6.145314168930054, 'min_batch': 5.8838447570800785, 'max_batch': 6.289188289642334}
step: 25940 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 9.085962, 'max_total_reward': 13.450001, 'min_total_reward': 2.46, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.692005681991577, 'actor_loss': -5.219039344787598, 'hyper_actor_loss': 0.012967190425843, 'behavior_loss': 0.26578623950481417, 'mean_batch': 6.200928735733032, 'min_batch': 5.959426212310791, 'max_batch': 6.31515212059021}
step: 25950 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 3.1404893, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.813193690776825, 'actor_loss': -5.206114625930786, 'hyper_actor_loss': 0.012965788878500462, 'behavior_loss': 0.27925279140472414, 'mean_batch': 6.151734638214111, 'min_batch': 5.929800701141358, 'max_batch': 6.257093095779419}
step: 25960 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 11.081506, 'max_total_reward': 12.340001, 'min_total_reward': 1.02, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1349963545799255, 'actor_loss': -5.217201519012451, 'hyper_actor_loss': 0.01298646191135049, 'behavior_loss': 0.27066393941640854, 'mean_batch': 6.183305358886718, 'min_batch': 5.965525388717651, 'max_batch': 6.3035218715667725}
step: 25970 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 5.009204, 'max_total_reward': 14.45, 'min_total_reward': 5.68, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9440613389015198, 'actor_loss': -5.231399250030518, 'hyper_actor_loss': 0.013035014923661947, 'behavior_loss': 0.28535232692956924, 'mean_batch': 6.242490005493164, 'min_batch': 5.993130874633789, 'max_batch': 6.360837936401367}
step: 25980 @ episode report: {'average_total_reward': 10.531001, 'reward_variance': 4.3701696, 'max_total_reward': 15.56, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.684199404716492, 'actor_loss': -5.188227224349975, 'hyper_actor_loss': 0.013041647523641587, 'behavior_loss': 0.2753382995724678, 'mean_batch': 6.1005665302276615, 'min_batch': 5.873349237442016, 'max_batch': 6.224521923065185}
step: 25990 @ episode report: {'average_total_reward': 10.386999, 'reward_variance': 4.0456815, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.324977123737335, 'actor_loss': -5.208188676834107, 'hyper_actor_loss': 0.012920543272048234, 'behavior_loss': 0.26129199266433717, 'mean_batch': 6.170730876922607, 'min_batch': 5.923932218551636, 'max_batch': 6.287352228164673}
step: 26000 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 2.7023857, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.606537640094757, 'actor_loss': -5.230683994293213, 'hyper_actor_loss': 0.012854630034416914, 'behavior_loss': 0.27405655682086943, 'mean_batch': 6.233840370178223, 'min_batch': 5.997084283828736, 'max_batch': 6.357124900817871}
step: 26010 @ episode report: {'average_total_reward': 8.988001, 'reward_variance': 3.3537164, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.903820884227753, 'actor_loss': -5.195001888275146, 'hyper_actor_loss': 0.012718050461262464, 'behavior_loss': 0.29273262321949006, 'mean_batch': 6.12473692893982, 'min_batch': 5.890175867080688, 'max_batch': 6.249066734313965}
step: 26020 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 12.999461, 'max_total_reward': 14.56, 'min_total_reward': 2.02, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.718951165676117, 'actor_loss': -5.198293590545655, 'hyper_actor_loss': 0.012879427336156369, 'behavior_loss': 0.27108861654996874, 'mean_batch': 6.123512077331543, 'min_batch': 5.91091513633728, 'max_batch': 6.257750511169434}
step: 26030 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 4.0231614, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7514118194580077, 'actor_loss': -5.219649076461792, 'hyper_actor_loss': 0.01302962526679039, 'behavior_loss': 0.2675579354166985, 'mean_batch': 6.197113466262818, 'min_batch': 5.966391229629517, 'max_batch': 6.350499248504638}
step: 26040 @ episode report: {'average_total_reward': 9.876, 'reward_variance': 3.812345, 'max_total_reward': 13.340001, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9819886088371277, 'actor_loss': -5.21749324798584, 'hyper_actor_loss': 0.013050354178994894, 'behavior_loss': 0.3009636551141739, 'mean_batch': 6.191446161270141, 'min_batch': 5.958982944488525, 'max_batch': 6.348345136642456}
step: 26050 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 3.1017795, 'max_total_reward': 14.34, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5613866567611696, 'actor_loss': -5.234051275253296, 'hyper_actor_loss': 0.013391183223575354, 'behavior_loss': 0.2529134303331375, 'mean_batch': 6.24327507019043, 'min_batch': 6.008556461334228, 'max_batch': 6.421386480331421}
step: 26060 @ episode report: {'average_total_reward': 10.453, 'reward_variance': 4.8454614, 'max_total_reward': 13.45, 'min_total_reward': 5.7899995, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7281944513320924, 'actor_loss': -5.23700590133667, 'hyper_actor_loss': 0.01322325635701418, 'behavior_loss': 0.26531375050544737, 'mean_batch': 6.275937843322754, 'min_batch': 5.994966650009156, 'max_batch': 6.453268575668335}
step: 26070 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 1.350156, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1724855422973635, 'actor_loss': -5.250818920135498, 'hyper_actor_loss': 0.012898742966353894, 'behavior_loss': 0.25360744297504423, 'mean_batch': 6.299726104736328, 'min_batch': 6.055460643768311, 'max_batch': 6.488791465759277}
step: 26080 @ episode report: {'average_total_reward': 10.543001, 'reward_variance': 4.323102, 'max_total_reward': 14.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0969601392745973, 'actor_loss': -5.237108039855957, 'hyper_actor_loss': 0.01278709964826703, 'behavior_loss': 0.2866224363446236, 'mean_batch': 6.270577621459961, 'min_batch': 6.000792551040649, 'max_batch': 6.437604856491089}
step: 26090 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 2.9625962, 'max_total_reward': 14.450001, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2129059553146364, 'actor_loss': -5.203545045852661, 'hyper_actor_loss': 0.012905209977179765, 'behavior_loss': 0.25714619010686873, 'mean_batch': 6.170000123977661, 'min_batch': 5.897100305557251, 'max_batch': 6.37792558670044}
step: 26100 @ episode report: {'average_total_reward': 11.397001, 'reward_variance': 1.3858408, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.335643631219864, 'actor_loss': -5.227810716629028, 'hyper_actor_loss': 0.013226003851741552, 'behavior_loss': 0.2736126556992531, 'mean_batch': 6.241395139694214, 'min_batch': 5.973617076873779, 'max_batch': 6.415784788131714}
step: 26110 @ episode report: {'average_total_reward': 11.664, 'reward_variance': 2.1435235, 'max_total_reward': 14.339999, 'min_total_reward': 9.01, 'average_n_step': 12.5, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8710556268692016, 'actor_loss': -5.267147207260132, 'hyper_actor_loss': 0.013560273684561253, 'behavior_loss': 0.2873686656355858, 'mean_batch': 6.366185569763184, 'min_batch': 6.090876722335816, 'max_batch': 6.537000370025635}
step: 26120 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 1.9074285, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.202846419811249, 'actor_loss': -5.252779245376587, 'hyper_actor_loss': 0.013613666873425245, 'behavior_loss': 0.25109068751335145, 'mean_batch': 6.307123613357544, 'min_batch': 6.059935522079468, 'max_batch': 6.462174558639527}
step: 26130 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 1.9274819, 'max_total_reward': 12.34, 'min_total_reward': 7.899999, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4385084390640257, 'actor_loss': -5.248598051071167, 'hyper_actor_loss': 0.013446391932666302, 'behavior_loss': 0.2903256118297577, 'mean_batch': 6.292331981658935, 'min_batch': 6.049097633361816, 'max_batch': 6.43362283706665}
step: 26140 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 3.1878042, 'max_total_reward': 14.339999, 'min_total_reward': 7.7900004, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.157846522331238, 'actor_loss': -5.20016713142395, 'hyper_actor_loss': 0.013518324773758649, 'behavior_loss': 0.2838591828942299, 'mean_batch': 6.136955595016479, 'min_batch': 5.90888729095459, 'max_batch': 6.305208396911621}
step: 26150 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 5.612599, 'max_total_reward': 13.45, 'min_total_reward': 5.46, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4975948870182036, 'actor_loss': -5.216905832290649, 'hyper_actor_loss': 0.013820850849151611, 'behavior_loss': 0.26803062558174134, 'mean_batch': 6.171808338165283, 'min_batch': 5.974801874160766, 'max_batch': 6.288566780090332}
step: 26160 @ episode report: {'average_total_reward': 10.709001, 'reward_variance': 2.9209092, 'max_total_reward': 14.34, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.480947268009186, 'actor_loss': -5.2827051162719725, 'hyper_actor_loss': 0.013755123782902955, 'behavior_loss': 0.2825821086764336, 'mean_batch': 6.3925282001495365, 'min_batch': 6.160860586166382, 'max_batch': 6.51996955871582}
step: 26170 @ episode report: {'average_total_reward': 11.031, 'reward_variance': 3.32379, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3303412079811094, 'actor_loss': -5.269404411315918, 'hyper_actor_loss': 0.01349226264283061, 'behavior_loss': 0.26506965458393095, 'mean_batch': 6.341296195983887, 'min_batch': 6.128720712661743, 'max_batch': 6.480872344970703}
step: 26180 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 0.72645605, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9000006, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.49011709690094, 'actor_loss': -5.260452032089233, 'hyper_actor_loss': 0.01334060337394476, 'behavior_loss': 0.26140104681253434, 'mean_batch': 6.302680158615113, 'min_batch': 6.110727739334107, 'max_batch': 6.417044544219971}
step: 26190 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 2.2279046, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4226441025733947, 'actor_loss': -5.254960298538208, 'hyper_actor_loss': 0.01339877163991332, 'behavior_loss': 0.26513556241989134, 'mean_batch': 6.299512958526611, 'min_batch': 6.080422496795654, 'max_batch': 6.432345914840698}
step: 26200 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 3.664861, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4556981801986693, 'actor_loss': -5.2802643299102785, 'hyper_actor_loss': 0.013406336680054665, 'behavior_loss': 0.26222546994686124, 'mean_batch': 6.372803688049316, 'min_batch': 6.164524936676026, 'max_batch': 6.50448899269104}
step: 26210 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 4.3845415, 'max_total_reward': 12.01, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.779541790485382, 'actor_loss': -5.266543340682984, 'hyper_actor_loss': 0.013456777855753898, 'behavior_loss': 0.27395243793725965, 'mean_batch': 6.341911125183105, 'min_batch': 6.110242080688477, 'max_batch': 6.477593469619751}
step: 26220 @ episode report: {'average_total_reward': 10.542, 'reward_variance': 3.9402173, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.495782232284546, 'actor_loss': -5.251346254348755, 'hyper_actor_loss': 0.013574255537241698, 'behavior_loss': 0.27693738639354704, 'mean_batch': 6.291987609863281, 'min_batch': 6.065665245056152, 'max_batch': 6.435986089706421}
step: 26230 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 8.094636, 'max_total_reward': 12.34, 'min_total_reward': 2.3500001, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.603537750244141, 'actor_loss': -5.273380517959595, 'hyper_actor_loss': 0.013969070091843606, 'behavior_loss': 0.2756054237484932, 'mean_batch': 6.348293733596802, 'min_batch': 6.145828819274902, 'max_batch': 6.504580688476563}
step: 26240 @ episode report: {'average_total_reward': 10.920001, 'reward_variance': 2.4290395, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.053008830547333, 'actor_loss': -5.284826707839966, 'hyper_actor_loss': 0.014185064937919378, 'behavior_loss': 0.2582076132297516, 'mean_batch': 6.389973306655884, 'min_batch': 6.176235151290894, 'max_batch': 6.521596622467041}
step: 26250 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 1.4085205, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2482708930969237, 'actor_loss': -5.276129531860351, 'hyper_actor_loss': 0.013898103963583708, 'behavior_loss': 0.2819314241409302, 'mean_batch': 6.377061557769776, 'min_batch': 6.135703182220459, 'max_batch': 6.515776205062866}
step: 26260 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 4.2284, 'max_total_reward': 15.67, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.564595091342926, 'actor_loss': -5.266985511779785, 'hyper_actor_loss': 0.01408059811219573, 'behavior_loss': 0.26156096160411835, 'mean_batch': 6.354998016357422, 'min_batch': 6.10067343711853, 'max_batch': 6.491371154785156}
step: 26270 @ episode report: {'average_total_reward': 10.876001, 'reward_variance': 1.8995041, 'max_total_reward': 13.34, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3943129241466523, 'actor_loss': -5.304140281677246, 'hyper_actor_loss': 0.014210193697363139, 'behavior_loss': 0.26190791726112367, 'mean_batch': 6.468959093093872, 'min_batch': 6.219612121582031, 'max_batch': 6.6266683578491214}
step: 26280 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 5.328006, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4489033102989195, 'actor_loss': -5.331599521636963, 'hyper_actor_loss': 0.013942482881247997, 'behavior_loss': 0.26494706273078916, 'mean_batch': 6.547155809402466, 'min_batch': 6.316488647460938, 'max_batch': 6.713834238052368}
step: 26290 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 4.638102, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4071815729141237, 'actor_loss': -5.3158509731292725, 'hyper_actor_loss': 0.013879701402038336, 'behavior_loss': 0.27014548480510714, 'mean_batch': 6.5111377239227295, 'min_batch': 6.252119779586792, 'max_batch': 6.675255298614502}
step: 26300 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 0.7149399, 'max_total_reward': 12.339999, 'min_total_reward': 9.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.904716908931732, 'actor_loss': -5.310789155960083, 'hyper_actor_loss': 0.013873181212693453, 'behavior_loss': 0.25494440346956254, 'mean_batch': 6.498282861709595, 'min_batch': 6.233373022079467, 'max_batch': 6.6528465270996096}
step: 26310 @ episode report: {'average_total_reward': 9.876, 'reward_variance': 5.442025, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3236525774002077, 'actor_loss': -5.295821475982666, 'hyper_actor_loss': 0.013810402899980544, 'behavior_loss': 0.2539039820432663, 'mean_batch': 6.437814664840698, 'min_batch': 6.197963285446167, 'max_batch': 6.591365909576416}
step: 26320 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 3.3230834, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6228344678878783, 'actor_loss': -5.314974164962768, 'hyper_actor_loss': 0.0138933633454144, 'behavior_loss': 0.2586566761136055, 'mean_batch': 6.506975317001343, 'min_batch': 6.250639963150024, 'max_batch': 6.6728963375091555}
step: 26330 @ episode report: {'average_total_reward': 9.943, 'reward_variance': 2.6680806, 'max_total_reward': 12.23, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.642421293258667, 'actor_loss': -5.317007255554199, 'hyper_actor_loss': 0.014006646536290645, 'behavior_loss': 0.27476463168859483, 'mean_batch': 6.517168617248535, 'min_batch': 6.253568172454834, 'max_batch': 6.669189405441284}
step: 26340 @ episode report: {'average_total_reward': 10.020999, 'reward_variance': 3.3583293, 'max_total_reward': 13.45, 'min_total_reward': 7.68, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.797161030769348, 'actor_loss': -5.314644289016724, 'hyper_actor_loss': 0.01418789392337203, 'behavior_loss': 0.2776321917772293, 'mean_batch': 6.4891135692596436, 'min_batch': 6.265867614746094, 'max_batch': 6.638627672195435}
step: 26350 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 3.7358832, 'max_total_reward': 14.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8213503241539, 'actor_loss': -5.2918500900268555, 'hyper_actor_loss': 0.014526683557778596, 'behavior_loss': 0.2635842964053154, 'mean_batch': 6.438419246673584, 'min_batch': 6.172955131530761, 'max_batch': 6.596627283096313}
step: 26360 @ episode report: {'average_total_reward': 9.676001, 'reward_variance': 4.269903, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.110795259475708, 'actor_loss': -5.311518669128418, 'hyper_actor_loss': 0.014545731525868178, 'behavior_loss': 0.27535504251718523, 'mean_batch': 6.493490076065063, 'min_batch': 6.2424081325531, 'max_batch': 6.658293962478638}
step: 26370 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.599905, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5772642731666564, 'actor_loss': -5.302432250976563, 'hyper_actor_loss': 0.014692363608628512, 'behavior_loss': 0.25957419723272324, 'mean_batch': 6.465375471115112, 'min_batch': 6.212526893615722, 'max_batch': 6.632184457778931}
step: 26380 @ episode report: {'average_total_reward': 9.367001, 'reward_variance': 2.4518414, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.880407154560089, 'actor_loss': -5.304601383209229, 'hyper_actor_loss': 0.01452770046889782, 'behavior_loss': 0.2694732502102852, 'mean_batch': 6.498549699783325, 'min_batch': 6.194432258605957, 'max_batch': 6.685705995559692}
step: 26390 @ episode report: {'average_total_reward': 8.589001, 'reward_variance': 1.2706892, 'max_total_reward': 10.01, 'min_total_reward': 6.5699997, 'average_n_step': 9.7, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5085761070251467, 'actor_loss': -5.331998348236084, 'hyper_actor_loss': 0.014563900791108609, 'behavior_loss': 0.2557723045349121, 'mean_batch': 6.56016435623169, 'min_batch': 6.306447458267212, 'max_batch': 6.740782737731934}
step: 26400 @ episode report: {'average_total_reward': 10.219999, 'reward_variance': 2.5102, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.556915670633316, 'actor_loss': -5.340328073501587, 'hyper_actor_loss': 0.014402892347425223, 'behavior_loss': 0.27732274383306504, 'mean_batch': 6.5827436447143555, 'min_batch': 6.337483024597168, 'max_batch': 6.739875316619873}
step: 26410 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 5.72929, 'max_total_reward': 14.450001, 'min_total_reward': 6.68, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.524637484550476, 'actor_loss': -5.298565435409546, 'hyper_actor_loss': 0.014655743725597858, 'behavior_loss': 0.2681044727563858, 'mean_batch': 6.440880489349365, 'min_batch': 6.212289667129516, 'max_batch': 6.599095726013184}
step: 26420 @ episode report: {'average_total_reward': 8.833, 'reward_variance': 3.258601, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2843276858329773, 'actor_loss': -5.33026442527771, 'hyper_actor_loss': 0.014689483027905226, 'behavior_loss': 0.24534692615270615, 'mean_batch': 6.535564804077149, 'min_batch': 6.319460201263428, 'max_batch': 6.718345308303833}
step: 26430 @ episode report: {'average_total_reward': 10.431001, 'reward_variance': 5.0596285, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7375863194465637, 'actor_loss': -5.327076053619384, 'hyper_actor_loss': 0.014398586843162775, 'behavior_loss': 0.2741824254393578, 'mean_batch': 6.538631772994995, 'min_batch': 6.2964869976043705, 'max_batch': 6.764123582839966}
step: 26440 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 0.73080474, 'max_total_reward': 10.9, 'min_total_reward': 7.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.743199181556702, 'actor_loss': -5.306330156326294, 'hyper_actor_loss': 0.01464687567204237, 'behavior_loss': 0.2651207074522972, 'mean_batch': 6.480005073547363, 'min_batch': 6.222719478607178, 'max_batch': 6.750767040252685}
step: 26450 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 1.5226638, 'max_total_reward': 11.23, 'min_total_reward': 7.79, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.980561542510986, 'actor_loss': -5.311848449707031, 'hyper_actor_loss': 0.014782936219125986, 'behavior_loss': 0.2899478241801262, 'mean_batch': 6.501893472671509, 'min_batch': 6.235982465744018, 'max_batch': 6.785644006729126}
step: 26460 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 1.7132809, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.60529203414917, 'actor_loss': -5.308109474182129, 'hyper_actor_loss': 0.01542763039469719, 'behavior_loss': 0.26538240909576416, 'mean_batch': 6.5011208057403564, 'min_batch': 6.2134867191314695, 'max_batch': 6.796636867523193}
step: 26470 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.6395209, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9306907534599302, 'actor_loss': -5.3145403385162355, 'hyper_actor_loss': 0.015704682655632497, 'behavior_loss': 0.27159045785665514, 'mean_batch': 6.480366182327271, 'min_batch': 6.273587226867676, 'max_batch': 6.714325952529907}
step: 26480 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 12.1582365, 'max_total_reward': 12.34, 'min_total_reward': 1.02, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.04752140045166, 'actor_loss': -5.252212858200073, 'hyper_actor_loss': 0.015395479556173087, 'behavior_loss': 0.2684995844960213, 'mean_batch': 6.2719847679138185, 'min_batch': 6.0908668518066404, 'max_batch': 6.446722316741943}
step: 26490 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 0.7440159, 'max_total_reward': 11.01, 'min_total_reward': 7.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.970717930793762, 'actor_loss': -5.248198747634888, 'hyper_actor_loss': 0.015158131066709758, 'behavior_loss': 0.27216497659683225, 'mean_batch': 6.270721387863159, 'min_batch': 6.067328453063965, 'max_batch': 6.3982349872589115}
step: 26500 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 4.365876, 'max_total_reward': 12.340001, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.896232008934021, 'actor_loss': -5.272676944732666, 'hyper_actor_loss': 0.015082470793277025, 'behavior_loss': 0.2759533807635307, 'mean_batch': 6.3563896179199215, 'min_batch': 6.1336905002594, 'max_batch': 6.508032321929932}
step: 26510 @ episode report: {'average_total_reward': 10.199, 'reward_variance': 3.1709485, 'max_total_reward': 12.339999, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1024984240531923, 'actor_loss': -5.261170101165772, 'hyper_actor_loss': 0.015207721665501595, 'behavior_loss': 0.2915006518363953, 'mean_batch': 6.312362289428711, 'min_batch': 6.10603814125061, 'max_batch': 6.482418870925903}
step: 26520 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.0682247, 'max_total_reward': 12.34, 'min_total_reward': 8.68, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7751734852790833, 'actor_loss': -5.26196665763855, 'hyper_actor_loss': 0.015624726004898549, 'behavior_loss': 0.27163146138191224, 'mean_batch': 6.313720989227295, 'min_batch': 6.109460020065308, 'max_batch': 6.504238939285278}
step: 26530 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 4.836837, 'max_total_reward': 14.56, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4106894373893737, 'actor_loss': -5.275126791000366, 'hyper_actor_loss': 0.015606646798551083, 'behavior_loss': 0.2777658700942993, 'mean_batch': 6.35549898147583, 'min_batch': 6.149699735641479, 'max_batch': 6.536983394622803}
step: 26540 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 1.2385843, 'max_total_reward': 12.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.50435608625412, 'actor_loss': -5.29956283569336, 'hyper_actor_loss': 0.015526199713349342, 'behavior_loss': 0.26441192626953125, 'mean_batch': 6.434396076202392, 'min_batch': 6.224497699737549, 'max_batch': 6.647771215438842}
step: 26550 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 5.7199965, 'max_total_reward': 14.560001, 'min_total_reward': 5.6800003, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8593154668807985, 'actor_loss': -5.287137985229492, 'hyper_actor_loss': 0.01503604557365179, 'behavior_loss': 0.2733773946762085, 'mean_batch': 6.409712457656861, 'min_batch': 6.171387243270874, 'max_batch': 6.6721738338470455}
step: 26560 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 4.3155437, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.871584248542786, 'actor_loss': -5.229320907592774, 'hyper_actor_loss': 0.015304415952414274, 'behavior_loss': 0.2701645702123642, 'mean_batch': 6.213636636734009, 'min_batch': 6.008607530593872, 'max_batch': 6.42670259475708}
step: 26570 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 11.053423, 'max_total_reward': 13.340001, 'min_total_reward': 1.35, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.213537335395813, 'actor_loss': -5.238493347167969, 'hyper_actor_loss': 0.015257159247994423, 'behavior_loss': 0.2758998110890388, 'mean_batch': 6.226235103607178, 'min_batch': 6.051462697982788, 'max_batch': 6.437437677383423}
step: 26580 @ episode report: {'average_total_reward': 9.533, 'reward_variance': 9.053861, 'max_total_reward': 13.01, 'min_total_reward': 1.35, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3180787801742553, 'actor_loss': -5.257441091537475, 'hyper_actor_loss': 0.015378279983997345, 'behavior_loss': 0.27081927061080935, 'mean_batch': 6.290532398223877, 'min_batch': 6.104549312591553, 'max_batch': 6.483846712112427}
step: 26590 @ episode report: {'average_total_reward': 10.742002, 'reward_variance': 0.53279567, 'max_total_reward': 12.34, 'min_total_reward': 10.01, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.63345228433609, 'actor_loss': -5.28326530456543, 'hyper_actor_loss': 0.015285641141235828, 'behavior_loss': 0.2602870002388954, 'mean_batch': 6.3545843124389645, 'min_batch': 6.200754165649414, 'max_batch': 6.535410356521607}
step: 26600 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 1.1409647, 'max_total_reward': 11.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9507816076278686, 'actor_loss': -5.234219694137574, 'hyper_actor_loss': 0.014986195135861635, 'behavior_loss': 0.27972161769866943, 'mean_batch': 6.208087348937989, 'min_batch': 6.04358925819397, 'max_batch': 6.383617877960205}
step: 26610 @ episode report: {'average_total_reward': 10.509, 'reward_variance': 2.0260892, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4526281654834747, 'actor_loss': -5.2312112808227536, 'hyper_actor_loss': 0.015225345268845558, 'behavior_loss': 0.2718248337507248, 'mean_batch': 6.225214242935181, 'min_batch': 6.008645153045654, 'max_batch': 6.4058294773101805}
step: 26620 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.4126809, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6317428231239317, 'actor_loss': -5.269700193405152, 'hyper_actor_loss': 0.015514143463224172, 'behavior_loss': 0.28357591927051545, 'mean_batch': 6.336114883422852, 'min_batch': 6.135254669189453, 'max_batch': 6.579666614532471}
step: 26630 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 2.68673, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.305018198490143, 'actor_loss': -5.225716066360474, 'hyper_actor_loss': 0.016021698713302612, 'behavior_loss': 0.25931489318609235, 'mean_batch': 6.200426483154297, 'min_batch': 6.000243234634399, 'max_batch': 6.406510829925537}
step: 26640 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 3.4089046, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2740970492362975, 'actor_loss': -5.188635730743409, 'hyper_actor_loss': 0.01604207381606102, 'behavior_loss': 0.2835955753922462, 'mean_batch': 6.094743633270264, 'min_batch': 5.882321071624756, 'max_batch': 6.28370475769043}
step: 26650 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 5.798527, 'max_total_reward': 14.560001, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.785445821285248, 'actor_loss': -5.2758553981781, 'hyper_actor_loss': 0.015808624122291802, 'behavior_loss': 0.27529600709676744, 'mean_batch': 6.368530368804931, 'min_batch': 6.141713380813599, 'max_batch': 6.538922929763794}
step: 26660 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 8.256909, 'max_total_reward': 13.34, 'min_total_reward': 4.68, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9529335260391236, 'actor_loss': -5.219264554977417, 'hyper_actor_loss': 0.015898254979401828, 'behavior_loss': 0.2704550936818123, 'mean_batch': 6.203727912902832, 'min_batch': 5.958858585357666, 'max_batch': 6.442742109298706}
step: 26670 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 3.2157638, 'max_total_reward': 13.34, 'min_total_reward': 7.57, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.369256818294525, 'actor_loss': -5.213955640792847, 'hyper_actor_loss': 0.015987419150769712, 'behavior_loss': 0.26657041907310486, 'mean_batch': 6.174467992782593, 'min_batch': 5.954928064346314, 'max_batch': 6.415582323074341}
step: 26680 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 4.6751623, 'max_total_reward': 15.670001, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.735702431201935, 'actor_loss': -5.244053745269776, 'hyper_actor_loss': 0.01609514933079481, 'behavior_loss': 0.2653918147087097, 'mean_batch': 6.275911426544189, 'min_batch': 6.037412214279175, 'max_batch': 6.540602111816407}
step: 26690 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 1.2398443, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8206367015838625, 'actor_loss': -5.213937759399414, 'hyper_actor_loss': 0.016406436450779438, 'behavior_loss': 0.2711352124810219, 'mean_batch': 6.185222148895264, 'min_batch': 5.9440491676330565, 'max_batch': 6.427212572097778}
step: 26700 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 2.7569041, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8477362751960755, 'actor_loss': -5.180030059814453, 'hyper_actor_loss': 0.01657971702516079, 'behavior_loss': 0.2563915729522705, 'mean_batch': 6.151905298233032, 'min_batch': 5.777822017669678, 'max_batch': 6.4806445121765135}
step: 26710 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 2.8743646, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0539968252182006, 'actor_loss': -5.185440874099731, 'hyper_actor_loss': 0.016808323562145233, 'behavior_loss': 0.28343477547168733, 'mean_batch': 6.146182107925415, 'min_batch': 5.814027118682861, 'max_batch': 6.515210199356079}
step: 26720 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 1.9487498, 'max_total_reward': 11.120001, 'min_total_reward': 6.8999996, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9449278593063353, 'actor_loss': -5.203771924972534, 'hyper_actor_loss': 0.017367345839738847, 'behavior_loss': 0.28094266206026075, 'mean_batch': 6.186673355102539, 'min_batch': 5.88250732421875, 'max_batch': 6.494044780731201}
step: 26730 @ episode report: {'average_total_reward': 10.109, 'reward_variance': 7.8401093, 'max_total_reward': 13.450001, 'min_total_reward': 4.46, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.526809906959534, 'actor_loss': -5.245645666122437, 'hyper_actor_loss': 0.017692773789167403, 'behavior_loss': 0.2676789939403534, 'mean_batch': 6.310531663894653, 'min_batch': 6.013689851760864, 'max_batch': 6.602538013458252}
step: 26740 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 3.6617458, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9129758358001707, 'actor_loss': -5.2555732250213625, 'hyper_actor_loss': 0.017766554653644562, 'behavior_loss': 0.2724428579211235, 'mean_batch': 6.3293068408966064, 'min_batch': 6.055879926681518, 'max_batch': 6.585446119308472}
step: 26750 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 2.4613166, 'max_total_reward': 12.01, 'min_total_reward': 6.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0741676688194275, 'actor_loss': -5.205607175827026, 'hyper_actor_loss': 0.01767975129187107, 'behavior_loss': 0.2863647222518921, 'mean_batch': 6.173973321914673, 'min_batch': 5.905555152893067, 'max_batch': 6.453414011001587}
step: 26760 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 1.5416448, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.55111711025238, 'actor_loss': -5.2066733837127686, 'hyper_actor_loss': 0.018446109257638454, 'behavior_loss': 0.2802563190460205, 'mean_batch': 6.165656185150146, 'min_batch': 5.920147228240967, 'max_batch': 6.420204925537109}
step: 26770 @ episode report: {'average_total_reward': 9.110001, 'reward_variance': 2.2369401, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.202409362792969, 'actor_loss': -5.2191197872161865, 'hyper_actor_loss': 0.01883160527795553, 'behavior_loss': 0.2833690643310547, 'mean_batch': 6.215649747848511, 'min_batch': 5.945759725570679, 'max_batch': 6.443182945251465}
step: 26780 @ episode report: {'average_total_reward': 9.332, 'reward_variance': 4.3366165, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.217423069477081, 'actor_loss': -5.2329460144042965, 'hyper_actor_loss': 0.01873568706214428, 'behavior_loss': 0.28038225173950193, 'mean_batch': 6.240258502960205, 'min_batch': 6.004706192016601, 'max_batch': 6.472558307647705}
step: 26790 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 1.7473882, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6348456263542177, 'actor_loss': -5.280562162399292, 'hyper_actor_loss': 0.01871458292007446, 'behavior_loss': 0.2755608543753624, 'mean_batch': 6.393243455886841, 'min_batch': 6.146592712402343, 'max_batch': 6.60820894241333}
step: 26800 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 3.448256, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2021758556365967, 'actor_loss': -5.235943698883057, 'hyper_actor_loss': 0.01843802463263273, 'behavior_loss': 0.2661347553133965, 'mean_batch': 6.255366945266724, 'min_batch': 6.0090117931365965, 'max_batch': 6.4636757373809814}
step: 26810 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 1.579669, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8244938254356384, 'actor_loss': -5.192163753509521, 'hyper_actor_loss': 0.01827161442488432, 'behavior_loss': 0.2892966717481613, 'mean_batch': 6.126770830154419, 'min_batch': 5.871732234954834, 'max_batch': 6.359166240692138}
step: 26820 @ episode report: {'average_total_reward': 9.998001, 'reward_variance': 2.2784762, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.389721488952637, 'actor_loss': -5.246617031097412, 'hyper_actor_loss': 0.01879897378385067, 'behavior_loss': 0.27732513546943666, 'mean_batch': 6.307067966461181, 'min_batch': 6.023766803741455, 'max_batch': 6.520412397384644}
step: 26830 @ episode report: {'average_total_reward': 10.853002, 'reward_variance': 1.513281, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.712845063209534, 'actor_loss': -5.257650661468506, 'hyper_actor_loss': 0.019519602693617345, 'behavior_loss': 0.28346890658140184, 'mean_batch': 6.325234365463257, 'min_batch': 6.072931289672852, 'max_batch': 6.535434007644653}
step: 26840 @ episode report: {'average_total_reward': 10.01, 'reward_variance': 1.4127203, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.505266797542572, 'actor_loss': -5.233214282989502, 'hyper_actor_loss': 0.019342921674251556, 'behavior_loss': 0.28827331960201263, 'mean_batch': 6.261722660064697, 'min_batch': 5.985591220855713, 'max_batch': 6.474937200546265}
step: 26850 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.1406238, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7473399162292482, 'actor_loss': -5.260784530639649, 'hyper_actor_loss': 0.019273559935390948, 'behavior_loss': 0.2661344274878502, 'mean_batch': 6.325152206420898, 'min_batch': 6.091158723831176, 'max_batch': 6.544141960144043}
step: 26860 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 1.6672161, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.459774398803711, 'actor_loss': -5.255518102645874, 'hyper_actor_loss': 0.019171901792287827, 'behavior_loss': 0.2604679808020592, 'mean_batch': 6.326821899414062, 'min_batch': 6.057481050491333, 'max_batch': 6.531023740768433}
step: 26870 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 3.6699898, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1996198415756227, 'actor_loss': -5.273991918563842, 'hyper_actor_loss': 0.019041349180042744, 'behavior_loss': 0.2650682583451271, 'mean_batch': 6.37750654220581, 'min_batch': 6.121411561965942, 'max_batch': 6.584624814987182}
step: 26880 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 1.5430291, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.662234592437744, 'actor_loss': -5.290923166275024, 'hyper_actor_loss': 0.0191515589132905, 'behavior_loss': 0.28175385147333143, 'mean_batch': 6.4218597412109375, 'min_batch': 6.183095645904541, 'max_batch': 6.635072946548462}
step: 26890 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 4.552521, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4146769523620604, 'actor_loss': -5.2231827735900875, 'hyper_actor_loss': 0.01947130560874939, 'behavior_loss': 0.27542746961116793, 'mean_batch': 6.227149629592896, 'min_batch': 5.959431123733521, 'max_batch': 6.449657917022705}
step: 26900 @ episode report: {'average_total_reward': 10.176, 'reward_variance': 4.1445246, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4494911670684814, 'actor_loss': -5.229204845428467, 'hyper_actor_loss': 0.019914130307734014, 'behavior_loss': 0.276914581656456, 'mean_batch': 6.247779369354248, 'min_batch': 5.9762743473052975, 'max_batch': 6.432182359695434}
step: 26910 @ episode report: {'average_total_reward': 10.088, 'reward_variance': 1.7893753, 'max_total_reward': 12.12, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9093573451042176, 'actor_loss': -5.267889547348022, 'hyper_actor_loss': 0.019966750219464303, 'behavior_loss': 0.25938559919595716, 'mean_batch': 6.4017986297607425, 'min_batch': 6.061449766159058, 'max_batch': 6.607789087295532}
step: 26920 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 2.957568, 'max_total_reward': 14.559999, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.015011250972748, 'actor_loss': -5.281542015075684, 'hyper_actor_loss': 0.019549000449478625, 'behavior_loss': 0.2692771300673485, 'mean_batch': 6.429700422286987, 'min_batch': 6.118290185928345, 'max_batch': 6.617015075683594}
step: 26930 @ episode report: {'average_total_reward': 10.687001, 'reward_variance': 2.7895017, 'max_total_reward': 13.900001, 'min_total_reward': 7.9000006, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6874075174331664, 'actor_loss': -5.309766674041748, 'hyper_actor_loss': 0.019512486830353736, 'behavior_loss': 0.2871670126914978, 'mean_batch': 6.489886951446533, 'min_batch': 6.2346149444580075, 'max_batch': 6.679229593276977}
step: 26940 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 4.8015594, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9777241110801698, 'actor_loss': -5.263320684432983, 'hyper_actor_loss': 0.019619386270642282, 'behavior_loss': 0.2621351942420006, 'mean_batch': 6.343584871292114, 'min_batch': 6.089226388931275, 'max_batch': 6.5442845821380615}
step: 26950 @ episode report: {'average_total_reward': 9.309999, 'reward_variance': 8.17334, 'max_total_reward': 13.34, 'min_total_reward': 3.5699997, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.455141615867615, 'actor_loss': -5.248141145706176, 'hyper_actor_loss': 0.019612095877528192, 'behavior_loss': 0.28041572868824005, 'mean_batch': 6.315710067749023, 'min_batch': 6.024420166015625, 'max_batch': 6.495824098587036}
step: 26960 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 7.1421356, 'max_total_reward': 15.67, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.415450465679169, 'actor_loss': -5.294977855682373, 'hyper_actor_loss': 0.01983069200068712, 'behavior_loss': 0.26376093327999117, 'mean_batch': 6.4525634765625, 'min_batch': 6.178795862197876, 'max_batch': 6.624379348754883}
step: 26970 @ episode report: {'average_total_reward': 9.188999, 'reward_variance': 7.756587, 'max_total_reward': 13.34, 'min_total_reward': 3.2400002, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8845137000083922, 'actor_loss': -5.2984894752502445, 'hyper_actor_loss': 0.019908457808196545, 'behavior_loss': 0.2820805937051773, 'mean_batch': 6.42962794303894, 'min_batch': 6.222768020629883, 'max_batch': 6.581070518493652}
step: 26980 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 2.9223688, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8411078095436095, 'actor_loss': -5.263671588897705, 'hyper_actor_loss': 0.019438224844634533, 'behavior_loss': 0.26841124445199965, 'mean_batch': 6.3124395370483395, 'min_batch': 6.120979118347168, 'max_batch': 6.4715495109558105}
step: 26990 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 3.216341, 'max_total_reward': 13.34, 'min_total_reward': 6.57, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8532577991485595, 'actor_loss': -5.255734586715699, 'hyper_actor_loss': 0.019572671689093112, 'behavior_loss': 0.27202201187610625, 'mean_batch': 6.326246690750122, 'min_batch': 6.059898710250854, 'max_batch': 6.498975849151611}
step: 27000 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 2.1673603, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.394487762451172, 'actor_loss': -5.273385667800904, 'hyper_actor_loss': 0.019620723091065884, 'behavior_loss': 0.27143392711877823, 'mean_batch': 6.360948181152343, 'min_batch': 6.133812141418457, 'max_batch': 6.513883352279663}
step: 27010 @ episode report: {'average_total_reward': 10.465, 'reward_variance': 4.6347847, 'max_total_reward': 13.45, 'min_total_reward': 6.5700006, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6030588865280153, 'actor_loss': -5.288480663299561, 'hyper_actor_loss': 0.01961571369320154, 'behavior_loss': 0.27064239978790283, 'mean_batch': 6.394599342346192, 'min_batch': 6.194111251831055, 'max_batch': 6.540325689315796}
step: 27020 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 1.755249, 'max_total_reward': 14.45, 'min_total_reward': 9.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9368196725845337, 'actor_loss': -5.239952135086059, 'hyper_actor_loss': 0.019298147037625314, 'behavior_loss': 0.2714021161198616, 'mean_batch': 6.246166181564331, 'min_batch': 6.041426515579223, 'max_batch': 6.383408832550049}
step: 27030 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 1.2399609, 'max_total_reward': 11.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6179052352905274, 'actor_loss': -5.246258020401001, 'hyper_actor_loss': 0.019080471806228162, 'behavior_loss': 0.2794328048825264, 'mean_batch': 6.26131010055542, 'min_batch': 6.064983606338501, 'max_batch': 6.400071048736573}
step: 27040 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 4.002819, 'max_total_reward': 13.45, 'min_total_reward': 5.57, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7813409149646757, 'actor_loss': -5.259919500350952, 'hyper_actor_loss': 0.019090177863836287, 'behavior_loss': 0.2702387735247612, 'mean_batch': 6.331090354919434, 'min_batch': 6.080606698989868, 'max_batch': 6.479333353042603}
step: 27050 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 4.15705, 'max_total_reward': 15.670001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0600859999656675, 'actor_loss': -5.258734607696534, 'hyper_actor_loss': 0.018902076967060567, 'behavior_loss': 0.26360201835632324, 'mean_batch': 6.324940824508667, 'min_batch': 6.079055738449097, 'max_batch': 6.469478988647461}
step: 27060 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 1.2005644, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.753023052215576, 'actor_loss': -5.265061521530152, 'hyper_actor_loss': 0.01919796019792557, 'behavior_loss': 0.2651699423789978, 'mean_batch': 6.341367578506469, 'min_batch': 6.1016487121582035, 'max_batch': 6.506737279891968}
step: 27070 @ episode report: {'average_total_reward': 9.343, 'reward_variance': 5.638202, 'max_total_reward': 12.230001, 'min_total_reward': 4.6800003, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7962615549564362, 'actor_loss': -5.253971529006958, 'hyper_actor_loss': 0.019068903289735317, 'behavior_loss': 0.27006307393312456, 'mean_batch': 6.308072185516357, 'min_batch': 6.066146945953369, 'max_batch': 6.475083637237549}
step: 27080 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 5.1305366, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5985552430152894, 'actor_loss': -5.249578428268433, 'hyper_actor_loss': 0.0186737596988678, 'behavior_loss': 0.26214794516563417, 'mean_batch': 6.29013614654541, 'min_batch': 6.056883478164673, 'max_batch': 6.4632879257202145}
step: 27090 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 0.6676611, 'max_total_reward': 11.23, 'min_total_reward': 8.79, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9517397403717043, 'actor_loss': -5.275512409210205, 'hyper_actor_loss': 0.018771963939070702, 'behavior_loss': 0.2759786307811737, 'mean_batch': 6.371098947525025, 'min_batch': 6.136872339248657, 'max_batch': 6.593673610687256}
step: 27100 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 5.57885, 'max_total_reward': 14.34, 'min_total_reward': 6.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.164488935470581, 'actor_loss': -5.286681079864502, 'hyper_actor_loss': 0.01920756921172142, 'behavior_loss': 0.2647221595048904, 'mean_batch': 6.435548210144043, 'min_batch': 6.143747615814209, 'max_batch': 6.724283123016358}
step: 27110 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 3.747504, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8941788554191588, 'actor_loss': -5.2319742202758786, 'hyper_actor_loss': 0.019332547299563886, 'behavior_loss': 0.26814499497413635, 'mean_batch': 6.249720239639283, 'min_batch': 5.990238618850708, 'max_batch': 6.4480610370635985}
step: 27120 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 5.2083044, 'max_total_reward': 14.56, 'min_total_reward': 7.57, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4553950786590577, 'actor_loss': -5.243102169036865, 'hyper_actor_loss': 0.019221656024456024, 'behavior_loss': 0.2772028654813766, 'mean_batch': 6.292846822738648, 'min_batch': 6.015575790405274, 'max_batch': 6.449842548370361}
step: 27130 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 1.9093603, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7658965826034545, 'actor_loss': -5.266670656204224, 'hyper_actor_loss': 0.01894551273435354, 'behavior_loss': 0.28757254332304, 'mean_batch': 6.3310404300689695, 'min_batch': 6.1214409351348875, 'max_batch': 6.501436376571656}
step: 27140 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 3.7575607, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.885456347465515, 'actor_loss': -5.211273908615112, 'hyper_actor_loss': 0.01913763638585806, 'behavior_loss': 0.2794713631272316, 'mean_batch': 6.172438383102417, 'min_batch': 5.940775918960571, 'max_batch': 6.3589280128479}
step: 27150 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 4.4634767, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0955047488212584, 'actor_loss': -5.196025848388672, 'hyper_actor_loss': 0.019339622743427754, 'behavior_loss': 0.28451440930366517, 'mean_batch': 6.144185733795166, 'min_batch': 5.877662324905396, 'max_batch': 6.324064540863037}
step: 27160 @ episode report: {'average_total_reward': 10.976, 'reward_variance': 2.3359847, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6925380706787108, 'actor_loss': -5.255617904663086, 'hyper_actor_loss': 0.01965876594185829, 'behavior_loss': 0.2811699599027634, 'mean_batch': 6.308054685592651, 'min_batch': 6.076498699188233, 'max_batch': 6.536546993255615}
step: 27170 @ episode report: {'average_total_reward': 11.086001, 'reward_variance': 1.6334646, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.434094476699829, 'actor_loss': -5.249746417999267, 'hyper_actor_loss': 0.01928941123187542, 'behavior_loss': 0.267541278898716, 'mean_batch': 6.315360450744629, 'min_batch': 6.033725070953369, 'max_batch': 6.562299966812134}
step: 27180 @ episode report: {'average_total_reward': 11.619, 'reward_variance': 1.2355694, 'max_total_reward': 13.45, 'min_total_reward': 10.12, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4093591928482057, 'actor_loss': -5.256234788894654, 'hyper_actor_loss': 0.018861023895442485, 'behavior_loss': 0.2780620753765106, 'mean_batch': 6.322806072235108, 'min_batch': 6.0657891750335695, 'max_batch': 6.577530336380005}
step: 27190 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 3.276064, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8328341484069823, 'actor_loss': -5.2383650779724125, 'hyper_actor_loss': 0.019066302850842477, 'behavior_loss': 0.2691170260310173, 'mean_batch': 6.261191892623901, 'min_batch': 6.017011499404907, 'max_batch': 6.48423023223877}
step: 27200 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 3.1911016, 'max_total_reward': 13.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5950525283813475, 'actor_loss': -5.237924528121948, 'hyper_actor_loss': 0.018696016073226927, 'behavior_loss': 0.281287881731987, 'mean_batch': 6.292611122131348, 'min_batch': 5.984677410125732, 'max_batch': 6.598891019821167}
step: 27210 @ episode report: {'average_total_reward': 9.132001, 'reward_variance': 1.9612169, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.068114572763443, 'actor_loss': -5.287456274032593, 'hyper_actor_loss': 0.01928764916956425, 'behavior_loss': 0.27370886951684953, 'mean_batch': 6.441838550567627, 'min_batch': 6.143614387512207, 'max_batch': 6.725010919570923}
step: 27220 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 1.3784211, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.33970160484314, 'actor_loss': -5.222725868225098, 'hyper_actor_loss': 0.019272134825587272, 'behavior_loss': 0.2618715763092041, 'mean_batch': 6.208931398391724, 'min_batch': 5.973466634750366, 'max_batch': 6.343918895721435}
step: 27230 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 11.003763, 'max_total_reward': 16.67, 'min_total_reward': 2.3500001, 'average_n_step': 11.4, 'max_n_step': 17.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2551525354385378, 'actor_loss': -5.264257764816284, 'hyper_actor_loss': 0.018563399091362953, 'behavior_loss': 0.2786171078681946, 'mean_batch': 6.325365781784058, 'min_batch': 6.11235032081604, 'max_batch': 6.451890325546264}
step: 27240 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 7.7272606, 'max_total_reward': 12.23, 'min_total_reward': 2.3500001, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8022401094436646, 'actor_loss': -5.264232540130616, 'hyper_actor_loss': 0.018418115377426148, 'behavior_loss': 0.2719631791114807, 'mean_batch': 6.328633069992065, 'min_batch': 6.109104347229004, 'max_batch': 6.443968677520752}
step: 27250 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.7982042, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0587799191474914, 'actor_loss': -5.197263860702515, 'hyper_actor_loss': 0.01839664448052645, 'behavior_loss': 0.2815952733159065, 'mean_batch': 6.147033166885376, 'min_batch': 5.88210916519165, 'max_batch': 6.271154069900513}
step: 27260 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 2.2012286, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9799640417099, 'actor_loss': -5.217579650878906, 'hyper_actor_loss': 0.018658087216317655, 'behavior_loss': 0.28106165379285813, 'mean_batch': 6.180011034011841, 'min_batch': 5.970660257339477, 'max_batch': 6.314514064788819}
step: 27270 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 4.7888975, 'max_total_reward': 14.450001, 'min_total_reward': 7.57, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.552768111228943, 'actor_loss': -5.2412505626678465, 'hyper_actor_loss': 0.018794058077037334, 'behavior_loss': 0.2797410532832146, 'mean_batch': 6.256269216537476, 'min_batch': 6.039025115966797, 'max_batch': 6.380454063415527}
step: 27280 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.4527836, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9604355096817017, 'actor_loss': -5.216063213348389, 'hyper_actor_loss': 0.018850873969495297, 'behavior_loss': 0.2747287958860397, 'mean_batch': 6.179568529129028, 'min_batch': 5.962518692016602, 'max_batch': 6.3020744800567625}
step: 27290 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 7.5385866, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.781381916999817, 'actor_loss': -5.190381288528442, 'hyper_actor_loss': 0.018132119625806808, 'behavior_loss': 0.26464606672525404, 'mean_batch': 6.099744749069214, 'min_batch': 5.886807680130005, 'max_batch': 6.2121480941772464}
step: 27300 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 1.6826448, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7134320378303527, 'actor_loss': -5.215955448150635, 'hyper_actor_loss': 0.017605500295758247, 'behavior_loss': 0.2783250853419304, 'mean_batch': 6.173833990097046, 'min_batch': 5.9670857906341555, 'max_batch': 6.30236701965332}
step: 27310 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 1.9577806, 'max_total_reward': 13.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.891755700111389, 'actor_loss': -5.214612531661987, 'hyper_actor_loss': 0.01783546879887581, 'behavior_loss': 0.2663427710533142, 'mean_batch': 6.179246616363526, 'min_batch': 5.953794145584107, 'max_batch': 6.335004091262817}
step: 27320 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.5458555, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.60506751537323, 'actor_loss': -5.185862588882446, 'hyper_actor_loss': 0.017484043166041373, 'behavior_loss': 0.27902743220329285, 'mean_batch': 6.094881963729859, 'min_batch': 5.864949369430542, 'max_batch': 6.211644029617309}
step: 27330 @ episode report: {'average_total_reward': 10.331001, 'reward_variance': 2.7476285, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.956023168563843, 'actor_loss': -5.212537002563477, 'hyper_actor_loss': 0.017741948552429675, 'behavior_loss': 0.27383423298597337, 'mean_batch': 6.196805858612061, 'min_batch': 5.924669790267944, 'max_batch': 6.339597702026367}
step: 27340 @ episode report: {'average_total_reward': 10.021, 'reward_variance': 5.2295895, 'max_total_reward': 14.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.027365875244141, 'actor_loss': -5.207255411148071, 'hyper_actor_loss': 0.018210592120885848, 'behavior_loss': 0.27304581105709075, 'mean_batch': 6.197539758682251, 'min_batch': 5.893304824829102, 'max_batch': 6.373941946029663}
step: 27350 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 2.0423005, 'max_total_reward': 12.340001, 'min_total_reward': 6.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.032075572013855, 'actor_loss': -5.189395713806152, 'hyper_actor_loss': 0.01858101524412632, 'behavior_loss': 0.2769726783037186, 'mean_batch': 6.143558311462402, 'min_batch': 5.839544677734375, 'max_batch': 6.35038194656372}
step: 27360 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 1.5132809, 'max_total_reward': 12.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0280242919921876, 'actor_loss': -5.1973449230194095, 'hyper_actor_loss': 0.019004527665674686, 'behavior_loss': 0.29483634829521177, 'mean_batch': 6.224201917648315, 'min_batch': 5.810923004150391, 'max_batch': 6.43844575881958}
step: 27370 @ episode report: {'average_total_reward': 10.842, 'reward_variance': 3.9555366, 'max_total_reward': 15.67, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.713544154167175, 'actor_loss': -5.2406556606292725, 'hyper_actor_loss': 0.01926727518439293, 'behavior_loss': 0.26514163315296174, 'mean_batch': 6.305635976791382, 'min_batch': 5.989187526702881, 'max_batch': 6.505150175094604}
step: 27380 @ episode report: {'average_total_reward': 9.211, 'reward_variance': 12.965027, 'max_total_reward': 14.34, 'min_total_reward': 0.69000006, 'average_n_step': 10.3, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3027886509895326, 'actor_loss': -5.250506067276001, 'hyper_actor_loss': 0.018775982968509197, 'behavior_loss': 0.2629935503005981, 'mean_batch': 6.285260486602783, 'min_batch': 6.0670263290405275, 'max_batch': 6.454264545440674}
step: 27390 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 4.019115, 'max_total_reward': 14.559999, 'min_total_reward': 6.680001, 'average_n_step': 10.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.703791308403015, 'actor_loss': -5.239636516571045, 'hyper_actor_loss': 0.01820195056498051, 'behavior_loss': 0.2696456089615822, 'mean_batch': 6.249185276031494, 'min_batch': 6.036308479309082, 'max_batch': 6.407291603088379}
step: 27400 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 2.2350843, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.872195672988892, 'actor_loss': -5.220767593383789, 'hyper_actor_loss': 0.01793707087635994, 'behavior_loss': 0.274248993396759, 'mean_batch': 6.1876256465911865, 'min_batch': 5.982438325881958, 'max_batch': 6.332174825668335}
step: 27410 @ episode report: {'average_total_reward': 9.887, 'reward_variance': 6.382901, 'max_total_reward': 13.45, 'min_total_reward': 3.5700002, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3661619305610655, 'actor_loss': -5.209809160232544, 'hyper_actor_loss': 0.01825620885938406, 'behavior_loss': 0.27065792083740237, 'mean_batch': 6.180617237091065, 'min_batch': 5.924668502807617, 'max_batch': 6.353846311569214}
step: 27420 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 3.5893815, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2615309715270997, 'actor_loss': -5.267299604415894, 'hyper_actor_loss': 0.018386139161884786, 'behavior_loss': 0.2764083206653595, 'mean_batch': 6.346086215972901, 'min_batch': 6.110776662826538, 'max_batch': 6.56025652885437}
step: 27430 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 2.0085416, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3001739740371705, 'actor_loss': -5.248871374130249, 'hyper_actor_loss': 0.018439296633005142, 'behavior_loss': 0.27261206805706023, 'mean_batch': 6.316541862487793, 'min_batch': 6.027357053756714, 'max_batch': 6.594971370697022}
step: 27440 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 6.6633034, 'max_total_reward': 11.2300005, 'min_total_reward': 2.13, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.644243371486664, 'actor_loss': -5.240685081481933, 'hyper_actor_loss': 0.018432047590613364, 'behavior_loss': 0.2785862162709236, 'mean_batch': 6.306299924850464, 'min_batch': 5.988172483444214, 'max_batch': 6.688748073577881}
step: 27450 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 0.741196, 'max_total_reward': 11.2300005, 'min_total_reward': 9.01, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6409437537193297, 'actor_loss': -5.241804933547973, 'hyper_actor_loss': 0.018627856485545637, 'behavior_loss': 0.28237965852022173, 'mean_batch': 6.304934406280518, 'min_batch': 5.99602952003479, 'max_batch': 6.618436288833618}
step: 27460 @ episode report: {'average_total_reward': 10.099, 'reward_variance': 4.16779, 'max_total_reward': 13.340001, 'min_total_reward': 6.4599996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.112597405910492, 'actor_loss': -5.271657991409302, 'hyper_actor_loss': 0.01867093238979578, 'behavior_loss': 0.26136970371007917, 'mean_batch': 6.437076377868652, 'min_batch': 6.050745820999145, 'max_batch': 6.798932456970215}
step: 27470 @ episode report: {'average_total_reward': 8.844, 'reward_variance': 3.9760048, 'max_total_reward': 12.340001, 'min_total_reward': 5.57, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.94672144651413, 'actor_loss': -5.19051194190979, 'hyper_actor_loss': 0.018545041047036647, 'behavior_loss': 0.28280346393585204, 'mean_batch': 6.106308364868164, 'min_batch': 5.882977628707886, 'max_batch': 6.3721428394317625}
step: 27480 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 1.9206291, 'max_total_reward': 12.12, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.941054618358612, 'actor_loss': -5.197533369064331, 'hyper_actor_loss': 0.018483641557395458, 'behavior_loss': 0.27940947711467745, 'mean_batch': 6.104432916641235, 'min_batch': 5.924996709823608, 'max_batch': 6.274767065048218}
step: 27490 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.2041755, 'max_total_reward': 14.45, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3034715056419373, 'actor_loss': -5.234102725982666, 'hyper_actor_loss': 0.018857385218143462, 'behavior_loss': 0.2816064268350601, 'mean_batch': 6.23315691947937, 'min_batch': 6.018565654754639, 'max_batch': 6.420302963256836}
step: 27500 @ episode report: {'average_total_reward': 10.775, 'reward_variance': 2.307225, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.042403054237366, 'actor_loss': -5.249361181259156, 'hyper_actor_loss': 0.019170175306499004, 'behavior_loss': 0.27967050671577454, 'mean_batch': 6.303995656967163, 'min_batch': 6.042766809463501, 'max_batch': 6.541987419128418}
step: 27510 @ episode report: {'average_total_reward': 9.921, 'reward_variance': 3.8234887, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.709184193611145, 'actor_loss': -5.188819169998169, 'hyper_actor_loss': 0.018985688500106335, 'behavior_loss': 0.2859061986207962, 'mean_batch': 6.103331995010376, 'min_batch': 5.874544763565064, 'max_batch': 6.28154993057251}
step: 27520 @ episode report: {'average_total_reward': 9.931999, 'reward_variance': 3.636216, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.74636133313179, 'actor_loss': -5.21698784828186, 'hyper_actor_loss': 0.01870803367346525, 'behavior_loss': 0.2752078264951706, 'mean_batch': 6.185668134689331, 'min_batch': 5.961675453186035, 'max_batch': 6.4395997524261475}
step: 27530 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.2749279, 'max_total_reward': 13.23, 'min_total_reward': 7.6800003, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2368590354919435, 'actor_loss': -5.2520825386047365, 'hyper_actor_loss': 0.018302610702812673, 'behavior_loss': 0.2558368414640427, 'mean_batch': 6.334718418121338, 'min_batch': 6.029488849639892, 'max_batch': 6.6744307518005375}
step: 27540 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 3.051084, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.672535312175751, 'actor_loss': -5.242611074447632, 'hyper_actor_loss': 0.01814651545137167, 'behavior_loss': 0.2708317279815674, 'mean_batch': 6.325634336471557, 'min_batch': 5.981887865066528, 'max_batch': 6.6133644580841064}
step: 27550 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 2.61672, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.89146773815155, 'actor_loss': -5.231442499160766, 'hyper_actor_loss': 0.018271606788039206, 'behavior_loss': 0.2702661037445068, 'mean_batch': 6.232863330841065, 'min_batch': 6.002685499191284, 'max_batch': 6.45166597366333}
step: 27560 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.019115, 'max_total_reward': 14.559999, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8093648552894592, 'actor_loss': -5.2166040420532225, 'hyper_actor_loss': 0.018360909633338453, 'behavior_loss': 0.27067201137542723, 'mean_batch': 6.1854571342468265, 'min_batch': 5.959610795974731, 'max_batch': 6.404781675338745}
step: 27570 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 1.0549402, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3944732308387757, 'actor_loss': -5.211280345916748, 'hyper_actor_loss': 0.01810715701431036, 'behavior_loss': 0.2734858512878418, 'mean_batch': 6.175051307678222, 'min_batch': 5.937885713577271, 'max_batch': 6.366154146194458}
step: 27580 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.485385, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5590295851230622, 'actor_loss': -5.243682432174682, 'hyper_actor_loss': 0.01818257961422205, 'behavior_loss': 0.26348199546337125, 'mean_batch': 6.2644922733306885, 'min_batch': 6.045956087112427, 'max_batch': 6.419020795822144}
step: 27590 @ episode report: {'average_total_reward': 10.853001, 'reward_variance': 3.3161206, 'max_total_reward': 13.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7424506187438964, 'actor_loss': -5.225346374511719, 'hyper_actor_loss': 0.01775718852877617, 'behavior_loss': 0.25379016548395156, 'mean_batch': 6.213039779663086, 'min_batch': 5.985144519805909, 'max_batch': 6.368541812896728}
step: 27600 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 2.3994043, 'max_total_reward': 13.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8027235150337217, 'actor_loss': -5.209748125076294, 'hyper_actor_loss': 0.0176811708137393, 'behavior_loss': 0.27564391046762465, 'mean_batch': 6.155072498321533, 'min_batch': 5.947973442077637, 'max_batch': 6.318090581893921}
step: 27610 @ episode report: {'average_total_reward': 11.031, 'reward_variance': 3.3794887, 'max_total_reward': 15.34, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0716548919677735, 'actor_loss': -5.191623783111572, 'hyper_actor_loss': 0.017762220464646816, 'behavior_loss': 0.2864089831709862, 'mean_batch': 6.130665254592896, 'min_batch': 5.8649708271026615, 'max_batch': 6.2788714408874515}
step: 27620 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 4.8306365, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.566586899757385, 'actor_loss': -5.222053718566895, 'hyper_actor_loss': 0.018464751355350018, 'behavior_loss': 0.27219279706478117, 'mean_batch': 6.234721374511719, 'min_batch': 5.945467281341553, 'max_batch': 6.39141058921814}
step: 27630 @ episode report: {'average_total_reward': 9.344001, 'reward_variance': 2.8059049, 'max_total_reward': 11.120001, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.387339401245117, 'actor_loss': -5.264350509643554, 'hyper_actor_loss': 0.018549185805022718, 'behavior_loss': 0.269547039270401, 'mean_batch': 6.378238487243652, 'min_batch': 6.062566471099854, 'max_batch': 6.537666082382202}
step: 27640 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 3.0284765, 'max_total_reward': 13.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4320962905883787, 'actor_loss': -5.24175124168396, 'hyper_actor_loss': 0.01843998972326517, 'behavior_loss': 0.2759258717298508, 'mean_batch': 6.290800857543945, 'min_batch': 6.009114456176758, 'max_batch': 6.453257131576538}
step: 27650 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 6.2590203, 'max_total_reward': 12.34, 'min_total_reward': 3.46, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.019446301460266, 'actor_loss': -5.222361612319946, 'hyper_actor_loss': 0.018503346107900144, 'behavior_loss': 0.27329286485910415, 'mean_batch': 6.228357553482056, 'min_batch': 5.953342533111572, 'max_batch': 6.37305850982666}
step: 27660 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 8.758105, 'max_total_reward': 12.34, 'min_total_reward': 2.46, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3688427805900574, 'actor_loss': -5.205413913726806, 'hyper_actor_loss': 0.018378893658518792, 'behavior_loss': 0.2709041401743889, 'mean_batch': 6.149045085906982, 'min_batch': 5.928508043289185, 'max_batch': 6.2932140827178955}
step: 27670 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 3.3065853, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.673398184776306, 'actor_loss': -5.253876352310181, 'hyper_actor_loss': 0.018253112398087978, 'behavior_loss': 0.260981884598732, 'mean_batch': 6.305958700180054, 'min_batch': 6.067732429504394, 'max_batch': 6.506346321105957}
step: 27680 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 2.2012968, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7616174817085266, 'actor_loss': -5.209136438369751, 'hyper_actor_loss': 0.017978011257946493, 'behavior_loss': 0.2591681361198425, 'mean_batch': 6.141100645065308, 'min_batch': 5.958790111541748, 'max_batch': 6.3056511878967285}
step: 27690 @ episode report: {'average_total_reward': 10.009001, 'reward_variance': 8.598551, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.172649586200714, 'actor_loss': -5.220701074600219, 'hyper_actor_loss': 0.017813376151025295, 'behavior_loss': 0.2639710962772369, 'mean_batch': 6.20115065574646, 'min_batch': 5.970139122009277, 'max_batch': 6.392201852798462}
step: 27700 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 11.759457, 'max_total_reward': 14.45, 'min_total_reward': 1.13, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.599924051761627, 'actor_loss': -5.253719472885132, 'hyper_actor_loss': 0.01802111752331257, 'behavior_loss': 0.25963361859321593, 'mean_batch': 6.317040205001831, 'min_batch': 6.056195545196533, 'max_batch': 6.514241647720337}
step: 27710 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 3.7362564, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.531078553199768, 'actor_loss': -5.220237350463867, 'hyper_actor_loss': 0.01812348309904337, 'behavior_loss': 0.2841268241405487, 'mean_batch': 6.18896517753601, 'min_batch': 5.97783465385437, 'max_batch': 6.354085969924927}
step: 27720 @ episode report: {'average_total_reward': 7.878, 'reward_variance': 14.081777, 'max_total_reward': 12.34, 'min_total_reward': 1.1300001, 'average_n_step': 9.0, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.626504325866699, 'actor_loss': -5.234491539001465, 'hyper_actor_loss': 0.01864317264407873, 'behavior_loss': 0.27344106137752533, 'mean_batch': 6.238255548477173, 'min_batch': 6.015826749801636, 'max_batch': 6.392216491699219}
step: 27730 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 3.2303245, 'max_total_reward': 13.339999, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.572047173976898, 'actor_loss': -5.245129632949829, 'hyper_actor_loss': 0.01892753355205059, 'behavior_loss': 0.2763607442378998, 'mean_batch': 6.29404616355896, 'min_batch': 6.02622504234314, 'max_batch': 6.481207799911499}
step: 27740 @ episode report: {'average_total_reward': 11.209002, 'reward_variance': 2.1280093, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.301917141675949, 'actor_loss': -5.255835103988647, 'hyper_actor_loss': 0.019106866046786308, 'behavior_loss': 0.26407657116651534, 'mean_batch': 6.317531967163086, 'min_batch': 6.068477392196655, 'max_batch': 6.490381288528442}
step: 27750 @ episode report: {'average_total_reward': 10.431002, 'reward_variance': 1.5318491, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1029486536979674, 'actor_loss': -5.2730207443237305, 'hyper_actor_loss': 0.019026133976876736, 'behavior_loss': 0.2835381403565407, 'mean_batch': 6.3677905082702635, 'min_batch': 6.125040721893311, 'max_batch': 6.542217874526978}
step: 27760 @ episode report: {'average_total_reward': 10.108999, 'reward_variance': 8.957169, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.541895341873169, 'actor_loss': -5.264153575897216, 'hyper_actor_loss': 0.019291391223669054, 'behavior_loss': 0.27045431137084963, 'mean_batch': 6.332356548309326, 'min_batch': 6.1049110889434814, 'max_batch': 6.5114298343658445}
step: 27770 @ episode report: {'average_total_reward': 10.775, 'reward_variance': 2.5780647, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.695764571428299, 'actor_loss': -5.2581854343414305, 'hyper_actor_loss': 0.019081468880176543, 'behavior_loss': 0.26682464927434923, 'mean_batch': 6.330108165740967, 'min_batch': 6.071111345291138, 'max_batch': 6.51474928855896}
step: 27780 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.3218055, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.627639412879944, 'actor_loss': -5.258779573440552, 'hyper_actor_loss': 0.018778279423713684, 'behavior_loss': 0.27956016212701795, 'mean_batch': 6.330894517898559, 'min_batch': 6.073621654510498, 'max_batch': 6.5601396560668945}
step: 27790 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 1.5811613, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.209301269054413, 'actor_loss': -5.28802809715271, 'hyper_actor_loss': 0.018747956678271293, 'behavior_loss': 0.25857196301221846, 'mean_batch': 6.451887750625611, 'min_batch': 6.137104511260986, 'max_batch': 6.704724502563477}
step: 27800 @ episode report: {'average_total_reward': 9.887001, 'reward_variance': 0.9570211, 'max_total_reward': 11.2300005, 'min_total_reward': 8.900001, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.318064033985138, 'actor_loss': -5.308769989013672, 'hyper_actor_loss': 0.018613359704613686, 'behavior_loss': 0.27751008719205855, 'mean_batch': 6.5078386783599855, 'min_batch': 6.21174693107605, 'max_batch': 6.7482008934021}
step: 27810 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.1317894, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.237162458896637, 'actor_loss': -5.278557205200196, 'hyper_actor_loss': 0.018830873258411884, 'behavior_loss': 0.26455332338809967, 'mean_batch': 6.438302373886108, 'min_batch': 6.0915210247039795, 'max_batch': 6.676204252243042}
step: 27820 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 0.7345646, 'max_total_reward': 11.230001, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8526129961013793, 'actor_loss': -5.29217791557312, 'hyper_actor_loss': 0.01905407030135393, 'behavior_loss': 0.26560087502002716, 'mean_batch': 6.47102837562561, 'min_batch': 6.1438414573669435, 'max_batch': 6.69386887550354}
step: 27830 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 5.082141, 'max_total_reward': 12.34, 'min_total_reward': 5.5699997, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.860561800003052, 'actor_loss': -5.299460697174072, 'hyper_actor_loss': 0.019210092909634113, 'behavior_loss': 0.2770722463726997, 'mean_batch': 6.487732648849487, 'min_batch': 6.172832059860229, 'max_batch': 6.720507669448852}
step: 27840 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 1.6897055, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6944268703460694, 'actor_loss': -5.288881111145019, 'hyper_actor_loss': 0.019439045898616315, 'behavior_loss': 0.27627303898334504, 'mean_batch': 6.443442869186401, 'min_batch': 6.149692344665527, 'max_batch': 6.689178562164306}
step: 27850 @ episode report: {'average_total_reward': 9.033, 'reward_variance': 4.4014015, 'max_total_reward': 12.120001, 'min_total_reward': 5.68, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4501503825187685, 'actor_loss': -5.311132526397705, 'hyper_actor_loss': 0.019774426706135273, 'behavior_loss': 0.27809076458215715, 'mean_batch': 6.506430625915527, 'min_batch': 6.227494144439698, 'max_batch': 6.714230537414551}
step: 27860 @ episode report: {'average_total_reward': 11.775001, 'reward_variance': 2.6610055, 'max_total_reward': 14.450001, 'min_total_reward': 8.79, 'average_n_step': 12.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3641308188438415, 'actor_loss': -5.328269672393799, 'hyper_actor_loss': 0.01954151876270771, 'behavior_loss': 0.2768144741654396, 'mean_batch': 6.550631999969482, 'min_batch': 6.292223358154297, 'max_batch': 6.7585756301879885}
step: 27870 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 4.2259817, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9827858448028564, 'actor_loss': -5.31373233795166, 'hyper_actor_loss': 0.019907921738922595, 'behavior_loss': 0.2722810998558998, 'mean_batch': 6.505899572372437, 'min_batch': 6.244215774536133, 'max_batch': 6.706137847900391}
step: 27880 @ episode report: {'average_total_reward': 9.743, 'reward_variance': 3.857802, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.927148532867432, 'actor_loss': -5.299555826187134, 'hyper_actor_loss': 0.01977507397532463, 'behavior_loss': 0.262168125808239, 'mean_batch': 6.4651689529418945, 'min_batch': 6.194906377792359, 'max_batch': 6.6867440700531}
step: 27890 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.595941, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.202904152870178, 'actor_loss': -5.295401000976563, 'hyper_actor_loss': 0.019393695704638957, 'behavior_loss': 0.28414166420698167, 'mean_batch': 6.45465612411499, 'min_batch': 6.179221963882446, 'max_batch': 6.672569131851196}
step: 27900 @ episode report: {'average_total_reward': 11.5859995, 'reward_variance': 3.0936644, 'max_total_reward': 15.56, 'min_total_reward': 10.009999, 'average_n_step': 12.4, 'max_n_step': 16.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4192036211490633, 'actor_loss': -5.320032835006714, 'hyper_actor_loss': 0.019702607952058315, 'behavior_loss': 0.2698775500059128, 'mean_batch': 6.541317129135132, 'min_batch': 6.2496452808380125, 'max_batch': 6.770190143585205}
step: 27910 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 4.520841, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7219401717185976, 'actor_loss': -5.358422183990479, 'hyper_actor_loss': 0.020027348212897776, 'behavior_loss': 0.27598830312490463, 'mean_batch': 6.6727776527404785, 'min_batch': 6.366173028945923, 'max_batch': 6.896533679962158}
step: 27920 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 3.1863046, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.815691339969635, 'actor_loss': -5.301854848861694, 'hyper_actor_loss': 0.020289894938468934, 'behavior_loss': 0.28204886317253114, 'mean_batch': 6.466757678985596, 'min_batch': 6.2077085971832275, 'max_batch': 6.67807035446167}
step: 27930 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 10.471701, 'max_total_reward': 13.34, 'min_total_reward': 2.13, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.446082428097725, 'actor_loss': -5.315458154678344, 'hyper_actor_loss': 0.0199056638404727, 'behavior_loss': 0.2663999378681183, 'mean_batch': 6.533786344528198, 'min_batch': 6.228570556640625, 'max_batch': 6.7730895519256595}
step: 27940 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 3.088616, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7760881900787355, 'actor_loss': -5.368391418457032, 'hyper_actor_loss': 0.019698121398687363, 'behavior_loss': 0.26529481410980227, 'mean_batch': 6.700995540618896, 'min_batch': 6.4031758308410645, 'max_batch': 6.943199396133423}
step: 27950 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 2.092117, 'max_total_reward': 12.340001, 'min_total_reward': 7.7899995, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.692131280899048, 'actor_loss': -5.3313562870025635, 'hyper_actor_loss': 0.019384687393903734, 'behavior_loss': 0.2795934766530991, 'mean_batch': 6.596944999694824, 'min_batch': 6.268699073791504, 'max_batch': 6.850954627990722}
step: 27960 @ episode report: {'average_total_reward': 9.543, 'reward_variance': 1.4932202, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.633043813705444, 'actor_loss': -5.327702283859253, 'hyper_actor_loss': 0.01975036635994911, 'behavior_loss': 0.27296132147312163, 'mean_batch': 6.570050621032715, 'min_batch': 6.27034707069397, 'max_batch': 6.813775157928466}
step: 27970 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 5.0606966, 'max_total_reward': 14.56, 'min_total_reward': 5.7900004, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6221006512641907, 'actor_loss': -5.359356927871704, 'hyper_actor_loss': 0.019879528880119325, 'behavior_loss': 0.2643746122717857, 'mean_batch': 6.6832905292510985, 'min_batch': 6.362090253829956, 'max_batch': 6.928054666519165}
step: 27980 @ episode report: {'average_total_reward': 9.687, 'reward_variance': 5.559281, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9143019676208497, 'actor_loss': -5.339419984817505, 'hyper_actor_loss': 0.019417687132954598, 'behavior_loss': 0.24875643402338027, 'mean_batch': 6.58934760093689, 'min_batch': 6.325467157363891, 'max_batch': 6.807621335983276}
step: 27990 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 3.894024, 'max_total_reward': 13.23, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8342400014400484, 'actor_loss': -5.322393465042114, 'hyper_actor_loss': 0.019106431305408476, 'behavior_loss': 0.26979877799749374, 'mean_batch': 6.52093276977539, 'min_batch': 6.2838287353515625, 'max_batch': 6.78644323348999}
step: 28000 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 3.4036202, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9670862197875976, 'actor_loss': -5.329412889480591, 'hyper_actor_loss': 0.019136842153966428, 'behavior_loss': 0.2801771655678749, 'mean_batch': 6.57472596168518, 'min_batch': 6.276424694061279, 'max_batch': 6.805275917053223}
step: 28010 @ episode report: {'average_total_reward': 10.5199995, 'reward_variance': 2.9042008, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.866692465543747, 'actor_loss': -5.323988199234009, 'hyper_actor_loss': 0.019347785599529745, 'behavior_loss': 0.27853899598121645, 'mean_batch': 6.556323766708374, 'min_batch': 6.260058975219726, 'max_batch': 6.802807283401489}
step: 28020 @ episode report: {'average_total_reward': 11.386001, 'reward_variance': 5.245124, 'max_total_reward': 14.45, 'min_total_reward': 6.9, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3997963428497315, 'actor_loss': -5.332116889953613, 'hyper_actor_loss': 0.019630244001746178, 'behavior_loss': 0.27967295199632647, 'mean_batch': 6.59473295211792, 'min_batch': 6.2743383884429935, 'max_batch': 6.842407083511352}
step: 28030 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 3.9648643, 'max_total_reward': 14.450001, 'min_total_reward': 7.68, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7372840285301208, 'actor_loss': -5.336071252822876, 'hyper_actor_loss': 0.01994178257882595, 'behavior_loss': 0.2699815571308136, 'mean_batch': 6.574254035949707, 'min_batch': 6.318876838684082, 'max_batch': 6.859724235534668}
step: 28040 @ episode report: {'average_total_reward': 10.264999, 'reward_variance': 5.940465, 'max_total_reward': 14.450001, 'min_total_reward': 5.46, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9604952573776244, 'actor_loss': -5.371862411499023, 'hyper_actor_loss': 0.01959459315985441, 'behavior_loss': 0.2696445122361183, 'mean_batch': 6.753874254226685, 'min_batch': 6.375130748748779, 'max_batch': 7.075739908218384}
step: 28050 @ episode report: {'average_total_reward': 9.465001, 'reward_variance': 3.0999653, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.492496740818024, 'actor_loss': -5.358023977279663, 'hyper_actor_loss': 0.0192214110866189, 'behavior_loss': 0.26556198596954345, 'mean_batch': 6.679207134246826, 'min_batch': 6.3576939582824705, 'max_batch': 6.955022287368775}
step: 28060 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 1.5254091, 'max_total_reward': 11.120001, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8039201378822325, 'actor_loss': -5.386016702651977, 'hyper_actor_loss': 0.01932531539350748, 'behavior_loss': 0.2882767289876938, 'mean_batch': 6.770673322677612, 'min_batch': 6.44940676689148, 'max_batch': 7.05735502243042}
step: 28070 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 1.0566642, 'max_total_reward': 12.2300005, 'min_total_reward': 8.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.095170760154724, 'actor_loss': -5.365608882904053, 'hyper_actor_loss': 0.019512216746807098, 'behavior_loss': 0.279042686522007, 'mean_batch': 6.716368961334228, 'min_batch': 6.3706183433532715, 'max_batch': 6.987266492843628}
step: 28080 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 3.1844013, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.045656132698059, 'actor_loss': -5.3383056640625, 'hyper_actor_loss': 0.01956802550703287, 'behavior_loss': 0.27625380307435987, 'mean_batch': 6.614681959152222, 'min_batch': 6.294504308700562, 'max_batch': 6.917616701126098}
step: 28090 @ episode report: {'average_total_reward': 10.675001, 'reward_variance': 4.0822244, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1190850675106048, 'actor_loss': -5.395814514160156, 'hyper_actor_loss': 0.019255611300468444, 'behavior_loss': 0.2631741985678673, 'mean_batch': 6.800631284713745, 'min_batch': 6.485740280151367, 'max_batch': 7.102623128890992}
step: 28100 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 1.1092412, 'max_total_reward': 11.2300005, 'min_total_reward': 7.7899995, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4692861318588255, 'actor_loss': -5.423851060867309, 'hyper_actor_loss': 0.018756712414324285, 'behavior_loss': 0.26049557626247405, 'mean_batch': 6.896380186080933, 'min_batch': 6.5763026714324955, 'max_batch': 7.1820971965789795}
step: 28110 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 4.6386967, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1240266799926757, 'actor_loss': -5.365894794464111, 'hyper_actor_loss': 0.018530362658202647, 'behavior_loss': 0.28114757090806963, 'mean_batch': 6.696954154968262, 'min_batch': 6.391524696350098, 'max_batch': 7.022887134552002}
step: 28120 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 4.0974565, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2676646232604982, 'actor_loss': -5.3373414993286135, 'hyper_actor_loss': 0.01882242541760206, 'behavior_loss': 0.2722213178873062, 'mean_batch': 6.602409315109253, 'min_batch': 6.300053882598877, 'max_batch': 6.90227575302124}
step: 28130 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 2.5344691, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8508857250213624, 'actor_loss': -5.377468299865723, 'hyper_actor_loss': 0.0187981303781271, 'behavior_loss': 0.27405114471912384, 'mean_batch': 6.757822895050049, 'min_batch': 6.407247304916382, 'max_batch': 7.072768306732177}
step: 28140 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 4.574605, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6866907358169554, 'actor_loss': -5.392906332015992, 'hyper_actor_loss': 0.01883972380310297, 'behavior_loss': 0.2718475893139839, 'mean_batch': 6.831262826919556, 'min_batch': 6.437140274047851, 'max_batch': 7.1779907703399655}
step: 28150 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 3.1971288, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2111037135124207, 'actor_loss': -5.396475124359131, 'hyper_actor_loss': 0.01867925189435482, 'behavior_loss': 0.26552733182907107, 'mean_batch': 6.848162698745727, 'min_batch': 6.443821144104004, 'max_batch': 7.234311723709107}
step: 28160 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 11.769625, 'max_total_reward': 14.56, 'min_total_reward': 2.24, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.278312420845032, 'actor_loss': -5.339744710922242, 'hyper_actor_loss': 0.018687529116868974, 'behavior_loss': 0.27376976907253264, 'mean_batch': 6.6166829586029055, 'min_batch': 6.302183055877686, 'max_batch': 6.983218193054199}
step: 28170 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.7832642, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6316330075263976, 'actor_loss': -5.385076713562012, 'hyper_actor_loss': 0.018526526726782323, 'behavior_loss': 0.26996878534555435, 'mean_batch': 6.796668767929077, 'min_batch': 6.42073540687561, 'max_batch': 7.1682905673980715}
step: 28180 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 2.237545, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9674272656440737, 'actor_loss': -5.422905349731446, 'hyper_actor_loss': 0.018452255614101888, 'behavior_loss': 0.27863395065069196, 'mean_batch': 6.906641626358033, 'min_batch': 6.560234498977661, 'max_batch': 7.260046100616455}
step: 28190 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 4.128386, 'max_total_reward': 13.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.265565538406372, 'actor_loss': -5.350558757781982, 'hyper_actor_loss': 0.01861413288861513, 'behavior_loss': 0.2760969951748848, 'mean_batch': 6.652377557754517, 'min_batch': 6.3370050430297855, 'max_batch': 6.961696910858154}
step: 28200 @ episode report: {'average_total_reward': 11.097, 'reward_variance': 2.2280412, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.066355991363525, 'actor_loss': -5.331244230270386, 'hyper_actor_loss': 0.018598273396492004, 'behavior_loss': 0.2847323030233383, 'mean_batch': 6.580946254730224, 'min_batch': 6.282191133499145, 'max_batch': 6.882472515106201}
step: 28210 @ episode report: {'average_total_reward': 11.1640005, 'reward_variance': 6.7948837, 'max_total_reward': 14.56, 'min_total_reward': 4.6800003, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5724130392074587, 'actor_loss': -5.375739479064942, 'hyper_actor_loss': 0.018429713509976863, 'behavior_loss': 0.27585613280534743, 'mean_batch': 6.725564241409302, 'min_batch': 6.426383972167969, 'max_batch': 7.006379270553589}
step: 28220 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 1.1901693, 'max_total_reward': 10.120001, 'min_total_reward': 6.9, 'average_n_step': 10.3, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.505498480796814, 'actor_loss': -5.358114242553711, 'hyper_actor_loss': 0.018416788801550864, 'behavior_loss': 0.2739257201552391, 'mean_batch': 6.664417791366577, 'min_batch': 6.372255754470825, 'max_batch': 6.931006956100464}
step: 28230 @ episode report: {'average_total_reward': 10.643001, 'reward_variance': 2.0744014, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7899995, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1877846240997316, 'actor_loss': -5.343640899658203, 'hyper_actor_loss': 0.018327921442687512, 'behavior_loss': 0.27768787890672686, 'mean_batch': 6.608920049667359, 'min_batch': 6.3334705352783205, 'max_batch': 6.866477632522583}
step: 28240 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 6.0186152, 'max_total_reward': 14.45, 'min_total_reward': 4.6800003, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3686959505081178, 'actor_loss': -5.365715885162354, 'hyper_actor_loss': 0.018160180002450944, 'behavior_loss': 0.27042938619852064, 'mean_batch': 6.712086343765259, 'min_batch': 6.375353384017944, 'max_batch': 6.972571134567261}
step: 28250 @ episode report: {'average_total_reward': 9.432, 'reward_variance': 9.517256, 'max_total_reward': 15.56, 'min_total_reward': 4.5699997, 'average_n_step': 10.4, 'max_n_step': 16.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8964328527450562, 'actor_loss': -5.368498134613037, 'hyper_actor_loss': 0.018248476088047028, 'behavior_loss': 0.286750128865242, 'mean_batch': 6.744264364242554, 'min_batch': 6.362644481658935, 'max_batch': 7.024376964569091}
step: 28260 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 4.093796, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2811917066574097, 'actor_loss': -5.387352180480957, 'hyper_actor_loss': 0.01831972748041153, 'behavior_loss': 0.2806779831647873, 'mean_batch': 6.774349880218506, 'min_batch': 6.454934120178223, 'max_batch': 7.047468090057373}
step: 28270 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 8.655122, 'max_total_reward': 14.560001, 'min_total_reward': 2.3500001, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1680320262908936, 'actor_loss': -5.374433898925782, 'hyper_actor_loss': 0.018693735636770726, 'behavior_loss': 0.2881349503993988, 'mean_batch': 6.7360223770141605, 'min_batch': 6.408057594299317, 'max_batch': 7.000116062164307}
step: 28280 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 4.2860446, 'max_total_reward': 13.45, 'min_total_reward': 7.5699997, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.298391306400299, 'actor_loss': -5.391565990447998, 'hyper_actor_loss': 0.018983975611627103, 'behavior_loss': 0.2904371306300163, 'mean_batch': 6.780977201461792, 'min_batch': 6.4757184982299805, 'max_batch': 7.034554481506348}
step: 28290 @ episode report: {'average_total_reward': 9.466001, 'reward_variance': 2.4827836, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5762988567352294, 'actor_loss': -5.348773527145386, 'hyper_actor_loss': 0.01889215223491192, 'behavior_loss': 0.27652580142021177, 'mean_batch': 6.634987020492554, 'min_batch': 6.341066884994507, 'max_batch': 6.882946014404297}
step: 28300 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 2.707337, 'max_total_reward': 13.010001, 'min_total_reward': 7.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.863620972633362, 'actor_loss': -5.357618141174316, 'hyper_actor_loss': 0.01886049434542656, 'behavior_loss': 0.27694797813892363, 'mean_batch': 6.684285354614258, 'min_batch': 6.351905822753906, 'max_batch': 6.952978420257568}
step: 28310 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 5.121382, 'max_total_reward': 13.340001, 'min_total_reward': 5.7899995, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1531871914863587, 'actor_loss': -5.4150793075561525, 'hyper_actor_loss': 0.01821232624351978, 'behavior_loss': 0.2743144005537033, 'mean_batch': 6.850270795822143, 'min_batch': 6.562601566314697, 'max_batch': 7.1281860828399655}
step: 28320 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 2.3269649, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9766833186149597, 'actor_loss': -5.398955345153809, 'hyper_actor_loss': 0.017995181120932104, 'behavior_loss': 0.27327319979667664, 'mean_batch': 6.809114027023315, 'min_batch': 6.4965699195861815, 'max_batch': 7.0792265892028805}
step: 28330 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 6.3049293, 'max_total_reward': 11.2300005, 'min_total_reward': 2.35, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.98694531917572, 'actor_loss': -5.372557497024536, 'hyper_actor_loss': 0.01793857291340828, 'behavior_loss': 0.2810333281755447, 'mean_batch': 6.732614421844483, 'min_batch': 6.399596929550171, 'max_batch': 7.006832790374756}
step: 28340 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 2.889336, 'max_total_reward': 13.450001, 'min_total_reward': 7.9000006, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.617277717590332, 'actor_loss': -5.3418535709381105, 'hyper_actor_loss': 0.01816162895411253, 'behavior_loss': 0.27612304538488386, 'mean_batch': 6.635769033432007, 'min_batch': 6.29659857749939, 'max_batch': 6.915299606323242}
step: 28350 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 2.8105168, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.105246162414551, 'actor_loss': -5.371603155136109, 'hyper_actor_loss': 0.017928516119718553, 'behavior_loss': 0.2591322049498558, 'mean_batch': 6.721661853790283, 'min_batch': 6.403813266754151, 'max_batch': 7.073703384399414}
step: 28360 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.7313839, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6418458580970765, 'actor_loss': -5.370220708847046, 'hyper_actor_loss': 0.017542108707129956, 'behavior_loss': 0.2737471327185631, 'mean_batch': 6.744189357757568, 'min_batch': 6.3737763404846195, 'max_batch': 7.105968284606933}
step: 28370 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 4.8968816, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.679853093624115, 'actor_loss': -5.358701992034912, 'hyper_actor_loss': 0.017341554164886475, 'behavior_loss': 0.2735900431871414, 'mean_batch': 6.691122102737427, 'min_batch': 6.350340270996094, 'max_batch': 7.000297546386719}
step: 28380 @ episode report: {'average_total_reward': 8.977, 'reward_variance': 2.5739017, 'max_total_reward': 11.120001, 'min_total_reward': 5.79, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.297788608074188, 'actor_loss': -5.388378667831421, 'hyper_actor_loss': 0.01735539808869362, 'behavior_loss': 0.2924281805753708, 'mean_batch': 6.791712522506714, 'min_batch': 6.445177412033081, 'max_batch': 7.112870121002198}
step: 28390 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 3.460236, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3879333972930907, 'actor_loss': -5.3379181861877445, 'hyper_actor_loss': 0.01766361463814974, 'behavior_loss': 0.2645109951496124, 'mean_batch': 6.6211646556854244, 'min_batch': 6.2861167907714846, 'max_batch': 6.927122020721436}
step: 28400 @ episode report: {'average_total_reward': 8.922, 'reward_variance': 5.010856, 'max_total_reward': 11.2300005, 'min_total_reward': 4.57, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8756078243255616, 'actor_loss': -5.3878154277801515, 'hyper_actor_loss': 0.017488103918731214, 'behavior_loss': 0.27350314557552335, 'mean_batch': 6.768971109390259, 'min_batch': 6.4631993770599365, 'max_batch': 7.065536594390869}
step: 28410 @ episode report: {'average_total_reward': 11.253, 'reward_variance': 1.2252007, 'max_total_reward': 13.23, 'min_total_reward': 10.12, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.245825695991516, 'actor_loss': -5.397849178314209, 'hyper_actor_loss': 0.01743013095110655, 'behavior_loss': 0.2570738434791565, 'mean_batch': 6.838339185714721, 'min_batch': 6.4619396209716795, 'max_batch': 7.1812217235565186}
step: 28420 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 3.7978606, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8977765083312987, 'actor_loss': -5.377009868621826, 'hyper_actor_loss': 0.017118556052446367, 'behavior_loss': 0.26699601113796234, 'mean_batch': 6.773740291595459, 'min_batch': 6.389050245285034, 'max_batch': 7.082345390319825}
step: 28430 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 4.1232243, 'max_total_reward': 13.339999, 'min_total_reward': 6.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3755728721618654, 'actor_loss': -5.372716760635376, 'hyper_actor_loss': 0.016740695387125016, 'behavior_loss': 0.2605723008513451, 'mean_batch': 6.750879144668579, 'min_batch': 6.383520174026489, 'max_batch': 7.055666828155518}
step: 28440 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 3.6754603, 'max_total_reward': 14.450001, 'min_total_reward': 6.7899995, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7560741305351257, 'actor_loss': -5.3715626239776615, 'hyper_actor_loss': 0.016746135242283345, 'behavior_loss': 0.2739830106496811, 'mean_batch': 6.733398485183716, 'min_batch': 6.392430305480957, 'max_batch': 7.047939920425415}
step: 28450 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 4.6367197, 'max_total_reward': 11.120001, 'min_total_reward': 3.46, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8116501331329347, 'actor_loss': -5.402118873596192, 'hyper_actor_loss': 0.01682621017098427, 'behavior_loss': 0.26916883885860443, 'mean_batch': 6.849637365341186, 'min_batch': 6.47929277420044, 'max_batch': 7.197084093093872}
step: 28460 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 3.869604, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.941106152534485, 'actor_loss': -5.365221881866455, 'hyper_actor_loss': 0.01692840177565813, 'behavior_loss': 0.2771695479750633, 'mean_batch': 6.706242227554322, 'min_batch': 6.377395343780518, 'max_batch': 7.028073835372925}
step: 28470 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 4.60746, 'max_total_reward': 13.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1890780448913576, 'actor_loss': -5.343117666244507, 'hyper_actor_loss': 0.017250563763082028, 'behavior_loss': 0.279739972949028, 'mean_batch': 6.614703130722046, 'min_batch': 6.324507236480713, 'max_batch': 6.908304643630982}
step: 28480 @ episode report: {'average_total_reward': 10.443001, 'reward_variance': 3.668441, 'max_total_reward': 13.34, 'min_total_reward': 7.68, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4028365135192873, 'actor_loss': -5.357256984710693, 'hyper_actor_loss': 0.01757733430713415, 'behavior_loss': 0.28642556965351107, 'mean_batch': 6.650263261795044, 'min_batch': 6.380273771286011, 'max_batch': 6.927950716018676}
step: 28490 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 1.4844491, 'max_total_reward': 12.23, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7261098325252533, 'actor_loss': -5.370987462997436, 'hyper_actor_loss': 0.01730800364166498, 'behavior_loss': 0.2748243108391762, 'mean_batch': 6.708570337295532, 'min_batch': 6.412373781204224, 'max_batch': 6.98925518989563}
step: 28500 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 0.5211412, 'max_total_reward': 11.120001, 'min_total_reward': 9.01, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9866863250732423, 'actor_loss': -5.369438171386719, 'hyper_actor_loss': 0.016636268608272074, 'behavior_loss': 0.2831351414322853, 'mean_batch': 6.716907930374146, 'min_batch': 6.394552278518677, 'max_batch': 7.024308967590332}
step: 28510 @ episode report: {'average_total_reward': 10.266001, 'reward_variance': 3.2035832, 'max_total_reward': 14.559999, 'min_total_reward': 7.5699997, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6269912123680115, 'actor_loss': -5.377405071258545, 'hyper_actor_loss': 0.01626775208860636, 'behavior_loss': 0.27015806883573534, 'mean_batch': 6.749337100982666, 'min_batch': 6.4144354343414305, 'max_batch': 7.049157762527466}
step: 28520 @ episode report: {'average_total_reward': 10.132, 'reward_variance': 1.5416361, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.171482789516449, 'actor_loss': -5.378801250457764, 'hyper_actor_loss': 0.016477295197546482, 'behavior_loss': 0.2672723338007927, 'mean_batch': 6.763579845428467, 'min_batch': 6.410401630401611, 'max_batch': 7.078778409957886}
step: 28530 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 1.3424617, 'max_total_reward': 12.2300005, 'min_total_reward': 8.789999, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6278162956237794, 'actor_loss': -5.282627964019776, 'hyper_actor_loss': 0.01615318823605776, 'behavior_loss': 0.2528555437922478, 'mean_batch': 6.439880466461181, 'min_batch': 6.115004777908325, 'max_batch': 6.7138285636901855}
step: 28540 @ episode report: {'average_total_reward': 8.788, 'reward_variance': 5.9987974, 'max_total_reward': 13.450001, 'min_total_reward': 4.68, 'average_n_step': 9.8, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0125813722610473, 'actor_loss': -5.323178386688232, 'hyper_actor_loss': 0.01588943097740412, 'behavior_loss': 0.28038289248943327, 'mean_batch': 6.575739097595215, 'min_batch': 6.237710332870483, 'max_batch': 6.8586678981781}
step: 28550 @ episode report: {'average_total_reward': 9.821, 'reward_variance': 3.0076885, 'max_total_reward': 12.339999, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.672195553779602, 'actor_loss': -5.354180860519409, 'hyper_actor_loss': 0.015965949278324842, 'behavior_loss': 0.2709088623523712, 'mean_batch': 6.697034692764282, 'min_batch': 6.31661958694458, 'max_batch': 7.002285480499268}
step: 28560 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 2.9898086, 'max_total_reward': 12.23, 'min_total_reward': 6.57, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9501535296440125, 'actor_loss': -5.350412225723266, 'hyper_actor_loss': 0.016375970095396042, 'behavior_loss': 0.2865118682384491, 'mean_batch': 6.681334495544434, 'min_batch': 6.307206392288208, 'max_batch': 6.978936052322387}
step: 28570 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 3.19175, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7119404077529907, 'actor_loss': -5.387111186981201, 'hyper_actor_loss': 0.01695961654186249, 'behavior_loss': 0.28619585931301117, 'mean_batch': 6.828800678253174, 'min_batch': 6.402536344528198, 'max_batch': 7.133875036239624}
step: 28580 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 0.7373086, 'max_total_reward': 12.339999, 'min_total_reward': 9.01, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.132550811767578, 'actor_loss': -5.342782115936279, 'hyper_actor_loss': 0.016962165758013726, 'behavior_loss': 0.27629261314868925, 'mean_batch': 6.683961057662964, 'min_batch': 6.257028007507325, 'max_batch': 7.0357951641082765}
step: 28590 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 4.417955, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.979347550868988, 'actor_loss': -5.403450870513916, 'hyper_actor_loss': 0.01652846485376358, 'behavior_loss': 0.2675002008676529, 'mean_batch': 6.87178521156311, 'min_batch': 6.466940116882324, 'max_batch': 7.1750936031341555}
step: 28600 @ episode report: {'average_total_reward': 11.586, 'reward_variance': 5.8018637, 'max_total_reward': 16.779999, 'min_total_reward': 7.79, 'average_n_step': 12.4, 'max_n_step': 17.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.721867489814758, 'actor_loss': -5.4089196681976315, 'hyper_actor_loss': 0.016367766819894315, 'behavior_loss': 0.25394503623247144, 'mean_batch': 6.895204401016235, 'min_batch': 6.480276966094971, 'max_batch': 7.196810722351074}
step: 28610 @ episode report: {'average_total_reward': 10.775001, 'reward_variance': 2.5536454, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.158725380897522, 'actor_loss': -5.386915016174316, 'hyper_actor_loss': 0.01621692916378379, 'behavior_loss': 0.2724968805909157, 'mean_batch': 6.800354528427124, 'min_batch': 6.427429628372193, 'max_batch': 7.123683023452759}
step: 28620 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.0891037, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.977510416507721, 'actor_loss': -5.380018091201782, 'hyper_actor_loss': 0.016194742545485495, 'behavior_loss': 0.27174071222543716, 'mean_batch': 6.768398571014404, 'min_batch': 6.413267755508423, 'max_batch': 7.07651686668396}
step: 28630 @ episode report: {'average_total_reward': 11.264, 'reward_variance': 2.1311438, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.387992763519287, 'actor_loss': -5.376656150817871, 'hyper_actor_loss': 0.01613759621977806, 'behavior_loss': 0.2706684410572052, 'mean_batch': 6.750867605209351, 'min_batch': 6.408487701416016, 'max_batch': 7.030437231063843}
step: 28640 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 5.574425, 'max_total_reward': 12.2300005, 'min_total_reward': 3.35, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9605866432189942, 'actor_loss': -5.361503648757934, 'hyper_actor_loss': 0.015940098464488982, 'behavior_loss': 0.25714778155088425, 'mean_batch': 6.6891522884368895, 'min_batch': 6.370297288894653, 'max_batch': 6.952327537536621}
step: 28650 @ episode report: {'average_total_reward': 11.442, 'reward_variance': 3.1630359, 'max_total_reward': 14.559999, 'min_total_reward': 7.79, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8135617852210997, 'actor_loss': -5.3871410369873045, 'hyper_actor_loss': 0.015996791049838067, 'behavior_loss': 0.2704336017370224, 'mean_batch': 6.765478467941284, 'min_batch': 6.461652851104736, 'max_batch': 7.0580566883087155}
step: 28660 @ episode report: {'average_total_reward': 10.853, 'reward_variance': 4.6214805, 'max_total_reward': 13.450001, 'min_total_reward': 5.6800003, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.17642058134079, 'actor_loss': -5.356425523757935, 'hyper_actor_loss': 0.01563497241586447, 'behavior_loss': 0.28195017725229266, 'mean_batch': 6.674394798278809, 'min_batch': 6.352101850509643, 'max_batch': 6.956586694717407}
step: 28670 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 1.9837803, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.400367039442062, 'actor_loss': -5.325242280960083, 'hyper_actor_loss': 0.015652294736355543, 'behavior_loss': 0.2868813812732697, 'mean_batch': 6.564260673522949, 'min_batch': 6.260402250289917, 'max_batch': 6.851514911651611}
step: 28680 @ episode report: {'average_total_reward': 9.754, 'reward_variance': 7.3879037, 'max_total_reward': 13.45, 'min_total_reward': 2.35, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.244809556007385, 'actor_loss': -5.340723514556885, 'hyper_actor_loss': 0.015977270994335414, 'behavior_loss': 0.26434596329927446, 'mean_batch': 6.623851919174195, 'min_batch': 6.300742340087891, 'max_batch': 6.944010257720947}
step: 28690 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 5.4451227, 'max_total_reward': 13.12, 'min_total_reward': 4.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1704925894737244, 'actor_loss': -5.355017948150635, 'hyper_actor_loss': 0.015975130163133143, 'behavior_loss': 0.2883154258131981, 'mean_batch': 6.673106527328491, 'min_batch': 6.344313287734986, 'max_batch': 7.019330978393555}
step: 28700 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 2.4699292, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.381284308433533, 'actor_loss': -5.342295217514038, 'hyper_actor_loss': 0.01620842106640339, 'behavior_loss': 0.27087567150592806, 'mean_batch': 6.6324379444122314, 'min_batch': 6.30243935585022, 'max_batch': 6.898808526992798}
step: 28710 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 5.014636, 'max_total_reward': 14.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.910974407196045, 'actor_loss': -5.3424805164337155, 'hyper_actor_loss': 0.01604229100048542, 'behavior_loss': 0.27607393115758894, 'mean_batch': 6.635967779159546, 'min_batch': 6.300464057922364, 'max_batch': 6.9250133514404295}
step: 28720 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 1.9642432, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2368150472640993, 'actor_loss': -5.3854756355285645, 'hyper_actor_loss': 0.01614457881078124, 'behavior_loss': 0.25542755275964735, 'mean_batch': 6.809272432327271, 'min_batch': 6.409883499145508, 'max_batch': 7.111964893341065}
step: 28730 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 3.119096, 'max_total_reward': 13.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.955074143409729, 'actor_loss': -5.333018350601196, 'hyper_actor_loss': 0.016229075938463212, 'behavior_loss': 0.26941089928150175, 'mean_batch': 6.60901141166687, 'min_batch': 6.26640248298645, 'max_batch': 6.949963569641113}
step: 28740 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 3.6286006, 'max_total_reward': 13.23, 'min_total_reward': 6.46, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.796730089187622, 'actor_loss': -5.382326412200928, 'hyper_actor_loss': 0.016135603189468384, 'behavior_loss': 0.27635773122310636, 'mean_batch': 6.735733938217163, 'min_batch': 6.459859418869018, 'max_batch': 7.019977283477783}
step: 28750 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.4203207, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4647121667861938, 'actor_loss': -5.382091331481933, 'hyper_actor_loss': 0.016275836899876595, 'behavior_loss': 0.27344347089529036, 'mean_batch': 6.752961444854736, 'min_batch': 6.4411839008331295, 'max_batch': 7.067434167861938}
step: 28760 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 7.988566, 'max_total_reward': 16.78, 'min_total_reward': 6.7899995, 'average_n_step': 12.0, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4463337421417237, 'actor_loss': -5.337341451644898, 'hyper_actor_loss': 0.016423897445201875, 'behavior_loss': 0.2672071442008018, 'mean_batch': 6.596200227737427, 'min_batch': 6.305939483642578, 'max_batch': 6.84476900100708}
step: 28770 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 4.1097493, 'max_total_reward': 13.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3454825639724732, 'actor_loss': -5.314956188201904, 'hyper_actor_loss': 0.016445500031113624, 'behavior_loss': 0.29046485424041746, 'mean_batch': 6.5370958805084225, 'min_batch': 6.221948194503784, 'max_batch': 6.841291713714599}
step: 28780 @ episode report: {'average_total_reward': 10.432001, 'reward_variance': 1.8346369, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3975561618804933, 'actor_loss': -5.3396180152893065, 'hyper_actor_loss': 0.016477434337139128, 'behavior_loss': 0.2831213191151619, 'mean_batch': 6.615441417694091, 'min_batch': 6.301551294326782, 'max_batch': 6.958802938461304}
step: 28790 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.6635842, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0190916538238524, 'actor_loss': -5.345894861221313, 'hyper_actor_loss': 0.01617196509614587, 'behavior_loss': 0.26981944143772124, 'mean_batch': 6.648767185211182, 'min_batch': 6.309604167938232, 'max_batch': 7.065812301635742}
step: 28800 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 2.4153557, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9900187492370605, 'actor_loss': -5.364205265045166, 'hyper_actor_loss': 0.016112007200717926, 'behavior_loss': 0.27451226860284805, 'mean_batch': 6.698050451278687, 'min_batch': 6.379849290847778, 'max_batch': 7.1060247898101805}
step: 28810 @ episode report: {'average_total_reward': 9.754, 'reward_variance': 6.6754847, 'max_total_reward': 14.56, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.064564752578735, 'actor_loss': -5.312414360046387, 'hyper_actor_loss': 0.01604226594790816, 'behavior_loss': 0.28210827261209487, 'mean_batch': 6.526200866699218, 'min_batch': 6.2163403034210205, 'max_batch': 6.865941572189331}
step: 28820 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 1.433761, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.93476345539093, 'actor_loss': -5.333095455169678, 'hyper_actor_loss': 0.01602373654022813, 'behavior_loss': 0.26314251869916916, 'mean_batch': 6.62362756729126, 'min_batch': 6.2529912948608395, 'max_batch': 7.085626840591431}
step: 28830 @ episode report: {'average_total_reward': 10.5199995, 'reward_variance': 4.3583, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.833669877052307, 'actor_loss': -5.338842916488647, 'hyper_actor_loss': 0.01596737001091242, 'behavior_loss': 0.26717121452093123, 'mean_batch': 6.6413195610046385, 'min_batch': 6.2724024772644045, 'max_batch': 7.00632152557373}
step: 28840 @ episode report: {'average_total_reward': 11.63, 'reward_variance': 4.7488203, 'max_total_reward': 15.67, 'min_total_reward': 6.79, 'average_n_step': 12.4, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.570726776123047, 'actor_loss': -5.357668876647949, 'hyper_actor_loss': 0.015413366723805666, 'behavior_loss': 0.28395929634571077, 'mean_batch': 6.692335987091065, 'min_batch': 6.342693424224853, 'max_batch': 7.019298458099366}
step: 28850 @ episode report: {'average_total_reward': 10.409001, 'reward_variance': 2.5842097, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.976514744758606, 'actor_loss': -5.352043676376343, 'hyper_actor_loss': 0.015137097146362067, 'behavior_loss': 0.2488481506705284, 'mean_batch': 6.667630004882812, 'min_batch': 6.330946969985962, 'max_batch': 6.9604755401611325}
step: 28860 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 3.0650887, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7314669251441956, 'actor_loss': -5.338181591033935, 'hyper_actor_loss': 0.015129318926483393, 'behavior_loss': 0.27283081263303754, 'mean_batch': 6.63228325843811, 'min_batch': 6.276861953735351, 'max_batch': 6.920684576034546}
step: 28870 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 0.9980996, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9000006, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0207634210586547, 'actor_loss': -5.355409812927246, 'hyper_actor_loss': 0.01523549472913146, 'behavior_loss': 0.2557772621512413, 'mean_batch': 6.679742908477783, 'min_batch': 6.340382051467896, 'max_batch': 6.938148546218872}
step: 28880 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 6.2685347, 'max_total_reward': 14.559999, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9547876715660095, 'actor_loss': -5.331480550765991, 'hyper_actor_loss': 0.015092863887548446, 'behavior_loss': 0.26109858602285385, 'mean_batch': 6.602073335647583, 'min_batch': 6.263369512557984, 'max_batch': 6.9959478855133055}
step: 28890 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 7.926484, 'max_total_reward': 13.340001, 'min_total_reward': 2.46, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.16540949344635, 'actor_loss': -5.285736751556397, 'hyper_actor_loss': 0.015107328444719315, 'behavior_loss': 0.2653454810380936, 'mean_batch': 6.44093132019043, 'min_batch': 6.133016538619995, 'max_batch': 6.788718223571777}
step: 28900 @ episode report: {'average_total_reward': 11.097002, 'reward_variance': 2.4234009, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.477705442905426, 'actor_loss': -5.303531503677368, 'hyper_actor_loss': 0.015438711829483509, 'behavior_loss': 0.2762647733092308, 'mean_batch': 6.488975191116333, 'min_batch': 6.197612524032593, 'max_batch': 6.793592309951782}
step: 28910 @ episode report: {'average_total_reward': 9.8880005, 'reward_variance': 0.88531655, 'max_total_reward': 11.2300005, 'min_total_reward': 8.679999, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.413612115383148, 'actor_loss': -5.355967426300049, 'hyper_actor_loss': 0.015628742147237064, 'behavior_loss': 0.28719316571950915, 'mean_batch': 6.668086862564087, 'min_batch': 6.355162668228149, 'max_batch': 6.9860435962677006}
step: 28920 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 3.8390648, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6531484603881834, 'actor_loss': -5.312706232070923, 'hyper_actor_loss': 0.015916256792843343, 'behavior_loss': 0.274550749361515, 'mean_batch': 6.518928146362304, 'min_batch': 6.2262770652771, 'max_batch': 6.831846427917481}
step: 28930 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 4.5279403, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.313049340248108, 'actor_loss': -5.265371227264405, 'hyper_actor_loss': 0.016032500378787517, 'behavior_loss': 0.28170585036277773, 'mean_batch': 6.359848165512085, 'min_batch': 6.085830163955689, 'max_batch': 6.764899063110351}
step: 28940 @ episode report: {'average_total_reward': 10.509, 'reward_variance': 1.4113483, 'max_total_reward': 12.339999, 'min_total_reward': 7.680001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.596835398674011, 'actor_loss': -5.312637519836426, 'hyper_actor_loss': 0.016359230689704417, 'behavior_loss': 0.2643288806080818, 'mean_batch': 6.549726104736328, 'min_batch': 6.196314716339112, 'max_batch': 6.992352437973023}
step: 28950 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 1.5382041, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2957903265953066, 'actor_loss': -5.301793766021729, 'hyper_actor_loss': 0.016093011386692523, 'behavior_loss': 0.26998245269060134, 'mean_batch': 6.538361692428589, 'min_batch': 6.140225982666015, 'max_batch': 6.8918062210083}
step: 28960 @ episode report: {'average_total_reward': 11.075001, 'reward_variance': 4.715165, 'max_total_reward': 14.56, 'min_total_reward': 6.9000006, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.687925064563751, 'actor_loss': -5.2801032066345215, 'hyper_actor_loss': 0.015763277560472487, 'behavior_loss': 0.27168606221675873, 'mean_batch': 6.41757984161377, 'min_batch': 6.121011018753052, 'max_batch': 6.774172735214234}
step: 28970 @ episode report: {'average_total_reward': 9.997999, 'reward_variance': 4.671836, 'max_total_reward': 13.450001, 'min_total_reward': 6.9000006, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.219064545631409, 'actor_loss': -5.305680847167968, 'hyper_actor_loss': 0.01591536235064268, 'behavior_loss': 0.272920361161232, 'mean_batch': 6.546773242950439, 'min_batch': 6.155894374847412, 'max_batch': 6.9060118198394775}
step: 28980 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 3.1260896, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.694870126247406, 'actor_loss': -5.335641717910766, 'hyper_actor_loss': 0.016423323564231394, 'behavior_loss': 0.2617258906364441, 'mean_batch': 6.604251194000244, 'min_batch': 6.287228202819824, 'max_batch': 6.933090448379517}
step: 28990 @ episode report: {'average_total_reward': 11.486, 'reward_variance': 5.5263247, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.054494345188141, 'actor_loss': -5.312571573257446, 'hyper_actor_loss': 0.01635875701904297, 'behavior_loss': 0.26954372227191925, 'mean_batch': 6.545490741729736, 'min_batch': 6.199254512786865, 'max_batch': 6.85217661857605}
step: 29000 @ episode report: {'average_total_reward': 10.398, 'reward_variance': 3.465116, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7583929657936097, 'actor_loss': -5.322334814071655, 'hyper_actor_loss': 0.01616476774215698, 'behavior_loss': 0.2694021061062813, 'mean_batch': 6.565838861465454, 'min_batch': 6.240673685073853, 'max_batch': 6.8777587890625}
step: 29010 @ episode report: {'average_total_reward': 9.566, 'reward_variance': 1.847064, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0123841047286986, 'actor_loss': -5.33318190574646, 'hyper_actor_loss': 0.01620498448610306, 'behavior_loss': 0.2713457331061363, 'mean_batch': 6.58305811882019, 'min_batch': 6.292078018188477, 'max_batch': 6.9568188190460205}
step: 29020 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 4.4218698, 'max_total_reward': 13.450002, 'min_total_reward': 5.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1452424049377443, 'actor_loss': -5.295852613449097, 'hyper_actor_loss': 0.016229928471148014, 'behavior_loss': 0.2578762128949165, 'mean_batch': 6.468392086029053, 'min_batch': 6.168881559371949, 'max_batch': 6.831784582138061}
step: 29030 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 2.2061212, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.618343448638916, 'actor_loss': -5.314569091796875, 'hyper_actor_loss': 0.01619310528039932, 'behavior_loss': 0.28108515590429306, 'mean_batch': 6.534404230117798, 'min_batch': 6.222068214416504, 'max_batch': 6.882687139511108}
step: 29040 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 2.8430762, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7727641463279724, 'actor_loss': -5.323839139938355, 'hyper_actor_loss': 0.016497973911464216, 'behavior_loss': 0.2597754165530205, 'mean_batch': 6.570626831054687, 'min_batch': 6.245575571060181, 'max_batch': 7.0504673480987545}
step: 29050 @ episode report: {'average_total_reward': 10.753001, 'reward_variance': 3.3527215, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.707801604270935, 'actor_loss': -5.314073896408081, 'hyper_actor_loss': 0.016649619676172733, 'behavior_loss': 0.2750083029270172, 'mean_batch': 6.528476667404175, 'min_batch': 6.224487400054931, 'max_batch': 6.964836359024048}
step: 29060 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.2389647, 'max_total_reward': 11.23, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6877392888069154, 'actor_loss': -5.317990732192993, 'hyper_actor_loss': 0.01708089280873537, 'behavior_loss': 0.27280705124139787, 'mean_batch': 6.543555402755738, 'min_batch': 6.234616088867187, 'max_batch': 6.940173006057739}
step: 29070 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 8.758704, 'max_total_reward': 15.56, 'min_total_reward': 4.46, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.446313428878784, 'actor_loss': -5.320786428451538, 'hyper_actor_loss': 0.016984396055340766, 'behavior_loss': 0.2569437623023987, 'mean_batch': 6.584078168869018, 'min_batch': 6.213546419143677, 'max_batch': 6.888720321655273}
step: 29080 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 12.0894165, 'max_total_reward': 15.56, 'min_total_reward': 2.46, 'average_n_step': 10.3, 'max_n_step': 16.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.846590006351471, 'actor_loss': -5.344357681274414, 'hyper_actor_loss': 0.01654308643192053, 'behavior_loss': 0.2600971981883049, 'mean_batch': 6.650493478775024, 'min_batch': 6.298361206054688, 'max_batch': 6.981830406188965}
step: 29090 @ episode report: {'average_total_reward': 10.409001, 'reward_variance': 3.1527283, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4076531171798705, 'actor_loss': -5.2773661613464355, 'hyper_actor_loss': 0.016534015722572803, 'behavior_loss': 0.2872325822710991, 'mean_batch': 6.4308326721191404, 'min_batch': 6.092066812515259, 'max_batch': 6.76754674911499}
step: 29100 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 2.9541566, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.1035721063613892, 'actor_loss': -5.2993896961212155, 'hyper_actor_loss': 0.01669445764273405, 'behavior_loss': 0.26304595172405243, 'mean_batch': 6.508600282669067, 'min_batch': 6.1537182331085205, 'max_batch': 6.910479354858398}
step: 29110 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 0.99016887, 'max_total_reward': 12.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6645688891410826, 'actor_loss': -5.341056823730469, 'hyper_actor_loss': 0.016805656626820563, 'behavior_loss': 0.2636542409658432, 'mean_batch': 6.63579797744751, 'min_batch': 6.291471672058106, 'max_batch': 7.0186316013336185}
step: 29120 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 3.217984, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.629666006565094, 'actor_loss': -5.294383859634399, 'hyper_actor_loss': 0.01654512956738472, 'behavior_loss': 0.2688412845134735, 'mean_batch': 6.473810195922852, 'min_batch': 6.155034112930298, 'max_batch': 6.7644453048706055}
step: 29130 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 3.0736446, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.823035168647766, 'actor_loss': -5.323692893981933, 'hyper_actor_loss': 0.016677194088697434, 'behavior_loss': 0.2781040668487549, 'mean_batch': 6.582381391525269, 'min_batch': 6.233323431015014, 'max_batch': 6.969595241546631}
step: 29140 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 3.3225281, 'max_total_reward': 14.45, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8253071427345278, 'actor_loss': -5.329148626327514, 'hyper_actor_loss': 0.01688174046576023, 'behavior_loss': 0.2717456057667732, 'mean_batch': 6.60243182182312, 'min_batch': 6.24859938621521, 'max_batch': 6.922076320648193}
step: 29150 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 2.3926015, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.647793483734131, 'actor_loss': -5.311100053787231, 'hyper_actor_loss': 0.016931935213506222, 'behavior_loss': 0.2827488124370575, 'mean_batch': 6.525111055374145, 'min_batch': 6.2095215797424315, 'max_batch': 6.906508207321167}
step: 29160 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 1.8012245, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.523201811313629, 'actor_loss': -5.317623090744019, 'hyper_actor_loss': 0.017195063643157482, 'behavior_loss': 0.24769987612962724, 'mean_batch': 6.537890434265137, 'min_batch': 6.237550115585327, 'max_batch': 6.905402135848999}
step: 29170 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 1.6753409, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.690679985284805, 'actor_loss': -5.3362959861755375, 'hyper_actor_loss': 0.017051954567432404, 'behavior_loss': 0.284721277654171, 'mean_batch': 6.597733640670777, 'min_batch': 6.2975733280181885, 'max_batch': 7.04199252128601}
step: 29180 @ episode report: {'average_total_reward': 10.831001, 'reward_variance': 1.5498894, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2884889125823973, 'actor_loss': -5.309430694580078, 'hyper_actor_loss': 0.0173716576769948, 'behavior_loss': 0.25653670728206635, 'mean_batch': 6.545898056030273, 'min_batch': 6.179450273513794, 'max_batch': 7.046450138092041}
step: 29190 @ episode report: {'average_total_reward': 11.552, 'reward_variance': 2.460516, 'max_total_reward': 14.559999, 'min_total_reward': 9.01, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.230653929710388, 'actor_loss': -5.313267612457276, 'hyper_actor_loss': 0.017197279073297978, 'behavior_loss': 0.2510265663266182, 'mean_batch': 6.5588812828063965, 'min_batch': 6.191909980773926, 'max_batch': 7.041148996353149}
step: 29200 @ episode report: {'average_total_reward': 8.311, 'reward_variance': 10.445087, 'max_total_reward': 11.2300005, 'min_total_reward': 1.13, 'average_n_step': 9.4, 'max_n_step': 12.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9761465311050417, 'actor_loss': -5.265386772155762, 'hyper_actor_loss': 0.01715839896351099, 'behavior_loss': 0.26381765902042387, 'mean_batch': 6.3704400062561035, 'min_batch': 6.075942897796631, 'max_batch': 6.843852281570435}
step: 29210 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 3.555984, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.816648781299591, 'actor_loss': -5.280568170547485, 'hyper_actor_loss': 0.01701980233192444, 'behavior_loss': 0.26768067926168443, 'mean_batch': 6.424485778808593, 'min_batch': 6.11735348701477, 'max_batch': 6.878633213043213}
step: 29220 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 4.6825013, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.659665107727051, 'actor_loss': -5.302824211120606, 'hyper_actor_loss': 0.017367026209831236, 'behavior_loss': 0.2681404545903206, 'mean_batch': 6.505886363983154, 'min_batch': 6.176200723648071, 'max_batch': 6.9023205757141115}
step: 29230 @ episode report: {'average_total_reward': 10.264999, 'reward_variance': 2.5808048, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8940187811851503, 'actor_loss': -5.262488937377929, 'hyper_actor_loss': 0.01777599323540926, 'behavior_loss': 0.28019151240587237, 'mean_batch': 6.36931676864624, 'min_batch': 6.059459543228149, 'max_batch': 6.762889194488525}
step: 29240 @ episode report: {'average_total_reward': 9.344, 'reward_variance': 2.9574637, 'max_total_reward': 11.2300005, 'min_total_reward': 6.4600005, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3371551752090456, 'actor_loss': -5.260257720947266, 'hyper_actor_loss': 0.018095207586884498, 'behavior_loss': 0.26041311472654344, 'mean_batch': 6.374724912643432, 'min_batch': 6.040889739990234, 'max_batch': 6.853220653533936}
step: 29250 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 2.2451043, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4009522676467894, 'actor_loss': -5.273023319244385, 'hyper_actor_loss': 0.018362424336373806, 'behavior_loss': 0.2695703789591789, 'mean_batch': 6.423294162750244, 'min_batch': 6.072381067276001, 'max_batch': 6.948951721191406}
step: 29260 @ episode report: {'average_total_reward': 10.431002, 'reward_variance': 1.0145887, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.748996448516846, 'actor_loss': -5.299267911911011, 'hyper_actor_loss': 0.01827898807823658, 'behavior_loss': 0.2766276925802231, 'mean_batch': 6.519386100769043, 'min_batch': 6.141879749298096, 'max_batch': 7.044730854034424}
step: 29270 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 2.0012252, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.469394361972809, 'actor_loss': -5.281104183197021, 'hyper_actor_loss': 0.01855990067124367, 'behavior_loss': 0.265904526412487, 'mean_batch': 6.462281942367554, 'min_batch': 6.084348106384278, 'max_batch': 6.9830078125}
step: 29280 @ episode report: {'average_total_reward': 10.209, 'reward_variance': 4.282429, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.859245753288269, 'actor_loss': -5.2863739967346195, 'hyper_actor_loss': 0.018966291658580305, 'behavior_loss': 0.27109190821647644, 'mean_batch': 6.457502985000611, 'min_batch': 6.121031332015991, 'max_batch': 6.944460535049439}
step: 29290 @ episode report: {'average_total_reward': 10.432001, 'reward_variance': 2.9595766, 'max_total_reward': 13.450001, 'min_total_reward': 7.6799994, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.138513779640198, 'actor_loss': -5.249344062805176, 'hyper_actor_loss': 0.019272464513778686, 'behavior_loss': 0.2970083743333817, 'mean_batch': 6.333849048614502, 'min_batch': 6.0137265682220455, 'max_batch': 6.789641427993774}
step: 29300 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 10.220908, 'max_total_reward': 12.34, 'min_total_reward': 1.3500001, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9820370376110077, 'actor_loss': -5.2361548900604244, 'hyper_actor_loss': 0.019642761908471584, 'behavior_loss': 0.26080919057130814, 'mean_batch': 6.326581001281738, 'min_batch': 5.941947412490845, 'max_batch': 6.773520374298096}
step: 29310 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 6.200589, 'max_total_reward': 13.45, 'min_total_reward': 6.6799994, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.425726842880249, 'actor_loss': -5.272130393981934, 'hyper_actor_loss': 0.02011920530349016, 'behavior_loss': 0.2613284170627594, 'mean_batch': 6.415663528442383, 'min_batch': 6.073756217956543, 'max_batch': 6.935538864135742}
step: 29320 @ episode report: {'average_total_reward': 9.210001, 'reward_variance': 7.0960817, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5209652304649355, 'actor_loss': -5.257014417648316, 'hyper_actor_loss': 0.01975468508899212, 'behavior_loss': 0.26087409555912017, 'mean_batch': 6.368217182159424, 'min_batch': 6.02744722366333, 'max_batch': 6.902545928955078}
step: 29330 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 10.14835, 'max_total_reward': 13.45, 'min_total_reward': 2.1299999, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.726265025138855, 'actor_loss': -5.274609375, 'hyper_actor_loss': 0.019476707838475705, 'behavior_loss': 0.2726053908467293, 'mean_batch': 6.41115026473999, 'min_batch': 6.093333911895752, 'max_batch': 6.767952013015747}
step: 29340 @ episode report: {'average_total_reward': 11.175, 'reward_variance': 4.0749063, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0955179214477537, 'actor_loss': -5.32061014175415, 'hyper_actor_loss': 0.019395635835826396, 'behavior_loss': 0.2697963371872902, 'mean_batch': 6.574626159667969, 'min_batch': 6.221634101867676, 'max_batch': 6.964549922943116}
step: 29350 @ episode report: {'average_total_reward': 9.577, 'reward_variance': 3.2512805, 'max_total_reward': 12.339999, 'min_total_reward': 6.68, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9970976650714873, 'actor_loss': -5.292344236373902, 'hyper_actor_loss': 0.01971632055938244, 'behavior_loss': 0.26890780180692675, 'mean_batch': 6.474915790557861, 'min_batch': 6.141592073440552, 'max_batch': 6.884525442123413}
step: 29360 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 1.7337052, 'max_total_reward': 12.12, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.938283622264862, 'actor_loss': -5.24224271774292, 'hyper_actor_loss': 0.019878381118178367, 'behavior_loss': 0.2803905546665192, 'mean_batch': 6.329532623291016, 'min_batch': 5.975274991989136, 'max_batch': 6.725714635848999}
step: 29370 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 6.7049217, 'max_total_reward': 13.450001, 'min_total_reward': 4.6800003, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8842217206954954, 'actor_loss': -5.2602674007415775, 'hyper_actor_loss': 0.020303769409656523, 'behavior_loss': 0.29397828280925753, 'mean_batch': 6.372168731689453, 'min_batch': 6.04313473701477, 'max_batch': 6.721164846420288}
step: 29380 @ episode report: {'average_total_reward': 9.433001, 'reward_variance': 5.9043407, 'max_total_reward': 12.34, 'min_total_reward': 3.35, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6725353837013244, 'actor_loss': -5.248632717132568, 'hyper_actor_loss': 0.02079158816486597, 'behavior_loss': 0.2658650830388069, 'mean_batch': 6.337140464782715, 'min_batch': 6.006284189224243, 'max_batch': 6.753916025161743}
step: 29390 @ episode report: {'average_total_reward': 8.766001, 'reward_variance': 8.257386, 'max_total_reward': 12.230001, 'min_total_reward': 1.35, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8839189529418947, 'actor_loss': -5.283535623550415, 'hyper_actor_loss': 0.02039473466575146, 'behavior_loss': 0.28339819610118866, 'mean_batch': 6.460129261016846, 'min_batch': 6.101331996917724, 'max_batch': 6.804958868026733}
step: 29400 @ episode report: {'average_total_reward': 10.420001, 'reward_variance': 1.5422004, 'max_total_reward': 12.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2481584548950195, 'actor_loss': -5.254777526855468, 'hyper_actor_loss': 0.020522147603332996, 'behavior_loss': 0.2635603591799736, 'mean_batch': 6.3460962772369385, 'min_batch': 6.03488335609436, 'max_batch': 6.723243999481201}
step: 29410 @ episode report: {'average_total_reward': 9.654, 'reward_variance': 2.6494646, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8539159297943115, 'actor_loss': -5.260079002380371, 'hyper_actor_loss': 0.020206025801599026, 'behavior_loss': 0.2782887786626816, 'mean_batch': 6.362162637710571, 'min_batch': 6.051638555526734, 'max_batch': 6.753482055664063}
step: 29420 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 2.6233363, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.585046637058258, 'actor_loss': -5.246122789382935, 'hyper_actor_loss': 0.02028429564088583, 'behavior_loss': 0.27740060687065127, 'mean_batch': 6.335565614700317, 'min_batch': 5.993139123916626, 'max_batch': 6.763335227966309}
step: 29430 @ episode report: {'average_total_reward': 8.733, 'reward_variance': 1.5079418, 'max_total_reward': 11.120002, 'min_total_reward': 6.57, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3699533224105833, 'actor_loss': -5.251009464263916, 'hyper_actor_loss': 0.02036030851304531, 'behavior_loss': 0.2635760441422462, 'mean_batch': 6.3367572784423825, 'min_batch': 6.020843172073365, 'max_batch': 6.77861065864563}
step: 29440 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 3.4123008, 'max_total_reward': 13.450001, 'min_total_reward': 6.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6846842765808105, 'actor_loss': -5.268767404556274, 'hyper_actor_loss': 0.020314876921474934, 'behavior_loss': 0.25068862587213514, 'mean_batch': 6.379526281356812, 'min_batch': 6.087602806091309, 'max_batch': 6.808684158325195}
step: 29450 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 9.272012, 'max_total_reward': 14.45, 'min_total_reward': 2.24, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.023590099811554, 'actor_loss': -5.222537899017334, 'hyper_actor_loss': 0.019986734725534916, 'behavior_loss': 0.26988656967878344, 'mean_batch': 6.225560140609741, 'min_batch': 5.956676864624024, 'max_batch': 6.6789203643798825}
step: 29460 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 7.4006615, 'max_total_reward': 12.34, 'min_total_reward': 2.02, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1325632095336915, 'actor_loss': -5.196182537078857, 'hyper_actor_loss': 0.020455029979348182, 'behavior_loss': 0.2854132384061813, 'mean_batch': 6.147532558441162, 'min_batch': 5.874990606307984, 'max_batch': 6.557158041000366}
step: 29470 @ episode report: {'average_total_reward': 11.486001, 'reward_variance': 1.5715039, 'max_total_reward': 13.45, 'min_total_reward': 9.9, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8531410455703736, 'actor_loss': -5.231663799285888, 'hyper_actor_loss': 0.021440859697759152, 'behavior_loss': 0.27719527781009673, 'mean_batch': 6.31608395576477, 'min_batch': 5.925333642959595, 'max_batch': 6.8372986793518065}
step: 29480 @ episode report: {'average_total_reward': 9.565001, 'reward_variance': 3.7579052, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4101748704910277, 'actor_loss': -5.27062668800354, 'hyper_actor_loss': 0.021938178315758707, 'behavior_loss': 0.27012011855840684, 'mean_batch': 6.464244556427002, 'min_batch': 6.019169902801513, 'max_batch': 6.992294073104858}
step: 29490 @ episode report: {'average_total_reward': 10.608999, 'reward_variance': 5.41491, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5972752630710603, 'actor_loss': -5.214515972137451, 'hyper_actor_loss': 0.02143320757895708, 'behavior_loss': 0.26382109373807905, 'mean_batch': 6.246623849868774, 'min_batch': 5.88895583152771, 'max_batch': 6.671165323257446}
step: 29500 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 3.099081, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.711941826343536, 'actor_loss': -5.20999813079834, 'hyper_actor_loss': 0.021099297702312468, 'behavior_loss': 0.2627017453312874, 'mean_batch': 6.239191246032715, 'min_batch': 5.869412088394165, 'max_batch': 6.678292226791382}
step: 29510 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 2.7844763, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.902876889705658, 'actor_loss': -5.202130317687988, 'hyper_actor_loss': 0.02133445590734482, 'behavior_loss': 0.2746952801942825, 'mean_batch': 6.2048718452453615, 'min_batch': 5.855803775787353, 'max_batch': 6.688428592681885}
step: 29520 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 1.8376017, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.501409423351288, 'actor_loss': -5.242384958267212, 'hyper_actor_loss': 0.02178784105926752, 'behavior_loss': 0.27870123386383056, 'mean_batch': 6.3451642990112305, 'min_batch': 5.961789512634278, 'max_batch': 6.7699995040893555}
step: 29530 @ episode report: {'average_total_reward': 10.865001, 'reward_variance': 2.341845, 'max_total_reward': 14.450001, 'min_total_reward': 8.570001, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4120445013046266, 'actor_loss': -5.257162761688233, 'hyper_actor_loss': 0.022636868990957737, 'behavior_loss': 0.2755505844950676, 'mean_batch': 6.387601375579834, 'min_batch': 6.0098871231079105, 'max_batch': 6.821720552444458}
step: 29540 @ episode report: {'average_total_reward': 10.853001, 'reward_variance': 2.9942214, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.400278186798096, 'actor_loss': -5.241545391082764, 'hyper_actor_loss': 0.021940532326698303, 'behavior_loss': 0.25979636907577514, 'mean_batch': 6.326750183105469, 'min_batch': 5.973777723312378, 'max_batch': 6.761896753311158}
step: 29550 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 5.279765, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6075536012649536, 'actor_loss': -5.25827989578247, 'hyper_actor_loss': 0.02167276255786419, 'behavior_loss': 0.274806310236454, 'mean_batch': 6.373784732818604, 'min_batch': 6.029517364501953, 'max_batch': 6.890921592712402}
step: 29560 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.3406236, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4984236121177674, 'actor_loss': -5.244142627716064, 'hyper_actor_loss': 0.021424940973520278, 'behavior_loss': 0.2687471523880959, 'mean_batch': 6.335069847106934, 'min_batch': 5.9814286708831785, 'max_batch': 6.755092430114746}
step: 29570 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 9.524921, 'max_total_reward': 13.450001, 'min_total_reward': 2.24, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0741824388504027, 'actor_loss': -5.226314640045166, 'hyper_actor_loss': 0.022171913459897042, 'behavior_loss': 0.27422095090150833, 'mean_batch': 6.285181903839112, 'min_batch': 5.92251615524292, 'max_batch': 6.672389936447144}
step: 29580 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 3.6230373, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8681303381919863, 'actor_loss': -5.217930698394776, 'hyper_actor_loss': 0.02193252872675657, 'behavior_loss': 0.2670996949076653, 'mean_batch': 6.252383041381836, 'min_batch': 5.903759288787842, 'max_batch': 6.640526485443115}
step: 29590 @ episode report: {'average_total_reward': 10.665001, 'reward_variance': 3.2269063, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0108577728271486, 'actor_loss': -5.2255815982818605, 'hyper_actor_loss': 0.022316313162446023, 'behavior_loss': 0.2886771962046623, 'mean_batch': 6.2914466381073, 'min_batch': 5.912205839157105, 'max_batch': 6.689134025573731}
step: 29600 @ episode report: {'average_total_reward': 10.863999, 'reward_variance': 4.0623426, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8169975161552427, 'actor_loss': -5.221479511260986, 'hyper_actor_loss': 0.022697612084448336, 'behavior_loss': 0.27991715371608733, 'mean_batch': 6.251686334609985, 'min_batch': 5.925390625, 'max_batch': 6.6138389110565186}
step: 29610 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 4.283066, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.382801830768585, 'actor_loss': -5.227975606918335, 'hyper_actor_loss': 0.021888602897524832, 'behavior_loss': 0.26169221848249435, 'mean_batch': 6.277799940109253, 'min_batch': 5.9393470287323, 'max_batch': 6.641956186294555}
step: 29620 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 1.8929241, 'max_total_reward': 12.01, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5095726370811464, 'actor_loss': -5.246092700958252, 'hyper_actor_loss': 0.021605522371828556, 'behavior_loss': 0.2594504177570343, 'mean_batch': 6.347499227523803, 'min_batch': 5.981289625167847, 'max_batch': 6.74985637664795}
step: 29630 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 4.07611, 'max_total_reward': 12.34, 'min_total_reward': 5.7899995, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9300416231155397, 'actor_loss': -5.2294676303863525, 'hyper_actor_loss': 0.020818288251757622, 'behavior_loss': 0.26586590260267257, 'mean_batch': 6.285239267349243, 'min_batch': 5.941131687164306, 'max_batch': 6.677765703201294}
step: 29640 @ episode report: {'average_total_reward': 9.577001, 'reward_variance': 2.1828609, 'max_total_reward': 11.2300005, 'min_total_reward': 7.68, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9677798628807066, 'actor_loss': -5.1854737281799315, 'hyper_actor_loss': 0.021213338524103165, 'behavior_loss': 0.27055138200521467, 'mean_batch': 6.139235258102417, 'min_batch': 5.8208311080932615, 'max_batch': 6.5125480651855465}
step: 29650 @ episode report: {'average_total_reward': 9.575999, 'reward_variance': 15.235484, 'max_total_reward': 14.56, 'min_total_reward': 2.46, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6893782377243043, 'actor_loss': -5.227619647979736, 'hyper_actor_loss': 0.021532217971980572, 'behavior_loss': 0.2540226235985756, 'mean_batch': 6.320362377166748, 'min_batch': 5.897165393829345, 'max_batch': 6.71461706161499}
step: 29660 @ episode report: {'average_total_reward': 10.465001, 'reward_variance': 9.225945, 'max_total_reward': 13.450001, 'min_total_reward': 2.46, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.8927663803100585, 'actor_loss': -5.264407587051392, 'hyper_actor_loss': 0.021585526689887048, 'behavior_loss': 0.28257824629545214, 'mean_batch': 6.436363554000854, 'min_batch': 6.008890914916992, 'max_batch': 6.828017091751098}
step: 29670 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 4.241477, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7839197516441345, 'actor_loss': -5.2556524753570555, 'hyper_actor_loss': 0.022026511281728743, 'behavior_loss': 0.26597418189048766, 'mean_batch': 6.386434555053711, 'min_batch': 6.003209400177002, 'max_batch': 6.772449779510498}
step: 29680 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 2.8818297, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.559377634525299, 'actor_loss': -5.21753888130188, 'hyper_actor_loss': 0.02203480005264282, 'behavior_loss': 0.281973198056221, 'mean_batch': 6.248320531845093, 'min_batch': 5.9054069995880125, 'max_batch': 6.573471164703369}
step: 29690 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.8863611, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.584402549266815, 'actor_loss': -5.26965069770813, 'hyper_actor_loss': 0.02203286048024893, 'behavior_loss': 0.2674213334918022, 'mean_batch': 6.411012840270996, 'min_batch': 6.0636128902435305, 'max_batch': 6.701216411590576}
step: 29700 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 5.662981, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9021233558654784, 'actor_loss': -5.253266763687134, 'hyper_actor_loss': 0.022250428423285486, 'behavior_loss': 0.27335923761129377, 'mean_batch': 6.376857423782349, 'min_batch': 5.9969587326049805, 'max_batch': 6.6752927780151365}
step: 29710 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 0.5701244, 'max_total_reward': 11.120001, 'min_total_reward': 8.900001, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6298054456710815, 'actor_loss': -5.2239429473876955, 'hyper_actor_loss': 0.021863237395882605, 'behavior_loss': 0.26709759533405303, 'mean_batch': 6.264358425140381, 'min_batch': 5.928101301193237, 'max_batch': 6.578717041015625}
step: 29720 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 2.189797, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7873462080955504, 'actor_loss': -5.229170322418213, 'hyper_actor_loss': 0.02186176721006632, 'behavior_loss': 0.26126098036766054, 'mean_batch': 6.273174667358399, 'min_batch': 5.950558280944824, 'max_batch': 6.582347631454468}
step: 29730 @ episode report: {'average_total_reward': 10.321001, 'reward_variance': 5.40351, 'max_total_reward': 13.340001, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4221165776252747, 'actor_loss': -5.21347861289978, 'hyper_actor_loss': 0.02195300702005625, 'behavior_loss': 0.27116150557994845, 'mean_batch': 6.229294490814209, 'min_batch': 5.899150276184082, 'max_batch': 6.551664066314697}
step: 29740 @ episode report: {'average_total_reward': 8.278, 'reward_variance': 9.044657, 'max_total_reward': 13.450001, 'min_total_reward': 2.35, 'average_n_step': 9.4, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8123294591903685, 'actor_loss': -5.206467056274414, 'hyper_actor_loss': 0.022289928048849106, 'behavior_loss': 0.28275156319141387, 'mean_batch': 6.195548677444458, 'min_batch': 5.889952945709228, 'max_batch': 6.483900833129883}
step: 29750 @ episode report: {'average_total_reward': 10.354, 'reward_variance': 4.992803, 'max_total_reward': 14.339999, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.427694082260132, 'actor_loss': -5.2569615840911865, 'hyper_actor_loss': 0.022456725500524043, 'behavior_loss': 0.2787882849574089, 'mean_batch': 6.3597170352935795, 'min_batch': 6.035120820999145, 'max_batch': 6.648855304718017}
step: 29760 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 2.6493757, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.0753970623016356, 'actor_loss': -5.277431297302246, 'hyper_actor_loss': 0.02235793098807335, 'behavior_loss': 0.2640933498740196, 'mean_batch': 6.453040552139282, 'min_batch': 6.07096676826477, 'max_batch': 6.719921350479126}
step: 29770 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 3.9644806, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9526527285575868, 'actor_loss': -5.269735336303711, 'hyper_actor_loss': 0.021938153356313706, 'behavior_loss': 0.28969802558422086, 'mean_batch': 6.39320216178894, 'min_batch': 6.0816255569458, 'max_batch': 6.694092226028443}
step: 29780 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 4.974921, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.754930293560028, 'actor_loss': -5.204899024963379, 'hyper_actor_loss': 0.02165397014468908, 'behavior_loss': 0.28065899908542635, 'mean_batch': 6.2019247055053714, 'min_batch': 5.8747515201568605, 'max_batch': 6.527436304092407}
step: 29790 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 2.5851262, 'max_total_reward': 12.120001, 'min_total_reward': 6.899999, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.453667628765106, 'actor_loss': -5.264692974090576, 'hyper_actor_loss': 0.021645945496857166, 'behavior_loss': 0.27520159631967545, 'mean_batch': 6.416007804870605, 'min_batch': 6.028581523895264, 'max_batch': 6.794489765167237}
step: 29800 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 6.3325167, 'max_total_reward': 15.670001, 'min_total_reward': 7.7900004, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3976525247097014, 'actor_loss': -5.271801900863648, 'hyper_actor_loss': 0.021348381973803045, 'behavior_loss': 0.27852893024683, 'mean_batch': 6.455579137802124, 'min_batch': 6.034774589538574, 'max_batch': 6.84314751625061}
step: 29810 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 1.2153842, 'max_total_reward': 12.340001, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.955094599723816, 'actor_loss': -5.213484859466552, 'hyper_actor_loss': 0.02132766433060169, 'behavior_loss': 0.2808003529906273, 'mean_batch': 6.256983232498169, 'min_batch': 5.8734527111053465, 'max_batch': 6.67011137008667}
step: 29820 @ episode report: {'average_total_reward': 9.554999, 'reward_variance': 3.8073254, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.657883369922638, 'actor_loss': -5.261239624023437, 'hyper_actor_loss': 0.021570909768342972, 'behavior_loss': 0.2737876057624817, 'mean_batch': 6.417406940460205, 'min_batch': 6.006846904754639, 'max_batch': 6.779869413375854}
step: 29830 @ episode report: {'average_total_reward': 10.82, 'reward_variance': 3.3694603, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.659376311302185, 'actor_loss': -5.246954488754272, 'hyper_actor_loss': 0.02164322528988123, 'behavior_loss': 0.2760034441947937, 'mean_batch': 6.35308575630188, 'min_batch': 5.981789255142212, 'max_batch': 6.696074676513672}
step: 29840 @ episode report: {'average_total_reward': 11.02, 'reward_variance': 3.1541996, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.111145520210266, 'actor_loss': -5.265548133850098, 'hyper_actor_loss': 0.02166175451129675, 'behavior_loss': 0.2591080769896507, 'mean_batch': 6.383377122879028, 'min_batch': 6.064715433120727, 'max_batch': 6.6995614528656}
step: 29850 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 3.1725764, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7110334515571592, 'actor_loss': -5.26462721824646, 'hyper_actor_loss': 0.02138394918292761, 'behavior_loss': 0.2678754538297653, 'mean_batch': 6.3784239292144775, 'min_batch': 6.063678884506226, 'max_batch': 6.683573198318482}
step: 29860 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 4.5291305, 'max_total_reward': 12.340001, 'min_total_reward': 5.7899995, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.387302911281586, 'actor_loss': -5.2525434494018555, 'hyper_actor_loss': 0.021155574545264243, 'behavior_loss': 0.2614451810717583, 'mean_batch': 6.362510061264038, 'min_batch': 6.00591893196106, 'max_batch': 6.657535791397095}
step: 29870 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 5.6553016, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9479278564453124, 'actor_loss': -5.254232740402221, 'hyper_actor_loss': 0.020861914940178396, 'behavior_loss': 0.2555552452802658, 'mean_batch': 6.34822940826416, 'min_batch': 6.02952766418457, 'max_batch': 6.615879487991333}
step: 29880 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 1.949881, 'max_total_reward': 11.23, 'min_total_reward': 6.68, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8744107246398927, 'actor_loss': -5.238180875778198, 'hyper_actor_loss': 0.020449494011700153, 'behavior_loss': 0.2624855011701584, 'mean_batch': 6.315810489654541, 'min_batch': 5.96389741897583, 'max_batch': 6.644273805618286}
step: 29890 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 3.9559097, 'max_total_reward': 12.340001, 'min_total_reward': 5.5699997, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.78738648891449, 'actor_loss': -5.211390161514283, 'hyper_actor_loss': 0.021276257187128066, 'behavior_loss': 0.26806368231773375, 'mean_batch': 6.240942811965942, 'min_batch': 5.8760956764221195, 'max_batch': 6.562501716613769}
step: 29900 @ episode report: {'average_total_reward': 10.442, 'reward_variance': 4.5341973, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.700359654426575, 'actor_loss': -5.248828601837158, 'hyper_actor_loss': 0.02121304105967283, 'behavior_loss': 0.27325101792812345, 'mean_batch': 6.3621259212493895, 'min_batch': 5.984201145172119, 'max_batch': 6.6965433120727536}
step: 29910 @ episode report: {'average_total_reward': 11.1640005, 'reward_variance': 1.9522641, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.298094606399536, 'actor_loss': -5.239695024490357, 'hyper_actor_loss': 0.0217184541746974, 'behavior_loss': 0.2648428216576576, 'mean_batch': 6.3522326946258545, 'min_batch': 5.939297389984131, 'max_batch': 6.627932453155518}
step: 29920 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 1.9196888, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1538097739219664, 'actor_loss': -5.232054948806763, 'hyper_actor_loss': 0.02161311060190201, 'behavior_loss': 0.28064593076705935, 'mean_batch': 6.293461513519287, 'min_batch': 5.948679113388062, 'max_batch': 6.599846935272216}
step: 29930 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 4.916364, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.874111700057983, 'actor_loss': -5.223887205123901, 'hyper_actor_loss': 0.02200992051512003, 'behavior_loss': 0.2717194423079491, 'mean_batch': 6.25786190032959, 'min_batch': 5.933878707885742, 'max_batch': 6.562564182281494}
step: 29940 @ episode report: {'average_total_reward': 8.889001, 'reward_variance': 2.220869, 'max_total_reward': 11.120001, 'min_total_reward': 6.79, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8239841222763062, 'actor_loss': -5.240750074386597, 'hyper_actor_loss': 0.02160005588084459, 'behavior_loss': 0.25872993320226667, 'mean_batch': 6.317025518417358, 'min_batch': 5.978049325942993, 'max_batch': 6.6270688533782955}
step: 29950 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 3.7074413, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.708719289302826, 'actor_loss': -5.244253396987915, 'hyper_actor_loss': 0.020990406908094884, 'behavior_loss': 0.2724640265107155, 'mean_batch': 6.3329767227172855, 'min_batch': 5.9840929985046385, 'max_batch': 6.619844579696656}
step: 29960 @ episode report: {'average_total_reward': 11.186001, 'reward_variance': 3.3064637, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9974330067634583, 'actor_loss': -5.235576391220093, 'hyper_actor_loss': 0.02138624470680952, 'behavior_loss': 0.2760317504405975, 'mean_batch': 6.3295745849609375, 'min_batch': 5.935576105117798, 'max_batch': 6.682816791534424}
step: 29970 @ episode report: {'average_total_reward': 10.942001, 'reward_variance': 4.830717, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7879042744636537, 'actor_loss': -5.227456188201904, 'hyper_actor_loss': 0.021633968129754065, 'behavior_loss': 0.26751448661088945, 'mean_batch': 6.290464162826538, 'min_batch': 5.924218606948853, 'max_batch': 6.604643440246582}
step: 29980 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.7018566, 'max_total_reward': 13.340001, 'min_total_reward': 7.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.616551232337952, 'actor_loss': -5.232577657699585, 'hyper_actor_loss': 0.021792343631386758, 'behavior_loss': 0.2694535836577415, 'mean_batch': 6.316381406784058, 'min_batch': 5.930495309829712, 'max_batch': 6.627723836898804}
step: 29990 @ episode report: {'average_total_reward': 11.308001, 'reward_variance': 1.7992761, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8122029900550842, 'actor_loss': -5.242193269729614, 'hyper_actor_loss': 0.021316014043986798, 'behavior_loss': 0.27613341957330706, 'mean_batch': 6.337874412536621, 'min_batch': 5.967184829711914, 'max_batch': 6.6761232852935795}
step: 30000 @ episode report: {'average_total_reward': 10.675001, 'reward_variance': 5.314326, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6141731947660447, 'actor_loss': -5.223201513290405, 'hyper_actor_loss': 0.021500465646386146, 'behavior_loss': 0.2723080202937126, 'mean_batch': 6.273406076431274, 'min_batch': 5.915151643753052, 'max_batch': 6.574658393859863}
step: 30010 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 5.1679497, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7195561051368715, 'actor_loss': -5.23359169960022, 'hyper_actor_loss': 0.02105482593178749, 'behavior_loss': 0.26276898086071016, 'mean_batch': 6.318447637557983, 'min_batch': 5.934548187255859, 'max_batch': 6.653786516189575}
step: 30020 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.4984612, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1483555316925047, 'actor_loss': -5.229520034790039, 'hyper_actor_loss': 0.02066156603395939, 'behavior_loss': 0.2626120761036873, 'mean_batch': 6.325852966308593, 'min_batch': 5.903612899780273, 'max_batch': 6.679515314102173}
step: 30030 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 3.0717802, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.53816841840744, 'actor_loss': -5.2190549850463865, 'hyper_actor_loss': 0.0207556689158082, 'behavior_loss': 0.2560649737715721, 'mean_batch': 6.294606685638428, 'min_batch': 5.871344995498657, 'max_batch': 6.647110891342163}
step: 30040 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.5894637, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4770527243614198, 'actor_loss': -5.271485471725464, 'hyper_actor_loss': 0.021056316420435907, 'behavior_loss': 0.27593146115541456, 'mean_batch': 6.435469388961792, 'min_batch': 6.051209592819214, 'max_batch': 6.819606733322144}
step: 30050 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 4.3534155, 'max_total_reward': 14.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.652112919092178, 'actor_loss': -5.250093984603882, 'hyper_actor_loss': 0.021378501504659652, 'behavior_loss': 0.26915770322084426, 'mean_batch': 6.363911724090576, 'min_batch': 5.990022611618042, 'max_batch': 6.7430352687835695}
step: 30060 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 2.5904853, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.546582317352295, 'actor_loss': -5.266161203384399, 'hyper_actor_loss': 0.02162525150924921, 'behavior_loss': 0.2638551235198975, 'mean_batch': 6.385640811920166, 'min_batch': 6.0660398483276365, 'max_batch': 6.656581926345825}
step: 30070 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 3.995441, 'max_total_reward': 14.450001, 'min_total_reward': 7.9000006, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.561928761005402, 'actor_loss': -5.2845543384552, 'hyper_actor_loss': 0.02106487061828375, 'behavior_loss': 0.26112217307090757, 'mean_batch': 6.463934516906738, 'min_batch': 6.103799533843994, 'max_batch': 6.75363187789917}
step: 30080 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 2.5128415, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.246131181716919, 'actor_loss': -5.249066638946533, 'hyper_actor_loss': 0.021050711907446385, 'behavior_loss': 0.27452712655067446, 'mean_batch': 6.335003280639649, 'min_batch': 6.01167573928833, 'max_batch': 6.602951431274414}
step: 30090 @ episode report: {'average_total_reward': 10.830999, 'reward_variance': 4.3848295, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6738060891628264, 'actor_loss': -5.22309889793396, 'hyper_actor_loss': 0.021025737933814525, 'behavior_loss': 0.2673741400241852, 'mean_batch': 6.252232313156128, 'min_batch': 5.934780645370483, 'max_batch': 6.5296672821044925}
step: 30100 @ episode report: {'average_total_reward': 10.986001, 'reward_variance': 3.4171853, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4243474125862123, 'actor_loss': -5.278210115432739, 'hyper_actor_loss': 0.021250723861157894, 'behavior_loss': 0.24990274459123613, 'mean_batch': 6.434117794036865, 'min_batch': 6.093560218811035, 'max_batch': 6.688539314270019}
step: 30110 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 3.6141562, 'max_total_reward': 13.23, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.599992346763611, 'actor_loss': -5.274614381790161, 'hyper_actor_loss': 0.021291330829262732, 'behavior_loss': 0.25457781702280047, 'mean_batch': 6.427071809768677, 'min_batch': 6.078302574157715, 'max_batch': 6.741232395172119}
step: 30120 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 2.2547047, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 1.943429696559906, 'actor_loss': -5.299508380889892, 'hyper_actor_loss': 0.021198998391628265, 'behavior_loss': 0.2723050400614738, 'mean_batch': 6.496051788330078, 'min_batch': 6.165846109390259, 'max_batch': 6.761661338806152}
step: 30130 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 2.1010408, 'max_total_reward': 12.01, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7109291315078736, 'actor_loss': -5.298253297805786, 'hyper_actor_loss': 0.02173933256417513, 'behavior_loss': 0.2550696134567261, 'mean_batch': 6.478106307983398, 'min_batch': 6.174720048904419, 'max_batch': 6.709975719451904}
step: 30140 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 3.4280014, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2124065428972246, 'actor_loss': -5.2707305431365965, 'hyper_actor_loss': 0.02150536235421896, 'behavior_loss': 0.2478699266910553, 'mean_batch': 6.4074303150177006, 'min_batch': 6.073603582382202, 'max_batch': 6.661082744598389}
step: 30150 @ episode report: {'average_total_reward': 9.666, 'reward_variance': 5.400065, 'max_total_reward': 13.010001, 'min_total_reward': 5.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.5087007522583007, 'actor_loss': -5.279250526428223, 'hyper_actor_loss': 0.02102925702929497, 'behavior_loss': 0.2695644050836563, 'mean_batch': 6.445330095291138, 'min_batch': 6.089134311676025, 'max_batch': 6.718868160247803}
step: 30160 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 5.530469, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3645249724388124, 'actor_loss': -5.280480432510376, 'hyper_actor_loss': 0.021390926092863083, 'behavior_loss': 0.25987267643213274, 'mean_batch': 6.45543942451477, 'min_batch': 6.087116718292236, 'max_batch': 6.722154235839843}
step: 30170 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.6046205, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6756050109863283, 'actor_loss': -5.297556638717651, 'hyper_actor_loss': 0.021292616426944733, 'behavior_loss': 0.277707476913929, 'mean_batch': 6.4888428211212155, 'min_batch': 6.160122203826904, 'max_batch': 6.734372472763061}
step: 30180 @ episode report: {'average_total_reward': 10.209002, 'reward_variance': 4.3627496, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.459804022312164, 'actor_loss': -5.282202911376953, 'hyper_actor_loss': 0.02129062619060278, 'behavior_loss': 0.2674563378095627, 'mean_batch': 6.46195969581604, 'min_batch': 6.091291761398315, 'max_batch': 6.728566408157349}
step: 30190 @ episode report: {'average_total_reward': 10.709002, 'reward_variance': 1.9596497, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2177440524101257, 'actor_loss': -5.27088360786438, 'hyper_actor_loss': 0.021197276562452315, 'behavior_loss': 0.26349718421697615, 'mean_batch': 6.40967903137207, 'min_batch': 6.0723412990570065, 'max_batch': 6.6721906661987305}
step: 30200 @ episode report: {'average_total_reward': 10.465, 'reward_variance': 1.6997454, 'max_total_reward': 12.34, 'min_total_reward': 8.679999, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.497854495048523, 'actor_loss': -5.233816814422608, 'hyper_actor_loss': 0.021142098307609557, 'behavior_loss': 0.26162106543779373, 'mean_batch': 6.287621927261353, 'min_batch': 5.964518928527832, 'max_batch': 6.5660005569458}
step: 30210 @ episode report: {'average_total_reward': 11.219, 'reward_variance': 5.4269686, 'max_total_reward': 14.450001, 'min_total_reward': 5.7900004, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4381823778152465, 'actor_loss': -5.281446886062622, 'hyper_actor_loss': 0.02109252456575632, 'behavior_loss': 0.27601602375507356, 'mean_batch': 6.42239294052124, 'min_batch': 6.124243211746216, 'max_batch': 6.716624927520752}
step: 30220 @ episode report: {'average_total_reward': 10.764, 'reward_variance': 2.2738836, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6197753667831423, 'actor_loss': -5.25414137840271, 'hyper_actor_loss': 0.021537660993635653, 'behavior_loss': 0.2666704341769218, 'mean_batch': 6.346655225753784, 'min_batch': 6.030350542068481, 'max_batch': 6.637869024276734}
step: 30230 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 4.9185834, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4724708795547485, 'actor_loss': -5.29219241142273, 'hyper_actor_loss': 0.021985464729368687, 'behavior_loss': 0.26675803661346437, 'mean_batch': 6.470100259780883, 'min_batch': 6.145056629180909, 'max_batch': 6.720609140396118}
step: 30240 @ episode report: {'average_total_reward': 10.963999, 'reward_variance': 3.9744847, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.3616214245557785, 'actor_loss': -5.325893926620483, 'hyper_actor_loss': 0.02169666439294815, 'behavior_loss': 0.26112028658390046, 'mean_batch': 6.578416919708252, 'min_batch': 6.251018714904785, 'max_batch': 6.876790285110474}
step: 30250 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 2.4040568, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.244048702716827, 'actor_loss': -5.323483848571778, 'hyper_actor_loss': 0.02139351423829794, 'behavior_loss': 0.279253588616848, 'mean_batch': 6.5711798667907715, 'min_batch': 6.242490816116333, 'max_batch': 6.821249485015869}
step: 30260 @ episode report: {'average_total_reward': 10.132, 'reward_variance': 8.765716, 'max_total_reward': 13.34, 'min_total_reward': 2.3500001, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.66149246096611, 'actor_loss': -5.310413503646851, 'hyper_actor_loss': 0.021629229374229907, 'behavior_loss': 0.2886304140090942, 'mean_batch': 6.514271640777588, 'min_batch': 6.215255975723267, 'max_batch': 6.767200088500976}
step: 30270 @ episode report: {'average_total_reward': 8.866, 'reward_variance': 7.283763, 'max_total_reward': 12.23, 'min_total_reward': 2.3500001, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.681105208396912, 'actor_loss': -5.2816730499267575, 'hyper_actor_loss': 0.021635565720498563, 'behavior_loss': 0.25407612323760986, 'mean_batch': 6.447199535369873, 'min_batch': 6.102253866195679, 'max_batch': 6.716810989379883}
step: 30280 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 2.969584, 'max_total_reward': 14.339999, 'min_total_reward': 8.679999, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.653865909576416, 'actor_loss': -5.28549976348877, 'hyper_actor_loss': 0.021129066497087477, 'behavior_loss': 0.2778287470340729, 'mean_batch': 6.4681891918182375, 'min_batch': 6.105651569366455, 'max_batch': 6.7458655834198}
step: 30290 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.2298412, 'max_total_reward': 12.230001, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.795957887172699, 'actor_loss': -5.277642774581909, 'hyper_actor_loss': 0.02106307428330183, 'behavior_loss': 0.26504115760326385, 'mean_batch': 6.452912330627441, 'min_batch': 6.072634267807007, 'max_batch': 6.726843214035034}
step: 30300 @ episode report: {'average_total_reward': 10.665, 'reward_variance': 3.7710052, 'max_total_reward': 13.45, 'min_total_reward': 5.5699997, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7973106622695925, 'actor_loss': -5.288007068634033, 'hyper_actor_loss': 0.020930190570652485, 'behavior_loss': 0.2851062297821045, 'mean_batch': 6.498383617401123, 'min_batch': 6.092711782455444, 'max_batch': 6.829258394241333}
step: 30310 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 3.7276962, 'max_total_reward': 13.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.528702163696289, 'actor_loss': -5.296346616744995, 'hyper_actor_loss': 0.02100833673030138, 'behavior_loss': 0.26330804973840716, 'mean_batch': 6.488727283477783, 'min_batch': 6.153154945373535, 'max_batch': 6.756162548065186}
step: 30320 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 6.0133257, 'max_total_reward': 14.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.94535346031189, 'actor_loss': -5.285899353027344, 'hyper_actor_loss': 0.020572786033153535, 'behavior_loss': 0.2700264513492584, 'mean_batch': 6.464391565322876, 'min_batch': 6.111827564239502, 'max_batch': 6.7913734912872314}
step: 30330 @ episode report: {'average_total_reward': 10.653001, 'reward_variance': 1.0492212, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4428489565849305, 'actor_loss': -5.29993371963501, 'hyper_actor_loss': 0.020256650075316428, 'behavior_loss': 0.2701407805085182, 'mean_batch': 6.503234195709228, 'min_batch': 6.161775207519531, 'max_batch': 6.822163677215576}
step: 30340 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 6.5482635, 'max_total_reward': 14.56, 'min_total_reward': 5.7900004, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6884042978286744, 'actor_loss': -5.291423606872558, 'hyper_actor_loss': 0.02028761673718691, 'behavior_loss': 0.27737624049186704, 'mean_batch': 6.4830018997192385, 'min_batch': 6.128722429275513, 'max_batch': 6.752378225326538}
step: 30350 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 3.9260068, 'max_total_reward': 13.340001, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.274836540222168, 'actor_loss': -5.32182765007019, 'hyper_actor_loss': 0.020600128918886185, 'behavior_loss': 0.2610954850912094, 'mean_batch': 6.587843704223633, 'min_batch': 6.216792058944702, 'max_batch': 6.868306732177734}
step: 30360 @ episode report: {'average_total_reward': 10.342001, 'reward_variance': 2.9077563, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.245711016654968, 'actor_loss': -5.28959903717041, 'hyper_actor_loss': 0.020246213674545287, 'behavior_loss': 0.272675421833992, 'mean_batch': 6.466113567352295, 'min_batch': 6.133904981613159, 'max_batch': 6.74427285194397}
step: 30370 @ episode report: {'average_total_reward': 10.776001, 'reward_variance': 2.6163843, 'max_total_reward': 13.450001, 'min_total_reward': 8.68, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2941161394119263, 'actor_loss': -5.274190473556518, 'hyper_actor_loss': 0.020494022592902183, 'behavior_loss': 0.2687814891338348, 'mean_batch': 6.41045241355896, 'min_batch': 6.09218921661377, 'max_batch': 6.709469509124756}
step: 30380 @ episode report: {'average_total_reward': 11.762999, 'reward_variance': 2.305741, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 12.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2792996227741242, 'actor_loss': -5.345911741256714, 'hyper_actor_loss': 0.02032900582998991, 'behavior_loss': 0.2534108832478523, 'mean_batch': 6.668452596664428, 'min_batch': 6.291174650192261, 'max_batch': 6.99368052482605}
step: 30390 @ episode report: {'average_total_reward': 11.542001, 'reward_variance': 2.898416, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.684381639957428, 'actor_loss': -5.314088916778564, 'hyper_actor_loss': 0.020164715871214867, 'behavior_loss': 0.2588361859321594, 'mean_batch': 6.5299389362335205, 'min_batch': 6.22433648109436, 'max_batch': 6.817010498046875}
step: 30400 @ episode report: {'average_total_reward': 10.853001, 'reward_variance': 2.7453814, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3023590087890624, 'actor_loss': -5.300230693817139, 'hyper_actor_loss': 0.019742672331631184, 'behavior_loss': 0.2635796949267387, 'mean_batch': 6.4629748344421385, 'min_batch': 6.201277589797973, 'max_batch': 6.720922946929932}
step: 30410 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 5.246403, 'max_total_reward': 12.12, 'min_total_reward': 4.68, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4483636558055877, 'actor_loss': -5.31642746925354, 'hyper_actor_loss': 0.01989936549216509, 'behavior_loss': 0.2707695230841637, 'mean_batch': 6.539897727966308, 'min_batch': 6.22859001159668, 'max_batch': 6.816875743865967}
step: 30420 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 1.5953639, 'max_total_reward': 13.12, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9086788296699524, 'actor_loss': -5.310287666320801, 'hyper_actor_loss': 0.02027423456311226, 'behavior_loss': 0.2594422847032547, 'mean_batch': 6.531144046783448, 'min_batch': 6.1988077640533445, 'max_batch': 6.805201816558838}
step: 30430 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 3.20336, 'max_total_reward': 13.12, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.937612533569336, 'actor_loss': -5.289948654174805, 'hyper_actor_loss': 0.02014655712991953, 'behavior_loss': 0.25824466794729234, 'mean_batch': 6.463485288619995, 'min_batch': 6.137677955627441, 'max_batch': 6.770308494567871}
step: 30440 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 3.9054954, 'max_total_reward': 13.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.924218702316284, 'actor_loss': -5.31405668258667, 'hyper_actor_loss': 0.019886372052133082, 'behavior_loss': 0.2602881699800491, 'mean_batch': 6.571170949935913, 'min_batch': 6.18450345993042, 'max_batch': 6.898403978347778}
step: 30450 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 3.2372766, 'max_total_reward': 13.12, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7214871406555177, 'actor_loss': -5.287661218643189, 'hyper_actor_loss': 0.020020514912903308, 'behavior_loss': 0.2709059938788414, 'mean_batch': 6.486638116836548, 'min_batch': 6.10125846862793, 'max_batch': 6.799588537216186}
step: 30460 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.2188563, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0741499185562136, 'actor_loss': -5.290455102920532, 'hyper_actor_loss': 0.019999696128070354, 'behavior_loss': 0.2703893154859543, 'mean_batch': 6.505612516403199, 'min_batch': 6.1009479522705075, 'max_batch': 6.836940813064575}
step: 30470 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 3.2427204, 'max_total_reward': 15.56, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.004963827133179, 'actor_loss': -5.340542411804199, 'hyper_actor_loss': 0.019946155697107316, 'behavior_loss': 0.269660148024559, 'mean_batch': 6.647026586532593, 'min_batch': 6.277926826477051, 'max_batch': 7.03931360244751}
step: 30480 @ episode report: {'average_total_reward': 10.297999, 'reward_variance': 5.4967175, 'max_total_reward': 14.450001, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.183275890350342, 'actor_loss': -5.3248614311218265, 'hyper_actor_loss': 0.020249023102223873, 'behavior_loss': 0.27323694825172423, 'mean_batch': 6.615542316436768, 'min_batch': 6.209501075744629, 'max_batch': 7.001588678359985}
step: 30490 @ episode report: {'average_total_reward': 10.576, 'reward_variance': 2.9463644, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.209358644485474, 'actor_loss': -5.316500282287597, 'hyper_actor_loss': 0.0204513493925333, 'behavior_loss': 0.2589823201298714, 'mean_batch': 6.569299602508545, 'min_batch': 6.201252079010009, 'max_batch': 6.957586669921875}
step: 30500 @ episode report: {'average_total_reward': 10.742002, 'reward_variance': 2.994575, 'max_total_reward': 14.559999, 'min_total_reward': 9.009999, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6074086666107177, 'actor_loss': -5.324061536788941, 'hyper_actor_loss': 0.020084581337869167, 'behavior_loss': 0.27097277343273163, 'mean_batch': 6.66119270324707, 'min_batch': 6.162475633621216, 'max_batch': 7.089055967330933}
step: 30510 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 4.593786, 'max_total_reward': 15.670001, 'min_total_reward': 7.6800003, 'average_n_step': 11.3, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.888093423843384, 'actor_loss': -5.362399387359619, 'hyper_actor_loss': 0.020158052258193494, 'behavior_loss': 0.2631935939192772, 'mean_batch': 6.737065744400025, 'min_batch': 6.330560111999512, 'max_batch': 7.093228101730347}
step: 30520 @ episode report: {'average_total_reward': 9.421, 'reward_variance': 5.433948, 'max_total_reward': 14.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.017941117286682, 'actor_loss': -5.32498025894165, 'hyper_actor_loss': 0.020271679386496544, 'behavior_loss': 0.2675093412399292, 'mean_batch': 6.61087555885315, 'min_batch': 6.215217542648316, 'max_batch': 6.944969606399536}
step: 30530 @ episode report: {'average_total_reward': 11.529999, 'reward_variance': 3.6378784, 'max_total_reward': 14.559999, 'min_total_reward': 8.900001, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0630724906921385, 'actor_loss': -5.343126392364502, 'hyper_actor_loss': 0.01969105452299118, 'behavior_loss': 0.26282784193754194, 'mean_batch': 6.675733423233032, 'min_batch': 6.266719770431519, 'max_batch': 6.993694925308228}
step: 30540 @ episode report: {'average_total_reward': 10.532001, 'reward_variance': 3.0674958, 'max_total_reward': 14.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.766629934310913, 'actor_loss': -5.3572132110595705, 'hyper_actor_loss': 0.01964764315634966, 'behavior_loss': 0.2679120749235153, 'mean_batch': 6.72042760848999, 'min_batch': 6.313423204421997, 'max_batch': 7.068913412094116}
step: 30550 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 3.0726244, 'max_total_reward': 12.12, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8826910138130186, 'actor_loss': -5.365209436416626, 'hyper_actor_loss': 0.01988487709313631, 'behavior_loss': 0.2891795694828033, 'mean_batch': 6.742325115203857, 'min_batch': 6.34370493888855, 'max_batch': 7.0552815914154055}
step: 30560 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 13.64707, 'max_total_reward': 14.450001, 'min_total_reward': 2.1299999, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.415794253349304, 'actor_loss': -5.37101469039917, 'hyper_actor_loss': 0.0204017985612154, 'behavior_loss': 0.27275352776050565, 'mean_batch': 6.774264335632324, 'min_batch': 6.350471687316895, 'max_batch': 7.158767127990723}
step: 30570 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 2.6821995, 'max_total_reward': 14.34, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.7192529678344726, 'actor_loss': -5.369871282577515, 'hyper_actor_loss': 0.020734054781496526, 'behavior_loss': 0.26818283647298813, 'mean_batch': 6.771870756149292, 'min_batch': 6.345435428619385, 'max_batch': 7.1774674415588375}
step: 30580 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.0261765, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.355044436454773, 'actor_loss': -5.4008783340454105, 'hyper_actor_loss': 0.020317379012703897, 'behavior_loss': 0.28497461378574374, 'mean_batch': 6.88985013961792, 'min_batch': 6.433151149749756, 'max_batch': 7.301334095001221}
step: 30590 @ episode report: {'average_total_reward': 8.977, 'reward_variance': 5.69926, 'max_total_reward': 11.12, 'min_total_reward': 2.46, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1002612948417663, 'actor_loss': -5.377355337142944, 'hyper_actor_loss': 0.020287972316145896, 'behavior_loss': 0.27178910821676255, 'mean_batch': 6.83691668510437, 'min_batch': 6.332178926467895, 'max_batch': 7.245981645584107}
step: 30600 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 4.476724, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2930450558662416, 'actor_loss': -5.3910847187042235, 'hyper_actor_loss': 0.020748770236968993, 'behavior_loss': 0.25987573266029357, 'mean_batch': 6.874690961837769, 'min_batch': 6.384611558914185, 'max_batch': 7.393898630142212}
step: 30610 @ episode report: {'average_total_reward': 11.297, 'reward_variance': 3.3538616, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1108405351638795, 'actor_loss': -5.397905158996582, 'hyper_actor_loss': 0.02047334350645542, 'behavior_loss': 0.27583337724208834, 'mean_batch': 6.909382057189942, 'min_batch': 6.3963111400604244, 'max_batch': 7.437856292724609}
step: 30620 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 4.105746, 'max_total_reward': 13.340001, 'min_total_reward': 6.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4470855474472044, 'actor_loss': -5.372212028503418, 'hyper_actor_loss': 0.02046239897608757, 'behavior_loss': 0.26784449964761736, 'mean_batch': 6.807497882843018, 'min_batch': 6.3270923614501955, 'max_batch': 7.241898822784424}
step: 30630 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 3.8107243, 'max_total_reward': 13.339999, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7421816110610964, 'actor_loss': -5.389754056930542, 'hyper_actor_loss': 0.020385748706758022, 'behavior_loss': 0.2693395301699638, 'mean_batch': 6.8476598262786865, 'min_batch': 6.401371192932129, 'max_batch': 7.322166061401367}
step: 30640 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 3.180116, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.2262261509895325, 'actor_loss': -5.432950019836426, 'hyper_actor_loss': 0.020194662734866142, 'behavior_loss': 0.2434108093380928, 'mean_batch': 6.991657829284668, 'min_batch': 6.546917724609375, 'max_batch': 7.468143463134766}
step: 30650 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 2.6846204, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.761861968040466, 'actor_loss': -5.450116491317749, 'hyper_actor_loss': 0.02020210903137922, 'behavior_loss': 0.2704221799969673, 'mean_batch': 7.074088287353516, 'min_batch': 6.582603597640992, 'max_batch': 7.563968896865845}
step: 30660 @ episode report: {'average_total_reward': 10.653, 'reward_variance': 4.547941, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2277668833732607, 'actor_loss': -5.413663768768311, 'hyper_actor_loss': 0.02013300471007824, 'behavior_loss': 0.2572967603802681, 'mean_batch': 6.926305818557739, 'min_batch': 6.48153338432312, 'max_batch': 7.361348438262939}
step: 30670 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 2.691161, 'max_total_reward': 12.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.14630411863327, 'actor_loss': -5.434502029418946, 'hyper_actor_loss': 0.020489526726305485, 'behavior_loss': 0.27404640763998034, 'mean_batch': 7.021858882904053, 'min_batch': 6.528521585464477, 'max_batch': 7.425877523422241}
step: 30680 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.3219047, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9145874261856077, 'actor_loss': -5.44541974067688, 'hyper_actor_loss': 0.020523872599005698, 'behavior_loss': 0.25990587323904035, 'mean_batch': 7.045967054367066, 'min_batch': 6.577276802062988, 'max_batch': 7.568117332458496}
step: 30690 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 2.9185967, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9212241172790527, 'actor_loss': -5.455190229415893, 'hyper_actor_loss': 0.020167869888246058, 'behavior_loss': 0.27133230268955233, 'mean_batch': 7.076711416244507, 'min_batch': 6.613026857376099, 'max_batch': 7.558449983596802}
step: 30700 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 3.8129508, 'max_total_reward': 14.450002, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3425169467926024, 'actor_loss': -5.446719360351563, 'hyper_actor_loss': 0.02012483384460211, 'behavior_loss': 0.2688414752483368, 'mean_batch': 7.035138654708862, 'min_batch': 6.596394395828247, 'max_batch': 7.425770616531372}
step: 30710 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 3.3927207, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.714845931529999, 'actor_loss': -5.4554891109466555, 'hyper_actor_loss': 0.02017643991857767, 'behavior_loss': 0.260662579536438, 'mean_batch': 7.045311069488525, 'min_batch': 6.644313192367553, 'max_batch': 7.441095447540283}
step: 30720 @ episode report: {'average_total_reward': 10.720001, 'reward_variance': 1.5990405, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4776230692863463, 'actor_loss': -5.487280797958374, 'hyper_actor_loss': 0.02019740343093872, 'behavior_loss': 0.26664737313985826, 'mean_batch': 7.190929746627807, 'min_batch': 6.720175790786743, 'max_batch': 7.612818384170533}
step: 30730 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 3.3113358, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.746831953525543, 'actor_loss': -5.46669569015503, 'hyper_actor_loss': 0.020688716880977155, 'behavior_loss': 0.2740292757749557, 'mean_batch': 7.126976346969604, 'min_batch': 6.64433012008667, 'max_batch': 7.521105241775513}
step: 30740 @ episode report: {'average_total_reward': 11.153, 'reward_variance': 5.255662, 'max_total_reward': 14.56, 'min_total_reward': 7.68, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.602925705909729, 'actor_loss': -5.458081769943237, 'hyper_actor_loss': 0.02073078081011772, 'behavior_loss': 0.26701392233371735, 'mean_batch': 7.116051864624024, 'min_batch': 6.597143602371216, 'max_batch': 7.4951235294342045}
step: 30750 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 2.271622, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2658660411834717, 'actor_loss': -5.510996532440186, 'hyper_actor_loss': 0.020397518202662467, 'behavior_loss': 0.2658148482441902, 'mean_batch': 7.2788971900939945, 'min_batch': 6.798547029495239, 'max_batch': 7.674425172805786}
step: 30760 @ episode report: {'average_total_reward': 10.709002, 'reward_variance': 4.1750097, 'max_total_reward': 14.560001, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9146714210510254, 'actor_loss': -5.490176677703857, 'hyper_actor_loss': 0.02042417470365763, 'behavior_loss': 0.25880641490221024, 'mean_batch': 7.148842144012451, 'min_batch': 6.779038953781128, 'max_batch': 7.48941740989685}
step: 30770 @ episode report: {'average_total_reward': 11.6970005, 'reward_variance': 3.3963616, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 12.5, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8336822986602783, 'actor_loss': -5.4629558563232425, 'hyper_actor_loss': 0.020446218363940716, 'behavior_loss': 0.2664512053132057, 'mean_batch': 7.091408824920654, 'min_batch': 6.650541067123413, 'max_batch': 7.455481100082397}
step: 30780 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 1.6151441, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1274936199188232, 'actor_loss': -5.468248558044434, 'hyper_actor_loss': 0.01999857258051634, 'behavior_loss': 0.24815988689661025, 'mean_batch': 7.0680938243865965, 'min_batch': 6.707805633544922, 'max_batch': 7.484227561950684}
step: 30790 @ episode report: {'average_total_reward': 10.098, 'reward_variance': 3.8493958, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3140140533447267, 'actor_loss': -5.489717197418213, 'hyper_actor_loss': 0.020052334852516653, 'behavior_loss': 0.2657932847738266, 'mean_batch': 7.181127595901489, 'min_batch': 6.7456108093261715, 'max_batch': 7.599497652053833}
step: 30800 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 5.936919, 'max_total_reward': 15.56, 'min_total_reward': 6.7900004, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.585724425315857, 'actor_loss': -5.463020849227905, 'hyper_actor_loss': 0.020047293789684773, 'behavior_loss': 0.2552132591605186, 'mean_batch': 7.074222755432129, 'min_batch': 6.66799030303955, 'max_batch': 7.4092213153839115}
step: 30810 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 8.786202, 'max_total_reward': 13.340001, 'min_total_reward': 1.24, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.306013834476471, 'actor_loss': -5.49659481048584, 'hyper_actor_loss': 0.020384443923830986, 'behavior_loss': 0.2602138713002205, 'mean_batch': 7.193858861923218, 'min_batch': 6.781169700622558, 'max_batch': 7.552721548080444}
step: 30820 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 3.3945765, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8175549507141113, 'actor_loss': -5.474291801452637, 'hyper_actor_loss': 0.020552559569478036, 'behavior_loss': 0.27133541107177733, 'mean_batch': 7.135679292678833, 'min_batch': 6.685894727706909, 'max_batch': 7.463080835342407}
step: 30830 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 5.668261, 'max_total_reward': 13.23, 'min_total_reward': 6.57, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.199787402153015, 'actor_loss': -5.471277904510498, 'hyper_actor_loss': 0.02074744626879692, 'behavior_loss': 0.2708321064710617, 'mean_batch': 7.115824031829834, 'min_batch': 6.683534145355225, 'max_batch': 7.462640953063965}
step: 30840 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 2.0113158, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6243666648864745, 'actor_loss': -5.517724561691284, 'hyper_actor_loss': 0.021147880144417285, 'behavior_loss': 0.28267037868499756, 'mean_batch': 7.253580331802368, 'min_batch': 6.86802191734314, 'max_batch': 7.595580148696899}
step: 30850 @ episode report: {'average_total_reward': 10.720001, 'reward_variance': 2.4137807, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.051476263999939, 'actor_loss': -5.4868340492248535, 'hyper_actor_loss': 0.021160564199090005, 'behavior_loss': 0.27985130697488786, 'mean_batch': 7.184990739822387, 'min_batch': 6.72265043258667, 'max_batch': 7.598109149932862}
step: 30860 @ episode report: {'average_total_reward': 9.887001, 'reward_variance': 1.6718609, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.199567949771881, 'actor_loss': -5.526675844192505, 'hyper_actor_loss': 0.021401431411504745, 'behavior_loss': 0.26624385416507723, 'mean_batch': 7.311384582519532, 'min_batch': 6.87512788772583, 'max_batch': 7.74062147140503}
step: 30870 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 6.659917, 'max_total_reward': 14.450001, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.6630032300949096, 'actor_loss': -5.529424667358398, 'hyper_actor_loss': 0.02089265063405037, 'behavior_loss': 0.2450484573841095, 'mean_batch': 7.327327871322632, 'min_batch': 6.878640460968017, 'max_batch': 7.7480165481567385}
step: 30880 @ episode report: {'average_total_reward': 11.153001, 'reward_variance': 2.891161, 'max_total_reward': 14.45, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6410301685333253, 'actor_loss': -5.52141547203064, 'hyper_actor_loss': 0.020572385378181936, 'behavior_loss': 0.26313540041446687, 'mean_batch': 7.283214473724366, 'min_batch': 6.865521955490112, 'max_batch': 7.735271978378296}
step: 30890 @ episode report: {'average_total_reward': 10.009001, 'reward_variance': 3.06793, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.704401421546936, 'actor_loss': -5.451123285293579, 'hyper_actor_loss': 0.020406792312860488, 'behavior_loss': 0.2632510602474213, 'mean_batch': 7.046317672729492, 'min_batch': 6.61439881324768, 'max_batch': 7.402371454238891}
step: 30900 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 11.122884, 'max_total_reward': 15.56, 'min_total_reward': 4.57, 'average_n_step': 10.8, 'max_n_step': 16.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.116627073287964, 'actor_loss': -5.524748039245606, 'hyper_actor_loss': 0.020983111672103406, 'behavior_loss': 0.2664551615715027, 'mean_batch': 7.306292629241943, 'min_batch': 6.868369483947754, 'max_batch': 7.751416444778442}
step: 30910 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 6.441105, 'max_total_reward': 13.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.259206533432007, 'actor_loss': -5.561607789993286, 'hyper_actor_loss': 0.021015174128115176, 'behavior_loss': 0.2735319331288338, 'mean_batch': 7.479496812820434, 'min_batch': 6.959356451034546, 'max_batch': 7.930747413635254}
step: 30920 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 1.7697798, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.269813299179077, 'actor_loss': -5.522437953948975, 'hyper_actor_loss': 0.02107705529779196, 'behavior_loss': 0.2584634989500046, 'mean_batch': 7.3174238204956055, 'min_batch': 6.840506935119629, 'max_batch': 7.7328431606292725}
step: 30930 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 5.212504, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.683746075630188, 'actor_loss': -5.524194383621216, 'hyper_actor_loss': 0.020964401587843896, 'behavior_loss': 0.27186850309371946, 'mean_batch': 7.310996723175049, 'min_batch': 6.858478212356568, 'max_batch': 7.666590023040771}
step: 30940 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 3.104089, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7585554838180544, 'actor_loss': -5.5215309143066404, 'hyper_actor_loss': 0.021193571947515012, 'behavior_loss': 0.2684565335512161, 'mean_batch': 7.308758068084717, 'min_batch': 6.842024660110473, 'max_batch': 7.7616149425506595}
step: 30950 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 4.731349, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.954695165157318, 'actor_loss': -5.498234701156616, 'hyper_actor_loss': 0.02120114304125309, 'behavior_loss': 0.2803804397583008, 'mean_batch': 7.247860527038574, 'min_batch': 6.740918922424316, 'max_batch': 7.709534692764282}
step: 30960 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 2.5959005, 'max_total_reward': 12.339999, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5577291369438173, 'actor_loss': -5.551022100448608, 'hyper_actor_loss': 0.02145331334322691, 'behavior_loss': 0.27135911732912066, 'mean_batch': 7.42438268661499, 'min_batch': 6.937873458862304, 'max_batch': 7.946189641952515}
step: 30970 @ episode report: {'average_total_reward': 9.776, 'reward_variance': 3.8535438, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6063942670822144, 'actor_loss': -5.55376091003418, 'hyper_actor_loss': 0.021119111590087412, 'behavior_loss': 0.2549393981695175, 'mean_batch': 7.46853609085083, 'min_batch': 6.915241241455078, 'max_batch': 8.01869044303894}
step: 30980 @ episode report: {'average_total_reward': 9.9539995, 'reward_variance': 8.860205, 'max_total_reward': 13.2300005, 'min_total_reward': 2.46, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.208371376991272, 'actor_loss': -5.524940490722656, 'hyper_actor_loss': 0.0206731703132391, 'behavior_loss': 0.27611440867185594, 'mean_batch': 7.389110469818116, 'min_batch': 6.791139698028564, 'max_batch': 7.926179885864258}
step: 30990 @ episode report: {'average_total_reward': 11.397001, 'reward_variance': 1.1150008, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.829712963104248, 'actor_loss': -5.54517183303833, 'hyper_actor_loss': 0.020619841292500496, 'behavior_loss': 0.2718750238418579, 'mean_batch': 7.489600992202758, 'min_batch': 6.836807298660278, 'max_batch': 8.04056887626648}
step: 31000 @ episode report: {'average_total_reward': 11.1640005, 'reward_variance': 3.5040443, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.351455473899842, 'actor_loss': -5.495034027099609, 'hyper_actor_loss': 0.020258745923638345, 'behavior_loss': 0.26123070120811465, 'mean_batch': 7.214468240737915, 'min_batch': 6.750205183029175, 'max_batch': 7.740424680709839}
step: 31010 @ episode report: {'average_total_reward': 10.598, 'reward_variance': 2.2012954, 'max_total_reward': 13.339999, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.140392637252807, 'actor_loss': -5.529887628555298, 'hyper_actor_loss': 0.02076425142586231, 'behavior_loss': 0.26808741837739947, 'mean_batch': 7.394301652908325, 'min_batch': 6.819755935668946, 'max_batch': 7.927568578720093}
step: 31020 @ episode report: {'average_total_reward': 11.719, 'reward_variance': 4.5513296, 'max_total_reward': 14.559999, 'min_total_reward': 7.68, 'average_n_step': 12.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7582660913467407, 'actor_loss': -5.535447406768799, 'hyper_actor_loss': 0.0204999178647995, 'behavior_loss': 0.2767647236585617, 'mean_batch': 7.432434749603272, 'min_batch': 6.822639036178589, 'max_batch': 8.03818120956421}
step: 31030 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 4.7687445, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7287291884422302, 'actor_loss': -5.547330904006958, 'hyper_actor_loss': 0.020826201885938644, 'behavior_loss': 0.26856870800256727, 'mean_batch': 7.4705499649047855, 'min_batch': 6.868727779388427, 'max_batch': 8.004836082458496}
step: 31040 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 3.1088493, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.905976140499115, 'actor_loss': -5.560497426986695, 'hyper_actor_loss': 0.020893767476081848, 'behavior_loss': 0.25681031346321104, 'mean_batch': 7.466262006759644, 'min_batch': 6.963639402389527, 'max_batch': 7.957054471969604}
step: 31050 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 1.7308292, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.831518125534058, 'actor_loss': -5.515032720565796, 'hyper_actor_loss': 0.020765351690351964, 'behavior_loss': 0.27949785590171816, 'mean_batch': 7.282597780227661, 'min_batch': 6.822309589385986, 'max_batch': 7.6567731380462645}
step: 31060 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 0.7373694, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.082751011848449, 'actor_loss': -5.5368963241577145, 'hyper_actor_loss': 0.021134645864367484, 'behavior_loss': 0.268689201772213, 'mean_batch': 7.348193883895874, 'min_batch': 6.910933256149292, 'max_batch': 7.750909423828125}
step: 31070 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 1.8431286, 'max_total_reward': 11.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6865254640579224, 'actor_loss': -5.564410448074341, 'hyper_actor_loss': 0.020816782489418983, 'behavior_loss': 0.26770334392786027, 'mean_batch': 7.474958181381226, 'min_batch': 6.983853101730347, 'max_batch': 7.88772406578064}
step: 31080 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 4.580737, 'max_total_reward': 15.670001, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.746749472618103, 'actor_loss': -5.588167953491211, 'hyper_actor_loss': 0.02123829908668995, 'behavior_loss': 0.26867508739233015, 'mean_batch': 7.569023990631104, 'min_batch': 7.062282991409302, 'max_batch': 7.948904895782471}
step: 31090 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 1.7278436, 'max_total_reward': 12.23, 'min_total_reward': 7.7900004, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.797767663002014, 'actor_loss': -5.606560564041137, 'hyper_actor_loss': 0.02161761373281479, 'behavior_loss': 0.2707902878522873, 'mean_batch': 7.645569944381714, 'min_batch': 7.121825790405273, 'max_batch': 8.040608644485474}
step: 31100 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 4.83763, 'max_total_reward': 12.2300005, 'min_total_reward': 6.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5785279989242555, 'actor_loss': -5.625766754150391, 'hyper_actor_loss': 0.021388635970652103, 'behavior_loss': 0.2762866124510765, 'mean_batch': 7.7313501834869385, 'min_batch': 7.179165029525757, 'max_batch': 8.160607433319091}
step: 31110 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 0.74961627, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.079305839538574, 'actor_loss': -5.550534439086914, 'hyper_actor_loss': 0.021263628639280795, 'behavior_loss': 0.2657589763402939, 'mean_batch': 7.428985118865967, 'min_batch': 6.929676246643067, 'max_batch': 7.848099231719971}
step: 31120 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 2.1875453, 'max_total_reward': 12.230001, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.503462088108063, 'actor_loss': -5.59334888458252, 'hyper_actor_loss': 0.02117841299623251, 'behavior_loss': 0.25285944789648057, 'mean_batch': 7.567006397247314, 'min_batch': 7.101064968109131, 'max_batch': 7.942229557037353}
step: 31130 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.3014648, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.089814913272858, 'actor_loss': -5.6365851879119875, 'hyper_actor_loss': 0.021041887067258357, 'behavior_loss': 0.2564205273985863, 'mean_batch': 7.745505380630493, 'min_batch': 7.243347787857056, 'max_batch': 8.082617616653442}
step: 31140 @ episode report: {'average_total_reward': 11.63, 'reward_variance': 1.0525209, 'max_total_reward': 13.450001, 'min_total_reward': 10.009999, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7121410846710203, 'actor_loss': -5.609983682632446, 'hyper_actor_loss': 0.020846949703991414, 'behavior_loss': 0.26893416345119475, 'mean_batch': 7.638832092285156, 'min_batch': 7.152907943725586, 'max_batch': 8.020383071899413}
step: 31150 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 1.8551486, 'max_total_reward': 14.339999, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1809357047080993, 'actor_loss': -5.600842142105103, 'hyper_actor_loss': 0.02096571121364832, 'behavior_loss': 0.27314412742853167, 'mean_batch': 7.608789396286011, 'min_batch': 7.115971183776855, 'max_batch': 7.981946229934692}
step: 31160 @ episode report: {'average_total_reward': 8.988, 'reward_variance': 5.2058153, 'max_total_reward': 12.23, 'min_total_reward': 4.57, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.83390793800354, 'actor_loss': -5.634828376770019, 'hyper_actor_loss': 0.021370330080389976, 'behavior_loss': 0.2756964504718781, 'mean_batch': 7.688880538940429, 'min_batch': 7.283874607086181, 'max_batch': 8.10352725982666}
step: 31170 @ episode report: {'average_total_reward': 9.743, 'reward_variance': 4.028741, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6094260692596434, 'actor_loss': -5.600150108337402, 'hyper_actor_loss': 0.02167321741580963, 'behavior_loss': 0.26403609812259676, 'mean_batch': 7.621336221694946, 'min_batch': 7.098579168319702, 'max_batch': 7.979123878479004}
step: 31180 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 5.753984, 'max_total_reward': 13.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6390695333480836, 'actor_loss': -5.625863313674927, 'hyper_actor_loss': 0.021570819057524206, 'behavior_loss': 0.2763434961438179, 'mean_batch': 7.690238189697266, 'min_batch': 7.217849683761597, 'max_batch': 8.095780038833619}
step: 31190 @ episode report: {'average_total_reward': 10.065, 'reward_variance': 2.8403847, 'max_total_reward': 13.23, 'min_total_reward': 6.7900004, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.468594360351562, 'actor_loss': -5.600457954406738, 'hyper_actor_loss': 0.021362046524882317, 'behavior_loss': 0.26309622824192047, 'mean_batch': 7.580031442642212, 'min_batch': 7.140665054321289, 'max_batch': 8.014780521392822}
step: 31200 @ episode report: {'average_total_reward': 9.210001, 'reward_variance': 5.756821, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.078072333335877, 'actor_loss': -5.597382068634033, 'hyper_actor_loss': 0.02086802814155817, 'behavior_loss': 0.27247786819934844, 'mean_batch': 7.576311016082764, 'min_batch': 7.120730257034301, 'max_batch': 7.964943981170654}
step: 31210 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 2.5213497, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9895384192466734, 'actor_loss': -5.62961106300354, 'hyper_actor_loss': 0.020937830582261084, 'behavior_loss': 0.27671693116426466, 'mean_batch': 7.709444808959961, 'min_batch': 7.22758207321167, 'max_batch': 8.13377504348755}
step: 31220 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 4.801577, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1348124742507935, 'actor_loss': -5.668629217147827, 'hyper_actor_loss': 0.02124417293816805, 'behavior_loss': 0.2595134645700455, 'mean_batch': 7.860192155838012, 'min_batch': 7.370461940765381, 'max_batch': 8.278342914581298}
step: 31230 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.7926443, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7661041736602785, 'actor_loss': -5.615772724151611, 'hyper_actor_loss': 0.021103328838944436, 'behavior_loss': 0.26934398859739306, 'mean_batch': 7.658008146286011, 'min_batch': 7.175162601470947, 'max_batch': 8.06871976852417}
step: 31240 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 5.203376, 'max_total_reward': 13.45, 'min_total_reward': 4.46, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.715981936454773, 'actor_loss': -5.616180038452148, 'hyper_actor_loss': 0.020925499871373175, 'behavior_loss': 0.266065414249897, 'mean_batch': 7.649129581451416, 'min_batch': 7.187068939208984, 'max_batch': 8.071178245544434}
step: 31250 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 8.362636, 'max_total_reward': 13.45, 'min_total_reward': 2.46, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.288564109802246, 'actor_loss': -5.605410528182984, 'hyper_actor_loss': 0.02075803969055414, 'behavior_loss': 0.27004760056734084, 'mean_batch': 7.636702537536621, 'min_batch': 7.12149829864502, 'max_batch': 8.054375505447387}
step: 31260 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 2.4843087, 'max_total_reward': 13.339999, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.344446873664856, 'actor_loss': -5.65465726852417, 'hyper_actor_loss': 0.020568622462451457, 'behavior_loss': 0.2668907597661018, 'mean_batch': 7.825723171234131, 'min_batch': 7.300559425354004, 'max_batch': 8.277344226837158}
step: 31270 @ episode report: {'average_total_reward': 10.608999, 'reward_variance': 2.6554492, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6794072866439818, 'actor_loss': -5.643092393875122, 'hyper_actor_loss': 0.02057197205722332, 'behavior_loss': 0.265148489177227, 'mean_batch': 7.768344449996948, 'min_batch': 7.270487070083618, 'max_batch': 8.247667789459229}
step: 31280 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.8366015, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2732638955116276, 'actor_loss': -5.611675786972046, 'hyper_actor_loss': 0.020657769218087197, 'behavior_loss': 0.26406143307685853, 'mean_batch': 7.6162598609924315, 'min_batch': 7.184954023361206, 'max_batch': 8.00879521369934}
step: 31290 @ episode report: {'average_total_reward': 11.053001, 'reward_variance': 2.246281, 'max_total_reward': 13.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.694460391998291, 'actor_loss': -5.633930969238281, 'hyper_actor_loss': 0.020757671631872653, 'behavior_loss': 0.2668640658259392, 'mean_batch': 7.743723630905151, 'min_batch': 7.226079273223877, 'max_batch': 8.210957336425782}
step: 31300 @ episode report: {'average_total_reward': 11.397, 'reward_variance': 4.5184617, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8145686388015747, 'actor_loss': -5.639450740814209, 'hyper_actor_loss': 0.020695206336677076, 'behavior_loss': 0.26415824294090273, 'mean_batch': 7.738872766494751, 'min_batch': 7.270640087127686, 'max_batch': 8.11016206741333}
step: 31310 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 5.3779707, 'max_total_reward': 14.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.496337461471557, 'actor_loss': -5.5995865821838375, 'hyper_actor_loss': 0.020304537005722524, 'behavior_loss': 0.2670696660876274, 'mean_batch': 7.5857508182525635, 'min_batch': 7.128492259979248, 'max_batch': 7.975217962265015}
step: 31320 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 1.672056, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.004370093345642, 'actor_loss': -5.608887958526611, 'hyper_actor_loss': 0.02072799913585186, 'behavior_loss': 0.2623859018087387, 'mean_batch': 7.630027437210083, 'min_batch': 7.153105401992798, 'max_batch': 8.049467945098877}
step: 31330 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 2.9796417, 'max_total_reward': 13.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.225533986091614, 'actor_loss': -5.623543977737427, 'hyper_actor_loss': 0.0209520747885108, 'behavior_loss': 0.26972548961639403, 'mean_batch': 7.690624713897705, 'min_batch': 7.200721406936646, 'max_batch': 8.058639430999756}
step: 31340 @ episode report: {'average_total_reward': 10.720001, 'reward_variance': 3.86546, 'max_total_reward': 14.34, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.072021865844727, 'actor_loss': -5.592988681793213, 'hyper_actor_loss': 0.02082136496901512, 'behavior_loss': 0.271827743947506, 'mean_batch': 7.573033809661865, 'min_batch': 7.09358286857605, 'max_batch': 7.99722728729248}
step: 31350 @ episode report: {'average_total_reward': 10.776, 'reward_variance': 3.3998456, 'max_total_reward': 13.450002, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.50040979385376, 'actor_loss': -5.645695686340332, 'hyper_actor_loss': 0.021280835382640362, 'behavior_loss': 0.26719060242176057, 'mean_batch': 7.7802488803863525, 'min_batch': 7.279483938217163, 'max_batch': 8.203133058547973}
step: 31360 @ episode report: {'average_total_reward': 11.297, 'reward_variance': 2.8830216, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7557254314422606, 'actor_loss': -5.643887519836426, 'hyper_actor_loss': 0.021053515933454038, 'behavior_loss': 0.27285544723272326, 'mean_batch': 7.791179180145264, 'min_batch': 7.254499769210815, 'max_batch': 8.227827739715575}
step: 31370 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 4.171629, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.469334077835083, 'actor_loss': -5.618732881546021, 'hyper_actor_loss': 0.021289547719061375, 'behavior_loss': 0.28132092505693435, 'mean_batch': 7.673414611816407, 'min_batch': 7.182452058792114, 'max_batch': 8.120242357254028}
step: 31380 @ episode report: {'average_total_reward': 10.787001, 'reward_variance': 2.0690417, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.377604985237122, 'actor_loss': -5.595657539367676, 'hyper_actor_loss': 0.02116022277623415, 'behavior_loss': 0.25229342877864835, 'mean_batch': 7.58346700668335, 'min_batch': 7.101801776885987, 'max_batch': 8.000049114227295}
step: 31390 @ episode report: {'average_total_reward': 10.653, 'reward_variance': 2.7277412, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.574778938293457, 'actor_loss': -5.619952058792114, 'hyper_actor_loss': 0.020707414671778678, 'behavior_loss': 0.2644003674387932, 'mean_batch': 7.66239652633667, 'min_batch': 7.201449012756347, 'max_batch': 8.021681642532348}
step: 31400 @ episode report: {'average_total_reward': 10.231001, 'reward_variance': 2.9726698, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.510535031557083, 'actor_loss': -5.654841756820678, 'hyper_actor_loss': 0.020321404933929442, 'behavior_loss': 0.2605910748243332, 'mean_batch': 7.784043025970459, 'min_batch': 7.340483808517456, 'max_batch': 8.17812352180481}
step: 31410 @ episode report: {'average_total_reward': 11.164, 'reward_variance': 2.0499444, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8258606791496277, 'actor_loss': -5.5834380149841305, 'hyper_actor_loss': 0.02034234404563904, 'behavior_loss': 0.2646945372223854, 'mean_batch': 7.514388704299927, 'min_batch': 7.080233478546143, 'max_batch': 7.895106410980224}
step: 31420 @ episode report: {'average_total_reward': 11.63, 'reward_variance': 2.6067212, 'max_total_reward': 14.56, 'min_total_reward': 9.009999, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5199694275856017, 'actor_loss': -5.639391565322876, 'hyper_actor_loss': 0.020688793808221816, 'behavior_loss': 0.26019505560398104, 'mean_batch': 7.768877029418945, 'min_batch': 7.242458438873291, 'max_batch': 8.18476390838623}
step: 31430 @ episode report: {'average_total_reward': 10.986, 'reward_variance': 5.783705, 'max_total_reward': 15.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.427191996574402, 'actor_loss': -5.648700523376465, 'hyper_actor_loss': 0.020536964014172553, 'behavior_loss': 0.2602685019373894, 'mean_batch': 7.770937061309814, 'min_batch': 7.308668518066407, 'max_batch': 8.151165628433228}
step: 31440 @ episode report: {'average_total_reward': 10.576, 'reward_variance': 3.4565644, 'max_total_reward': 13.450001, 'min_total_reward': 7.6800003, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7414313554763794, 'actor_loss': -5.6125048160552975, 'hyper_actor_loss': 0.02070743087679148, 'behavior_loss': 0.2502092644572258, 'mean_batch': 7.62628870010376, 'min_batch': 7.182283687591553, 'max_batch': 7.9559228897094725}
step: 31450 @ episode report: {'average_total_reward': 10.964, 'reward_variance': 2.9155445, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.233706283569336, 'actor_loss': -5.647270250320434, 'hyper_actor_loss': 0.02034590020775795, 'behavior_loss': 0.279382161796093, 'mean_batch': 7.749063491821289, 'min_batch': 7.3177937984466555, 'max_batch': 8.16567554473877}
step: 31460 @ episode report: {'average_total_reward': 10.088, 'reward_variance': 2.5385373, 'max_total_reward': 12.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5787236511707308, 'actor_loss': -5.639871978759766, 'hyper_actor_loss': 0.02085936740040779, 'behavior_loss': 0.2697221264243126, 'mean_batch': 7.747815752029419, 'min_batch': 7.2654523849487305, 'max_batch': 8.158776950836181}
step: 31470 @ episode report: {'average_total_reward': 9.232, 'reward_variance': 1.826816, 'max_total_reward': 11.12, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.223937296867371, 'actor_loss': -5.623790836334228, 'hyper_actor_loss': 0.021135995350778102, 'behavior_loss': 0.2635041534900665, 'mean_batch': 7.6834876537323, 'min_batch': 7.208928823471069, 'max_batch': 8.066313076019288}
step: 31480 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 5.104576, 'max_total_reward': 14.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.9141381025314335, 'actor_loss': -5.596955442428589, 'hyper_actor_loss': 0.021262916922569274, 'behavior_loss': 0.26736638098955157, 'mean_batch': 7.553631019592285, 'min_batch': 7.138776350021362, 'max_batch': 7.960539627075195}
step: 31490 @ episode report: {'average_total_reward': 10.066, 'reward_variance': 3.390524, 'max_total_reward': 12.34, 'min_total_reward': 6.46, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8424069762229918, 'actor_loss': -5.62328782081604, 'hyper_actor_loss': 0.020960315875709058, 'behavior_loss': 0.260222464799881, 'mean_batch': 7.696861219406128, 'min_batch': 7.193931293487549, 'max_batch': 8.172745752334595}
step: 31500 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 2.7358794, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.533490800857544, 'actor_loss': -5.662470293045044, 'hyper_actor_loss': 0.020806397870182992, 'behavior_loss': 0.24867894351482392, 'mean_batch': 7.873113298416138, 'min_batch': 7.313346338272095, 'max_batch': 8.317303276062011}
step: 31510 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.0405755, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3925532579421995, 'actor_loss': -5.678946018218994, 'hyper_actor_loss': 0.02029635962098837, 'behavior_loss': 0.2680883526802063, 'mean_batch': 7.919969940185547, 'min_batch': 7.3904704570770265, 'max_batch': 8.351277256011963}
step: 31520 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 3.2522964, 'max_total_reward': 13.340001, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.297313570976257, 'actor_loss': -5.641921424865723, 'hyper_actor_loss': 0.020605715550482274, 'behavior_loss': 0.283483923971653, 'mean_batch': 7.724893236160279, 'min_batch': 7.301637172698975, 'max_batch': 8.123622131347656}
step: 31530 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 3.5359008, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.524892544746399, 'actor_loss': -5.6396942138671875, 'hyper_actor_loss': 0.02092003673315048, 'behavior_loss': 0.27055563032627106, 'mean_batch': 7.760984086990357, 'min_batch': 7.252281618118286, 'max_batch': 8.17724084854126}
step: 31540 @ episode report: {'average_total_reward': 9.3220005, 'reward_variance': 9.022596, 'max_total_reward': 13.340001, 'min_total_reward': 2.02, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.026632034778595, 'actor_loss': -5.64656810760498, 'hyper_actor_loss': 0.020983845554292203, 'behavior_loss': 0.2681718453764915, 'mean_batch': 7.815771675109863, 'min_batch': 7.2503382682800295, 'max_batch': 8.287267971038819}
step: 31550 @ episode report: {'average_total_reward': 9.987, 'reward_variance': 5.2165613, 'max_total_reward': 13.339999, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.761965024471283, 'actor_loss': -5.6429548263549805, 'hyper_actor_loss': 0.02094857580959797, 'behavior_loss': 0.2523317724466324, 'mean_batch': 7.792114925384522, 'min_batch': 7.245940113067627, 'max_batch': 8.318026733398437}
step: 31560 @ episode report: {'average_total_reward': 10.554001, 'reward_variance': 4.5786643, 'max_total_reward': 14.2300005, 'min_total_reward': 7.57, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.281182599067688, 'actor_loss': -5.657696676254273, 'hyper_actor_loss': 0.020328201167285443, 'behavior_loss': 0.2507549062371254, 'mean_batch': 7.8362750053405765, 'min_batch': 7.312589836120606, 'max_batch': 8.360424518585205}
step: 31570 @ episode report: {'average_total_reward': 11.275002, 'reward_variance': 1.7339052, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.474022841453552, 'actor_loss': -5.6815728664398195, 'hyper_actor_loss': 0.020269125886261462, 'behavior_loss': 0.2755922362208366, 'mean_batch': 7.927224588394165, 'min_batch': 7.403970527648926, 'max_batch': 8.372807884216309}
step: 31580 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 3.479856, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.271182227134704, 'actor_loss': -5.584529066085816, 'hyper_actor_loss': 0.02005085665732622, 'behavior_loss': 0.2720338523387909, 'mean_batch': 7.5273521900177, 'min_batch': 7.075778675079346, 'max_batch': 7.949747323989868}
step: 31590 @ episode report: {'average_total_reward': 11.031, 'reward_variance': 1.5742285, 'max_total_reward': 13.339999, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3301633656024934, 'actor_loss': -5.606209564208984, 'hyper_actor_loss': 0.020507942698895932, 'behavior_loss': 0.26314497590065, 'mean_batch': 7.621564340591431, 'min_batch': 7.14245080947876, 'max_batch': 7.980168771743775}
step: 31600 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 5.3024364, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.172102046012879, 'actor_loss': -5.660857105255127, 'hyper_actor_loss': 0.020362575352191926, 'behavior_loss': 0.26813523322343824, 'mean_batch': 7.795555114746094, 'min_batch': 7.373986291885376, 'max_batch': 8.180154037475585}
step: 31610 @ episode report: {'average_total_reward': 11.153001, 'reward_variance': 13.04624, 'max_total_reward': 15.67, 'min_total_reward': 3.0200002, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.002078866958618, 'actor_loss': -5.601588296890259, 'hyper_actor_loss': 0.020397606678307055, 'behavior_loss': 0.2750736966729164, 'mean_batch': 7.561749410629273, 'min_batch': 7.164546728134155, 'max_batch': 7.900487756729126}
step: 31620 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 2.4357803, 'max_total_reward': 11.23, 'min_total_reward': 5.68, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.665848124027252, 'actor_loss': -5.578261423110962, 'hyper_actor_loss': 0.02044739816337824, 'behavior_loss': 0.26976599246263505, 'mean_batch': 7.452690839767456, 'min_batch': 7.101403665542603, 'max_batch': 7.755411148071289}
step: 31630 @ episode report: {'average_total_reward': 8.433001, 'reward_variance': 5.7092013, 'max_total_reward': 11.2300005, 'min_total_reward': 3.35, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8405245184898376, 'actor_loss': -5.608376455307007, 'hyper_actor_loss': 0.020286663249135018, 'behavior_loss': 0.26267296075820923, 'mean_batch': 7.568794107437133, 'min_batch': 7.206634902954102, 'max_batch': 7.891908597946167}
step: 31640 @ episode report: {'average_total_reward': 9.887001, 'reward_variance': 5.0264816, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2601238608360292, 'actor_loss': -5.636228466033936, 'hyper_actor_loss': 0.020340528152883054, 'behavior_loss': 0.271729077398777, 'mean_batch': 7.674090385437012, 'min_batch': 7.3080659866333, 'max_batch': 7.980569887161255}
step: 31650 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.3703003, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.912345027923584, 'actor_loss': -5.619060754776001, 'hyper_actor_loss': 0.020221839286386968, 'behavior_loss': 0.25446953177452086, 'mean_batch': 7.603994607925415, 'min_batch': 7.2499082565307615, 'max_batch': 7.900379180908203}
step: 31660 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 2.8390653, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.280162674188614, 'actor_loss': -5.635333633422851, 'hyper_actor_loss': 0.020430269464850426, 'behavior_loss': 0.26293244063854215, 'mean_batch': 7.659138774871826, 'min_batch': 7.315850067138672, 'max_batch': 7.9627495288848875}
step: 31670 @ episode report: {'average_total_reward': 11.664, 'reward_variance': 2.404684, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 12.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5602039098739624, 'actor_loss': -5.647628831863403, 'hyper_actor_loss': 0.020172195695340633, 'behavior_loss': 0.24796492010354995, 'mean_batch': 7.724802446365357, 'min_batch': 7.343215608596802, 'max_batch': 8.037204599380493}
step: 31680 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 2.6084607, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.699965476989746, 'actor_loss': -5.627171754837036, 'hyper_actor_loss': 0.02031487673521042, 'behavior_loss': 0.25763247311115267, 'mean_batch': 7.633635663986206, 'min_batch': 7.28074016571045, 'max_batch': 7.941484165191651}
step: 31690 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 8.20323, 'max_total_reward': 14.56, 'min_total_reward': 3.46, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.232009482383728, 'actor_loss': -5.61764235496521, 'hyper_actor_loss': 0.02020417582243681, 'behavior_loss': 0.25877605378627777, 'mean_batch': 7.581092071533203, 'min_batch': 7.261536169052124, 'max_batch': 7.863095808029175}
step: 31700 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 3.3236687, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.510948145389557, 'actor_loss': -5.610945749282837, 'hyper_actor_loss': 0.02048707604408264, 'behavior_loss': 0.26161145865917207, 'mean_batch': 7.580577182769775, 'min_batch': 7.2138536930084225, 'max_batch': 7.851755857467651}
step: 31710 @ episode report: {'average_total_reward': 11.164, 'reward_variance': 2.8648846, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5857115387916565, 'actor_loss': -5.6516392707824705, 'hyper_actor_loss': 0.020641112327575685, 'behavior_loss': 0.2521760553121567, 'mean_batch': 7.726768684387207, 'min_batch': 7.37164535522461, 'max_batch': 7.997504997253418}
step: 31720 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 1.6708494, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.056070876121521, 'actor_loss': -5.671666288375855, 'hyper_actor_loss': 0.0205767210572958, 'behavior_loss': 0.2609546363353729, 'mean_batch': 7.7889941215515135, 'min_batch': 7.459864091873169, 'max_batch': 8.078496360778809}
step: 31730 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.4749293, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.18860092163086, 'actor_loss': -5.630599880218506, 'hyper_actor_loss': 0.020545752719044685, 'behavior_loss': 0.2596623942255974, 'mean_batch': 7.6624212741851805, 'min_batch': 7.278377819061279, 'max_batch': 7.9778337478637695}
step: 31740 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 3.9594254, 'max_total_reward': 13.34, 'min_total_reward': 7.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.765117216110229, 'actor_loss': -5.621839141845703, 'hyper_actor_loss': 0.02077057920396328, 'behavior_loss': 0.2627465784549713, 'mean_batch': 7.601625585556031, 'min_batch': 7.272341680526734, 'max_batch': 7.958311748504639}
step: 31750 @ episode report: {'average_total_reward': 8.544001, 'reward_variance': 9.651944, 'max_total_reward': 12.34, 'min_total_reward': 2.02, 'average_n_step': 9.6, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.031115174293518, 'actor_loss': -5.609315490722656, 'hyper_actor_loss': 0.02062020618468523, 'behavior_loss': 0.2539589926600456, 'mean_batch': 7.572201204299927, 'min_batch': 7.20996356010437, 'max_batch': 7.948445463180542}
step: 31760 @ episode report: {'average_total_reward': 11.53, 'reward_variance': 1.8885195, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.47038414478302, 'actor_loss': -5.658028793334961, 'hyper_actor_loss': 0.020285282284021378, 'behavior_loss': 0.2661209344863892, 'mean_batch': 7.7738807678222654, 'min_batch': 7.373359966278076, 'max_batch': 8.104905986785889}
step: 31770 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 3.6416256, 'max_total_reward': 13.450001, 'min_total_reward': 7.7899995, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.287987315654755, 'actor_loss': -5.661660528182983, 'hyper_actor_loss': 0.020406030304729938, 'behavior_loss': 0.2606705009937286, 'mean_batch': 7.783323431015015, 'min_batch': 7.392186164855957, 'max_batch': 8.182269620895386}
step: 31780 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 2.8850563, 'max_total_reward': 14.45, 'min_total_reward': 8.79, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4936785221099855, 'actor_loss': -5.631524181365966, 'hyper_actor_loss': 0.020143028907477857, 'behavior_loss': 0.2754422828555107, 'mean_batch': 7.643291091918945, 'min_batch': 7.3030845642089846, 'max_batch': 7.969767236709595}
step: 31790 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 1.4824011, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.770746278762817, 'actor_loss': -5.65089168548584, 'hyper_actor_loss': 0.020253417454659937, 'behavior_loss': 0.255573944747448, 'mean_batch': 7.7157783031463625, 'min_batch': 7.375873136520386, 'max_batch': 8.03684334754944}
step: 31800 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 2.9487648, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6473315000534057, 'actor_loss': -5.635500717163086, 'hyper_actor_loss': 0.020611285418272018, 'behavior_loss': 0.2644868344068527, 'mean_batch': 7.663103103637695, 'min_batch': 7.313167762756348, 'max_batch': 7.985338354110718}
step: 31810 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 4.082141, 'max_total_reward': 12.23, 'min_total_reward': 4.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.832996296882629, 'actor_loss': -5.644302606582642, 'hyper_actor_loss': 0.020680780336260796, 'behavior_loss': 0.2685740441083908, 'mean_batch': 7.716388130187989, 'min_batch': 7.3270386219024655, 'max_batch': 8.00442395210266}
step: 31820 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 6.6584063, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.047194862365723, 'actor_loss': -5.632805967330933, 'hyper_actor_loss': 0.020624756067991256, 'behavior_loss': 0.25829669535160066, 'mean_batch': 7.667506885528565, 'min_batch': 7.289556217193604, 'max_batch': 7.96458249092102}
step: 31830 @ episode report: {'average_total_reward': 11.353, 'reward_variance': 2.8087018, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.633876156806946, 'actor_loss': -5.607893085479736, 'hyper_actor_loss': 0.020343196764588355, 'behavior_loss': 0.26124017983675, 'mean_batch': 7.575492095947266, 'min_batch': 7.1964452266693115, 'max_batch': 7.89918622970581}
step: 31840 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 5.62842, 'max_total_reward': 14.339999, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.021776103973389, 'actor_loss': -5.605242824554443, 'hyper_actor_loss': 0.020576767437160016, 'behavior_loss': 0.2573674201965332, 'mean_batch': 7.564708566665649, 'min_batch': 7.187643909454346, 'max_batch': 7.842821884155273}
step: 31850 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 1.53325, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8660062551498413, 'actor_loss': -5.645492124557495, 'hyper_actor_loss': 0.020358551666140555, 'behavior_loss': 0.27335537523031234, 'mean_batch': 7.709429121017456, 'min_batch': 7.342602014541626, 'max_batch': 8.036246490478515}
step: 31860 @ episode report: {'average_total_reward': 10.398, 'reward_variance': 4.131116, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7638819217681885, 'actor_loss': -5.639859390258789, 'hyper_actor_loss': 0.020675037056207657, 'behavior_loss': 0.26089721769094465, 'mean_batch': 7.695813751220703, 'min_batch': 7.314070987701416, 'max_batch': 7.994439554214478}
step: 31870 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 4.772642, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.835427165031433, 'actor_loss': -5.600462913513184, 'hyper_actor_loss': 0.020388746075332163, 'behavior_loss': 0.2675769358873367, 'mean_batch': 7.5293200492858885, 'min_batch': 7.187566614151001, 'max_batch': 7.848562812805175}
step: 31880 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 2.0274212, 'max_total_reward': 13.23, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.010984492301941, 'actor_loss': -5.6109028339385985, 'hyper_actor_loss': 0.020792698860168456, 'behavior_loss': 0.27638363242149355, 'mean_batch': 7.584032297134399, 'min_batch': 7.210018301010132, 'max_batch': 7.916045999526977}
step: 31890 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 2.3015604, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.684151625633239, 'actor_loss': -5.615742158889771, 'hyper_actor_loss': 0.02049089353531599, 'behavior_loss': 0.268908916413784, 'mean_batch': 7.652845764160157, 'min_batch': 7.180071544647217, 'max_batch': 8.03122615814209}
step: 31900 @ episode report: {'average_total_reward': 11.053001, 'reward_variance': 2.9120815, 'max_total_reward': 13.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.304812729358673, 'actor_loss': -5.608294820785522, 'hyper_actor_loss': 0.02054927237331867, 'behavior_loss': 0.27977755963802337, 'mean_batch': 7.639192676544189, 'min_batch': 7.139876842498779, 'max_batch': 8.049258422851562}
step: 31910 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 6.234836, 'max_total_reward': 14.34, 'min_total_reward': 5.57, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.986509609222412, 'actor_loss': -5.644326019287109, 'hyper_actor_loss': 0.020050056651234625, 'behavior_loss': 0.25973859876394273, 'mean_batch': 7.759450483322143, 'min_batch': 7.286772441864014, 'max_batch': 8.137353324890137}
step: 31920 @ episode report: {'average_total_reward': 8.977, 'reward_variance': 5.15536, 'max_total_reward': 11.2300005, 'min_total_reward': 4.57, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.306797385215759, 'actor_loss': -5.633177423477173, 'hyper_actor_loss': 0.019940406270325183, 'behavior_loss': 0.2540304183959961, 'mean_batch': 7.701708984375, 'min_batch': 7.260296201705932, 'max_batch': 8.067928314208984}
step: 31930 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 1.6672153, 'max_total_reward': 13.23, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.632095766067505, 'actor_loss': -5.620558643341065, 'hyper_actor_loss': 0.019717362336814405, 'behavior_loss': 0.2560372829437256, 'mean_batch': 7.60485806465149, 'min_batch': 7.260004472732544, 'max_batch': 7.897430515289306}
step: 31940 @ episode report: {'average_total_reward': 11.064, 'reward_variance': 3.805264, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.034117746353149, 'actor_loss': -5.6353291988372805, 'hyper_actor_loss': 0.019647835195064543, 'behavior_loss': 0.2683823585510254, 'mean_batch': 7.693095111846924, 'min_batch': 7.283733606338501, 'max_batch': 8.038295221328735}
step: 31950 @ episode report: {'average_total_reward': 11.297001, 'reward_variance': 3.2341816, 'max_total_reward': 15.670001, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7170111417770384, 'actor_loss': -5.615333843231201, 'hyper_actor_loss': 0.01959556043148041, 'behavior_loss': 0.26849864423274994, 'mean_batch': 7.5830464363098145, 'min_batch': 7.24273715019226, 'max_batch': 7.887645673751831}
step: 31960 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 4.9806204, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.116097331047058, 'actor_loss': -5.640378856658936, 'hyper_actor_loss': 0.02015217375010252, 'behavior_loss': 0.26870486289262774, 'mean_batch': 7.689872980117798, 'min_batch': 7.324019241333008, 'max_batch': 7.965424251556397}
step: 31970 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 1.8339049, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0664778649806976, 'actor_loss': -5.666053533554077, 'hyper_actor_loss': 0.020394628494977952, 'behavior_loss': 0.2713615417480469, 'mean_batch': 7.810264825820923, 'min_batch': 7.3980498790740965, 'max_batch': 8.111560821533203}
step: 31980 @ episode report: {'average_total_reward': 10.909001, 'reward_variance': 3.5894082, 'max_total_reward': 14.559999, 'min_total_reward': 7.7900004, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8030776262283323, 'actor_loss': -5.638884258270264, 'hyper_actor_loss': 0.020572126656770707, 'behavior_loss': 0.26514639854431155, 'mean_batch': 7.698262357711792, 'min_batch': 7.305149126052856, 'max_batch': 7.964433050155639}
step: 31990 @ episode report: {'average_total_reward': 10.909, 'reward_variance': 2.328049, 'max_total_reward': 13.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9678772568702696, 'actor_loss': -5.616205644607544, 'hyper_actor_loss': 0.020204531960189342, 'behavior_loss': 0.25067094564437864, 'mean_batch': 7.594939184188843, 'min_batch': 7.237829113006592, 'max_batch': 7.897668170928955}
step: 32000 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 1.5058439, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6271048903465273, 'actor_loss': -5.631325387954712, 'hyper_actor_loss': 0.01983151789754629, 'behavior_loss': 0.2691761299967766, 'mean_batch': 7.64283857345581, 'min_batch': 7.302182006835937, 'max_batch': 7.91532621383667}
step: 32010 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 3.94598, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6231628537178038, 'actor_loss': -5.649756050109863, 'hyper_actor_loss': 0.020141362212598324, 'behavior_loss': 0.25516200959682467, 'mean_batch': 7.714545059204101, 'min_batch': 7.368718051910401, 'max_batch': 7.991099834442139}
step: 32020 @ episode report: {'average_total_reward': 11.253, 'reward_variance': 3.5969613, 'max_total_reward': 14.56, 'min_total_reward': 7.6800003, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8339536666870115, 'actor_loss': -5.625183725357056, 'hyper_actor_loss': 0.01989212743937969, 'behavior_loss': 0.2563154026865959, 'mean_batch': 7.627440738677978, 'min_batch': 7.272652959823608, 'max_batch': 7.8891273021698}
step: 32030 @ episode report: {'average_total_reward': 11.486, 'reward_variance': 2.7303443, 'max_total_reward': 14.450001, 'min_total_reward': 7.7900004, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.568466305732727, 'actor_loss': -5.571903228759766, 'hyper_actor_loss': 0.019809279032051562, 'behavior_loss': 0.26141143441200254, 'mean_batch': 7.40781455039978, 'min_batch': 7.099167346954346, 'max_batch': 7.69627890586853}
step: 32040 @ episode report: {'average_total_reward': 11.364, 'reward_variance': 3.8416038, 'max_total_reward': 15.45, 'min_total_reward': 8.9, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.723098874092102, 'actor_loss': -5.572835111618042, 'hyper_actor_loss': 0.019733099080622197, 'behavior_loss': 0.250108839571476, 'mean_batch': 7.425676059722901, 'min_batch': 7.088514280319214, 'max_batch': 7.700945234298706}
step: 32050 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 3.8503647, 'max_total_reward': 13.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.28325207233429, 'actor_loss': -5.592377233505249, 'hyper_actor_loss': 0.019607370160520075, 'behavior_loss': 0.25480736047029495, 'mean_batch': 7.536914300918579, 'min_batch': 7.122353267669678, 'max_batch': 7.834196472167969}
step: 32060 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 2.253949, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.24520206451416, 'actor_loss': -5.621672964096069, 'hyper_actor_loss': 0.019337565824389457, 'behavior_loss': 0.25947527438402174, 'mean_batch': 7.636897706985474, 'min_batch': 7.237673234939575, 'max_batch': 8.008411073684693}
step: 32070 @ episode report: {'average_total_reward': 10.420001, 'reward_variance': 3.3426204, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1679211258888245, 'actor_loss': -5.657894134521484, 'hyper_actor_loss': 0.019374722428619862, 'behavior_loss': 0.25989108830690383, 'mean_batch': 7.813953447341919, 'min_batch': 7.335025358200073, 'max_batch': 8.150501346588134}
step: 32080 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 2.6189365, 'max_total_reward': 12.230001, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.199230456352234, 'actor_loss': -5.628658676147461, 'hyper_actor_loss': 0.01918764617294073, 'behavior_loss': 0.2692515179514885, 'mean_batch': 7.646037340164185, 'min_batch': 7.280167102813721, 'max_batch': 7.965936183929443}
step: 32090 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 7.03986, 'max_total_reward': 12.34, 'min_total_reward': 2.24, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.301701283454895, 'actor_loss': -5.578161287307739, 'hyper_actor_loss': 0.019417316652834415, 'behavior_loss': 0.25556428283452987, 'mean_batch': 7.432010316848755, 'min_batch': 7.120561838150024, 'max_batch': 7.693221378326416}
step: 32100 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 9.663666, 'max_total_reward': 13.45, 'min_total_reward': 2.24, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.215569376945496, 'actor_loss': -5.584151887893677, 'hyper_actor_loss': 0.019352290220558642, 'behavior_loss': 0.25813765078783035, 'mean_batch': 7.476544618606567, 'min_batch': 7.120746040344239, 'max_batch': 7.771933364868164}
step: 32110 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 1.484964, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6285414695739746, 'actor_loss': -5.62032265663147, 'hyper_actor_loss': 0.019225569255650044, 'behavior_loss': 0.2793561413884163, 'mean_batch': 7.614843654632568, 'min_batch': 7.249125528335571, 'max_batch': 7.895026206970215}
step: 32120 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 4.0035443, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.805622339248657, 'actor_loss': -5.608019161224365, 'hyper_actor_loss': 0.019241374731063843, 'behavior_loss': 0.2529055893421173, 'mean_batch': 7.562184858322143, 'min_batch': 7.21080174446106, 'max_batch': 7.833812236785889}
step: 32130 @ episode report: {'average_total_reward': 11.153, 'reward_variance': 2.742422, 'max_total_reward': 14.450001, 'min_total_reward': 8.789999, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.483308529853821, 'actor_loss': -5.589766502380371, 'hyper_actor_loss': 0.019146186485886573, 'behavior_loss': 0.27138241231441496, 'mean_batch': 7.506377553939819, 'min_batch': 7.132397651672363, 'max_batch': 7.873434209823609}
step: 32140 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 4.1524844, 'max_total_reward': 12.34, 'min_total_reward': 6.57, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.810055136680603, 'actor_loss': -5.629684495925903, 'hyper_actor_loss': 0.018834590911865234, 'behavior_loss': 0.2503621831536293, 'mean_batch': 7.694735050201416, 'min_batch': 7.240931844711303, 'max_batch': 8.07096357345581}
step: 32150 @ episode report: {'average_total_reward': 10.853, 'reward_variance': 3.3359008, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6354111194610597, 'actor_loss': -5.631993913650513, 'hyper_actor_loss': 0.018818348459899426, 'behavior_loss': 0.26477278470993043, 'mean_batch': 7.676360940933227, 'min_batch': 7.275293684005737, 'max_batch': 8.033588457107545}
step: 32160 @ episode report: {'average_total_reward': 9.532, 'reward_variance': 8.2396965, 'max_total_reward': 12.34, 'min_total_reward': 2.46, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.780618977546692, 'actor_loss': -5.630414342880249, 'hyper_actor_loss': 0.018835682049393655, 'behavior_loss': 0.27438023686408997, 'mean_batch': 7.659430265426636, 'min_batch': 7.279879236221314, 'max_batch': 7.9921411037445065}
step: 32170 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 1.3447454, 'max_total_reward': 12.34, 'min_total_reward': 8.789999, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.103447937965393, 'actor_loss': -5.606753253936768, 'hyper_actor_loss': 0.01887517087161541, 'behavior_loss': 0.27818489968776705, 'mean_batch': 7.574183702468872, 'min_batch': 7.189469480514527, 'max_batch': 7.852263975143432}
step: 32180 @ episode report: {'average_total_reward': 11.153, 'reward_variance': 1.7858009, 'max_total_reward': 13.34, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7301793932914733, 'actor_loss': -5.620785522460937, 'hyper_actor_loss': 0.018859995529055595, 'behavior_loss': 0.2765133112668991, 'mean_batch': 7.60877742767334, 'min_batch': 7.2579608917236325, 'max_batch': 7.938480520248413}
step: 32190 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 5.9629436, 'max_total_reward': 14.45, 'min_total_reward': 5.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7176063537597654, 'actor_loss': -5.633286333084106, 'hyper_actor_loss': 0.018675298430025578, 'behavior_loss': 0.28383558988571167, 'mean_batch': 7.6842276096344, 'min_batch': 7.277134275436401, 'max_batch': 8.015603256225585}
step: 32200 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 3.6385765, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.960694432258606, 'actor_loss': -5.619462490081787, 'hyper_actor_loss': 0.018634217232465743, 'behavior_loss': 0.25906177908182143, 'mean_batch': 7.610890197753906, 'min_batch': 7.246594381332398, 'max_batch': 7.911464357376099}
step: 32210 @ episode report: {'average_total_reward': 10.519999, 'reward_variance': 8.076599, 'max_total_reward': 12.34, 'min_total_reward': 2.35, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.070614433288574, 'actor_loss': -5.5951885223388675, 'hyper_actor_loss': 0.01822933927178383, 'behavior_loss': 0.26242334544658663, 'mean_batch': 7.545334339141846, 'min_batch': 7.13438229560852, 'max_batch': 7.887350702285767}
step: 32220 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 3.06072, 'max_total_reward': 14.450001, 'min_total_reward': 8.790001, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.725784158706665, 'actor_loss': -5.609073543548584, 'hyper_actor_loss': 0.01829017251729965, 'behavior_loss': 0.2632782384753227, 'mean_batch': 7.586408805847168, 'min_batch': 7.194722270965576, 'max_batch': 7.919465112686157}
step: 32230 @ episode report: {'average_total_reward': 10.598, 'reward_variance': 2.742976, 'max_total_reward': 13.23, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.982861888408661, 'actor_loss': -5.600547885894775, 'hyper_actor_loss': 0.018261286802589892, 'behavior_loss': 0.2853976398706436, 'mean_batch': 7.546910524368286, 'min_batch': 7.170825099945068, 'max_batch': 7.846045064926147}
step: 32240 @ episode report: {'average_total_reward': 11.741, 'reward_variance': 5.2661695, 'max_total_reward': 15.56, 'min_total_reward': 7.7900004, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7316096782684327, 'actor_loss': -5.5954132080078125, 'hyper_actor_loss': 0.01822489481419325, 'behavior_loss': 0.270224629342556, 'mean_batch': 7.532376003265381, 'min_batch': 7.147981452941894, 'max_batch': 7.869086360931396}
step: 32250 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.0803237, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.53626948595047, 'actor_loss': -5.603801250457764, 'hyper_actor_loss': 0.018106351792812347, 'behavior_loss': 0.2563969805836678, 'mean_batch': 7.5813616752624515, 'min_batch': 7.1622686862945555, 'max_batch': 7.890774583816528}
step: 32260 @ episode report: {'average_total_reward': 10.432001, 'reward_variance': 1.8784164, 'max_total_reward': 12.34, 'min_total_reward': 8.46, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.768211388587952, 'actor_loss': -5.574888420104981, 'hyper_actor_loss': 0.018086941353976725, 'behavior_loss': 0.25712103545665743, 'mean_batch': 7.460230159759521, 'min_batch': 7.070416021347046, 'max_batch': 7.757574415206909}
step: 32270 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 3.477796, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.988101100921631, 'actor_loss': -5.559305572509766, 'hyper_actor_loss': 0.018203677795827388, 'behavior_loss': 0.25347641855478287, 'mean_batch': 7.3905784606933596, 'min_batch': 7.026866769790649, 'max_batch': 7.692083072662354}
step: 32280 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 8.5679455, 'max_total_reward': 13.34, 'min_total_reward': 2.46, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.567167949676514, 'actor_loss': -5.63786563873291, 'hyper_actor_loss': 0.018368457071483137, 'behavior_loss': 0.2717702776193619, 'mean_batch': 7.70075101852417, 'min_batch': 7.295332574844361, 'max_batch': 8.037068319320678}
step: 32290 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 3.2337692, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.453448307514191, 'actor_loss': -5.662539625167847, 'hyper_actor_loss': 0.018407459184527398, 'behavior_loss': 0.2545172795653343, 'mean_batch': 7.812265872955322, 'min_batch': 7.370724105834961, 'max_batch': 8.152262306213379}
step: 32300 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 3.1462255, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2120123505592346, 'actor_loss': -5.600193119049072, 'hyper_actor_loss': 0.018439411371946334, 'behavior_loss': 0.26230342984199523, 'mean_batch': 7.560625219345093, 'min_batch': 7.155606317520141, 'max_batch': 7.894564008712768}
step: 32310 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 6.537542, 'max_total_reward': 15.56, 'min_total_reward': 5.68, 'average_n_step': 11.1, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.678243064880371, 'actor_loss': -5.627698135375977, 'hyper_actor_loss': 0.018533257581293584, 'behavior_loss': 0.26070058941841123, 'mean_batch': 7.632694816589355, 'min_batch': 7.285400676727295, 'max_batch': 7.946570014953613}
step: 32320 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 4.766657, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6447281002998353, 'actor_loss': -5.6467897415161135, 'hyper_actor_loss': 0.01883679535239935, 'behavior_loss': 0.2691738963127136, 'mean_batch': 7.730576276779175, 'min_batch': 7.331620788574218, 'max_batch': 8.015134477615357}
step: 32330 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 2.860081, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.578155255317688, 'actor_loss': -5.643279123306274, 'hyper_actor_loss': 0.01930103562772274, 'behavior_loss': 0.2660326659679413, 'mean_batch': 7.689153051376342, 'min_batch': 7.345380878448486, 'max_batch': 8.015213251113892}
step: 32340 @ episode report: {'average_total_reward': 9.987, 'reward_variance': 3.1941414, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.465199685096741, 'actor_loss': -5.659478664398193, 'hyper_actor_loss': 0.01928418278694153, 'behavior_loss': 0.25344150215387345, 'mean_batch': 7.744185590744019, 'min_batch': 7.412288093566895, 'max_batch': 8.029753160476684}
step: 32350 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 4.3660803, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.08052145242691, 'actor_loss': -5.647276449203491, 'hyper_actor_loss': 0.019429872557520867, 'behavior_loss': 0.2665646657347679, 'mean_batch': 7.715693998336792, 'min_batch': 7.349366807937622, 'max_batch': 8.055172061920166}
step: 32360 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 0.94216406, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.784501314163208, 'actor_loss': -5.646985101699829, 'hyper_actor_loss': 0.01942205298691988, 'behavior_loss': 0.2701541930437088, 'mean_batch': 7.704940843582153, 'min_batch': 7.3574951648712155, 'max_batch': 8.016274023056031}
step: 32370 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 1.7793362, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7645642042160032, 'actor_loss': -5.642281436920166, 'hyper_actor_loss': 0.01926851160824299, 'behavior_loss': 0.26713735461235044, 'mean_batch': 7.707332706451416, 'min_batch': 7.320657205581665, 'max_batch': 8.029486322402954}
step: 32380 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 0.9665841, 'max_total_reward': 11.2300005, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9740438938140867, 'actor_loss': -5.6362528800964355, 'hyper_actor_loss': 0.019367462024092674, 'behavior_loss': 0.2650730773806572, 'mean_batch': 7.681561279296875, 'min_batch': 7.301304340362549, 'max_batch': 7.948599243164063}
step: 32390 @ episode report: {'average_total_reward': 11.508, 'reward_variance': 3.6019561, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.776617980003357, 'actor_loss': -5.649332475662232, 'hyper_actor_loss': 0.019464284367859363, 'behavior_loss': 0.2650434821844101, 'mean_batch': 7.718165683746338, 'min_batch': 7.362130641937256, 'max_batch': 7.982824754714966}
step: 32400 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 3.1774163, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.804899513721466, 'actor_loss': -5.656230640411377, 'hyper_actor_loss': 0.01926286853849888, 'behavior_loss': 0.26646508872509, 'mean_batch': 7.733379125595093, 'min_batch': 7.398473834991455, 'max_batch': 8.04155969619751}
step: 32410 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 5.0574775, 'max_total_reward': 14.560001, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.517689514160156, 'actor_loss': -5.641408967971802, 'hyper_actor_loss': 0.01949338112026453, 'behavior_loss': 0.28577728420495985, 'mean_batch': 7.714687013626099, 'min_batch': 7.307614326477051, 'max_batch': 8.036990070343018}
step: 32420 @ episode report: {'average_total_reward': 10.687, 'reward_variance': 4.8880215, 'max_total_reward': 14.45, 'min_total_reward': 5.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3863773345947266, 'actor_loss': -5.624303531646729, 'hyper_actor_loss': 0.019857908599078655, 'behavior_loss': 0.2656203269958496, 'mean_batch': 7.6438782691955565, 'min_batch': 7.250049591064453, 'max_batch': 7.955262136459351}
step: 32430 @ episode report: {'average_total_reward': 10.164999, 'reward_variance': 4.4271655, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1466027975082396, 'actor_loss': -5.635170936584473, 'hyper_actor_loss': 0.019442440941929817, 'behavior_loss': 0.2667514458298683, 'mean_batch': 7.667577791213989, 'min_batch': 7.306675100326538, 'max_batch': 7.96431303024292}
step: 32440 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 1.668984, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5379976511001585, 'actor_loss': -5.632747411727905, 'hyper_actor_loss': 0.019143806025385856, 'behavior_loss': 0.2652976721525192, 'mean_batch': 7.672362661361694, 'min_batch': 7.284607934951782, 'max_batch': 7.979487943649292}
step: 32450 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.2749295, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.713887298107147, 'actor_loss': -5.6251997470855715, 'hyper_actor_loss': 0.019150743074715138, 'behavior_loss': 0.2597887128591537, 'mean_batch': 7.629040765762329, 'min_batch': 7.270857286453247, 'max_batch': 7.924898910522461}
step: 32460 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 2.4833694, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4395439863204955, 'actor_loss': -5.670626068115235, 'hyper_actor_loss': 0.018834203481674194, 'behavior_loss': 0.257895790040493, 'mean_batch': 7.789941120147705, 'min_batch': 7.451280975341797, 'max_batch': 8.0848237991333}
step: 32470 @ episode report: {'average_total_reward': 10.632001, 'reward_variance': 1.5622561, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.295830965042114, 'actor_loss': -5.591913938522339, 'hyper_actor_loss': 0.01917969323694706, 'behavior_loss': 0.2635462895035744, 'mean_batch': 7.514908361434936, 'min_batch': 7.140858793258667, 'max_batch': 7.799401140213012}
step: 32480 @ episode report: {'average_total_reward': 10.099001, 'reward_variance': 5.00937, 'max_total_reward': 13.34, 'min_total_reward': 5.57, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2192626118659975, 'actor_loss': -5.628933668136597, 'hyper_actor_loss': 0.019149350561201574, 'behavior_loss': 0.2620452165603638, 'mean_batch': 7.630600023269653, 'min_batch': 7.2987419128417965, 'max_batch': 7.893557453155518}
step: 32490 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 6.6026087, 'max_total_reward': 14.559999, 'min_total_reward': 5.57, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.870748615264892, 'actor_loss': -5.653477144241333, 'hyper_actor_loss': 0.01939210407435894, 'behavior_loss': 0.26361346542835234, 'mean_batch': 7.7470471382141115, 'min_batch': 7.366051101684571, 'max_batch': 8.034625148773193}
step: 32500 @ episode report: {'average_total_reward': 9.543, 'reward_variance': 2.9985807, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.130207800865174, 'actor_loss': -5.6092452049255375, 'hyper_actor_loss': 0.019259409978985786, 'behavior_loss': 0.2661362260580063, 'mean_batch': 7.5688151836395265, 'min_batch': 7.2123884677886965, 'max_batch': 7.843867588043213}
step: 32510 @ episode report: {'average_total_reward': 9.21, 'reward_variance': 9.917102, 'max_total_reward': 13.450001, 'min_total_reward': 1.02, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.647658979892731, 'actor_loss': -5.614241409301758, 'hyper_actor_loss': 0.019232104159891607, 'behavior_loss': 0.25843207389116285, 'mean_batch': 7.5780736923217775, 'min_batch': 7.2398459911346436, 'max_batch': 7.8963707447052}
step: 32520 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 1.3257802, 'max_total_reward': 11.23, 'min_total_reward': 7.7900004, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.759809422492981, 'actor_loss': -5.672124338150025, 'hyper_actor_loss': 0.01918480321764946, 'behavior_loss': 0.27589184790849686, 'mean_batch': 7.83045392036438, 'min_batch': 7.424105310440064, 'max_batch': 8.13786735534668}
step: 32530 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 4.3731956, 'max_total_reward': 13.45, 'min_total_reward': 5.57, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.877302145957947, 'actor_loss': -5.613356065750122, 'hyper_actor_loss': 0.018854046985507012, 'behavior_loss': 0.23883475214242936, 'mean_batch': 7.59637484550476, 'min_batch': 7.216538953781128, 'max_batch': 7.872102212905884}
step: 32540 @ episode report: {'average_total_reward': 11.386, 'reward_variance': 3.2715442, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.915218639373779, 'actor_loss': -5.61119966506958, 'hyper_actor_loss': 0.018665523454546928, 'behavior_loss': 0.2576706647872925, 'mean_batch': 7.571317911148071, 'min_batch': 7.224189758300781, 'max_batch': 7.8730193138122555}
step: 32550 @ episode report: {'average_total_reward': 10.431001, 'reward_variance': 2.2026894, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3450523376464845, 'actor_loss': -5.641075611114502, 'hyper_actor_loss': 0.018879319541156292, 'behavior_loss': 0.2685642331838608, 'mean_batch': 7.717106819152832, 'min_batch': 7.302967691421509, 'max_batch': 8.013355541229249}
step: 32560 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 3.1376212, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8418709874153136, 'actor_loss': -5.648657608032226, 'hyper_actor_loss': 0.019029589742422102, 'behavior_loss': 0.2634140193462372, 'mean_batch': 7.742047595977783, 'min_batch': 7.334576082229614, 'max_batch': 8.030882978439331}
step: 32570 @ episode report: {'average_total_reward': 11.619, 'reward_variance': 5.0075502, 'max_total_reward': 15.670001, 'min_total_reward': 8.9, 'average_n_step': 12.4, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.43410108089447, 'actor_loss': -5.61300311088562, 'hyper_actor_loss': 0.01896240245550871, 'behavior_loss': 0.2690807029604912, 'mean_batch': 7.5793335914611815, 'min_batch': 7.229883909225464, 'max_batch': 7.868467187881469}
step: 32580 @ episode report: {'average_total_reward': 11.453, 'reward_variance': 2.1178806, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.509209132194519, 'actor_loss': -5.589735412597657, 'hyper_actor_loss': 0.018937462009489536, 'behavior_loss': 0.26248316913843156, 'mean_batch': 7.47990870475769, 'min_batch': 7.157091474533081, 'max_batch': 7.762336254119873}
step: 32590 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 2.9462247, 'max_total_reward': 12.339999, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.763458228111267, 'actor_loss': -5.622503423690796, 'hyper_actor_loss': 0.01888402309268713, 'behavior_loss': 0.26411670744419097, 'mean_batch': 7.626129245758056, 'min_batch': 7.254268932342529, 'max_batch': 7.926779508590698}
step: 32600 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 10.471129, 'max_total_reward': 13.45, 'min_total_reward': 2.24, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.402947020530701, 'actor_loss': -5.649899053573608, 'hyper_actor_loss': 0.018685337156057358, 'behavior_loss': 0.2572227671742439, 'mean_batch': 7.750224208831787, 'min_batch': 7.336105537414551, 'max_batch': 8.030912065505982}
step: 32610 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 3.5518055, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.12313494682312, 'actor_loss': -5.642696809768677, 'hyper_actor_loss': 0.018862720020115374, 'behavior_loss': 0.24601744264364242, 'mean_batch': 7.7212574005126955, 'min_batch': 7.311044788360595, 'max_batch': 8.005483484268188}
step: 32620 @ episode report: {'average_total_reward': 10.776, 'reward_variance': 2.9800649, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9928302526474, 'actor_loss': -5.609582805633545, 'hyper_actor_loss': 0.01871547885239124, 'behavior_loss': 0.2692528322339058, 'mean_batch': 7.58402452468872, 'min_batch': 7.200685739517212, 'max_batch': 7.871164226531983}
step: 32630 @ episode report: {'average_total_reward': 10.631, 'reward_variance': 4.846389, 'max_total_reward': 15.559999, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.412025570869446, 'actor_loss': -5.6336359024047855, 'hyper_actor_loss': 0.01887702438980341, 'behavior_loss': 0.2716911181807518, 'mean_batch': 7.685388374328613, 'min_batch': 7.2784727096557615, 'max_batch': 8.004325866699219}
step: 32640 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 9.286944, 'max_total_reward': 13.339999, 'min_total_reward': 1.35, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.637735068798065, 'actor_loss': -5.626578378677368, 'hyper_actor_loss': 0.018979168310761452, 'behavior_loss': 0.2642031744122505, 'mean_batch': 7.661360740661621, 'min_batch': 7.250453519821167, 'max_batch': 7.963074016571045}
step: 32650 @ episode report: {'average_total_reward': 10.120001, 'reward_variance': 2.8617797, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.198147416114807, 'actor_loss': -5.634395408630371, 'hyper_actor_loss': 0.019008120521903038, 'behavior_loss': 0.2456606149673462, 'mean_batch': 7.6841590881347654, 'min_batch': 7.2853845119476315, 'max_batch': 7.993337345123291}
step: 32660 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.6203213, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.917552351951599, 'actor_loss': -5.638333749771118, 'hyper_actor_loss': 0.018749063648283482, 'behavior_loss': 0.27697805762290956, 'mean_batch': 7.751187086105347, 'min_batch': 7.250767230987549, 'max_batch': 8.115997695922852}
step: 32670 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 3.0547163, 'max_total_reward': 13.45, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4093463361263274, 'actor_loss': -5.642940521240234, 'hyper_actor_loss': 0.018905917182564735, 'behavior_loss': 0.2646171823143959, 'mean_batch': 7.733263921737671, 'min_batch': 7.301325368881225, 'max_batch': 8.07045645713806}
step: 32680 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 3.252489, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3717553943395613, 'actor_loss': -5.655861568450928, 'hyper_actor_loss': 0.018583947606384755, 'behavior_loss': 0.25808739066123965, 'mean_batch': 7.7724365234375, 'min_batch': 7.358638000488281, 'max_batch': 8.090378856658935}
step: 32690 @ episode report: {'average_total_reward': 10.098, 'reward_variance': 9.597376, 'max_total_reward': 15.67, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3957322359085085, 'actor_loss': -5.6741949081420895, 'hyper_actor_loss': 0.018419764004647732, 'behavior_loss': 0.26924609690904616, 'mean_batch': 7.832723665237427, 'min_batch': 7.4373297691345215, 'max_batch': 8.1312819480896}
step: 32700 @ episode report: {'average_total_reward': 11.918999, 'reward_variance': 5.7014093, 'max_total_reward': 16.67, 'min_total_reward': 8.79, 'average_n_step': 12.7, 'max_n_step': 17.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6500996232032774, 'actor_loss': -5.661957883834839, 'hyper_actor_loss': 0.018006675131618976, 'behavior_loss': 0.27316412776708604, 'mean_batch': 7.786584281921387, 'min_batch': 7.390820837020874, 'max_batch': 8.095908069610596}
step: 32710 @ episode report: {'average_total_reward': 11.552, 'reward_variance': 3.0266159, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.156768536567688, 'actor_loss': -5.665556240081787, 'hyper_actor_loss': 0.01804451234638691, 'behavior_loss': 0.2654292732477188, 'mean_batch': 7.80142912864685, 'min_batch': 7.4030379295349125, 'max_batch': 8.10837755203247}
step: 32720 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 1.9254239, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7049164295196535, 'actor_loss': -5.655507755279541, 'hyper_actor_loss': 0.018092998303472996, 'behavior_loss': 0.27567230015993116, 'mean_batch': 7.756812715530396, 'min_batch': 7.370975923538208, 'max_batch': 8.064280939102172}
step: 32730 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.771521, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.231278324127197, 'actor_loss': -5.687317609786987, 'hyper_actor_loss': 0.018223367258906366, 'behavior_loss': 0.2498584970831871, 'mean_batch': 7.912445402145385, 'min_batch': 7.459480333328247, 'max_batch': 8.251500988006592}
step: 32740 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 2.561484, 'max_total_reward': 12.34, 'min_total_reward': 6.680001, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.070789122581482, 'actor_loss': -5.684278297424316, 'hyper_actor_loss': 0.018143720179796218, 'behavior_loss': 0.24498667418956757, 'mean_batch': 7.873502397537232, 'min_batch': 7.473946237564087, 'max_batch': 8.223503398895264}
step: 32750 @ episode report: {'average_total_reward': 10.720001, 'reward_variance': 1.7477798, 'max_total_reward': 12.340001, 'min_total_reward': 8.790001, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.703432548046112, 'actor_loss': -5.662078142166138, 'hyper_actor_loss': 0.017923063412308694, 'behavior_loss': 0.2538060337305069, 'mean_batch': 7.826956701278687, 'min_batch': 7.354038047790527, 'max_batch': 8.143341827392579}
step: 32760 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 4.963664, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.031753516197204, 'actor_loss': -5.686700820922852, 'hyper_actor_loss': 0.017904289439320563, 'behavior_loss': 0.2671755746006966, 'mean_batch': 7.914905214309693, 'min_batch': 7.452796936035156, 'max_batch': 8.304041862487793}
step: 32770 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 1.1701012, 'max_total_reward': 12.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.405205631256104, 'actor_loss': -5.642445135116577, 'hyper_actor_loss': 0.01777978166937828, 'behavior_loss': 0.275143638253212, 'mean_batch': 7.729149723052979, 'min_batch': 7.3021057605743405, 'max_batch': 8.09619688987732}
step: 32780 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 8.035459, 'max_total_reward': 12.340001, 'min_total_reward': 2.24, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.394185125827789, 'actor_loss': -5.671260738372803, 'hyper_actor_loss': 0.01802162788808346, 'behavior_loss': 0.2495672658085823, 'mean_batch': 7.8420654296875, 'min_batch': 7.4071990013122555, 'max_batch': 8.187990093231202}
step: 32790 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 4.0839834, 'max_total_reward': 14.45, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3378314733505245, 'actor_loss': -5.682891702651977, 'hyper_actor_loss': 0.017602728866040706, 'behavior_loss': 0.2731502249836922, 'mean_batch': 7.857839679718017, 'min_batch': 7.478219127655029, 'max_batch': 8.169681644439697}
step: 32800 @ episode report: {'average_total_reward': 11.286, 'reward_variance': 2.5170646, 'max_total_reward': 14.450001, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.489439868927002, 'actor_loss': -5.617919540405273, 'hyper_actor_loss': 0.01750891599804163, 'behavior_loss': 0.2613469436764717, 'mean_batch': 7.615434885025024, 'min_batch': 7.231188011169434, 'max_batch': 7.942188310623169}
step: 32810 @ episode report: {'average_total_reward': 9.599, 'reward_variance': 3.9356475, 'max_total_reward': 13.229999, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4629984378814695, 'actor_loss': -5.680210018157959, 'hyper_actor_loss': 0.018186497502028942, 'behavior_loss': 0.25926441252231597, 'mean_batch': 7.837222099304199, 'min_batch': 7.478485107421875, 'max_batch': 8.147775077819825}
step: 32820 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.6402638, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.99838354587555, 'actor_loss': -5.650406265258789, 'hyper_actor_loss': 0.018137869611382484, 'behavior_loss': 0.2729875609278679, 'mean_batch': 7.754230213165283, 'min_batch': 7.336597490310669, 'max_batch': 8.07341628074646}
step: 32830 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 6.3317695, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.100472855567932, 'actor_loss': -5.652476358413696, 'hyper_actor_loss': 0.018304235488176345, 'behavior_loss': 0.25905237942934034, 'mean_batch': 7.761952447891235, 'min_batch': 7.343823957443237, 'max_batch': 8.085523414611817}
step: 32840 @ episode report: {'average_total_reward': 9.432, 'reward_variance': 5.106316, 'max_total_reward': 14.559999, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.174810314178467, 'actor_loss': -5.66824517250061, 'hyper_actor_loss': 0.01810435075312853, 'behavior_loss': 0.2583433911204338, 'mean_batch': 7.8440674304962155, 'min_batch': 7.38278431892395, 'max_batch': 8.196053409576416}
step: 32850 @ episode report: {'average_total_reward': 10.287, 'reward_variance': 4.194141, 'max_total_reward': 14.559999, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5722076416015627, 'actor_loss': -5.705413675308227, 'hyper_actor_loss': 0.017794734612107278, 'behavior_loss': 0.24033881425857545, 'mean_batch': 7.964254570007324, 'min_batch': 7.5463724613189695, 'max_batch': 8.322973537445069}
step: 32860 @ episode report: {'average_total_reward': 11.075002, 'reward_variance': 1.5581253, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.281931066513062, 'actor_loss': -5.708857631683349, 'hyper_actor_loss': 0.017492351308465003, 'behavior_loss': 0.26356188505887984, 'mean_batch': 7.99313268661499, 'min_batch': 7.544935131072998, 'max_batch': 8.352150344848633}
step: 32870 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 5.2405615, 'max_total_reward': 15.56, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7902191519737243, 'actor_loss': -5.697220420837402, 'hyper_actor_loss': 0.017788204737007617, 'behavior_loss': 0.2748070955276489, 'mean_batch': 7.951399469375611, 'min_batch': 7.49732403755188, 'max_batch': 8.304102516174316}
step: 32880 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 5.8343554, 'max_total_reward': 14.559999, 'min_total_reward': 5.7900004, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.105062019824982, 'actor_loss': -5.684537553787232, 'hyper_actor_loss': 0.017670691944658756, 'behavior_loss': 0.2563843339681625, 'mean_batch': 7.908861351013184, 'min_batch': 7.442275714874268, 'max_batch': 8.282887744903565}
step: 32890 @ episode report: {'average_total_reward': 10.865001, 'reward_variance': 1.0215449, 'max_total_reward': 12.2300005, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.097704899311066, 'actor_loss': -5.692885684967041, 'hyper_actor_loss': 0.017500708065927028, 'behavior_loss': 0.26225457191467283, 'mean_batch': 7.945747709274292, 'min_batch': 7.469993352890015, 'max_batch': 8.332938289642334}
step: 32900 @ episode report: {'average_total_reward': 12.219, 'reward_variance': 2.6993906, 'max_total_reward': 14.56, 'min_total_reward': 10.009999, 'average_n_step': 13.0, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.280269908905029, 'actor_loss': -5.704555988311768, 'hyper_actor_loss': 0.017318486608564852, 'behavior_loss': 0.2610256880521774, 'mean_batch': 7.971850347518921, 'min_batch': 7.532780408859253, 'max_batch': 8.32938356399536}
step: 32910 @ episode report: {'average_total_reward': 12.008001, 'reward_variance': 3.2883766, 'max_total_reward': 14.56, 'min_total_reward': 7.68, 'average_n_step': 12.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.905720663070679, 'actor_loss': -5.713696622848511, 'hyper_actor_loss': 0.017612485960125924, 'behavior_loss': 0.25464575439691545, 'mean_batch': 8.006571578979493, 'min_batch': 7.56905837059021, 'max_batch': 8.358362293243408}
step: 32920 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 3.826921, 'max_total_reward': 13.339999, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.197138381004334, 'actor_loss': -5.7114551067352295, 'hyper_actor_loss': 0.017791080102324486, 'behavior_loss': 0.2850667268037796, 'mean_batch': 7.996325492858887, 'min_batch': 7.5618205070495605, 'max_batch': 8.352070522308349}
step: 32930 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 6.6474404, 'max_total_reward': 14.56, 'min_total_reward': 5.5699997, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.599867820739746, 'actor_loss': -5.736426210403442, 'hyper_actor_loss': 0.01803088802844286, 'behavior_loss': 0.2745713651180267, 'mean_batch': 8.072812747955322, 'min_batch': 7.679257011413574, 'max_batch': 8.383367252349853}
step: 32940 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 1.5010488, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.039836943149567, 'actor_loss': -5.755596590042114, 'hyper_actor_loss': 0.01810198649764061, 'behavior_loss': 0.2624718114733696, 'mean_batch': 8.185184669494628, 'min_batch': 7.721141767501831, 'max_batch': 8.5222993850708}
step: 32950 @ episode report: {'average_total_reward': 11.208, 'reward_variance': 2.2441363, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7514368534088134, 'actor_loss': -5.726106214523315, 'hyper_actor_loss': 0.017614755034446716, 'behavior_loss': 0.2608991637825966, 'mean_batch': 8.058675003051757, 'min_batch': 7.614587593078613, 'max_batch': 8.389107799530029}
step: 32960 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 4.8204255, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.992688155174255, 'actor_loss': -5.725290775299072, 'hyper_actor_loss': 0.017340743727982045, 'behavior_loss': 0.2570192441344261, 'mean_batch': 8.051046895980836, 'min_batch': 7.61511754989624, 'max_batch': 8.376192855834962}
step: 32970 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 2.57997, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.880047821998596, 'actor_loss': -5.7266895294189455, 'hyper_actor_loss': 0.01719727963209152, 'behavior_loss': 0.2506308898329735, 'mean_batch': 8.04316749572754, 'min_batch': 7.633183765411377, 'max_batch': 8.366882705688477}
step: 32980 @ episode report: {'average_total_reward': 10.465001, 'reward_variance': 3.2781653, 'max_total_reward': 13.340001, 'min_total_reward': 7.7900004, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.375836825370788, 'actor_loss': -5.759948492050171, 'hyper_actor_loss': 0.0176498681306839, 'behavior_loss': 0.2614119082689285, 'mean_batch': 8.188234519958495, 'min_batch': 7.751498365402222, 'max_batch': 8.525344944000244}
step: 32990 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 2.9516294, 'max_total_reward': 14.450001, 'min_total_reward': 7.9000006, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.611301398277283, 'actor_loss': -5.763977193832398, 'hyper_actor_loss': 0.01758773420006037, 'behavior_loss': 0.25300312638282774, 'mean_batch': 8.190141487121583, 'min_batch': 7.780827760696411, 'max_batch': 8.514790153503418}
step: 33000 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 2.4188294, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.464547467231751, 'actor_loss': -5.750304746627807, 'hyper_actor_loss': 0.017412739247083663, 'behavior_loss': 0.26522756069898606, 'mean_batch': 8.139686012268067, 'min_batch': 7.7228539943695065, 'max_batch': 8.517016124725341}
step: 33010 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 1.0648296, 'max_total_reward': 11.230001, 'min_total_reward': 7.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.207406091690063, 'actor_loss': -5.740712690353393, 'hyper_actor_loss': 0.017577450908720493, 'behavior_loss': 0.26094340682029726, 'mean_batch': 8.126203632354736, 'min_batch': 7.661591291427612, 'max_batch': 8.52957649230957}
step: 33020 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.406596, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.423350167274475, 'actor_loss': -5.743368530273438, 'hyper_actor_loss': 0.017255297861993313, 'behavior_loss': 0.2832775577902794, 'mean_batch': 8.181138134002685, 'min_batch': 7.630875873565674, 'max_batch': 8.564462661743164}
step: 33030 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 0.7174213, 'max_total_reward': 12.340001, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.930986309051514, 'actor_loss': -5.734336519241333, 'hyper_actor_loss': 0.017251635529100896, 'behavior_loss': 0.27079063802957537, 'mean_batch': 8.077253723144532, 'min_batch': 7.659705591201782, 'max_batch': 8.46270809173584}
step: 33040 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 11.130705, 'max_total_reward': 15.670001, 'min_total_reward': 2.3500001, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.011241722106933, 'actor_loss': -5.7090507507324215, 'hyper_actor_loss': 0.0175245875492692, 'behavior_loss': 0.2604889333248138, 'mean_batch': 7.983017683029175, 'min_batch': 7.556414699554443, 'max_batch': 8.340213584899903}
step: 33050 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 1.0545416, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.247522926330566, 'actor_loss': -5.712016820907593, 'hyper_actor_loss': 0.01721353195607662, 'behavior_loss': 0.267966003715992, 'mean_batch': 8.037503147125244, 'min_batch': 7.529040765762329, 'max_batch': 8.368428421020507}
step: 33060 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 3.2548645, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2404110670089725, 'actor_loss': -5.739669466018677, 'hyper_actor_loss': 0.017304780520498754, 'behavior_loss': 0.26405139118432996, 'mean_batch': 8.118496799468994, 'min_batch': 7.660757350921631, 'max_batch': 8.467790794372558}
step: 33070 @ episode report: {'average_total_reward': 11.741, 'reward_variance': 4.065549, 'max_total_reward': 15.559999, 'min_total_reward': 9.01, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.319873213768005, 'actor_loss': -5.726889991760254, 'hyper_actor_loss': 0.016976956091821194, 'behavior_loss': 0.2614349439740181, 'mean_batch': 8.056846618652344, 'min_batch': 7.621710109710693, 'max_batch': 8.381081867218018}
step: 33080 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 8.976535, 'max_total_reward': 16.67, 'min_total_reward': 5.7900004, 'average_n_step': 11.5, 'max_n_step': 17.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.773360180854797, 'actor_loss': -5.737634515762329, 'hyper_actor_loss': 0.016738731972873212, 'behavior_loss': 0.2588601216673851, 'mean_batch': 8.11670742034912, 'min_batch': 7.648058986663818, 'max_batch': 8.461072444915771}
step: 33090 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 1.9612248, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.470445156097412, 'actor_loss': -5.745336103439331, 'hyper_actor_loss': 0.01680156197398901, 'behavior_loss': 0.26188036650419233, 'mean_batch': 8.16541166305542, 'min_batch': 7.661842966079712, 'max_batch': 8.534881019592286}
step: 33100 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 4.6916203, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.893644094467163, 'actor_loss': -5.70219464302063, 'hyper_actor_loss': 0.01676888149231672, 'behavior_loss': 0.259167343378067, 'mean_batch': 7.987958145141602, 'min_batch': 7.500515699386597, 'max_batch': 8.326133251190186}
step: 33110 @ episode report: {'average_total_reward': 9.987, 'reward_variance': 3.4625611, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6683780431747435, 'actor_loss': -5.731362819671631, 'hyper_actor_loss': 0.016944726184010505, 'behavior_loss': 0.25878563821315764, 'mean_batch': 8.093669223785401, 'min_batch': 7.621456336975098, 'max_batch': 8.453603649139405}
step: 33120 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 0.6778649, 'max_total_reward': 11.23, 'min_total_reward': 8.900001, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.436349594593048, 'actor_loss': -5.747259616851807, 'hyper_actor_loss': 0.017093151062726974, 'behavior_loss': 0.2625339925289154, 'mean_batch': 8.175519943237305, 'min_batch': 7.665866851806641, 'max_batch': 8.562185478210449}
step: 33130 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 2.7581813, 'max_total_reward': 14.450002, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.29157521724701, 'actor_loss': -5.768404483795166, 'hyper_actor_loss': 0.01696696262806654, 'behavior_loss': 0.2672164097428322, 'mean_batch': 8.259635829925537, 'min_batch': 7.749814224243164, 'max_batch': 8.63770170211792}
step: 33140 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.391936, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.192049169540406, 'actor_loss': -5.730897378921509, 'hyper_actor_loss': 0.017138539999723434, 'behavior_loss': 0.2660889595746994, 'mean_batch': 8.126593112945557, 'min_batch': 7.5869592189788815, 'max_batch': 8.523785209655761}
step: 33150 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 0.7372853, 'max_total_reward': 12.12, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.357813930511474, 'actor_loss': -5.774351739883423, 'hyper_actor_loss': 0.01736386213451624, 'behavior_loss': 0.2654151558876038, 'mean_batch': 8.298603725433349, 'min_batch': 7.759863090515137, 'max_batch': 8.748125076293945}
step: 33160 @ episode report: {'average_total_reward': 11.242001, 'reward_variance': 1.0267961, 'max_total_reward': 13.23, 'min_total_reward': 10.009999, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8997838258743287, 'actor_loss': -5.777601480484009, 'hyper_actor_loss': 0.017305970937013627, 'behavior_loss': 0.2664352595806122, 'mean_batch': 8.317351913452148, 'min_batch': 7.7676050662994385, 'max_batch': 8.692455387115478}
step: 33170 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 11.323362, 'max_total_reward': 13.450001, 'min_total_reward': 3.24, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.173543167114258, 'actor_loss': -5.7947876930236815, 'hyper_actor_loss': 0.016716076992452145, 'behavior_loss': 0.2646147206425667, 'mean_batch': 8.308784484863281, 'min_batch': 7.9095563888549805, 'max_batch': 8.670880794525146}
step: 33180 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 12.503689, 'max_total_reward': 16.78, 'min_total_reward': 3.24, 'average_n_step': 11.7, 'max_n_step': 17.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.846811068058014, 'actor_loss': -5.741837835311889, 'hyper_actor_loss': 0.01683694068342447, 'behavior_loss': 0.2779394894838333, 'mean_batch': 8.126761722564698, 'min_batch': 7.6703453540802, 'max_batch': 8.515032958984374}
step: 33190 @ episode report: {'average_total_reward': 11.0199995, 'reward_variance': 5.6674414, 'max_total_reward': 15.56, 'min_total_reward': 7.79, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.653115725517273, 'actor_loss': -5.760835742950439, 'hyper_actor_loss': 0.01699239183217287, 'behavior_loss': 0.24917125552892685, 'mean_batch': 8.210734272003174, 'min_batch': 7.737143039703369, 'max_batch': 8.609967899322509}
step: 33200 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 2.1978052, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.01483541727066, 'actor_loss': -5.772152900695801, 'hyper_actor_loss': 0.01697875764220953, 'behavior_loss': 0.2565649852156639, 'mean_batch': 8.251544570922851, 'min_batch': 7.786378192901611, 'max_batch': 8.62519187927246}
step: 33210 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 3.2231834, 'max_total_reward': 12.340001, 'min_total_reward': 6.7900004, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.768339550495148, 'actor_loss': -5.785205698013305, 'hyper_actor_loss': 0.016986927762627602, 'behavior_loss': 0.24962202310562134, 'mean_batch': 8.300823307037353, 'min_batch': 7.841732311248779, 'max_batch': 8.694185829162597}
step: 33220 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 3.4234886, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.107640826702118, 'actor_loss': -5.79527702331543, 'hyper_actor_loss': 0.016734600253403186, 'behavior_loss': 0.241959847509861, 'mean_batch': 8.355524444580078, 'min_batch': 7.869649839401245, 'max_batch': 8.728357982635497}
step: 33230 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 3.8934703, 'max_total_reward': 12.230001, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5333297580480574, 'actor_loss': -5.800230550765991, 'hyper_actor_loss': 0.016853136569261552, 'behavior_loss': 0.25685067772865294, 'mean_batch': 8.355750465393067, 'min_batch': 7.908105182647705, 'max_batch': 8.733580398559571}
step: 33240 @ episode report: {'average_total_reward': 10.853002, 'reward_variance': 1.4156011, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.078720438480377, 'actor_loss': -5.790932369232178, 'hyper_actor_loss': 0.01694900207221508, 'behavior_loss': 0.25990109890699387, 'mean_batch': 8.342719745635986, 'min_batch': 7.847304248809815, 'max_batch': 8.693169403076173}
step: 33250 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 5.5658827, 'max_total_reward': 16.449999, 'min_total_reward': 6.8999996, 'average_n_step': 11.9, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.319959449768066, 'actor_loss': -5.803659820556641, 'hyper_actor_loss': 0.017356251925230028, 'behavior_loss': 0.2664905458688736, 'mean_batch': 8.382814979553222, 'min_batch': 7.909782457351684, 'max_batch': 8.77102165222168}
step: 33260 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 1.5089403, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.866206645965576, 'actor_loss': -5.794798564910889, 'hyper_actor_loss': 0.017556578479707242, 'behavior_loss': 0.2594655275344849, 'mean_batch': 8.329537105560302, 'min_batch': 7.890177011489868, 'max_batch': 8.71374225616455}
step: 33270 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.485941, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.907645094394684, 'actor_loss': -5.775993585586548, 'hyper_actor_loss': 0.01766465660184622, 'behavior_loss': 0.2683523505926132, 'mean_batch': 8.224139976501466, 'min_batch': 7.842683362960815, 'max_batch': 8.569296264648438}
step: 33280 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 4.4662824, 'max_total_reward': 15.67, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9131604194641114, 'actor_loss': -5.778363418579102, 'hyper_actor_loss': 0.01753281019628048, 'behavior_loss': 0.2705095842480659, 'mean_batch': 8.272547435760497, 'min_batch': 7.81591305732727, 'max_batch': 8.622338771820068}
step: 33290 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 4.6828218, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.202885985374451, 'actor_loss': -5.797558689117432, 'hyper_actor_loss': 0.017221928760409354, 'behavior_loss': 0.258087532222271, 'mean_batch': 8.325386333465577, 'min_batch': 7.915974092483521, 'max_batch': 8.686646461486816}
step: 33300 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 3.6982963, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9290403485298158, 'actor_loss': -5.76934552192688, 'hyper_actor_loss': 0.01712742280215025, 'behavior_loss': 0.26949074268341067, 'mean_batch': 8.220407009124756, 'min_batch': 7.794197988510132, 'max_batch': 8.55720157623291}
step: 33310 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 6.547516, 'max_total_reward': 14.559999, 'min_total_reward': 4.02, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9546138525009153, 'actor_loss': -5.791571712493896, 'hyper_actor_loss': 0.017437363974750042, 'behavior_loss': 0.2571560308337212, 'mean_batch': 8.296176052093506, 'min_batch': 7.896209716796875, 'max_batch': 8.674107837677003}
step: 33320 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 1.8217157, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.598949205875397, 'actor_loss': -5.7845254898071286, 'hyper_actor_loss': 0.01748235635459423, 'behavior_loss': 0.2505881875753403, 'mean_batch': 8.30295534133911, 'min_batch': 7.83427586555481, 'max_batch': 8.687008380889893}
step: 33330 @ episode report: {'average_total_reward': 9.764999, 'reward_variance': 3.2030647, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7692764043807983, 'actor_loss': -5.772623205184937, 'hyper_actor_loss': 0.01735560465604067, 'behavior_loss': 0.2573922649025917, 'mean_batch': 8.245350170135499, 'min_batch': 7.795966529846192, 'max_batch': 8.671423053741455}
step: 33340 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 7.6816854, 'max_total_reward': 13.340001, 'min_total_reward': 4.57, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.205727577209473, 'actor_loss': -5.771163368225098, 'hyper_actor_loss': 0.017612217366695403, 'behavior_loss': 0.2779598906636238, 'mean_batch': 8.286395740509032, 'min_batch': 7.747048616409302, 'max_batch': 8.654448795318604}
step: 33350 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.8510642, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.929326176643372, 'actor_loss': -5.741201782226563, 'hyper_actor_loss': 0.017592349275946616, 'behavior_loss': 0.25629132688045503, 'mean_batch': 8.103558826446534, 'min_batch': 7.686866664886475, 'max_batch': 8.51752586364746}
step: 33360 @ episode report: {'average_total_reward': 10.420001, 'reward_variance': 5.12124, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.406271886825562, 'actor_loss': -5.77802095413208, 'hyper_actor_loss': 0.017876320332288743, 'behavior_loss': 0.2530423507094383, 'mean_batch': 8.27135066986084, 'min_batch': 7.814556074142456, 'max_batch': 8.664856052398681}
step: 33370 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 7.641237, 'max_total_reward': 14.450001, 'min_total_reward': 6.68, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.252455163002014, 'actor_loss': -5.785291624069214, 'hyper_actor_loss': 0.017569129727780818, 'behavior_loss': 0.261269374191761, 'mean_batch': 8.320723056793213, 'min_batch': 7.823857355117798, 'max_batch': 8.771022605895997}
step: 33380 @ episode report: {'average_total_reward': 11.142, 'reward_variance': 6.8845377, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6279075145721436, 'actor_loss': -5.762799453735352, 'hyper_actor_loss': 0.017574314773082734, 'behavior_loss': 0.2604862242937088, 'mean_batch': 8.215794467926026, 'min_batch': 7.747798204421997, 'max_batch': 8.620451641082763}
step: 33390 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 5.0171447, 'max_total_reward': 14.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.028715038299561, 'actor_loss': -5.754044008255005, 'hyper_actor_loss': 0.01746120974421501, 'behavior_loss': 0.2642024591565132, 'mean_batch': 8.229934120178223, 'min_batch': 7.667383193969727, 'max_batch': 8.61225700378418}
step: 33400 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 4.4420605, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.932669973373413, 'actor_loss': -5.776603889465332, 'hyper_actor_loss': 0.01754525415599346, 'behavior_loss': 0.2659875899553299, 'mean_batch': 8.299589920043946, 'min_batch': 7.777043437957763, 'max_batch': 8.695766162872314}
step: 33410 @ episode report: {'average_total_reward': 10.654001, 'reward_variance': 2.425044, 'max_total_reward': 13.23, 'min_total_reward': 7.7900004, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.235754501819611, 'actor_loss': -5.800144004821777, 'hyper_actor_loss': 0.017449528723955155, 'behavior_loss': 0.25673965364694595, 'mean_batch': 8.363046741485595, 'min_batch': 7.901220035552979, 'max_batch': 8.744826507568359}
step: 33420 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 3.9524841, 'max_total_reward': 13.340001, 'min_total_reward': 6.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.116243934631347, 'actor_loss': -5.7821534156799315, 'hyper_actor_loss': 0.017669628374278545, 'behavior_loss': 0.2627986207604408, 'mean_batch': 8.338643550872803, 'min_batch': 7.783366966247558, 'max_batch': 8.745292472839356}
step: 33430 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 3.8333817, 'max_total_reward': 13.340001, 'min_total_reward': 6.7900004, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.605320572853088, 'actor_loss': -5.778767871856689, 'hyper_actor_loss': 0.017320971935987473, 'behavior_loss': 0.2662846863269806, 'mean_batch': 8.309891986846925, 'min_batch': 7.7839902400970455, 'max_batch': 8.735096740722657}
step: 33440 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 5.647875, 'max_total_reward': 14.559999, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.747663164138794, 'actor_loss': -5.764769220352173, 'hyper_actor_loss': 0.01728958375751972, 'behavior_loss': 0.27071131467819215, 'mean_batch': 8.265631008148194, 'min_batch': 7.716069650650025, 'max_batch': 8.697125053405761}
step: 33450 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 4.5622616, 'max_total_reward': 14.2300005, 'min_total_reward': 6.5699997, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.57660276889801, 'actor_loss': -5.784162998199463, 'hyper_actor_loss': 0.017115030065178873, 'behavior_loss': 0.25641037672758105, 'mean_batch': 8.291866397857666, 'min_batch': 7.8423340797424315, 'max_batch': 8.72302312850952}
step: 33460 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 3.9943013, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.929116797447205, 'actor_loss': -5.80518913269043, 'hyper_actor_loss': 0.017008315399289133, 'behavior_loss': 0.24847735315561295, 'mean_batch': 8.39624481201172, 'min_batch': 7.909394407272339, 'max_batch': 8.831906604766846}
step: 33470 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 4.9329567, 'max_total_reward': 14.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.36717643737793, 'actor_loss': -5.766295003890991, 'hyper_actor_loss': 0.01659107729792595, 'behavior_loss': 0.2520996928215027, 'mean_batch': 8.239184284210205, 'min_batch': 7.752699899673462, 'max_batch': 8.646603870391846}
step: 33480 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 6.1386614, 'max_total_reward': 14.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.382270681858063, 'actor_loss': -5.804346990585327, 'hyper_actor_loss': 0.01662415247410536, 'behavior_loss': 0.2718250095844269, 'mean_batch': 8.368145847320557, 'min_batch': 7.929659128189087, 'max_batch': 8.748330974578858}
step: 33490 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 4.0455236, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.079743790626526, 'actor_loss': -5.7923424243927, 'hyper_actor_loss': 0.01657781470566988, 'behavior_loss': 0.24709122776985168, 'mean_batch': 8.332939720153808, 'min_batch': 7.86800217628479, 'max_batch': 8.697917079925537}
step: 33500 @ episode report: {'average_total_reward': 11.075, 'reward_variance': 2.4340053, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.835511970520019, 'actor_loss': -5.7960363864898685, 'hyper_actor_loss': 0.016603149473667145, 'behavior_loss': 0.25597073286771777, 'mean_batch': 8.34556303024292, 'min_batch': 7.8846189975738525, 'max_batch': 8.750385189056397}
step: 33510 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 1.926601, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.503848385810852, 'actor_loss': -5.793140840530396, 'hyper_actor_loss': 0.016657940484583376, 'behavior_loss': 0.2600818336009979, 'mean_batch': 8.328724575042724, 'min_batch': 7.877745676040649, 'max_batch': 8.765317153930663}
step: 33520 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 2.6262558, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.4232055187225345, 'actor_loss': -5.782086324691773, 'hyper_actor_loss': 0.016666939854621886, 'behavior_loss': 0.27835666090250016, 'mean_batch': 8.276722240447999, 'min_batch': 7.840559005737305, 'max_batch': 8.65089168548584}
step: 33530 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.0481162, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.530861926078797, 'actor_loss': -5.7827352523803714, 'hyper_actor_loss': 0.016935918480157852, 'behavior_loss': 0.25822521895170214, 'mean_batch': 8.305154514312743, 'min_batch': 7.818671369552613, 'max_batch': 8.740985774993897}
step: 33540 @ episode report: {'average_total_reward': 9.565001, 'reward_variance': 4.2043247, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.697396540641785, 'actor_loss': -5.781946897506714, 'hyper_actor_loss': 0.01677998211234808, 'behavior_loss': 0.25632981210947037, 'mean_batch': 8.315962982177734, 'min_batch': 7.802822065353394, 'max_batch': 8.714974498748779}
step: 33550 @ episode report: {'average_total_reward': 10.853001, 'reward_variance': 4.057802, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.640734601020813, 'actor_loss': -5.77352557182312, 'hyper_actor_loss': 0.0170228186994791, 'behavior_loss': 0.2576697155833244, 'mean_batch': 8.268635654449463, 'min_batch': 7.780891609191895, 'max_batch': 8.740331172943115}
step: 33560 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 5.1215844, 'max_total_reward': 15.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.945109105110168, 'actor_loss': -5.7837708473205565, 'hyper_actor_loss': 0.016841934993863106, 'behavior_loss': 0.27733484357595445, 'mean_batch': 8.288281917572021, 'min_batch': 7.842434740066528, 'max_batch': 8.678400230407714}
step: 33570 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 4.378595, 'max_total_reward': 14.23, 'min_total_reward': 6.6800003, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.639915585517883, 'actor_loss': -5.783427810668945, 'hyper_actor_loss': 0.01686333157122135, 'behavior_loss': 0.25893016159534454, 'mean_batch': 8.333263397216797, 'min_batch': 7.797758102416992, 'max_batch': 8.784024524688721}
step: 33580 @ episode report: {'average_total_reward': 10.709002, 'reward_variance': 1.0496495, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8215019941329955, 'actor_loss': -5.80537428855896, 'hyper_actor_loss': 0.017066958732903002, 'behavior_loss': 0.26230355352163315, 'mean_batch': 8.401774501800537, 'min_batch': 7.906127452850342, 'max_batch': 8.823486137390137}
step: 33590 @ episode report: {'average_total_reward': 11.164, 'reward_variance': 2.9353032, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.374215888977051, 'actor_loss': -5.800250244140625, 'hyper_actor_loss': 0.01686437912285328, 'behavior_loss': 0.25153314620256423, 'mean_batch': 8.37956953048706, 'min_batch': 7.886601400375366, 'max_batch': 8.823757934570313}
step: 33600 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 2.8721766, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.171669673919678, 'actor_loss': -5.741994380950928, 'hyper_actor_loss': 0.016508518531918526, 'behavior_loss': 0.2574720486998558, 'mean_batch': 8.139766216278076, 'min_batch': 7.659001350402832, 'max_batch': 8.553660583496093}
step: 33610 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 3.9118805, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9694467961788176, 'actor_loss': -5.768116474151611, 'hyper_actor_loss': 0.016677474603056908, 'behavior_loss': 0.26487857550382615, 'mean_batch': 8.207614994049072, 'min_batch': 7.797133111953736, 'max_batch': 8.57807970046997}
step: 33620 @ episode report: {'average_total_reward': 11.63, 'reward_variance': 3.3459811, 'max_total_reward': 14.56, 'min_total_reward': 7.6800003, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.321521577239037, 'actor_loss': -5.817521572113037, 'hyper_actor_loss': 0.017036371678113938, 'behavior_loss': 0.2678773030638695, 'mean_batch': 8.446618843078614, 'min_batch': 7.959472560882569, 'max_batch': 8.851902961730957}
step: 33630 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 3.698309, 'max_total_reward': 14.559999, 'min_total_reward': 7.6800003, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3201696395874025, 'actor_loss': -5.799390554428101, 'hyper_actor_loss': 0.017011469602584837, 'behavior_loss': 0.23638175725936889, 'mean_batch': 8.393031024932862, 'min_batch': 7.867204999923706, 'max_batch': 8.779310512542725}
step: 33640 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 3.1043046, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1017341136932375, 'actor_loss': -5.7870982646942135, 'hyper_actor_loss': 0.01672958880662918, 'behavior_loss': 0.262803053855896, 'mean_batch': 8.292541217803954, 'min_batch': 7.864264059066772, 'max_batch': 8.693133068084716}
step: 33650 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 5.61152, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.079494190216065, 'actor_loss': -5.7940844058990475, 'hyper_actor_loss': 0.016753270849585535, 'behavior_loss': 0.2656744971871376, 'mean_batch': 8.322015285491943, 'min_batch': 7.891623449325562, 'max_batch': 8.680619239807129}
step: 33660 @ episode report: {'average_total_reward': 11.897001, 'reward_variance': 4.1429214, 'max_total_reward': 14.56, 'min_total_reward': 8.68, 'average_n_step': 12.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.445382702350616, 'actor_loss': -5.7831662654876705, 'hyper_actor_loss': 0.016848086938261987, 'behavior_loss': 0.2600104331970215, 'mean_batch': 8.32344388961792, 'min_batch': 7.806005668640137, 'max_batch': 8.745610809326172}
step: 33670 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 2.3543441, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.762109649181366, 'actor_loss': -5.7942955017089846, 'hyper_actor_loss': 0.01637669261544943, 'behavior_loss': 0.2393804222345352, 'mean_batch': 8.355247592926025, 'min_batch': 7.86260952949524, 'max_batch': 8.763204669952392}
step: 33680 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 2.2137692, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7124769449234005, 'actor_loss': -5.764792966842651, 'hyper_actor_loss': 0.016325328685343265, 'behavior_loss': 0.2820894613862038, 'mean_batch': 8.254443168640137, 'min_batch': 7.729010677337646, 'max_batch': 8.678568840026855}
step: 33690 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 5.9578214, 'max_total_reward': 15.67, 'min_total_reward': 6.7899995, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.512225008010864, 'actor_loss': -5.772280025482178, 'hyper_actor_loss': 0.015885309875011445, 'behavior_loss': 0.25226675868034365, 'mean_batch': 8.288208293914796, 'min_batch': 7.75378999710083, 'max_batch': 8.728973960876464}
step: 33700 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 3.0416245, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.800974130630493, 'actor_loss': -5.780751657485962, 'hyper_actor_loss': 0.015904182195663454, 'behavior_loss': 0.2555274099111557, 'mean_batch': 8.32419319152832, 'min_batch': 7.784992933273315, 'max_batch': 8.770315074920655}
step: 33710 @ episode report: {'average_total_reward': 9.654, 'reward_variance': 5.681985, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.991037654876709, 'actor_loss': -5.800747108459473, 'hyper_actor_loss': 0.015709434077143668, 'behavior_loss': 0.2667422488331795, 'mean_batch': 8.37389554977417, 'min_batch': 7.895847272872925, 'max_batch': 8.882553672790527}
step: 33720 @ episode report: {'average_total_reward': 10.653, 'reward_variance': 4.0621614, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.546182036399841, 'actor_loss': -5.784596300125122, 'hyper_actor_loss': 0.01588172074407339, 'behavior_loss': 0.26658310890197756, 'mean_batch': 8.347454833984376, 'min_batch': 7.793719863891601, 'max_batch': 8.816497898101806}
step: 33730 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 4.3067613, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3529833316802975, 'actor_loss': -5.807020807266236, 'hyper_actor_loss': 0.015824488829821348, 'behavior_loss': 0.26855506747961044, 'mean_batch': 8.449659156799317, 'min_batch': 7.87377896308899, 'max_batch': 8.950720977783202}
step: 33740 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 3.400786, 'max_total_reward': 13.45, 'min_total_reward': 7.569999, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.375898230075836, 'actor_loss': -5.819496202468872, 'hyper_actor_loss': 0.015898317843675614, 'behavior_loss': 0.2522026553750038, 'mean_batch': 8.459260845184327, 'min_batch': 7.963539886474609, 'max_batch': 8.952715492248535}
step: 33750 @ episode report: {'average_total_reward': 10.909, 'reward_variance': 4.43583, 'max_total_reward': 15.450001, 'min_total_reward': 7.899999, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.642473602294922, 'actor_loss': -5.812369775772095, 'hyper_actor_loss': 0.016224461048841475, 'behavior_loss': 0.26229405403137207, 'mean_batch': 8.458838844299317, 'min_batch': 7.90887131690979, 'max_batch': 8.91466999053955}
step: 33760 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 0.90870935, 'max_total_reward': 12.340001, 'min_total_reward': 8.68, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.385566365718842, 'actor_loss': -5.8306670665740965, 'hyper_actor_loss': 0.016525344364345072, 'behavior_loss': 0.26796878427267073, 'mean_batch': 8.5305757522583, 'min_batch': 7.986626482009887, 'max_batch': 8.921726703643799}
step: 33770 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 1.488321, 'max_total_reward': 13.45, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.82335364818573, 'actor_loss': -5.7722179889678955, 'hyper_actor_loss': 0.016423934139311314, 'behavior_loss': 0.2511452153325081, 'mean_batch': 8.273031425476074, 'min_batch': 7.767389822006225, 'max_batch': 8.696451663970947}
step: 33780 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 1.7406092, 'max_total_reward': 11.23, 'min_total_reward': 6.7899995, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.455998945236206, 'actor_loss': -5.7976476669311525, 'hyper_actor_loss': 0.016345076635479926, 'behavior_loss': 0.24936649650335313, 'mean_batch': 8.331896686553955, 'min_batch': 7.9105946063995365, 'max_batch': 8.735606956481934}
step: 33790 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 1.9721998, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.758205986022949, 'actor_loss': -5.769701910018921, 'hyper_actor_loss': 0.01606085943058133, 'behavior_loss': 0.26180251091718676, 'mean_batch': 8.242656326293945, 'min_batch': 7.77691068649292, 'max_batch': 8.626708698272704}
step: 33800 @ episode report: {'average_total_reward': 11.1640005, 'reward_variance': 1.6594238, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.722825288772583, 'actor_loss': -5.756907892227173, 'hyper_actor_loss': 0.01578473150730133, 'behavior_loss': 0.2536836311221123, 'mean_batch': 8.180158996582032, 'min_batch': 7.735201978683472, 'max_batch': 8.582983207702636}
step: 33810 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 5.5592647, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.604702997207641, 'actor_loss': -5.7802910804748535, 'hyper_actor_loss': 0.015880254097282887, 'behavior_loss': 0.2561169549822807, 'mean_batch': 8.290345287322998, 'min_batch': 7.814015102386475, 'max_batch': 8.70670976638794}
step: 33820 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.888004, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.079687333106994, 'actor_loss': -5.756877851486206, 'hyper_actor_loss': 0.015911333449184894, 'behavior_loss': 0.26888189315795896, 'mean_batch': 8.178983879089355, 'min_batch': 7.7367595672607425, 'max_batch': 8.550078582763671}
step: 33830 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 1.7117049, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.262012481689453, 'actor_loss': -5.8009387969970705, 'hyper_actor_loss': 0.016101707704365253, 'behavior_loss': 0.2514885410666466, 'mean_batch': 8.349912929534913, 'min_batch': 7.920330572128296, 'max_batch': 8.709976863861083}
step: 33840 @ episode report: {'average_total_reward': 10.275999, 'reward_variance': 8.548682, 'max_total_reward': 16.779999, 'min_total_reward': 4.68, 'average_n_step': 11.2, 'max_n_step': 17.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.3798411130905155, 'actor_loss': -5.831135416030884, 'hyper_actor_loss': 0.01630432214587927, 'behavior_loss': 0.2637090250849724, 'mean_batch': 8.5036789894104, 'min_batch': 8.014988946914674, 'max_batch': 8.919609260559081}
step: 33850 @ episode report: {'average_total_reward': 11.086001, 'reward_variance': 3.187465, 'max_total_reward': 14.450001, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.346251535415649, 'actor_loss': -5.7825188636779785, 'hyper_actor_loss': 0.016110359318554403, 'behavior_loss': 0.2385849490761757, 'mean_batch': 8.293372631072998, 'min_batch': 7.8278480052948, 'max_batch': 8.668721961975098}
step: 33860 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 1.7810013, 'max_total_reward': 14.34, 'min_total_reward': 10.01, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4418877243995665, 'actor_loss': -5.820748710632325, 'hyper_actor_loss': 0.016070050187408924, 'behavior_loss': 0.24546759575605392, 'mean_batch': 8.431173515319824, 'min_batch': 7.999899435043335, 'max_batch': 8.842729187011718}
step: 33870 @ episode report: {'average_total_reward': 11.098001, 'reward_variance': 1.9972966, 'max_total_reward': 14.34, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.680339288711548, 'actor_loss': -5.838747024536133, 'hyper_actor_loss': 0.01640084572136402, 'behavior_loss': 0.2648172348737717, 'mean_batch': 8.52869110107422, 'min_batch': 8.05198049545288, 'max_batch': 8.92770471572876}
step: 33880 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 4.0280423, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.963711953163147, 'actor_loss': -5.814056730270385, 'hyper_actor_loss': 0.016553322784602642, 'behavior_loss': 0.26051454693078996, 'mean_batch': 8.441603183746338, 'min_batch': 7.9365616798400875, 'max_batch': 8.873017024993896}
step: 33890 @ episode report: {'average_total_reward': 10.975, 'reward_variance': 3.1176457, 'max_total_reward': 14.450001, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.3508923053741455, 'actor_loss': -5.7992688655853275, 'hyper_actor_loss': 0.016947160847485064, 'behavior_loss': 0.2693029001355171, 'mean_batch': 8.410848331451415, 'min_batch': 7.849121475219727, 'max_batch': 8.8458740234375}
step: 33900 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 3.9257214, 'max_total_reward': 15.67, 'min_total_reward': 7.9000006, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.702733206748962, 'actor_loss': -5.818475008010864, 'hyper_actor_loss': 0.016991830430924892, 'behavior_loss': 0.2584818944334984, 'mean_batch': 8.453288173675537, 'min_batch': 7.960935115814209, 'max_batch': 8.847199153900146}
step: 33910 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 3.5326157, 'max_total_reward': 11.2300005, 'min_total_reward': 4.68, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.459521532058716, 'actor_loss': -5.821397161483764, 'hyper_actor_loss': 0.016971232928335668, 'behavior_loss': 0.2679036661982536, 'mean_batch': 8.50736494064331, 'min_batch': 7.934323835372925, 'max_batch': 8.971771812438964}
step: 33920 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.1100037, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.657201838493347, 'actor_loss': -5.8266206741333, 'hyper_actor_loss': 0.01659284196794033, 'behavior_loss': 0.2554829463362694, 'mean_batch': 8.515246105194091, 'min_batch': 7.969145011901856, 'max_batch': 8.94129457473755}
step: 33930 @ episode report: {'average_total_reward': 8.866, 'reward_variance': 12.180685, 'max_total_reward': 13.34, 'min_total_reward': 1.24, 'average_n_step': 9.9, 'max_n_step': 14.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.144182920455933, 'actor_loss': -5.8190234184265135, 'hyper_actor_loss': 0.01657102834433317, 'behavior_loss': 0.26480224877595904, 'mean_batch': 8.48784008026123, 'min_batch': 7.9331906795501705, 'max_batch': 8.949194431304932}
step: 33940 @ episode report: {'average_total_reward': 10.642001, 'reward_variance': 2.5161362, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.088805246353149, 'actor_loss': -5.805743265151977, 'hyper_actor_loss': 0.01671236250549555, 'behavior_loss': 0.2690703973174095, 'mean_batch': 8.428677082061768, 'min_batch': 7.884272575378418, 'max_batch': 8.864424133300782}
step: 33950 @ episode report: {'average_total_reward': 9.776, 'reward_variance': 6.173645, 'max_total_reward': 13.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5026754379272464, 'actor_loss': -5.800793266296386, 'hyper_actor_loss': 0.016429610550403595, 'behavior_loss': 0.26296819746494293, 'mean_batch': 8.363008975982666, 'min_batch': 7.905612754821777, 'max_batch': 8.766843795776367}
step: 33960 @ episode report: {'average_total_reward': 10.431001, 'reward_variance': 4.3692093, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.113789415359497, 'actor_loss': -5.81175127029419, 'hyper_actor_loss': 0.01690503116697073, 'behavior_loss': 0.2661257565021515, 'mean_batch': 8.435605812072755, 'min_batch': 7.9252989292144775, 'max_batch': 8.859801959991454}
step: 33970 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 2.199076, 'max_total_reward': 12.339999, 'min_total_reward': 6.57, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.999168276786804, 'actor_loss': -5.811296081542968, 'hyper_actor_loss': 0.01682419702410698, 'behavior_loss': 0.2728093102574348, 'mean_batch': 8.432637023925782, 'min_batch': 7.923722982406616, 'max_batch': 8.861048316955566}
step: 33980 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 3.9417446, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.591185665130615, 'actor_loss': -5.8182137966156, 'hyper_actor_loss': 0.016830199770629405, 'behavior_loss': 0.2721895888447762, 'mean_batch': 8.463346576690673, 'min_batch': 7.950769853591919, 'max_batch': 8.847211742401123}
step: 33990 @ episode report: {'average_total_reward': 11.153002, 'reward_variance': 3.8988411, 'max_total_reward': 14.560001, 'min_total_reward': 7.79, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.225679087638855, 'actor_loss': -5.849378490447998, 'hyper_actor_loss': 0.016935847140848635, 'behavior_loss': 0.27177120596170423, 'mean_batch': 8.567267513275146, 'min_batch': 8.10207757949829, 'max_batch': 8.94644899368286}
step: 34000 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 4.6129465, 'max_total_reward': 14.560001, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.075741863250732, 'actor_loss': -5.866561317443848, 'hyper_actor_loss': 0.016804145835340022, 'behavior_loss': 0.2549460917711258, 'mean_batch': 8.633690452575683, 'min_batch': 8.178897285461426, 'max_batch': 9.016438388824463}
step: 34010 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 8.514661, 'max_total_reward': 16.56, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 17.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.480303311347962, 'actor_loss': -5.844130277633667, 'hyper_actor_loss': 0.016358703002333642, 'behavior_loss': 0.262061120569706, 'mean_batch': 8.537807750701905, 'min_batch': 8.087056255340576, 'max_batch': 8.939045715332032}
step: 34020 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 1.8689396, 'max_total_reward': 13.23, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.525121450424194, 'actor_loss': -5.8265380859375, 'hyper_actor_loss': 0.016139687225222587, 'behavior_loss': 0.270728112757206, 'mean_batch': 8.488672542572022, 'min_batch': 7.992177104949951, 'max_batch': 8.862670421600342}
step: 34030 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 4.014156, 'max_total_reward': 14.34, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.58402783870697, 'actor_loss': -5.863602018356323, 'hyper_actor_loss': 0.016335850581526756, 'behavior_loss': 0.26734882295131684, 'mean_batch': 8.665250205993653, 'min_batch': 8.125563621520996, 'max_batch': 9.073102951049805}
step: 34040 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 1.1701639, 'max_total_reward': 12.12, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.508769965171814, 'actor_loss': -5.820409679412842, 'hyper_actor_loss': 0.016635517962276934, 'behavior_loss': 0.26276553720235823, 'mean_batch': 8.486266708374023, 'min_batch': 7.946135711669922, 'max_batch': 8.89361743927002}
step: 34050 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 4.8291407, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8821455001831056, 'actor_loss': -5.839012145996094, 'hyper_actor_loss': 0.01654880605638027, 'behavior_loss': 0.2684857428073883, 'mean_batch': 8.519778823852539, 'min_batch': 8.06333875656128, 'max_batch': 8.883230590820313}
step: 34060 @ episode report: {'average_total_reward': 10.409001, 'reward_variance': 3.8897693, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.080850923061371, 'actor_loss': -5.8447541236877445, 'hyper_actor_loss': 0.016244744323194026, 'behavior_loss': 0.24592943638563156, 'mean_batch': 8.558332824707032, 'min_batch': 8.074405765533447, 'max_batch': 8.954932975769044}
step: 34070 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 2.0932555, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9232028484344483, 'actor_loss': -5.853441667556763, 'hyper_actor_loss': 0.016140588000416754, 'behavior_loss': 0.26545263081789017, 'mean_batch': 8.59850845336914, 'min_batch': 8.105210018157958, 'max_batch': 9.018939590454101}
step: 34080 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 3.4143035, 'max_total_reward': 14.339999, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.669144916534424, 'actor_loss': -5.8602197647094725, 'hyper_actor_loss': 0.016126875020563602, 'behavior_loss': 0.2694943964481354, 'mean_batch': 8.600366020202637, 'min_batch': 8.158285903930665, 'max_batch': 9.001231384277343}
step: 34090 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.7760034, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.836113548278808, 'actor_loss': -5.793079233169555, 'hyper_actor_loss': 0.016204309090971945, 'behavior_loss': 0.2537072077393532, 'mean_batch': 8.340097045898437, 'min_batch': 7.866674947738647, 'max_batch': 8.699507808685302}
step: 34100 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 7.336801, 'max_total_reward': 14.56, 'min_total_reward': 3.3500001, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.940279817581176, 'actor_loss': -5.807953214645385, 'hyper_actor_loss': 0.016028174478560687, 'behavior_loss': 0.2678479701280594, 'mean_batch': 8.397660732269287, 'min_batch': 7.930099105834961, 'max_batch': 8.81242618560791}
step: 34110 @ episode report: {'average_total_reward': 9.8550005, 'reward_variance': 2.9462254, 'max_total_reward': 12.12, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.813777041435242, 'actor_loss': -5.819036293029785, 'hyper_actor_loss': 0.015968956891447304, 'behavior_loss': 0.2585762977600098, 'mean_batch': 8.471176242828369, 'min_batch': 7.949333524703979, 'max_batch': 8.847151184082032}
step: 34120 @ episode report: {'average_total_reward': 11.740999, 'reward_variance': 1.3454487, 'max_total_reward': 13.450001, 'min_total_reward': 10.01, 'average_n_step': 12.5, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.371727633476257, 'actor_loss': -5.8286326885223385, 'hyper_actor_loss': 0.016130842454731464, 'behavior_loss': 0.2616446793079376, 'mean_batch': 8.50797996520996, 'min_batch': 7.991091680526734, 'max_batch': 8.946498680114747}
step: 34130 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 2.7321649, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.812084150314331, 'actor_loss': -5.817018985748291, 'hyper_actor_loss': 0.01596052423119545, 'behavior_loss': 0.24925560802221297, 'mean_batch': 8.428149223327637, 'min_batch': 7.972910022735595, 'max_batch': 8.836468696594238}
step: 34140 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.9879038, 'max_total_reward': 12.2300005, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.516958093643188, 'actor_loss': -5.8068760395050045, 'hyper_actor_loss': 0.015792097710072995, 'behavior_loss': 0.2578577771782875, 'mean_batch': 8.416334629058838, 'min_batch': 7.90469217300415, 'max_batch': 8.823200988769532}
step: 34150 @ episode report: {'average_total_reward': 11.263999, 'reward_variance': 2.065144, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.528519487380981, 'actor_loss': -5.799598598480225, 'hyper_actor_loss': 0.01564594665542245, 'behavior_loss': 0.25646340250968935, 'mean_batch': 8.410963344573975, 'min_batch': 7.852828788757324, 'max_batch': 8.835038375854491}
step: 34160 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 4.485196, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0448112964630125, 'actor_loss': -5.811072921752929, 'hyper_actor_loss': 0.01577521488070488, 'behavior_loss': 0.24474414736032485, 'mean_batch': 8.458787822723389, 'min_batch': 7.898528432846069, 'max_batch': 8.901010131835937}
step: 34170 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 5.1915693, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.02862868309021, 'actor_loss': -5.839790105819702, 'hyper_actor_loss': 0.015179138444364072, 'behavior_loss': 0.26682295501232145, 'mean_batch': 8.56997308731079, 'min_batch': 8.025320720672607, 'max_batch': 9.009853935241699}
step: 34180 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 3.4553962, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0176157534122465, 'actor_loss': -5.878148984909058, 'hyper_actor_loss': 0.01554814875125885, 'behavior_loss': 0.25036382079124453, 'mean_batch': 8.75401430130005, 'min_batch': 8.164406204223633, 'max_batch': 9.177858543395995}
step: 34190 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.1381767, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.698758685588837, 'actor_loss': -5.803844356536866, 'hyper_actor_loss': 0.015311335679143667, 'behavior_loss': 0.2708302244544029, 'mean_batch': 8.460118961334228, 'min_batch': 7.843426513671875, 'max_batch': 8.887553215026855}
step: 34200 @ episode report: {'average_total_reward': 11.164001, 'reward_variance': 1.8765848, 'max_total_reward': 13.340001, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4712008237838745, 'actor_loss': -5.843378114700317, 'hyper_actor_loss': 0.015271906834095716, 'behavior_loss': 0.2561167910695076, 'mean_batch': 8.511103534698487, 'min_batch': 8.10623607635498, 'max_batch': 8.908437824249267}
step: 34210 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 3.756464, 'max_total_reward': 15.56, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.071427130699158, 'actor_loss': -5.855530071258545, 'hyper_actor_loss': 0.015435365028679371, 'behavior_loss': 0.26923863738775256, 'mean_batch': 8.585594940185548, 'min_batch': 8.134195470809937, 'max_batch': 9.000892162322998}
step: 34220 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 2.8634865, 'max_total_reward': 13.450001, 'min_total_reward': 7.7899995, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.450896048545838, 'actor_loss': -5.812747669219971, 'hyper_actor_loss': 0.015455631632357835, 'behavior_loss': 0.25520157963037493, 'mean_batch': 8.420369529724121, 'min_batch': 7.946420907974243, 'max_batch': 8.835914611816406}
step: 34230 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 2.422782, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.840202140808105, 'actor_loss': -5.823963832855225, 'hyper_actor_loss': 0.015600477252155543, 'behavior_loss': 0.270814511179924, 'mean_batch': 8.45413122177124, 'min_batch': 8.004361152648926, 'max_batch': 8.843229389190673}
step: 34240 @ episode report: {'average_total_reward': 10.441999, 'reward_variance': 2.416516, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.442313289642334, 'actor_loss': -5.834896755218506, 'hyper_actor_loss': 0.015934311039745807, 'behavior_loss': 0.27335092425346375, 'mean_batch': 8.610839939117431, 'min_batch': 7.948509073257446, 'max_batch': 9.005563449859618}
step: 34250 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 2.6334496, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.882730317115784, 'actor_loss': -5.837249040603638, 'hyper_actor_loss': 0.015690273232758047, 'behavior_loss': 0.2700186803936958, 'mean_batch': 8.580484676361085, 'min_batch': 7.993756675720215, 'max_batch': 8.99561939239502}
step: 34260 @ episode report: {'average_total_reward': 9.9869995, 'reward_variance': 2.9721406, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.1308588743209835, 'actor_loss': -5.81284875869751, 'hyper_actor_loss': 0.015894587710499765, 'behavior_loss': 0.2628943040966988, 'mean_batch': 8.459562397003173, 'min_batch': 7.912510776519776, 'max_batch': 8.884745216369629}
step: 34270 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 6.4750032, 'max_total_reward': 14.559999, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.489381122589111, 'actor_loss': -5.8093970775604244, 'hyper_actor_loss': 0.015969336964190006, 'behavior_loss': 0.2734318464994431, 'mean_batch': 8.486433696746825, 'min_batch': 7.865413188934326, 'max_batch': 8.969131469726562}
step: 34280 @ episode report: {'average_total_reward': 9.998001, 'reward_variance': 5.015937, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.256054425239563, 'actor_loss': -5.808981084823609, 'hyper_actor_loss': 0.01608256371691823, 'behavior_loss': 0.25888174027204514, 'mean_batch': 8.55791015625, 'min_batch': 7.794924545288086, 'max_batch': 9.007230186462403}
step: 34290 @ episode report: {'average_total_reward': 10.287, 'reward_variance': 2.9787812, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.407483530044556, 'actor_loss': -5.81162281036377, 'hyper_actor_loss': 0.015783563163131474, 'behavior_loss': 0.26030580699443817, 'mean_batch': 8.452992725372315, 'min_batch': 7.910132265090942, 'max_batch': 8.919150066375732}
step: 34300 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 2.335001, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.254300606250763, 'actor_loss': -5.797119855880737, 'hyper_actor_loss': 0.015792274475097658, 'behavior_loss': 0.2861515060067177, 'mean_batch': 8.344530296325683, 'min_batch': 7.894469833374023, 'max_batch': 8.786190032958984}
step: 34310 @ episode report: {'average_total_reward': 10.931002, 'reward_variance': 4.1106286, 'max_total_reward': 14.45, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.910969400405884, 'actor_loss': -5.805440092086792, 'hyper_actor_loss': 0.01592729613184929, 'behavior_loss': 0.2677441671490669, 'mean_batch': 8.43105936050415, 'min_batch': 7.87897572517395, 'max_batch': 8.871233272552491}
step: 34320 @ episode report: {'average_total_reward': 11.275, 'reward_variance': 2.4463258, 'max_total_reward': 13.45, 'min_total_reward': 8.789999, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0545484781265255, 'actor_loss': -5.823834466934204, 'hyper_actor_loss': 0.0158562864176929, 'behavior_loss': 0.26620222479104994, 'mean_batch': 8.577192783355713, 'min_batch': 7.890605831146241, 'max_batch': 9.109864425659179}
step: 34330 @ episode report: {'average_total_reward': 10.209, 'reward_variance': 3.7211685, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.937661671638489, 'actor_loss': -5.811931037902832, 'hyper_actor_loss': 0.015328524261713028, 'behavior_loss': 0.255979859828949, 'mean_batch': 8.445641040802002, 'min_batch': 7.917075967788696, 'max_batch': 8.899305629730225}
step: 34340 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 8.666242, 'max_total_reward': 15.67, 'min_total_reward': 5.57, 'average_n_step': 10.5, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.695645976066589, 'actor_loss': -5.822484636306763, 'hyper_actor_loss': 0.015346243232488632, 'behavior_loss': 0.2690614327788353, 'mean_batch': 8.542299842834472, 'min_batch': 7.911056327819824, 'max_batch': 9.070305061340331}
step: 34350 @ episode report: {'average_total_reward': 11.286, 'reward_variance': 3.3075848, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.859553122520447, 'actor_loss': -5.816811275482178, 'hyper_actor_loss': 0.015183199010789395, 'behavior_loss': 0.25728275924921035, 'mean_batch': 8.507335567474366, 'min_batch': 7.899294900894165, 'max_batch': 8.948558616638184}
step: 34360 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 3.527924, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.213837790489197, 'actor_loss': -5.801511621475219, 'hyper_actor_loss': 0.014914147835224868, 'behavior_loss': 0.2615265607833862, 'mean_batch': 8.393893241882324, 'min_batch': 7.882308292388916, 'max_batch': 8.870317268371583}
step: 34370 @ episode report: {'average_total_reward': 10.886, 'reward_variance': 7.7230024, 'max_total_reward': 16.779999, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.544251155853272, 'actor_loss': -5.805827617645264, 'hyper_actor_loss': 0.015094570722430945, 'behavior_loss': 0.26844202131032946, 'mean_batch': 8.370841598510742, 'min_batch': 7.938136005401612, 'max_batch': 8.793634510040283}
step: 34380 @ episode report: {'average_total_reward': 10.531001, 'reward_variance': 2.4964898, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.368390130996704, 'actor_loss': -5.809014558792114, 'hyper_actor_loss': 0.015232563484460115, 'behavior_loss': 0.25997731685638426, 'mean_batch': 8.39346923828125, 'min_batch': 7.941869592666626, 'max_batch': 8.833855819702148}
step: 34390 @ episode report: {'average_total_reward': 10.431001, 'reward_variance': 6.1405687, 'max_total_reward': 14.45, 'min_total_reward': 5.68, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.377925848960876, 'actor_loss': -5.804836845397949, 'hyper_actor_loss': 0.015186161827296018, 'behavior_loss': 0.25709068775177, 'mean_batch': 8.406336879730224, 'min_batch': 7.897185039520264, 'max_batch': 8.810023498535156}
step: 34400 @ episode report: {'average_total_reward': 8.977, 'reward_variance': 2.1959019, 'max_total_reward': 11.230001, 'min_total_reward': 6.68, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.636949825286865, 'actor_loss': -5.786861419677734, 'hyper_actor_loss': 0.01513290060684085, 'behavior_loss': 0.2582489013671875, 'mean_batch': 8.348211097717286, 'min_batch': 7.810969352722168, 'max_batch': 8.816994285583496}
step: 34410 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 2.9342818, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.118620467185974, 'actor_loss': -5.834400653839111, 'hyper_actor_loss': 0.01521375747397542, 'behavior_loss': 0.24918401688337327, 'mean_batch': 8.570423316955566, 'min_batch': 7.9795238971710205, 'max_batch': 9.005593299865723}
step: 34420 @ episode report: {'average_total_reward': 11.984999, 'reward_variance': 2.4149656, 'max_total_reward': 14.559999, 'min_total_reward': 10.119999, 'average_n_step': 12.7, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.461568081378937, 'actor_loss': -5.830376243591308, 'hyper_actor_loss': 0.015198657661676407, 'behavior_loss': 0.2630633354187012, 'mean_batch': 8.585316562652588, 'min_batch': 7.9345029354095455, 'max_batch': 9.011836814880372}
step: 34430 @ episode report: {'average_total_reward': 10.4210005, 'reward_variance': 1.1814286, 'max_total_reward': 12.34, 'min_total_reward': 8.570001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.54167673587799, 'actor_loss': -5.8193799495697025, 'hyper_actor_loss': 0.015351298172026873, 'behavior_loss': 0.2555038332939148, 'mean_batch': 8.502123546600341, 'min_batch': 7.925016689300537, 'max_batch': 8.888060379028321}
step: 34440 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 3.960619, 'max_total_reward': 14.009999, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.147081470489502, 'actor_loss': -5.790837621688842, 'hyper_actor_loss': 0.015423044003546238, 'behavior_loss': 0.2679595649242401, 'mean_batch': 8.422100830078126, 'min_batch': 7.776725816726684, 'max_batch': 8.838560390472413}
step: 34450 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 5.3632293, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.597128462791443, 'actor_loss': -5.806329774856567, 'hyper_actor_loss': 0.01582043254747987, 'behavior_loss': 0.274453105032444, 'mean_batch': 8.41645917892456, 'min_batch': 7.900074481964111, 'max_batch': 8.867606449127198}
step: 34460 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 5.079882, 'max_total_reward': 14.56, 'min_total_reward': 7.6800003, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.518202304840088, 'actor_loss': -5.873217058181763, 'hyper_actor_loss': 0.015888117533177138, 'behavior_loss': 0.26589503735303877, 'mean_batch': 8.666214847564698, 'min_batch': 8.202538013458252, 'max_batch': 9.166738796234132}
step: 34470 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 2.103061, 'max_total_reward': 12.23, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.282642221450805, 'actor_loss': -5.831753969192505, 'hyper_actor_loss': 0.01601254176348448, 'behavior_loss': 0.2646030902862549, 'mean_batch': 8.517743015289307, 'min_batch': 8.006912231445312, 'max_batch': 8.963504791259766}
step: 34480 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 4.1946564, 'max_total_reward': 11.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.646369504928589, 'actor_loss': -5.789646339416504, 'hyper_actor_loss': 0.01584190558642149, 'behavior_loss': 0.2498355746269226, 'mean_batch': 8.386672592163086, 'min_batch': 7.797882890701294, 'max_batch': 8.81826229095459}
step: 34490 @ episode report: {'average_total_reward': 10.331001, 'reward_variance': 6.2487698, 'max_total_reward': 14.56, 'min_total_reward': 5.7900004, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.635531663894653, 'actor_loss': -5.835076093673706, 'hyper_actor_loss': 0.015738389920443296, 'behavior_loss': 0.2638424262404442, 'mean_batch': 8.582048034667968, 'min_batch': 7.973514080047607, 'max_batch': 9.064989948272705}
step: 34500 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 7.585457, 'max_total_reward': 14.56, 'min_total_reward': 3.3500001, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.086497116088867, 'actor_loss': -5.771915483474731, 'hyper_actor_loss': 0.015846774354577063, 'behavior_loss': 0.2602982625365257, 'mean_batch': 8.308496189117431, 'min_batch': 7.733529376983642, 'max_batch': 8.791438770294189}
step: 34510 @ episode report: {'average_total_reward': 10.964, 'reward_variance': 4.816065, 'max_total_reward': 15.67, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.928578972816467, 'actor_loss': -5.7655621528625485, 'hyper_actor_loss': 0.015700340457260608, 'behavior_loss': 0.2666413769125938, 'mean_batch': 8.264363384246826, 'min_batch': 7.723607301712036, 'max_batch': 8.718744945526122}
step: 34520 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 10.728728, 'max_total_reward': 15.45, 'min_total_reward': 2.3500001, 'average_n_step': 11.0, 'max_n_step': 16.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.85126017332077, 'actor_loss': -5.799414205551147, 'hyper_actor_loss': 0.015884342696517707, 'behavior_loss': 0.2696064099669456, 'mean_batch': 8.40786657333374, 'min_batch': 7.855305480957031, 'max_batch': 8.837809467315674}
step: 34530 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 3.1209054, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.356017589569092, 'actor_loss': -5.7910974502563475, 'hyper_actor_loss': 0.015869246050715446, 'behavior_loss': 0.2633891060948372, 'mean_batch': 8.441986083984375, 'min_batch': 7.764126873016357, 'max_batch': 8.873941993713379}
step: 34540 @ episode report: {'average_total_reward': 10.964, 'reward_variance': 4.940385, 'max_total_reward': 14.450001, 'min_total_reward': 6.7899995, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.855131840705871, 'actor_loss': -5.750534391403198, 'hyper_actor_loss': 0.015536781586706638, 'behavior_loss': 0.2620285376906395, 'mean_batch': 8.213919258117675, 'min_batch': 7.657413101196289, 'max_batch': 8.642675495147705}
step: 34550 @ episode report: {'average_total_reward': 10.631001, 'reward_variance': 2.6334488, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.670376205444336, 'actor_loss': -5.815623140335083, 'hyper_actor_loss': 0.015459370519965886, 'behavior_loss': 0.24791021198034285, 'mean_batch': 8.43328800201416, 'min_batch': 7.958202600479126, 'max_batch': 8.86907081604004}
step: 34560 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 2.2137804, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3644904613494875, 'actor_loss': -5.820138931274414, 'hyper_actor_loss': 0.014997887704521418, 'behavior_loss': 0.2464761182665825, 'mean_batch': 8.498016738891602, 'min_batch': 7.940363121032715, 'max_batch': 8.987879753112793}
step: 34570 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 1.6697689, 'max_total_reward': 12.23, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.011996352672577, 'actor_loss': -5.823347377777099, 'hyper_actor_loss': 0.014820192940533161, 'behavior_loss': 0.26499434411525724, 'mean_batch': 8.489270496368409, 'min_batch': 7.965598487854004, 'max_batch': 8.907287979125977}
step: 34580 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 1.2541006, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.120627212524414, 'actor_loss': -5.817206811904907, 'hyper_actor_loss': 0.015429031662642955, 'behavior_loss': 0.2728338479995728, 'mean_batch': 8.498629379272462, 'min_batch': 7.910448026657105, 'max_batch': 8.911506462097169}
step: 34590 @ episode report: {'average_total_reward': 11.197001, 'reward_variance': 2.4179018, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.822726249694824, 'actor_loss': -5.816866254806518, 'hyper_actor_loss': 0.01569148516282439, 'behavior_loss': 0.2718477949500084, 'mean_batch': 8.466015625, 'min_batch': 7.936789464950562, 'max_batch': 8.936360073089599}
step: 34600 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 4.9684896, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.123873257637024, 'actor_loss': -5.786215925216675, 'hyper_actor_loss': 0.015888186171650887, 'behavior_loss': 0.25873362421989443, 'mean_batch': 8.366126918792725, 'min_batch': 7.792363834381104, 'max_batch': 8.824591732025146}
step: 34610 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 2.7864437, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.084130954742432, 'actor_loss': -5.766051435470581, 'hyper_actor_loss': 0.015586590580642223, 'behavior_loss': 0.26501166075468063, 'mean_batch': 8.368805885314941, 'min_batch': 7.63781967163086, 'max_batch': 8.823264694213867}
step: 34620 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 5.619341, 'max_total_reward': 13.45, 'min_total_reward': 5.57, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.940066695213318, 'actor_loss': -5.777309846878052, 'hyper_actor_loss': 0.015416467376053334, 'behavior_loss': 0.25959538519382475, 'mean_batch': 8.387563514709473, 'min_batch': 7.712846183776856, 'max_batch': 8.88737382888794}
step: 34630 @ episode report: {'average_total_reward': 10.931002, 'reward_variance': 4.83031, 'max_total_reward': 15.67, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.43727560043335, 'actor_loss': -5.777543258666992, 'hyper_actor_loss': 0.015650391206145288, 'behavior_loss': 0.26664173007011416, 'mean_batch': 8.306038570404052, 'min_batch': 7.781383657455445, 'max_batch': 8.765622806549072}
step: 34640 @ episode report: {'average_total_reward': 10.709002, 'reward_variance': 1.83291, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.522105360031128, 'actor_loss': -5.810686826705933, 'hyper_actor_loss': 0.015552403964102268, 'behavior_loss': 0.2469830721616745, 'mean_batch': 8.407078647613526, 'min_batch': 7.943330192565918, 'max_batch': 8.890573883056641}
step: 34650 @ episode report: {'average_total_reward': 10.320001, 'reward_variance': 6.422821, 'max_total_reward': 14.45, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.696768641471863, 'actor_loss': -5.8125394821167, 'hyper_actor_loss': 0.015466930530965328, 'behavior_loss': 0.2569047138094902, 'mean_batch': 8.433505535125732, 'min_batch': 7.932215929031372, 'max_batch': 8.873743343353272}
step: 34660 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 4.844325, 'max_total_reward': 12.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.378817448019982, 'actor_loss': -5.845092821121216, 'hyper_actor_loss': 0.015353562030941247, 'behavior_loss': 0.25767693370580674, 'mean_batch': 8.583475589752197, 'min_batch': 8.05346326828003, 'max_batch': 9.099064350128174}
step: 34670 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 2.9633415, 'max_total_reward': 12.230001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.623902082443237, 'actor_loss': -5.826905202865601, 'hyper_actor_loss': 0.015534539800137281, 'behavior_loss': 0.2531092628836632, 'mean_batch': 8.540887546539306, 'min_batch': 7.94844536781311, 'max_batch': 8.960235404968262}
step: 34680 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 6.30976, 'max_total_reward': 15.559999, 'min_total_reward': 6.8999996, 'average_n_step': 11.6, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.111321640014649, 'actor_loss': -5.79236798286438, 'hyper_actor_loss': 0.015881314501166345, 'behavior_loss': 0.24368941634893418, 'mean_batch': 8.407713890075684, 'min_batch': 7.807333326339721, 'max_batch': 8.789851951599122}
step: 34690 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 6.158377, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.902445435523987, 'actor_loss': -5.793984699249267, 'hyper_actor_loss': 0.015936141740530728, 'behavior_loss': 0.2653745234012604, 'mean_batch': 8.478066349029541, 'min_batch': 7.757660150527954, 'max_batch': 8.903204917907715}
step: 34700 @ episode report: {'average_total_reward': 10.709001, 'reward_variance': 0.99596894, 'max_total_reward': 12.23, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.639781594276428, 'actor_loss': -5.864591884613037, 'hyper_actor_loss': 0.016076454240828753, 'behavior_loss': 0.2559693530201912, 'mean_batch': 8.618160343170166, 'min_batch': 8.176906490325928, 'max_batch': 9.084155654907226}
step: 34710 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 2.3964558, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.798970627784729, 'actor_loss': -5.831032943725586, 'hyper_actor_loss': 0.01660398282110691, 'behavior_loss': 0.2595200091600418, 'mean_batch': 8.526208114624023, 'min_batch': 7.993229532241822, 'max_batch': 8.92485589981079}
step: 34720 @ episode report: {'average_total_reward': 11.097, 'reward_variance': 4.05066, 'max_total_reward': 14.559999, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7046071767807005, 'actor_loss': -5.851238870620728, 'hyper_actor_loss': 0.016667286306619643, 'behavior_loss': 0.264756777882576, 'mean_batch': 8.625035190582276, 'min_batch': 8.06305980682373, 'max_batch': 9.081520271301269}
step: 34730 @ episode report: {'average_total_reward': 11.186, 'reward_variance': 3.726043, 'max_total_reward': 14.559999, 'min_total_reward': 7.9000006, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.650252771377564, 'actor_loss': -5.881069183349609, 'hyper_actor_loss': 0.016805951856076716, 'behavior_loss': 0.24919650703668594, 'mean_batch': 8.699333572387696, 'min_batch': 8.235326290130615, 'max_batch': 9.137214469909669}
step: 34740 @ episode report: {'average_total_reward': 10.420001, 'reward_variance': 3.3962998, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.403803265094757, 'actor_loss': -5.840185165405273, 'hyper_actor_loss': 0.016727556474506855, 'behavior_loss': 0.2495439499616623, 'mean_batch': 8.609833145141602, 'min_batch': 7.9913825511932375, 'max_batch': 9.088594150543212}
step: 34750 @ episode report: {'average_total_reward': 9.997999, 'reward_variance': 3.2934163, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.84376072883606, 'actor_loss': -5.843033361434936, 'hyper_actor_loss': 0.01673127803951502, 'behavior_loss': 0.26023211181163786, 'mean_batch': 8.637493991851807, 'min_batch': 7.987658548355102, 'max_batch': 9.04845495223999}
step: 34760 @ episode report: {'average_total_reward': 10.01, 'reward_variance': 5.3598804, 'max_total_reward': 14.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.248665380477905, 'actor_loss': -5.833914136886596, 'hyper_actor_loss': 0.016417467035353184, 'behavior_loss': 0.26562917083501814, 'mean_batch': 8.619469356536865, 'min_batch': 7.934725189208985, 'max_batch': 9.081388664245605}
step: 34770 @ episode report: {'average_total_reward': 10.887001, 'reward_variance': 0.69344103, 'max_total_reward': 12.340001, 'min_total_reward': 9.9, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.387538850307465, 'actor_loss': -5.827406311035157, 'hyper_actor_loss': 0.016673243977129458, 'behavior_loss': 0.2528193429112434, 'mean_batch': 8.55303258895874, 'min_batch': 7.946743583679199, 'max_batch': 9.049043941497803}
step: 34780 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 2.557185, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.668781733512878, 'actor_loss': -5.8433513164520265, 'hyper_actor_loss': 0.016626360081136226, 'behavior_loss': 0.24315515011548997, 'mean_batch': 8.590648078918457, 'min_batch': 8.031116485595703, 'max_batch': 9.142952728271485}
step: 34790 @ episode report: {'average_total_reward': 10.842, 'reward_variance': 1.557336, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5606204748153685, 'actor_loss': -5.800768566131592, 'hyper_actor_loss': 0.016551915369927884, 'behavior_loss': 0.25293798595666883, 'mean_batch': 8.479504203796386, 'min_batch': 7.8004231452941895, 'max_batch': 8.957555294036865}
step: 34800 @ episode report: {'average_total_reward': 10.653001, 'reward_variance': 1.9860615, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.319387173652649, 'actor_loss': -5.839292526245117, 'hyper_actor_loss': 0.016373984329402447, 'behavior_loss': 0.25393771231174467, 'mean_batch': 8.617355823516846, 'min_batch': 7.980643463134766, 'max_batch': 9.081809616088867}
step: 34810 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 3.6920896, 'max_total_reward': 13.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8505360841751095, 'actor_loss': -5.838316345214844, 'hyper_actor_loss': 0.016436889953911304, 'behavior_loss': 0.2614629194140434, 'mean_batch': 8.61025686264038, 'min_batch': 7.976604223251343, 'max_batch': 9.055627250671387}
step: 34820 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 5.154424, 'max_total_reward': 14.45, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.993110203742981, 'actor_loss': -5.837807893753052, 'hyper_actor_loss': 0.016839105077087878, 'behavior_loss': 0.2715596541762352, 'mean_batch': 8.533806419372558, 'min_batch': 8.04057698249817, 'max_batch': 8.930658531188964}
step: 34830 @ episode report: {'average_total_reward': 10.998, 'reward_variance': 1.817096, 'max_total_reward': 13.450001, 'min_total_reward': 9.79, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.504005038738251, 'actor_loss': -5.86457052230835, 'hyper_actor_loss': 0.016930746287107466, 'behavior_loss': 0.2529057145118713, 'mean_batch': 8.668991851806641, 'min_batch': 8.131106185913087, 'max_batch': 9.11096420288086}
step: 34840 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.7926457, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.997377109527588, 'actor_loss': -5.8463846206665036, 'hyper_actor_loss': 0.01674550026655197, 'behavior_loss': 0.24838220775127412, 'mean_batch': 8.631228923797607, 'min_batch': 8.020221328735351, 'max_batch': 9.053816795349121}
step: 34850 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 1.5084956, 'max_total_reward': 12.339999, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.398666572570801, 'actor_loss': -5.8626772403717045, 'hyper_actor_loss': 0.01639272440224886, 'behavior_loss': 0.2578593760728836, 'mean_batch': 8.641786766052245, 'min_batch': 8.139141273498534, 'max_batch': 9.0561674118042}
step: 34860 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 3.8357463, 'max_total_reward': 14.560001, 'min_total_reward': 6.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.775241947174072, 'actor_loss': -5.8853919982910154, 'hyper_actor_loss': 0.01640486139804125, 'behavior_loss': 0.25099871307611465, 'mean_batch': 8.713145351409912, 'min_batch': 8.2579270362854, 'max_batch': 9.18934679031372}
step: 34870 @ episode report: {'average_total_reward': 9.964999, 'reward_variance': 4.275804, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.088240623474121, 'actor_loss': -5.877521705627442, 'hyper_actor_loss': 0.01645328663289547, 'behavior_loss': 0.2537390038371086, 'mean_batch': 8.721763610839844, 'min_batch': 8.187364196777343, 'max_batch': 9.182883834838867}
step: 34880 @ episode report: {'average_total_reward': 8.622, 'reward_variance': 10.400996, 'max_total_reward': 14.45, 'min_total_reward': 1.35, 'average_n_step': 9.7, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.413974905014038, 'actor_loss': -5.892320585250855, 'hyper_actor_loss': 0.01655616480857134, 'behavior_loss': 0.2570249617099762, 'mean_batch': 8.794654369354248, 'min_batch': 8.23937005996704, 'max_batch': 9.229268455505371}
step: 34890 @ episode report: {'average_total_reward': 11.908, 'reward_variance': 2.467777, 'max_total_reward': 14.56, 'min_total_reward': 9.9, 'average_n_step': 12.7, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.367035555839538, 'actor_loss': -5.841798782348633, 'hyper_actor_loss': 0.01614286322146654, 'behavior_loss': 0.25858995914459226, 'mean_batch': 8.65235357284546, 'min_batch': 7.977357816696167, 'max_batch': 9.118109130859375}
step: 34900 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 2.5142438, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.833460569381714, 'actor_loss': -5.844868850708008, 'hyper_actor_loss': 0.016020142007619143, 'behavior_loss': 0.2640116736292839, 'mean_batch': 8.571294021606445, 'min_batch': 8.062007188796997, 'max_batch': 9.00071907043457}
step: 34910 @ episode report: {'average_total_reward': 9.809999, 'reward_variance': 3.67546, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.138821721076965, 'actor_loss': -5.856089305877686, 'hyper_actor_loss': 0.016820290125906467, 'behavior_loss': 0.27004454731941224, 'mean_batch': 8.746679210662842, 'min_batch': 8.006589221954346, 'max_batch': 9.265924263000489}
step: 34920 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 3.2486198, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.452797484397888, 'actor_loss': -5.853862190246582, 'hyper_actor_loss': 0.016552186384797097, 'behavior_loss': 0.253849695622921, 'mean_batch': 8.609984016418457, 'min_batch': 8.09798755645752, 'max_batch': 9.117153453826905}
step: 34930 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 1.3862809, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6085999488830565, 'actor_loss': -5.851645231246948, 'hyper_actor_loss': 0.016331138648092748, 'behavior_loss': 0.2529448330402374, 'mean_batch': 8.602130031585693, 'min_batch': 8.087501049041748, 'max_batch': 9.107822608947753}
step: 34940 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.1075852, 'max_total_reward': 13.340001, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.364958560466766, 'actor_loss': -5.885330390930176, 'hyper_actor_loss': 0.01597170950844884, 'behavior_loss': 0.25865222662687304, 'mean_batch': 8.735139274597168, 'min_batch': 8.23723931312561, 'max_batch': 9.235577011108399}
step: 34950 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 1.284036, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.645690226554871, 'actor_loss': -5.906654930114746, 'hyper_actor_loss': 0.016021931357681752, 'behavior_loss': 0.2475035384297371, 'mean_batch': 8.894040775299072, 'min_batch': 8.267484903335571, 'max_batch': 9.416975688934325}
step: 34960 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.2974834, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.250922894477844, 'actor_loss': -5.851150369644165, 'hyper_actor_loss': 0.0158462006598711, 'behavior_loss': 0.2699135705828667, 'mean_batch': 8.70121078491211, 'min_batch': 7.997533750534058, 'max_batch': 9.197585487365723}
step: 34970 @ episode report: {'average_total_reward': 10.542002, 'reward_variance': 3.2009568, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.887587666511536, 'actor_loss': -5.883145427703857, 'hyper_actor_loss': 0.016094637289643287, 'behavior_loss': 0.26403987109661103, 'mean_batch': 8.732293033599854, 'min_batch': 8.222336530685425, 'max_batch': 9.209654903411865}
step: 34980 @ episode report: {'average_total_reward': 11.519, 'reward_variance': 3.5478892, 'max_total_reward': 14.450001, 'min_total_reward': 9.01, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.966186690330505, 'actor_loss': -5.868168115615845, 'hyper_actor_loss': 0.016175293922424318, 'behavior_loss': 0.261641700565815, 'mean_batch': 8.795743179321288, 'min_batch': 8.05659613609314, 'max_batch': 9.254492568969727}
step: 34990 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 1.9259897, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5214437484741214, 'actor_loss': -5.8931849002838135, 'hyper_actor_loss': 0.01617181170731783, 'behavior_loss': 0.25767749547958374, 'mean_batch': 8.774879550933838, 'min_batch': 8.264410209655761, 'max_batch': 9.227880859375}
step: 35000 @ episode report: {'average_total_reward': 9.565001, 'reward_variance': 6.695365, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.538184642791748, 'actor_loss': -5.845877265930175, 'hyper_actor_loss': 0.016042654123157262, 'behavior_loss': 0.2718056753277779, 'mean_batch': 8.675488758087159, 'min_batch': 7.989850187301636, 'max_batch': 9.14611005783081}
step: 35010 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 2.5982838, 'max_total_reward': 11.23, 'min_total_reward': 6.6800003, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.269003844261169, 'actor_loss': -5.857377719879151, 'hyper_actor_loss': 0.016074441093951463, 'behavior_loss': 0.25608823001384734, 'mean_batch': 8.64811429977417, 'min_batch': 8.090627241134644, 'max_batch': 9.15329418182373}
step: 35020 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 4.0964212, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.069692850112915, 'actor_loss': -5.853970670700074, 'hyper_actor_loss': 0.015943216718733312, 'behavior_loss': 0.2615572988986969, 'mean_batch': 8.678607368469239, 'min_batch': 8.03743109703064, 'max_batch': 9.148086452484131}
step: 35030 @ episode report: {'average_total_reward': 10.552999, 'reward_variance': 3.2636018, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.251385807991028, 'actor_loss': -5.872042608261109, 'hyper_actor_loss': 0.01568491794168949, 'behavior_loss': 0.2630744636058807, 'mean_batch': 8.735358142852784, 'min_batch': 8.132021856307983, 'max_batch': 9.217464160919189}
step: 35040 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 3.5423844, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.822324538230896, 'actor_loss': -5.867627763748169, 'hyper_actor_loss': 0.015839982032775878, 'behavior_loss': 0.2471720278263092, 'mean_batch': 8.683605098724366, 'min_batch': 8.140353918075562, 'max_batch': 9.193328857421875}
step: 35050 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 1.2424965, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.50306282043457, 'actor_loss': -5.840970849990844, 'hyper_actor_loss': 0.015579164307564498, 'behavior_loss': 0.26299535036087035, 'mean_batch': 8.62869997024536, 'min_batch': 7.981895017623901, 'max_batch': 9.107748889923096}
step: 35060 @ episode report: {'average_total_reward': 11.308001, 'reward_variance': 1.8212764, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.59488416314125, 'actor_loss': -5.872669839859009, 'hyper_actor_loss': 0.01544954562559724, 'behavior_loss': 0.2338319957256317, 'mean_batch': 8.832662582397461, 'min_batch': 8.057777070999146, 'max_batch': 9.329741764068604}
step: 35070 @ episode report: {'average_total_reward': 11.186, 'reward_variance': 2.6646833, 'max_total_reward': 14.45, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.004752087593078, 'actor_loss': -5.845504808425903, 'hyper_actor_loss': 0.015121659450232982, 'behavior_loss': 0.2747021749615669, 'mean_batch': 8.62796745300293, 'min_batch': 8.018995666503907, 'max_batch': 9.091406345367432}
step: 35080 @ episode report: {'average_total_reward': 11.407999, 'reward_variance': 1.1344159, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.2318288564682005, 'actor_loss': -5.788300371170044, 'hyper_actor_loss': 0.015643380302935838, 'behavior_loss': 0.26296778321266173, 'mean_batch': 8.494451713562011, 'min_batch': 7.703407192230225, 'max_batch': 8.935846138000489}
step: 35090 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 1.607064, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.676256394386291, 'actor_loss': -5.864562463760376, 'hyper_actor_loss': 0.015555707365274429, 'behavior_loss': 0.2527734562754631, 'mean_batch': 8.68352746963501, 'min_batch': 8.116476392745971, 'max_batch': 9.17989387512207}
step: 35100 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 1.3357801, 'max_total_reward': 12.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.594481134414673, 'actor_loss': -5.8797290325164795, 'hyper_actor_loss': 0.015317145362496376, 'behavior_loss': 0.2555259943008423, 'mean_batch': 8.75149621963501, 'min_batch': 8.175612449645996, 'max_batch': 9.199950790405273}
step: 35110 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 2.7572014, 'max_total_reward': 13.450001, 'min_total_reward': 8.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.184754776954651, 'actor_loss': -5.868707132339478, 'hyper_actor_loss': 0.015662113018333913, 'behavior_loss': 0.2671172767877579, 'mean_batch': 8.700904083251952, 'min_batch': 8.132678699493407, 'max_batch': 9.241549968719482}
step: 35120 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 4.8921814, 'max_total_reward': 12.340001, 'min_total_reward': 5.57, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.799231624603271, 'actor_loss': -5.860822343826294, 'hyper_actor_loss': 0.015668466966599227, 'behavior_loss': 0.25253674685955046, 'mean_batch': 8.680636405944824, 'min_batch': 8.088096284866333, 'max_batch': 9.207281875610352}
step: 35130 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 3.0092292, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.11413197517395, 'actor_loss': -5.825482749938965, 'hyper_actor_loss': 0.015642785280942918, 'behavior_loss': 0.2572157382965088, 'mean_batch': 8.643643856048584, 'min_batch': 7.871278715133667, 'max_batch': 9.236067008972167}
step: 35140 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 5.1531816, 'max_total_reward': 14.56, 'min_total_reward': 5.7899995, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.761347699165344, 'actor_loss': -5.852270889282226, 'hyper_actor_loss': 0.015795715246349575, 'behavior_loss': 0.2486157923936844, 'mean_batch': 8.650523853302001, 'min_batch': 8.051310729980468, 'max_batch': 9.148089122772216}
step: 35150 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 3.8088202, 'max_total_reward': 12.34, 'min_total_reward': 6.57, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.814340734481812, 'actor_loss': -5.839103174209595, 'hyper_actor_loss': 0.01574403392150998, 'behavior_loss': 0.2566014647483826, 'mean_batch': 8.582292556762695, 'min_batch': 8.007270193099975, 'max_batch': 9.059385204315186}
step: 35160 @ episode report: {'average_total_reward': 11.097, 'reward_variance': 4.472662, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.142592811584473, 'actor_loss': -5.803422164916992, 'hyper_actor_loss': 0.0159846780821681, 'behavior_loss': 0.25734980702400206, 'mean_batch': 8.45084171295166, 'min_batch': 7.847129774093628, 'max_batch': 8.932514762878418}
step: 35170 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 2.691465, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.570279145240784, 'actor_loss': -5.837098836898804, 'hyper_actor_loss': 0.015707263350486757, 'behavior_loss': 0.2561317771673203, 'mean_batch': 8.551888847351075, 'min_batch': 8.018033933639526, 'max_batch': 9.044216918945313}
step: 35180 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 4.038724, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.023854374885559, 'actor_loss': -5.8212169170379635, 'hyper_actor_loss': 0.015645078290253876, 'behavior_loss': 0.2693130150437355, 'mean_batch': 8.497376251220704, 'min_batch': 7.9448436260223385, 'max_batch': 8.935709857940674}
step: 35190 @ episode report: {'average_total_reward': 11.175, 'reward_variance': 0.9642847, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.219148516654968, 'actor_loss': -5.859062433242798, 'hyper_actor_loss': 0.015848594717681408, 'behavior_loss': 0.26704062074422835, 'mean_batch': 8.626782035827636, 'min_batch': 8.124181270599365, 'max_batch': 9.066378593444824}
step: 35200 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 4.531349, 'max_total_reward': 12.340001, 'min_total_reward': 6.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.277734398841858, 'actor_loss': -5.854531764984131, 'hyper_actor_loss': 0.015664620138704777, 'behavior_loss': 0.2528019905090332, 'mean_batch': 8.650645446777343, 'min_batch': 8.06725025177002, 'max_batch': 9.109655094146728}
step: 35210 @ episode report: {'average_total_reward': 11.308001, 'reward_variance': 2.831376, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7959929466247555, 'actor_loss': -5.858029747009278, 'hyper_actor_loss': 0.015283994190394879, 'behavior_loss': 0.2691215589642525, 'mean_batch': 8.611960411071777, 'min_batch': 8.129393672943115, 'max_batch': 9.056791210174561}
step: 35220 @ episode report: {'average_total_reward': 10.542, 'reward_variance': 3.305696, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.096116948127746, 'actor_loss': -5.822049474716186, 'hyper_actor_loss': 0.015571023430675268, 'behavior_loss': 0.2737590134143829, 'mean_batch': 8.499711799621583, 'min_batch': 7.946414852142334, 'max_batch': 8.925380992889405}
step: 35230 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 0.99536383, 'max_total_reward': 12.23, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.691554045677185, 'actor_loss': -5.85150294303894, 'hyper_actor_loss': 0.015332566294819116, 'behavior_loss': 0.2573841527104378, 'mean_batch': 8.614422512054443, 'min_batch': 8.07549409866333, 'max_batch': 9.103136539459229}
step: 35240 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 3.2376823, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.180705451965332, 'actor_loss': -5.847184896469116, 'hyper_actor_loss': 0.015437404811382293, 'behavior_loss': 0.2589199960231781, 'mean_batch': 8.688365173339843, 'min_batch': 7.972795915603638, 'max_batch': 9.129985141754151}
step: 35250 @ episode report: {'average_total_reward': 10.464001, 'reward_variance': 4.1219654, 'max_total_reward': 12.340001, 'min_total_reward': 6.7899995, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.006937265396118, 'actor_loss': -5.842507457733154, 'hyper_actor_loss': 0.015371670015156269, 'behavior_loss': 0.2555290535092354, 'mean_batch': 8.570741558074952, 'min_batch': 8.043320035934448, 'max_batch': 8.977582550048828}
step: 35260 @ episode report: {'average_total_reward': 11.475, 'reward_variance': 4.3009458, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.825226521492004, 'actor_loss': -5.859004926681519, 'hyper_actor_loss': 0.015319715533405543, 'behavior_loss': 0.2682638168334961, 'mean_batch': 8.638271903991699, 'min_batch': 8.11370940208435, 'max_batch': 9.06690092086792}
step: 35270 @ episode report: {'average_total_reward': 10.775001, 'reward_variance': 2.209545, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.963705539703369, 'actor_loss': -5.859866571426392, 'hyper_actor_loss': 0.015295112784951926, 'behavior_loss': 0.25455387532711027, 'mean_batch': 8.64437780380249, 'min_batch': 8.11414270401001, 'max_batch': 9.092164516448975}
step: 35280 @ episode report: {'average_total_reward': 11.419001, 'reward_variance': 3.1469488, 'max_total_reward': 15.67, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9965044021606446, 'actor_loss': -5.88573956489563, 'hyper_actor_loss': 0.01522818012163043, 'behavior_loss': 0.25157269537448884, 'mean_batch': 8.752069664001464, 'min_batch': 8.22580361366272, 'max_batch': 9.171194648742675}
step: 35290 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 5.39049, 'max_total_reward': 13.450001, 'min_total_reward': 4.57, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.018971991539002, 'actor_loss': -5.891584825515747, 'hyper_actor_loss': 0.014908379781991244, 'behavior_loss': 0.2523917376995087, 'mean_batch': 8.74644079208374, 'min_batch': 8.27754774093628, 'max_batch': 9.125435543060302}
step: 35300 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 1.6214043, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.583866357803345, 'actor_loss': -5.8839374542236325, 'hyper_actor_loss': 0.01499318890273571, 'behavior_loss': 0.281687793135643, 'mean_batch': 8.694087791442872, 'min_batch': 8.264150905609132, 'max_batch': 9.090126514434814}
step: 35310 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 6.653989, 'max_total_reward': 15.67, 'min_total_reward': 6.57, 'average_n_step': 10.9, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.781819987297058, 'actor_loss': -5.855453538894653, 'hyper_actor_loss': 0.01528017595410347, 'behavior_loss': 0.25674229562282563, 'mean_batch': 8.562137126922607, 'min_batch': 8.155843734741211, 'max_batch': 8.9557541847229}
step: 35320 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 4.8357205, 'max_total_reward': 14.559999, 'min_total_reward': 6.6800003, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.136846351623535, 'actor_loss': -5.828520011901856, 'hyper_actor_loss': 0.01554775470867753, 'behavior_loss': 0.26477431654930117, 'mean_batch': 8.521338748931885, 'min_batch': 7.9777251243591305, 'max_batch': 8.9095534324646}
step: 35330 @ episode report: {'average_total_reward': 10.964, 'reward_variance': 2.4471242, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.567723965644836, 'actor_loss': -5.833371162414551, 'hyper_actor_loss': 0.015511046163737774, 'behavior_loss': 0.2583582580089569, 'mean_batch': 8.555722332000732, 'min_batch': 7.985417795181275, 'max_batch': 8.899320507049561}
step: 35340 @ episode report: {'average_total_reward': 11.597, 'reward_variance': 1.4059817, 'max_total_reward': 13.450001, 'min_total_reward': 9.9, 'average_n_step': 12.4, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.285758900642395, 'actor_loss': -5.830082941055298, 'hyper_actor_loss': 0.015768236294388772, 'behavior_loss': 0.2648432046175003, 'mean_batch': 8.491521167755128, 'min_batch': 8.017450284957885, 'max_batch': 8.883550262451172}
step: 35350 @ episode report: {'average_total_reward': 11.120001, 'reward_variance': 1.8323, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.54326639175415, 'actor_loss': -5.83804292678833, 'hyper_actor_loss': 0.015483960416167975, 'behavior_loss': 0.24559214860200881, 'mean_batch': 8.584059715270996, 'min_batch': 7.999377489089966, 'max_batch': 8.942891120910645}
step: 35360 @ episode report: {'average_total_reward': 11.142, 'reward_variance': 8.555997, 'max_total_reward': 15.670001, 'min_total_reward': 5.5699997, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.636352324485779, 'actor_loss': -5.8897322654724125, 'hyper_actor_loss': 0.015423015039414168, 'behavior_loss': 0.270491224527359, 'mean_batch': 8.72934799194336, 'min_batch': 8.278910923004151, 'max_batch': 9.118642616271973}
step: 35370 @ episode report: {'average_total_reward': 10.509, 'reward_variance': 4.531648, 'max_total_reward': 13.450001, 'min_total_reward': 6.9000006, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.208316445350647, 'actor_loss': -5.85967173576355, 'hyper_actor_loss': 0.015980200469493867, 'behavior_loss': 0.26091465055942537, 'mean_batch': 8.625419235229492, 'min_batch': 8.132491302490234, 'max_batch': 8.996390628814698}
step: 35380 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 7.1748457, 'max_total_reward': 12.34, 'min_total_reward': 2.46, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.326691317558288, 'actor_loss': -5.792259931564331, 'hyper_actor_loss': 0.016211881302297115, 'behavior_loss': 0.27646167278289796, 'mean_batch': 8.46008472442627, 'min_batch': 7.7592520236969, 'max_batch': 8.827029132843018}
step: 35390 @ episode report: {'average_total_reward': 9.554, 'reward_variance': 5.530045, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.451949906349182, 'actor_loss': -5.847408294677734, 'hyper_actor_loss': 0.016254478134214878, 'behavior_loss': 0.2597526878118515, 'mean_batch': 8.631603336334228, 'min_batch': 8.031335306167602, 'max_batch': 9.054814720153809}
step: 35400 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 4.4666452, 'max_total_reward': 14.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5970123410224915, 'actor_loss': -5.873317861557007, 'hyper_actor_loss': 0.015964842587709426, 'behavior_loss': 0.2647964388132095, 'mean_batch': 8.735754108428955, 'min_batch': 8.141458320617676, 'max_batch': 9.14705171585083}
step: 35410 @ episode report: {'average_total_reward': 10.441999, 'reward_variance': 2.9313562, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.665293598175049, 'actor_loss': -5.886061954498291, 'hyper_actor_loss': 0.015667907800525425, 'behavior_loss': 0.2411916360259056, 'mean_batch': 8.714579963684082, 'min_batch': 8.262005043029784, 'max_batch': 9.15641508102417}
step: 35420 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 2.0255241, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.438119435310364, 'actor_loss': -5.863798904418945, 'hyper_actor_loss': 0.015599352680146695, 'behavior_loss': 0.2568544387817383, 'mean_batch': 8.666023063659669, 'min_batch': 8.127256393432617, 'max_batch': 9.079104232788087}
step: 35430 @ episode report: {'average_total_reward': 11.475, 'reward_variance': 5.071686, 'max_total_reward': 14.450001, 'min_total_reward': 5.7900004, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.055155086517334, 'actor_loss': -5.831246471405029, 'hyper_actor_loss': 0.015419251844286918, 'behavior_loss': 0.26155768632888793, 'mean_batch': 8.506553649902344, 'min_batch': 8.014056158065795, 'max_batch': 8.916349601745605}
step: 35440 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 2.9059415, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.813592481613159, 'actor_loss': -5.804816436767578, 'hyper_actor_loss': 0.015691357385367154, 'behavior_loss': 0.2719350427389145, 'mean_batch': 8.448511409759522, 'min_batch': 7.86836199760437, 'max_batch': 8.88241367340088}
step: 35450 @ episode report: {'average_total_reward': 11.031001, 'reward_variance': 4.24589, 'max_total_reward': 13.45, 'min_total_reward': 7.46, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.013923835754395, 'actor_loss': -5.854836559295654, 'hyper_actor_loss': 0.01571888104081154, 'behavior_loss': 0.24964480549097062, 'mean_batch': 8.62994680404663, 'min_batch': 8.086712217330932, 'max_batch': 9.07745532989502}
step: 35460 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 4.7191095, 'max_total_reward': 13.34, 'min_total_reward': 6.57, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.91660521030426, 'actor_loss': -5.867357158660889, 'hyper_actor_loss': 0.015754670184105635, 'behavior_loss': 0.2714121341705322, 'mean_batch': 8.749723339080811, 'min_batch': 8.079042387008666, 'max_batch': 9.243552112579346}
step: 35470 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 2.0210898, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.190813183784485, 'actor_loss': -5.883154630661011, 'hyper_actor_loss': 0.01565202381461859, 'behavior_loss': 0.26251461207866666, 'mean_batch': 8.757385635375977, 'min_batch': 8.197823810577393, 'max_batch': 9.20752935409546}
step: 35480 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 2.9673812, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.381144237518311, 'actor_loss': -5.859704828262329, 'hyper_actor_loss': 0.015891203377395868, 'behavior_loss': 0.24965717643499374, 'mean_batch': 8.675544834136963, 'min_batch': 8.089923191070557, 'max_batch': 9.087963199615478}
step: 35490 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 2.0986211, 'max_total_reward': 13.23, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.205420470237732, 'actor_loss': -5.846342515945435, 'hyper_actor_loss': 0.015562464017421007, 'behavior_loss': 0.24966053813695907, 'mean_batch': 8.542109203338622, 'min_batch': 8.100609064102173, 'max_batch': 8.979276371002197}
step: 35500 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.1217618, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.503969335556031, 'actor_loss': -5.813280296325684, 'hyper_actor_loss': 0.015436935424804687, 'behavior_loss': 0.2518498465418816, 'mean_batch': 8.502280902862548, 'min_batch': 7.88089542388916, 'max_batch': 8.877317142486572}
step: 35510 @ episode report: {'average_total_reward': 11.064, 'reward_variance': 3.5273647, 'max_total_reward': 14.56, 'min_total_reward': 7.6800003, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.174259495735169, 'actor_loss': -5.861687183380127, 'hyper_actor_loss': 0.01570202484726906, 'behavior_loss': 0.25672279447317126, 'mean_batch': 8.632497215270996, 'min_batch': 8.14349422454834, 'max_batch': 9.017884063720704}
step: 35520 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 5.370808, 'max_total_reward': 14.559999, 'min_total_reward': 5.7900004, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.281863260269165, 'actor_loss': -5.829146957397461, 'hyper_actor_loss': 0.015700714383274316, 'behavior_loss': 0.25777304023504255, 'mean_batch': 8.588538074493409, 'min_batch': 7.928996610641479, 'max_batch': 9.04769582748413}
step: 35530 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 0.9100007, 'max_total_reward': 12.119999, 'min_total_reward': 9.01, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.972787380218506, 'actor_loss': -5.843761348724366, 'hyper_actor_loss': 0.015464344434440136, 'behavior_loss': 0.25796333849430086, 'mean_batch': 8.549147987365723, 'min_batch': 8.073221445083618, 'max_batch': 9.023067188262939}
step: 35540 @ episode report: {'average_total_reward': 8.689, 'reward_variance': 7.2879286, 'max_total_reward': 12.12, 'min_total_reward': 4.46, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.528599548339844, 'actor_loss': -5.898416328430176, 'hyper_actor_loss': 0.01569204553961754, 'behavior_loss': 0.2583608329296112, 'mean_batch': 8.816940593719483, 'min_batch': 8.269218826293946, 'max_batch': 9.28068790435791}
step: 35550 @ episode report: {'average_total_reward': 10.964001, 'reward_variance': 2.6202846, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.819776105880737, 'actor_loss': -5.901790142059326, 'hyper_actor_loss': 0.015538935456424952, 'behavior_loss': 0.25857451260089875, 'mean_batch': 8.782993125915528, 'min_batch': 8.329155445098877, 'max_batch': 9.227489852905274}
step: 35560 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 4.437221, 'max_total_reward': 14.559999, 'min_total_reward': 7.79, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.846239948272705, 'actor_loss': -5.84679856300354, 'hyper_actor_loss': 0.015498172119259834, 'behavior_loss': 0.26174069195985794, 'mean_batch': 8.562099266052247, 'min_batch': 8.085919904708863, 'max_batch': 9.005743980407715}
step: 35570 @ episode report: {'average_total_reward': 10.709002, 'reward_variance': 2.7941694, 'max_total_reward': 13.340001, 'min_total_reward': 8.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.202540373802185, 'actor_loss': -5.877557420730591, 'hyper_actor_loss': 0.01577880121767521, 'behavior_loss': 0.25663415640592574, 'mean_batch': 8.776142787933349, 'min_batch': 8.140513801574707, 'max_batch': 9.189616012573243}
step: 35580 @ episode report: {'average_total_reward': 11.431001, 'reward_variance': 0.8654292, 'max_total_reward': 12.9, 'min_total_reward': 9.9, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8976288676261905, 'actor_loss': -5.8996377944946286, 'hyper_actor_loss': 0.015523525606840848, 'behavior_loss': 0.24768248647451402, 'mean_batch': 8.80019407272339, 'min_batch': 8.295520782470703, 'max_batch': 9.257742214202882}
step: 35590 @ episode report: {'average_total_reward': 10.553, 'reward_variance': 3.6611812, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.961715030670166, 'actor_loss': -5.86906943321228, 'hyper_actor_loss': 0.01565269911661744, 'behavior_loss': 0.25875636041164396, 'mean_batch': 8.666372299194336, 'min_batch': 8.171053743362426, 'max_batch': 9.094614696502685}
step: 35600 @ episode report: {'average_total_reward': 10.398, 'reward_variance': 1.3109154, 'max_total_reward': 12.23, 'min_total_reward': 7.680001, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.63578097820282, 'actor_loss': -5.872422695159912, 'hyper_actor_loss': 0.015368641074746846, 'behavior_loss': 0.24944029450416566, 'mean_batch': 8.670271396636963, 'min_batch': 8.191515159606933, 'max_batch': 9.104476642608642}
step: 35610 @ episode report: {'average_total_reward': 10.665001, 'reward_variance': 5.9643655, 'max_total_reward': 14.34, 'min_total_reward': 5.57, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.791789960861206, 'actor_loss': -5.852860164642334, 'hyper_actor_loss': 0.015509080421179534, 'behavior_loss': 0.26335693895816803, 'mean_batch': 8.711815547943115, 'min_batch': 8.005118417739869, 'max_batch': 9.17943353652954}
step: 35620 @ episode report: {'average_total_reward': 11.164, 'reward_variance': 1.483844, 'max_total_reward': 13.339999, 'min_total_reward': 8.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.104792380332947, 'actor_loss': -5.862215805053711, 'hyper_actor_loss': 0.015390373580157757, 'behavior_loss': 0.24883800595998765, 'mean_batch': 8.683214473724366, 'min_batch': 8.099784183502198, 'max_batch': 9.210730266571044}
step: 35630 @ episode report: {'average_total_reward': 11.064, 'reward_variance': 3.2855854, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.766655385494232, 'actor_loss': -5.913612794876099, 'hyper_actor_loss': 0.015206219162791967, 'behavior_loss': 0.24165797531604766, 'mean_batch': 8.883174991607666, 'min_batch': 8.332570457458496, 'max_batch': 9.35262851715088}
step: 35640 @ episode report: {'average_total_reward': 11.608001, 'reward_variance': 4.280356, 'max_total_reward': 15.67, 'min_total_reward': 7.9, 'average_n_step': 12.4, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.937344026565552, 'actor_loss': -5.917153167724609, 'hyper_actor_loss': 0.015376684535294772, 'behavior_loss': 0.24306379109621049, 'mean_batch': 8.860322761535645, 'min_batch': 8.38504114151001, 'max_batch': 9.301780700683594}
step: 35650 @ episode report: {'average_total_reward': 11.153, 'reward_variance': 2.9375818, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.923077344894409, 'actor_loss': -5.8551489353179935, 'hyper_actor_loss': 0.015336667466908694, 'behavior_loss': 0.2621280297636986, 'mean_batch': 8.568138790130615, 'min_batch': 8.147775650024414, 'max_batch': 8.983717918395996}
step: 35660 @ episode report: {'average_total_reward': 10.4869995, 'reward_variance': 7.2978606, 'max_total_reward': 14.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.455057120323181, 'actor_loss': -5.904287099838257, 'hyper_actor_loss': 0.015428431704640389, 'behavior_loss': 0.25654648393392565, 'mean_batch': 8.814374256134034, 'min_batch': 8.319793319702148, 'max_batch': 9.255212879180908}
step: 35670 @ episode report: {'average_total_reward': 10.110001, 'reward_variance': 4.966921, 'max_total_reward': 14.34, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.712373924255371, 'actor_loss': -5.94227294921875, 'hyper_actor_loss': 0.015470388531684875, 'behavior_loss': 0.2546717092394829, 'mean_batch': 8.979761123657227, 'min_batch': 8.482181072235107, 'max_batch': 9.430155563354493}
step: 35680 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 4.2174425, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.101688551902771, 'actor_loss': -5.883839654922485, 'hyper_actor_loss': 0.015385132376104593, 'behavior_loss': 0.2645395278930664, 'mean_batch': 8.734871196746827, 'min_batch': 8.226177549362182, 'max_batch': 9.187596988677978}
step: 35690 @ episode report: {'average_total_reward': 9.555, 'reward_variance': 2.8317447, 'max_total_reward': 12.339999, 'min_total_reward': 6.6800003, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.930463433265686, 'actor_loss': -5.852897071838379, 'hyper_actor_loss': 0.015034104324877262, 'behavior_loss': 0.2591144606471062, 'mean_batch': 8.643032264709472, 'min_batch': 8.065335369110107, 'max_batch': 9.06123628616333}
step: 35700 @ episode report: {'average_total_reward': 11.264002, 'reward_variance': 2.104305, 'max_total_reward': 14.450002, 'min_total_reward': 9.9, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.466094708442688, 'actor_loss': -5.888530731201172, 'hyper_actor_loss': 0.014987794682383537, 'behavior_loss': 0.2640447437763214, 'mean_batch': 8.773551845550537, 'min_batch': 8.227450466156006, 'max_batch': 9.252686500549316}
step: 35710 @ episode report: {'average_total_reward': 10.465, 'reward_variance': 9.809607, 'max_total_reward': 14.56, 'min_total_reward': 3.24, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.65021498799324, 'actor_loss': -5.888517808914185, 'hyper_actor_loss': 0.014795420598238707, 'behavior_loss': 0.2727756902575493, 'mean_batch': 8.780545806884765, 'min_batch': 8.220998191833496, 'max_batch': 9.294249725341796}
step: 35720 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.0213602, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.278301453590393, 'actor_loss': -5.887362384796143, 'hyper_actor_loss': 0.01456255130469799, 'behavior_loss': 0.2615618512034416, 'mean_batch': 8.810565376281739, 'min_batch': 8.183731079101562, 'max_batch': 9.30297794342041}
step: 35730 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.2101052, 'max_total_reward': 12.34, 'min_total_reward': 6.5699997, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.9372803449630736, 'actor_loss': -5.82968578338623, 'hyper_actor_loss': 0.014533945452421903, 'behavior_loss': 0.28227389305830003, 'mean_batch': 8.546349716186523, 'min_batch': 7.965814828872681, 'max_batch': 8.956066036224366}
step: 35740 @ episode report: {'average_total_reward': 11.142, 'reward_variance': 1.7781366, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.0260244846344, 'actor_loss': -5.850844812393189, 'hyper_actor_loss': 0.0140305632725358, 'behavior_loss': 0.25849456787109376, 'mean_batch': 8.6152813911438, 'min_batch': 8.069936275482178, 'max_batch': 9.104956245422363}
step: 35750 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.4041767, 'max_total_reward': 13.45, 'min_total_reward': 7.7899995, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.928041625022888, 'actor_loss': -5.872915935516358, 'hyper_actor_loss': 0.013775399886071682, 'behavior_loss': 0.27700632214546206, 'mean_batch': 8.688602828979493, 'min_batch': 8.178925132751464, 'max_batch': 9.166503810882569}
step: 35760 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 4.0797496, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.142830634117127, 'actor_loss': -5.847616243362427, 'hyper_actor_loss': 0.013691397197544575, 'behavior_loss': 0.2797404080629349, 'mean_batch': 8.59084186553955, 'min_batch': 8.065777206420899, 'max_batch': 9.040103149414062}
step: 35770 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 5.3610973, 'max_total_reward': 12.34, 'min_total_reward': 4.5699997, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.2709407091140745, 'actor_loss': -5.83264045715332, 'hyper_actor_loss': 0.013959583453834057, 'behavior_loss': 0.2527748256921768, 'mean_batch': 8.574431800842286, 'min_batch': 7.967995500564575, 'max_batch': 8.982957363128662}
step: 35780 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 2.411316, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.218655967712403, 'actor_loss': -5.881772470474243, 'hyper_actor_loss': 0.013329187408089638, 'behavior_loss': 0.26216294765472414, 'mean_batch': 8.707200908660889, 'min_batch': 8.234793281555175, 'max_batch': 9.116890048980713}
step: 35790 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 2.4055438, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.195655941963196, 'actor_loss': -5.851233911514282, 'hyper_actor_loss': 0.013232290837913751, 'behavior_loss': 0.25813171863555906, 'mean_batch': 8.60971622467041, 'min_batch': 8.07936496734619, 'max_batch': 9.048085117340088}
step: 35800 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 4.398781, 'max_total_reward': 14.450001, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.184078621864319, 'actor_loss': -5.835091590881348, 'hyper_actor_loss': 0.013415854051709175, 'behavior_loss': 0.2517003297805786, 'mean_batch': 8.544295120239259, 'min_batch': 8.009883880615234, 'max_batch': 8.943607616424561}
step: 35810 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 3.654881, 'max_total_reward': 14.56, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.285101079940796, 'actor_loss': -5.871088314056396, 'hyper_actor_loss': 0.0134705176576972, 'behavior_loss': 0.25798509269952774, 'mean_batch': 8.686144161224366, 'min_batch': 8.166004943847657, 'max_batch': 9.107161712646484}
step: 35820 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 3.1698012, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.150287008285522, 'actor_loss': -5.888828897476197, 'hyper_actor_loss': 0.013555210549384356, 'behavior_loss': 0.25094244331121446, 'mean_batch': 8.819062805175781, 'min_batch': 8.192086458206177, 'max_batch': 9.228724193572997}
step: 35830 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 3.276961, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8524100422859195, 'actor_loss': -5.891065883636474, 'hyper_actor_loss': 0.013723913300782441, 'behavior_loss': 0.2598731845617294, 'mean_batch': 8.726607131958009, 'min_batch': 8.291761875152588, 'max_batch': 9.124787902832031}
step: 35840 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 3.2361894, 'max_total_reward': 14.559999, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.685400795936585, 'actor_loss': -5.904726552963257, 'hyper_actor_loss': 0.01387779051437974, 'behavior_loss': 0.25873277634382247, 'mean_batch': 8.825669765472412, 'min_batch': 8.312474727630615, 'max_batch': 9.25385332107544}
step: 35850 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 3.705782, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7492265701293945, 'actor_loss': -5.908237886428833, 'hyper_actor_loss': 0.013980056066066027, 'behavior_loss': 0.25379347503185273, 'mean_batch': 8.833211326599121, 'min_batch': 8.333967590332032, 'max_batch': 9.328408145904541}
step: 35860 @ episode report: {'average_total_reward': 11.142, 'reward_variance': 8.067796, 'max_total_reward': 16.78, 'min_total_reward': 5.680001, 'average_n_step': 12.0, 'max_n_step': 17.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8269695520401, 'actor_loss': -5.873274564743042, 'hyper_actor_loss': 0.014419890381395817, 'behavior_loss': 0.25321310460567475, 'mean_batch': 8.753461456298828, 'min_batch': 8.124925661087037, 'max_batch': 9.175504589080811}
step: 35870 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 4.3247437, 'max_total_reward': 12.2300005, 'min_total_reward': 5.680001, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.000360298156738, 'actor_loss': -5.8587892055511475, 'hyper_actor_loss': 0.014062929060310125, 'behavior_loss': 0.25824049562215806, 'mean_batch': 8.728094673156738, 'min_batch': 8.035069894790649, 'max_batch': 9.167275142669677}
step: 35880 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 2.3627198, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.986817741394043, 'actor_loss': -5.89384765625, 'hyper_actor_loss': 0.014163981564342976, 'behavior_loss': 0.2502675116062164, 'mean_batch': 8.802419948577882, 'min_batch': 8.243805313110352, 'max_batch': 9.286833381652832}
step: 35890 @ episode report: {'average_total_reward': 11.497001, 'reward_variance': 2.574642, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.127408528327942, 'actor_loss': -5.908695125579834, 'hyper_actor_loss': 0.01361618833616376, 'behavior_loss': 0.2569213047623634, 'mean_batch': 8.86350326538086, 'min_batch': 8.3101149559021, 'max_batch': 9.256497287750244}
step: 35900 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 2.020721, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.220139813423157, 'actor_loss': -5.92015528678894, 'hyper_actor_loss': 0.013802984170615673, 'behavior_loss': 0.25877213925123216, 'mean_batch': 8.939349365234374, 'min_batch': 8.336174297332764, 'max_batch': 9.38908634185791}
step: 35910 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 3.3032756, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.492772316932678, 'actor_loss': -5.893474006652832, 'hyper_actor_loss': 0.014095481857657433, 'behavior_loss': 0.26804978102445604, 'mean_batch': 8.8838716506958, 'min_batch': 8.177129077911378, 'max_batch': 9.295678329467773}
step: 35920 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 4.128562, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8423158645629885, 'actor_loss': -5.9154621124267575, 'hyper_actor_loss': 0.014069549925625324, 'behavior_loss': 0.26686123609542844, 'mean_batch': 8.879873657226563, 'min_batch': 8.351517248153687, 'max_batch': 9.319755935668946}
step: 35930 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 1.1888158, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.686610221862793, 'actor_loss': -5.895769119262695, 'hyper_actor_loss': 0.01416855864226818, 'behavior_loss': 0.24962600618600844, 'mean_batch': 8.836203384399415, 'min_batch': 8.233445310592652, 'max_batch': 9.26603832244873}
step: 35940 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 0.6727764, 'max_total_reward': 11.2300005, 'min_total_reward': 9.009999, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6621788263320925, 'actor_loss': -5.86869626045227, 'hyper_actor_loss': 0.014004544354975224, 'behavior_loss': 0.2566117435693741, 'mean_batch': 8.803900146484375, 'min_batch': 8.042125558853149, 'max_batch': 9.254122257232666}
step: 35950 @ episode report: {'average_total_reward': 10.742002, 'reward_variance': 3.2504773, 'max_total_reward': 14.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8391683340072635, 'actor_loss': -5.91161880493164, 'hyper_actor_loss': 0.013888843823224306, 'behavior_loss': 0.2683969184756279, 'mean_batch': 8.919981765747071, 'min_batch': 8.283508825302125, 'max_batch': 9.296311092376708}
step: 35960 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 2.986906, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.711441373825073, 'actor_loss': -5.873409652709961, 'hyper_actor_loss': 0.013695295713841916, 'behavior_loss': 0.2636554315686226, 'mean_batch': 8.782916164398193, 'min_batch': 8.101361799240113, 'max_batch': 9.16354751586914}
step: 35970 @ episode report: {'average_total_reward': 11.075, 'reward_variance': 2.1486452, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.648921871185303, 'actor_loss': -5.892895078659057, 'hyper_actor_loss': 0.01418526927009225, 'behavior_loss': 0.2609829857945442, 'mean_batch': 8.81293478012085, 'min_batch': 8.229851865768433, 'max_batch': 9.24255313873291}
step: 35980 @ episode report: {'average_total_reward': 11.442, 'reward_variance': 0.940416, 'max_total_reward': 13.34, 'min_total_reward': 10.01, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.370759654045105, 'actor_loss': -5.91279821395874, 'hyper_actor_loss': 0.013728894572705031, 'behavior_loss': 0.2566972866654396, 'mean_batch': 8.858818435668946, 'min_batch': 8.349063968658447, 'max_batch': 9.288496494293213}
step: 35990 @ episode report: {'average_total_reward': 11.075, 'reward_variance': 1.0188646, 'max_total_reward': 13.23, 'min_total_reward': 10.01, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.631656289100647, 'actor_loss': -5.930589389801026, 'hyper_actor_loss': 0.013743243273347616, 'behavior_loss': 0.25693409740924833, 'mean_batch': 8.92700548171997, 'min_batch': 8.433110904693603, 'max_batch': 9.357342529296876}
step: 36000 @ episode report: {'average_total_reward': 10.853001, 'reward_variance': 3.8089614, 'max_total_reward': 13.340001, 'min_total_reward': 6.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.495957732200623, 'actor_loss': -5.915855741500854, 'hyper_actor_loss': 0.013753469102084637, 'behavior_loss': 0.2708572044968605, 'mean_batch': 8.894676208496094, 'min_batch': 8.342729949951172, 'max_batch': 9.320556449890137}
step: 36010 @ episode report: {'average_total_reward': 11.286001, 'reward_variance': 4.249264, 'max_total_reward': 15.56, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.709957933425903, 'actor_loss': -5.8227873802185055, 'hyper_actor_loss': 0.0140808648429811, 'behavior_loss': 0.26116148084402085, 'mean_batch': 8.709081554412842, 'min_batch': 7.775664234161377, 'max_batch': 9.099332237243653}
step: 36020 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 7.750786, 'max_total_reward': 13.450001, 'min_total_reward': 3.46, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.874941468238831, 'actor_loss': -5.882837915420533, 'hyper_actor_loss': 0.01398897310718894, 'behavior_loss': 0.25049743950366976, 'mean_batch': 8.7179105758667, 'min_batch': 8.232825660705567, 'max_batch': 9.123463153839111}
step: 36030 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 5.427885, 'max_total_reward': 15.67, 'min_total_reward': 7.8999996, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.199739956855774, 'actor_loss': -5.90038743019104, 'hyper_actor_loss': 0.013845627941191197, 'behavior_loss': 0.2605185404419899, 'mean_batch': 8.7929856300354, 'min_batch': 8.30705018043518, 'max_batch': 9.192060661315917}
step: 36040 @ episode report: {'average_total_reward': 10.01, 'reward_variance': 1.4686209, 'max_total_reward': 12.34, 'min_total_reward': 8.68, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.106250643730164, 'actor_loss': -5.869624614715576, 'hyper_actor_loss': 0.013994418270885944, 'behavior_loss': 0.25475458055734634, 'mean_batch': 8.79079008102417, 'min_batch': 8.067099046707153, 'max_batch': 9.218377113342285}
step: 36050 @ episode report: {'average_total_reward': 9.943, 'reward_variance': 7.7208, 'max_total_reward': 13.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.497973871231079, 'actor_loss': -5.847417736053467, 'hyper_actor_loss': 0.013819341082125902, 'behavior_loss': 0.2440023183822632, 'mean_batch': 8.802588176727294, 'min_batch': 7.894700813293457, 'max_batch': 9.179967498779297}
step: 36060 @ episode report: {'average_total_reward': 10.443, 'reward_variance': 3.5025418, 'max_total_reward': 14.2300005, 'min_total_reward': 7.57, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.672472858428955, 'actor_loss': -5.841588163375855, 'hyper_actor_loss': 0.013514048885554075, 'behavior_loss': 0.2624918669462204, 'mean_batch': 8.744858074188233, 'min_batch': 7.891396141052246, 'max_batch': 9.136003780364991}
step: 36070 @ episode report: {'average_total_reward': 8.444, 'reward_variance': 3.665844, 'max_total_reward': 12.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 9.5, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.957658267021179, 'actor_loss': -5.860983610153198, 'hyper_actor_loss': 0.013874431885778905, 'behavior_loss': 0.26979382038116456, 'mean_batch': 8.684002876281738, 'min_batch': 8.092062616348267, 'max_batch': 9.074349880218506}
step: 36080 @ episode report: {'average_total_reward': 10.753001, 'reward_variance': 2.8308213, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8282801270484925, 'actor_loss': -5.9185333251953125, 'hyper_actor_loss': 0.013884245324879885, 'behavior_loss': 0.2513247519731522, 'mean_batch': 8.866704368591309, 'min_batch': 8.388559818267822, 'max_batch': 9.322775840759277}
step: 36090 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 10.927561, 'max_total_reward': 14.34, 'min_total_reward': 1.35, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.39599575996399, 'actor_loss': -5.86556396484375, 'hyper_actor_loss': 0.013841516058892011, 'behavior_loss': 0.258340859413147, 'mean_batch': 8.675900554656982, 'min_batch': 8.136227178573609, 'max_batch': 9.05562629699707}
step: 36100 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 3.3542252, 'max_total_reward': 12.34, 'min_total_reward': 5.7899995, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.823216485977173, 'actor_loss': -5.828161001205444, 'hyper_actor_loss': 0.013936955016106367, 'behavior_loss': 0.2498221591114998, 'mean_batch': 8.543239974975586, 'min_batch': 7.954901647567749, 'max_batch': 9.026451873779298}
step: 36110 @ episode report: {'average_total_reward': 11.275, 'reward_variance': 3.0634847, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0649076223373415, 'actor_loss': -5.877563428878784, 'hyper_actor_loss': 0.014204978570342064, 'behavior_loss': 0.2645910710096359, 'mean_batch': 8.74755573272705, 'min_batch': 8.164911317825318, 'max_batch': 9.197189044952392}
step: 36120 @ episode report: {'average_total_reward': 10.998001, 'reward_variance': 1.575736, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7737387895584105, 'actor_loss': -5.899113273620605, 'hyper_actor_loss': 0.013808701653033495, 'behavior_loss': 0.2617092564702034, 'mean_batch': 8.759333038330078, 'min_batch': 8.327575969696046, 'max_batch': 9.168994617462157}
step: 36130 @ episode report: {'average_total_reward': 10.321, 'reward_variance': 3.8127892, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.221492290496826, 'actor_loss': -5.902147674560547, 'hyper_actor_loss': 0.014071017503738403, 'behavior_loss': 0.24325331747531892, 'mean_batch': 8.816239929199218, 'min_batch': 8.303288745880128, 'max_batch': 9.176366233825684}
step: 36140 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 3.5359166, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.206379055976868, 'actor_loss': -5.911399841308594, 'hyper_actor_loss': 0.014066585525870322, 'behavior_loss': 0.26384477615356444, 'mean_batch': 8.889389133453369, 'min_batch': 8.314197397232055, 'max_batch': 9.281734085083007}
step: 36150 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 1.8779047, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.99237756729126, 'actor_loss': -5.8909708023071286, 'hyper_actor_loss': 0.014394272677600383, 'behavior_loss': 0.2790714353322983, 'mean_batch': 8.754214668273926, 'min_batch': 8.269712734222413, 'max_batch': 9.118532657623291}
step: 36160 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 2.1523805, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.318980765342713, 'actor_loss': -5.809557867050171, 'hyper_actor_loss': 0.014707029424607753, 'behavior_loss': 0.26761591285467146, 'mean_batch': 8.574181652069091, 'min_batch': 7.801914930343628, 'max_batch': 8.986157894134521}
step: 36170 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 3.6094604, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.596305108070373, 'actor_loss': -5.888904762268067, 'hyper_actor_loss': 0.01419106051325798, 'behavior_loss': 0.2495468944311142, 'mean_batch': 8.721917819976806, 'min_batch': 8.2785813331604, 'max_batch': 9.069320011138917}
step: 36180 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 2.3303006, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.302635574340821, 'actor_loss': -5.871877384185791, 'hyper_actor_loss': 0.014310845080763102, 'behavior_loss': 0.26451452225446703, 'mean_batch': 8.725362396240234, 'min_batch': 8.137708806991578, 'max_batch': 9.107522678375243}
step: 36190 @ episode report: {'average_total_reward': 11.109, 'reward_variance': 2.9849687, 'max_total_reward': 13.340001, 'min_total_reward': 7.79, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.737551641464234, 'actor_loss': -5.881586313247681, 'hyper_actor_loss': 0.014245092868804932, 'behavior_loss': 0.263982880115509, 'mean_batch': 8.784147262573242, 'min_batch': 8.16622018814087, 'max_batch': 9.19289722442627}
step: 36200 @ episode report: {'average_total_reward': 11.32, 'reward_variance': 1.8653599, 'max_total_reward': 13.34, 'min_total_reward': 9.900001, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.191343665122986, 'actor_loss': -5.904029321670532, 'hyper_actor_loss': 0.013791588414460421, 'behavior_loss': 0.2620111882686615, 'mean_batch': 8.811054134368897, 'min_batch': 8.320045661926269, 'max_batch': 9.22512731552124}
step: 36210 @ episode report: {'average_total_reward': 11.120001, 'reward_variance': 0.72694004, 'max_total_reward': 12.34, 'min_total_reward': 9.900001, 'average_n_step': 12.0, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.287790203094483, 'actor_loss': -5.86593861579895, 'hyper_actor_loss': 0.014224324468523264, 'behavior_loss': 0.26387911289930344, 'mean_batch': 8.740737915039062, 'min_batch': 8.079324626922608, 'max_batch': 9.078192043304444}
step: 36220 @ episode report: {'average_total_reward': 10.908999, 'reward_variance': 2.8965695, 'max_total_reward': 13.340001, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.230330967903138, 'actor_loss': -5.873359060287475, 'hyper_actor_loss': 0.014102325774729252, 'behavior_loss': 0.2657308652997017, 'mean_batch': 8.750307559967041, 'min_batch': 8.129215383529663, 'max_batch': 9.128345775604249}
step: 36230 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 3.8355222, 'max_total_reward': 13.450001, 'min_total_reward': 7.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.201476156711578, 'actor_loss': -5.920613193511963, 'hyper_actor_loss': 0.014285039901733399, 'behavior_loss': 0.2641449779272079, 'mean_batch': 8.870615577697754, 'min_batch': 8.40332202911377, 'max_batch': 9.296438312530517}
step: 36240 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 0.988221, 'max_total_reward': 13.45, 'min_total_reward': 10.01, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.85194959640503, 'actor_loss': -5.9236002445220945, 'hyper_actor_loss': 0.014043527282774448, 'behavior_loss': 0.2551960363984108, 'mean_batch': 8.889356327056884, 'min_batch': 8.409750175476074, 'max_batch': 9.27648696899414}
step: 36250 @ episode report: {'average_total_reward': 10.830999, 'reward_variance': 1.893989, 'max_total_reward': 13.45, 'min_total_reward': 8.789999, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.5977455377578735, 'actor_loss': -5.861739587783814, 'hyper_actor_loss': 0.014375736936926842, 'behavior_loss': 0.25504026412963865, 'mean_batch': 8.64530544281006, 'min_batch': 8.132333421707154, 'max_batch': 9.037936592102051}
step: 36260 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 2.917965, 'max_total_reward': 12.340001, 'min_total_reward': 7.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.14178433418274, 'actor_loss': -5.8766051769256595, 'hyper_actor_loss': 0.014003418572247028, 'behavior_loss': 0.25590978413820265, 'mean_batch': 8.689504432678223, 'min_batch': 8.20897912979126, 'max_batch': 9.084303092956542}
step: 36270 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.2853856, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.952424943447113, 'actor_loss': -5.921606063842773, 'hyper_actor_loss': 0.01394675364717841, 'behavior_loss': 0.24824305027723312, 'mean_batch': 8.879816150665283, 'min_batch': 8.40305757522583, 'max_batch': 9.223237609863281}
step: 36280 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 8.573384, 'max_total_reward': 12.339999, 'min_total_reward': 2.46, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.562457633018494, 'actor_loss': -5.883817386627197, 'hyper_actor_loss': 0.013848725240677595, 'behavior_loss': 0.26922734677791593, 'mean_batch': 8.721807670593261, 'min_batch': 8.241285800933838, 'max_batch': 9.052933406829833}
step: 36290 @ episode report: {'average_total_reward': 10.975, 'reward_variance': 1.6903852, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.277236199378967, 'actor_loss': -5.864986419677734, 'hyper_actor_loss': 0.013971448503434658, 'behavior_loss': 0.24946572184562682, 'mean_batch': 8.630834484100342, 'min_batch': 8.170200490951538, 'max_batch': 8.954270362854004}
step: 36300 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.9219048, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.3692890167236325, 'actor_loss': -5.891624450683594, 'hyper_actor_loss': 0.014480959344655275, 'behavior_loss': 0.27520965188741686, 'mean_batch': 8.747957038879395, 'min_batch': 8.277464485168457, 'max_batch': 9.137025356292725}
step: 36310 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 2.1500762, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.753378009796142, 'actor_loss': -5.8859950542449955, 'hyper_actor_loss': 0.014287210628390312, 'behavior_loss': 0.25704888850450514, 'mean_batch': 8.710421562194824, 'min_batch': 8.268646478652954, 'max_batch': 9.054104328155518}
step: 36320 @ episode report: {'average_total_reward': 11.6970005, 'reward_variance': 2.5666816, 'max_total_reward': 14.56, 'min_total_reward': 9.79, 'average_n_step': 12.5, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.448973560333252, 'actor_loss': -5.855931138992309, 'hyper_actor_loss': 0.014414335880428553, 'behavior_loss': 0.24870110899209977, 'mean_batch': 8.590105152130127, 'min_batch': 8.136783790588378, 'max_batch': 8.9232647895813}
step: 36330 @ episode report: {'average_total_reward': 10.354, 'reward_variance': 2.8020642, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.890507936477661, 'actor_loss': -5.890675401687622, 'hyper_actor_loss': 0.013858897518366576, 'behavior_loss': 0.2550266444683075, 'mean_batch': 8.704257583618164, 'min_batch': 8.311356353759766, 'max_batch': 9.038878440856934}
step: 36340 @ episode report: {'average_total_reward': 10.908999, 'reward_variance': 5.9781303, 'max_total_reward': 15.56, 'min_total_reward': 6.4599996, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.377397203445435, 'actor_loss': -5.90476427078247, 'hyper_actor_loss': 0.013870088197290898, 'behavior_loss': 0.25524749904870986, 'mean_batch': 8.781274509429931, 'min_batch': 8.354511833190918, 'max_batch': 9.169171237945557}
step: 36350 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 2.785284, 'max_total_reward': 13.34, 'min_total_reward': 8.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.162604713439942, 'actor_loss': -5.867809534072876, 'hyper_actor_loss': 0.01411508172750473, 'behavior_loss': 0.26905603259801864, 'mean_batch': 8.647479343414307, 'min_batch': 8.176354932785035, 'max_batch': 9.007921504974366}
step: 36360 @ episode report: {'average_total_reward': 10.199, 'reward_variance': 1.9245287, 'max_total_reward': 12.34, 'min_total_reward': 7.680001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.597528576850891, 'actor_loss': -5.891017055511474, 'hyper_actor_loss': 0.01356504112482071, 'behavior_loss': 0.24078139513731003, 'mean_batch': 8.707188510894776, 'min_batch': 8.310506248474121, 'max_batch': 9.09652156829834}
step: 36370 @ episode report: {'average_total_reward': 11.020001, 'reward_variance': 1.6246201, 'max_total_reward': 12.339999, 'min_total_reward': 7.7900004, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.389857029914856, 'actor_loss': -5.902799892425537, 'hyper_actor_loss': 0.013894679863005877, 'behavior_loss': 0.24775539636611937, 'mean_batch': 8.812169742584228, 'min_batch': 8.311251974105835, 'max_batch': 9.14015817642212}
step: 36380 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 4.0585847, 'max_total_reward': 13.34, 'min_total_reward': 5.46, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.292745351791382, 'actor_loss': -5.887437057495117, 'hyper_actor_loss': 0.013836900983005763, 'behavior_loss': 0.25997775346040725, 'mean_batch': 8.76677942276001, 'min_batch': 8.227161121368407, 'max_batch': 9.102819347381592}
step: 36390 @ episode report: {'average_total_reward': 11.53, 'reward_variance': 4.6211395, 'max_total_reward': 14.45, 'min_total_reward': 6.79, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.645493268966675, 'actor_loss': -5.884731960296631, 'hyper_actor_loss': 0.013636375591158868, 'behavior_loss': 0.255158007144928, 'mean_batch': 8.69126787185669, 'min_batch': 8.273389434814453, 'max_batch': 9.09313735961914}
step: 36400 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 4.3038793, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.338484215736389, 'actor_loss': -5.860900259017944, 'hyper_actor_loss': 0.013690983783453703, 'behavior_loss': 0.26746069490909574, 'mean_batch': 8.709398365020752, 'min_batch': 8.06756911277771, 'max_batch': 9.119236469268799}
step: 36410 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 2.49114, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.019196653366089, 'actor_loss': -5.887014627456665, 'hyper_actor_loss': 0.014045471139252187, 'behavior_loss': 0.2571325659751892, 'mean_batch': 8.734836673736572, 'min_batch': 8.251123332977295, 'max_batch': 9.142202377319336}
step: 36420 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 5.0997357, 'max_total_reward': 13.339999, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.419992542266845, 'actor_loss': -5.877295589447021, 'hyper_actor_loss': 0.013817453663796187, 'behavior_loss': 0.2628701701760292, 'mean_batch': 8.704378986358643, 'min_batch': 8.200310325622558, 'max_batch': 9.152930450439452}
step: 36430 @ episode report: {'average_total_reward': 11.1310005, 'reward_variance': 2.1308694, 'max_total_reward': 14.450001, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.616483592987061, 'actor_loss': -5.857738590240478, 'hyper_actor_loss': 0.013713812828063965, 'behavior_loss': 0.25934580266475676, 'mean_batch': 8.619104290008545, 'min_batch': 8.120669984817505, 'max_batch': 9.059009265899657}
step: 36440 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 7.4779196, 'max_total_reward': 16.779999, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.922849249839783, 'actor_loss': -5.823820400238037, 'hyper_actor_loss': 0.013709537591785193, 'behavior_loss': 0.25708186328411103, 'mean_batch': 8.523059368133545, 'min_batch': 7.943605422973633, 'max_batch': 8.982732486724853}
step: 36450 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 5.7052298, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.629522037506104, 'actor_loss': -5.82924451828003, 'hyper_actor_loss': 0.013411184959113597, 'behavior_loss': 0.27563521414995196, 'mean_batch': 8.509782886505127, 'min_batch': 7.993689107894897, 'max_batch': 8.9272705078125}
step: 36460 @ episode report: {'average_total_reward': 10.309001, 'reward_variance': 5.7937903, 'max_total_reward': 13.45, 'min_total_reward': 5.7899995, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.586817979812622, 'actor_loss': -5.870897626876831, 'hyper_actor_loss': 0.013495698012411595, 'behavior_loss': 0.2574672639369965, 'mean_batch': 8.624892520904542, 'min_batch': 8.222243785858154, 'max_batch': 9.003499412536621}
step: 36470 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 3.005676, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.781156063079834, 'actor_loss': -5.845637083053589, 'hyper_actor_loss': 0.013638488575816154, 'behavior_loss': 0.2535097777843475, 'mean_batch': 8.526403141021728, 'min_batch': 8.110558557510377, 'max_batch': 8.9650372505188}
step: 36480 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 3.0039086, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.453504276275635, 'actor_loss': -5.848163604736328, 'hyper_actor_loss': 0.013577232975512743, 'behavior_loss': 0.2620191052556038, 'mean_batch': 8.574355602264404, 'min_batch': 8.086337089538574, 'max_batch': 8.947297763824462}
step: 36490 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 6.878764, 'max_total_reward': 14.339999, 'min_total_reward': 4.68, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.299647581577301, 'actor_loss': -5.863002300262451, 'hyper_actor_loss': 0.01349440161138773, 'behavior_loss': 0.25815525352954866, 'mean_batch': 8.596557426452637, 'min_batch': 8.184959888458252, 'max_batch': 8.979831790924072}
step: 36500 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 1.3527092, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.346545219421387, 'actor_loss': -5.859704923629761, 'hyper_actor_loss': 0.013900337927043437, 'behavior_loss': 0.2700979754328728, 'mean_batch': 8.56535987854004, 'min_batch': 8.187645196914673, 'max_batch': 8.936353588104248}
step: 36510 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 1.5352293, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.586961364746093, 'actor_loss': -5.8590288162231445, 'hyper_actor_loss': 0.014020717609673739, 'behavior_loss': 0.2567748114466667, 'mean_batch': 8.598050403594971, 'min_batch': 8.15077247619629, 'max_batch': 9.006325244903564}
step: 36520 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 3.158089, 'max_total_reward': 13.340001, 'min_total_reward': 7.9000006, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.14493248462677, 'actor_loss': -5.845972776412964, 'hyper_actor_loss': 0.01397910611703992, 'behavior_loss': 0.25048701763153075, 'mean_batch': 8.514739990234375, 'min_batch': 8.124722480773926, 'max_batch': 8.817250633239746}
step: 36530 @ episode report: {'average_total_reward': 10.853, 'reward_variance': 5.702423, 'max_total_reward': 14.450001, 'min_total_reward': 6.7899995, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.861682724952698, 'actor_loss': -5.827484893798828, 'hyper_actor_loss': 0.01404487332329154, 'behavior_loss': 0.27053382992744446, 'mean_batch': 8.475556373596191, 'min_batch': 8.01722002029419, 'max_batch': 8.87320318222046}
step: 36540 @ episode report: {'average_total_reward': 9.765, 'reward_variance': 3.2054844, 'max_total_reward': 13.45, 'min_total_reward': 6.9000006, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.316417169570923, 'actor_loss': -5.8342077255249025, 'hyper_actor_loss': 0.013712087832391261, 'behavior_loss': 0.26158978044986725, 'mean_batch': 8.452729320526123, 'min_batch': 8.087281799316406, 'max_batch': 8.807042980194092}
step: 36550 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 1.8165203, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.013071489334107, 'actor_loss': -5.838779592514038, 'hyper_actor_loss': 0.013807692844420672, 'behavior_loss': 0.2571084529161453, 'mean_batch': 8.528587436676025, 'min_batch': 8.052892017364503, 'max_batch': 8.974119567871094}
step: 36560 @ episode report: {'average_total_reward': 10.963999, 'reward_variance': 3.042285, 'max_total_reward': 14.56, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.109247517585755, 'actor_loss': -5.838820552825927, 'hyper_actor_loss': 0.013614979572594166, 'behavior_loss': 0.23697105348110198, 'mean_batch': 8.521600914001464, 'min_batch': 8.060269117355347, 'max_batch': 8.938896465301514}
step: 36570 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 2.3051655, 'max_total_reward': 12.34, 'min_total_reward': 7.5699997, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.995870685577392, 'actor_loss': -5.830263090133667, 'hyper_actor_loss': 0.013625841587781906, 'behavior_loss': 0.25171696543693545, 'mean_batch': 8.537488842010498, 'min_batch': 7.978245496749878, 'max_batch': 8.967144107818603}
step: 36580 @ episode report: {'average_total_reward': 11.73, 'reward_variance': 3.0946198, 'max_total_reward': 15.67, 'min_total_reward': 10.12, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6431115627288815, 'actor_loss': -5.861332416534424, 'hyper_actor_loss': 0.014335278794169426, 'behavior_loss': 0.25663250386714936, 'mean_batch': 8.616039276123047, 'min_batch': 8.153304815292358, 'max_batch': 9.043940544128418}
step: 36590 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 2.7481558, 'max_total_reward': 12.339999, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.501011252403259, 'actor_loss': -5.872027969360351, 'hyper_actor_loss': 0.014574747625738382, 'behavior_loss': 0.2685912400484085, 'mean_batch': 8.675717067718505, 'min_batch': 8.184514331817628, 'max_batch': 9.028283405303956}
step: 36600 @ episode report: {'average_total_reward': 10.543001, 'reward_variance': 2.3200612, 'max_total_reward': 13.12, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.866751575469971, 'actor_loss': -5.838326072692871, 'hyper_actor_loss': 0.014707516599446534, 'behavior_loss': 0.2634110078215599, 'mean_batch': 8.52527141571045, 'min_batch': 8.052198648452759, 'max_batch': 8.904458618164062}
step: 36610 @ episode report: {'average_total_reward': 10.721001, 'reward_variance': 1.9763088, 'max_total_reward': 13.01, 'min_total_reward': 8.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9831783533096314, 'actor_loss': -5.836127758026123, 'hyper_actor_loss': 0.01446485910564661, 'behavior_loss': 0.2672857195138931, 'mean_batch': 8.63928451538086, 'min_batch': 7.940224075317383, 'max_batch': 9.061136150360108}
step: 36620 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 2.713162, 'max_total_reward': 13.450001, 'min_total_reward': 7.899999, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.720379829406738, 'actor_loss': -5.8811540603637695, 'hyper_actor_loss': 0.014501741528511048, 'behavior_loss': 0.240480700135231, 'mean_batch': 8.691912078857422, 'min_batch': 8.243887090682984, 'max_batch': 9.085107898712158}
step: 36630 @ episode report: {'average_total_reward': 11.264001, 'reward_variance': 2.0042052, 'max_total_reward': 13.340001, 'min_total_reward': 7.899999, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.863649892807007, 'actor_loss': -5.826264238357544, 'hyper_actor_loss': 0.014575929008424282, 'behavior_loss': 0.2828677982091904, 'mean_batch': 8.489583396911621, 'min_batch': 7.990010499954224, 'max_batch': 8.920786571502685}
step: 36640 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 3.1429615, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.516716384887696, 'actor_loss': -5.815679550170898, 'hyper_actor_loss': 0.015159297548234463, 'behavior_loss': 0.2729976326227188, 'mean_batch': 8.460660266876221, 'min_batch': 7.933338594436646, 'max_batch': 8.894711208343505}
step: 36650 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 6.7671456, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8044257283210756, 'actor_loss': -5.852725315093994, 'hyper_actor_loss': 0.015237093064934015, 'behavior_loss': 0.24245007783174516, 'mean_batch': 8.61409797668457, 'min_batch': 8.08737473487854, 'max_batch': 9.02756290435791}
step: 36660 @ episode report: {'average_total_reward': 10.698001, 'reward_variance': 0.9781164, 'max_total_reward': 13.450001, 'min_total_reward': 10.119999, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.77517728805542, 'actor_loss': -5.889240169525147, 'hyper_actor_loss': 0.014437713287770748, 'behavior_loss': 0.27364260256290435, 'mean_batch': 8.73813772201538, 'min_batch': 8.266277027130126, 'max_batch': 9.119966411590577}
step: 36670 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 4.68787, 'max_total_reward': 14.559999, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.858893156051636, 'actor_loss': -5.849173307418823, 'hyper_actor_loss': 0.014316727686673403, 'behavior_loss': 0.2508790880441666, 'mean_batch': 8.561910057067871, 'min_batch': 8.10633692741394, 'max_batch': 8.952063274383544}
step: 36680 @ episode report: {'average_total_reward': 11.308001, 'reward_variance': 4.5098963, 'max_total_reward': 14.559999, 'min_total_reward': 7.8999996, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.916863036155701, 'actor_loss': -5.839122629165649, 'hyper_actor_loss': 0.01451027551665902, 'behavior_loss': 0.2607493817806244, 'mean_batch': 8.518922805786133, 'min_batch': 8.065481853485107, 'max_batch': 8.89693078994751}
step: 36690 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 6.232268, 'max_total_reward': 16.779999, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8852777004241945, 'actor_loss': -5.868641757965088, 'hyper_actor_loss': 0.014319236483424902, 'behavior_loss': 0.2570790946483612, 'mean_batch': 8.662378025054931, 'min_batch': 8.172655296325683, 'max_batch': 8.98212022781372}
step: 36700 @ episode report: {'average_total_reward': 10.110001, 'reward_variance': 1.9782006, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.957849359512329, 'actor_loss': -5.878131580352783, 'hyper_actor_loss': 0.014190001599490642, 'behavior_loss': 0.2756441056728363, 'mean_batch': 8.707315635681152, 'min_batch': 8.205972528457641, 'max_batch': 9.091027736663818}
step: 36710 @ episode report: {'average_total_reward': 10.320001, 'reward_variance': 7.432921, 'max_total_reward': 14.56, 'min_total_reward': 3.5700002, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5214296102523805, 'actor_loss': -5.873875522613526, 'hyper_actor_loss': 0.014114414248615504, 'behavior_loss': 0.23928198963403702, 'mean_batch': 8.65734577178955, 'min_batch': 8.215764617919922, 'max_batch': 9.092838573455811}
step: 36720 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 3.6304214, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8184321641922, 'actor_loss': -5.877722454071045, 'hyper_actor_loss': 0.013895199820399284, 'behavior_loss': 0.24498120248317717, 'mean_batch': 8.69683198928833, 'min_batch': 8.211930418014527, 'max_batch': 9.136309814453124}
step: 36730 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 5.0263224, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.786529779434204, 'actor_loss': -5.851922607421875, 'hyper_actor_loss': 0.013776949886232615, 'behavior_loss': 0.25824824571609495, 'mean_batch': 8.610597133636475, 'min_batch': 8.08203058242798, 'max_batch': 9.006526851654053}
step: 36740 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 2.7647839, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6599384307861325, 'actor_loss': -5.81908950805664, 'hyper_actor_loss': 0.013764758221805095, 'behavior_loss': 0.26022188514471056, 'mean_batch': 8.481352519989013, 'min_batch': 7.94406156539917, 'max_batch': 8.796603584289551}
step: 36750 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 2.4184563, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.279522490501404, 'actor_loss': -5.840703964233398, 'hyper_actor_loss': 0.013726905081421137, 'behavior_loss': 0.24780508726835251, 'mean_batch': 8.58168296813965, 'min_batch': 8.023189640045166, 'max_batch': 8.977912330627442}
step: 36760 @ episode report: {'average_total_reward': 11.386, 'reward_variance': 1.6126039, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.773203039169312, 'actor_loss': -5.854465198516846, 'hyper_actor_loss': 0.013604436255991458, 'behavior_loss': 0.2596499741077423, 'mean_batch': 8.5755859375, 'min_batch': 8.136073875427247, 'max_batch': 8.924208736419677}
step: 36770 @ episode report: {'average_total_reward': 10.431, 'reward_variance': 2.8906894, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.77368392944336, 'actor_loss': -5.850990962982178, 'hyper_actor_loss': 0.013567598909139634, 'behavior_loss': 0.25802183598279954, 'mean_batch': 8.557948017120362, 'min_batch': 8.123256015777589, 'max_batch': 8.927633666992188}
step: 36780 @ episode report: {'average_total_reward': 9.410001, 'reward_variance': 10.299421, 'max_total_reward': 14.56, 'min_total_reward': 4.35, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.79547483921051, 'actor_loss': -5.858308362960815, 'hyper_actor_loss': 0.013228401727974414, 'behavior_loss': 0.2605259522795677, 'mean_batch': 8.570838928222656, 'min_batch': 8.17075424194336, 'max_batch': 8.950771617889405}
step: 36790 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 10.050009, 'max_total_reward': 14.56, 'min_total_reward': 5.6800003, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.554966330528259, 'actor_loss': -5.839438533782959, 'hyper_actor_loss': 0.01355825737118721, 'behavior_loss': 0.24721376299858094, 'mean_batch': 8.552147769927979, 'min_batch': 8.039437866210937, 'max_batch': 8.867870330810547}
step: 36800 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 2.4695618, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8003278255462645, 'actor_loss': -5.8358416080474855, 'hyper_actor_loss': 0.013236345257610083, 'behavior_loss': 0.2611886203289032, 'mean_batch': 8.60494260787964, 'min_batch': 7.96442403793335, 'max_batch': 9.018388271331787}
step: 36810 @ episode report: {'average_total_reward': 9.144, 'reward_variance': 6.1839037, 'max_total_reward': 11.23, 'min_total_reward': 2.24, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.231422066688538, 'actor_loss': -5.837474012374878, 'hyper_actor_loss': 0.013225081004202366, 'behavior_loss': 0.2507434099912643, 'mean_batch': 8.526775550842284, 'min_batch': 8.045797300338744, 'max_batch': 8.879933166503907}
step: 36820 @ episode report: {'average_total_reward': 10.542001, 'reward_variance': 5.491997, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.887081265449524, 'actor_loss': -5.837686681747437, 'hyper_actor_loss': 0.013529800530523061, 'behavior_loss': 0.2537028506398201, 'mean_batch': 8.544238758087157, 'min_batch': 8.034217166900635, 'max_batch': 8.929696750640868}
step: 36830 @ episode report: {'average_total_reward': 10.265, 'reward_variance': 4.112805, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.671497917175293, 'actor_loss': -5.839495372772217, 'hyper_actor_loss': 0.01349250292405486, 'behavior_loss': 0.26380825936794283, 'mean_batch': 8.60956563949585, 'min_batch': 7.9887104511260985, 'max_batch': 9.003354358673096}
step: 36840 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.4418639, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.797063183784485, 'actor_loss': -5.829870986938476, 'hyper_actor_loss': 0.013325126003473997, 'behavior_loss': 0.2523672699928284, 'mean_batch': 8.55797004699707, 'min_batch': 7.958058786392212, 'max_batch': 8.934894943237305}
step: 36850 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 5.409082, 'max_total_reward': 13.340001, 'min_total_reward': 5.5700006, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.1009647130966185, 'actor_loss': -5.82567663192749, 'hyper_actor_loss': 0.01320281159132719, 'behavior_loss': 0.26969135254621507, 'mean_batch': 8.504632186889648, 'min_batch': 7.9748437881469725, 'max_batch': 8.864244842529297}
step: 36860 @ episode report: {'average_total_reward': 10.731, 'reward_variance': 3.9730294, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.335346579551697, 'actor_loss': -5.82320499420166, 'hyper_actor_loss': 0.01329208891838789, 'behavior_loss': 0.2642360508441925, 'mean_batch': 8.444880199432372, 'min_batch': 8.006822681427002, 'max_batch': 8.756967735290527}
step: 36870 @ episode report: {'average_total_reward': 10.5199995, 'reward_variance': 1.5037805, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.286358737945557, 'actor_loss': -5.83129391670227, 'hyper_actor_loss': 0.013335200771689416, 'behavior_loss': 0.2656181752681732, 'mean_batch': 8.555368137359618, 'min_batch': 7.972780179977417, 'max_batch': 8.89377670288086}
step: 36880 @ episode report: {'average_total_reward': 11.786, 'reward_variance': 3.755064, 'max_total_reward': 15.45, 'min_total_reward': 9.01, 'average_n_step': 12.6, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.726563715934754, 'actor_loss': -5.8446070671081545, 'hyper_actor_loss': 0.013580930419266224, 'behavior_loss': 0.26297359019517896, 'mean_batch': 8.54205904006958, 'min_batch': 8.086817312240601, 'max_batch': 8.92444829940796}
step: 36890 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 5.2049565, 'max_total_reward': 14.34, 'min_total_reward': 6.9000006, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.351820170879364, 'actor_loss': -5.833600950241089, 'hyper_actor_loss': 0.013711984641849995, 'behavior_loss': 0.2638430088758469, 'mean_batch': 8.51021900177002, 'min_batch': 8.028763008117675, 'max_batch': 8.878218269348144}
step: 36900 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 1.9602044, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.027752554416656, 'actor_loss': -5.840362930297852, 'hyper_actor_loss': 0.013501267973333597, 'behavior_loss': 0.2632544621825218, 'mean_batch': 8.530950260162353, 'min_batch': 8.063721323013306, 'max_batch': 8.848881435394286}
step: 36910 @ episode report: {'average_total_reward': 9.776001, 'reward_variance': 4.641644, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.489657747745514, 'actor_loss': -5.830038070678711, 'hyper_actor_loss': 0.01337808333337307, 'behavior_loss': 0.258243066072464, 'mean_batch': 8.49544448852539, 'min_batch': 8.014033031463622, 'max_batch': 8.827274417877197}
step: 36920 @ episode report: {'average_total_reward': 10.098001, 'reward_variance': 5.9450765, 'max_total_reward': 14.56, 'min_total_reward': 4.6800003, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.16435739994049, 'actor_loss': -5.812660551071167, 'hyper_actor_loss': 0.013228635396808386, 'behavior_loss': 0.253483359515667, 'mean_batch': 8.374942874908447, 'min_batch': 7.9888426780700685, 'max_batch': 8.735709857940673}
step: 36930 @ episode report: {'average_total_reward': 10.431, 'reward_variance': 5.9478292, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.119579911231995, 'actor_loss': -5.772433042526245, 'hyper_actor_loss': 0.013185106124728918, 'behavior_loss': 0.2587526962161064, 'mean_batch': 8.258638000488281, 'min_batch': 7.7834070205688475, 'max_batch': 8.583049392700195}
step: 36940 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 4.2794604, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.15512626171112, 'actor_loss': -5.784644889831543, 'hyper_actor_loss': 0.012927195336669684, 'behavior_loss': 0.26063406467437744, 'mean_batch': 8.237579536437988, 'min_batch': 7.897456216812134, 'max_batch': 8.554905891418457}
step: 36950 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 3.1372652, 'max_total_reward': 13.449999, 'min_total_reward': 7.68, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.386927628517151, 'actor_loss': -5.775499391555786, 'hyper_actor_loss': 0.013006508350372314, 'behavior_loss': 0.26525961309671403, 'mean_batch': 8.245808506011963, 'min_batch': 7.822144317626953, 'max_batch': 8.560538291931152}
step: 36960 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 2.674541, 'max_total_reward': 12.23, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.666576480865478, 'actor_loss': -5.7451635837554935, 'hyper_actor_loss': 0.013005591463297606, 'behavior_loss': 0.2587566465139389, 'mean_batch': 8.142693424224854, 'min_batch': 7.689590883255005, 'max_batch': 8.446860408782959}
step: 36970 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 3.52495, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1614825963974, 'actor_loss': -5.753540277481079, 'hyper_actor_loss': 0.01298451330512762, 'behavior_loss': 0.26476397514343264, 'mean_batch': 8.158906555175781, 'min_batch': 7.7310919761657715, 'max_batch': 8.484335803985596}
step: 36980 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 3.2661762, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6295257329940798, 'actor_loss': -5.772711515426636, 'hyper_actor_loss': 0.01292686564847827, 'behavior_loss': 0.2514117032289505, 'mean_batch': 8.333289909362794, 'min_batch': 7.731785154342651, 'max_batch': 8.675703430175782}
step: 36990 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 0.9912359, 'max_total_reward': 13.45, 'min_total_reward': 10.009999, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.83071768283844, 'actor_loss': -5.773212051391601, 'hyper_actor_loss': 0.012737733032554387, 'behavior_loss': 0.24728489816188812, 'mean_batch': 8.21283025741577, 'min_batch': 7.832807397842407, 'max_batch': 8.555377864837647}
step: 37000 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 8.343726, 'max_total_reward': 14.56, 'min_total_reward': 3.4599998, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5660899639129635, 'actor_loss': -5.736246776580811, 'hyper_actor_loss': 0.01234800722450018, 'behavior_loss': 0.24484479278326035, 'mean_batch': 8.115923118591308, 'min_batch': 7.6441529273986815, 'max_batch': 8.44486436843872}
step: 37010 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 1.3495411, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.376504135131836, 'actor_loss': -5.765524768829346, 'hyper_actor_loss': 0.012329955771565437, 'behavior_loss': 0.2699833497405052, 'mean_batch': 8.178594493865967, 'min_batch': 7.804165077209473, 'max_batch': 8.498146152496338}
step: 37020 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 2.4025967, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.886442470550537, 'actor_loss': -5.74939661026001, 'hyper_actor_loss': 0.012475036177784204, 'behavior_loss': 0.24076241850852967, 'mean_batch': 8.11409101486206, 'min_batch': 7.740133142471313, 'max_batch': 8.418900108337402}
step: 37030 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.2237797, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9334681749343874, 'actor_loss': -5.793758201599121, 'hyper_actor_loss': 0.012305807415395975, 'behavior_loss': 0.26136689484119413, 'mean_batch': 8.298066806793212, 'min_batch': 7.9122642993927, 'max_batch': 8.602984046936035}
step: 37040 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 1.6028364, 'max_total_reward': 12.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.044614791870117, 'actor_loss': -5.774291515350342, 'hyper_actor_loss': 0.012151603773236274, 'behavior_loss': 0.2648495599627495, 'mean_batch': 8.187384796142577, 'min_batch': 7.865012168884277, 'max_batch': 8.52267951965332}
step: 37050 @ episode report: {'average_total_reward': 10.375999, 'reward_variance': 3.864962, 'max_total_reward': 12.34, 'min_total_reward': 6.5700006, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8777209520339966, 'actor_loss': -5.71878752708435, 'hyper_actor_loss': 0.012566219270229339, 'behavior_loss': 0.2674591913819313, 'mean_batch': 8.03993625640869, 'min_batch': 7.582323884963989, 'max_batch': 8.329002094268798}
step: 37060 @ episode report: {'average_total_reward': 11.064, 'reward_variance': 10.770402, 'max_total_reward': 16.779999, 'min_total_reward': 5.79, 'average_n_step': 11.9, 'max_n_step': 17.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.463981437683105, 'actor_loss': -5.763244581222534, 'hyper_actor_loss': 0.012812031526118517, 'behavior_loss': 0.24667830169200897, 'mean_batch': 8.174834251403809, 'min_batch': 7.790798330307007, 'max_batch': 8.48038911819458}
step: 37070 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 2.938105, 'max_total_reward': 13.340001, 'min_total_reward': 7.6800003, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.755918002128601, 'actor_loss': -5.74675874710083, 'hyper_actor_loss': 0.012593501154333353, 'behavior_loss': 0.271972618997097, 'mean_batch': 8.097702693939208, 'min_batch': 7.735143995285034, 'max_batch': 8.407526302337647}
step: 37080 @ episode report: {'average_total_reward': 10.6310005, 'reward_variance': 2.011449, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.793673181533814, 'actor_loss': -5.721400785446167, 'hyper_actor_loss': 0.012821363098919392, 'behavior_loss': 0.2640694439411163, 'mean_batch': 7.990916919708252, 'min_batch': 7.642437553405761, 'max_batch': 8.286081981658935}
step: 37090 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.6259453, 'max_total_reward': 14.450001, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.130366730690002, 'actor_loss': -5.738936424255371, 'hyper_actor_loss': 0.013131995871663093, 'behavior_loss': 0.2587618425488472, 'mean_batch': 8.070372486114502, 'min_batch': 7.701180458068848, 'max_batch': 8.38331356048584}
step: 37100 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 2.740596, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.20158326625824, 'actor_loss': -5.755465316772461, 'hyper_actor_loss': 0.012883483711630107, 'behavior_loss': 0.2486553281545639, 'mean_batch': 8.143296432495116, 'min_batch': 7.759246206283569, 'max_batch': 8.494080829620362}
step: 37110 @ episode report: {'average_total_reward': 10.964, 'reward_variance': 1.8590244, 'max_total_reward': 13.45, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.346027159690857, 'actor_loss': -5.752714061737061, 'hyper_actor_loss': 0.012924553453922271, 'behavior_loss': 0.26881599575281145, 'mean_batch': 8.206682586669922, 'min_batch': 7.684084272384643, 'max_batch': 8.57400884628296}
step: 37120 @ episode report: {'average_total_reward': 10.209002, 'reward_variance': 4.655589, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8605692267417906, 'actor_loss': -5.780533742904663, 'hyper_actor_loss': 0.012839686777442693, 'behavior_loss': 0.25255183428525924, 'mean_batch': 8.263211441040038, 'min_batch': 7.841328048706055, 'max_batch': 8.653940105438233}
step: 37130 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 3.000703, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.630108487606049, 'actor_loss': -5.774763727188111, 'hyper_actor_loss': 0.012981515284627676, 'behavior_loss': 0.26556452810764314, 'mean_batch': 8.262413883209229, 'min_batch': 7.800428867340088, 'max_batch': 8.594091320037842}
step: 37140 @ episode report: {'average_total_reward': 10.653, 'reward_variance': 3.3646812, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.936833214759827, 'actor_loss': -5.760221338272094, 'hyper_actor_loss': 0.012677988689392804, 'behavior_loss': 0.2506117567420006, 'mean_batch': 8.192911338806152, 'min_batch': 7.749766731262207, 'max_batch': 8.519541358947754}
step: 37150 @ episode report: {'average_total_reward': 8.966001, 'reward_variance': 5.809204, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.994798541069031, 'actor_loss': -5.740022850036621, 'hyper_actor_loss': 0.012780889682471753, 'behavior_loss': 0.26805879175662994, 'mean_batch': 8.155767917633057, 'min_batch': 7.631658840179443, 'max_batch': 8.465985202789307}
step: 37160 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 1.7132813, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.312663936614991, 'actor_loss': -5.743472957611084, 'hyper_actor_loss': 0.012694327719509601, 'behavior_loss': 0.25091792792081835, 'mean_batch': 8.179459476470948, 'min_batch': 7.6401602268219, 'max_batch': 8.559736824035644}
step: 37170 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 4.6362762, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.181697702407837, 'actor_loss': -5.755068445205689, 'hyper_actor_loss': 0.012606394104659557, 'behavior_loss': 0.26441609412431716, 'mean_batch': 8.142633628845214, 'min_batch': 7.756759262084961, 'max_batch': 8.494112491607666}
step: 37180 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 1.7590443, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.141066932678223, 'actor_loss': -5.748671770095825, 'hyper_actor_loss': 0.012957287672907113, 'behavior_loss': 0.27154252082109454, 'mean_batch': 8.201996326446533, 'min_batch': 7.6564208507537845, 'max_batch': 8.528709220886231}
step: 37190 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 4.887621, 'max_total_reward': 12.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.19155375957489, 'actor_loss': -5.747011375427246, 'hyper_actor_loss': 0.012793438602238893, 'behavior_loss': 0.25157700181007386, 'mean_batch': 8.095329093933106, 'min_batch': 7.7394593238830565, 'max_batch': 8.466201114654542}
step: 37200 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.2702, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.891372740268707, 'actor_loss': -5.748267698287964, 'hyper_actor_loss': 0.013096548616886139, 'behavior_loss': 0.2364721730351448, 'mean_batch': 8.138013362884521, 'min_batch': 7.708657884597779, 'max_batch': 8.535996055603027}
step: 37210 @ episode report: {'average_total_reward': 9.776001, 'reward_variance': 1.4137642, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.112277984619141, 'actor_loss': -5.745392370223999, 'hyper_actor_loss': 0.0130005007609725, 'behavior_loss': 0.26890856474637986, 'mean_batch': 8.139227962493896, 'min_batch': 7.688482570648193, 'max_batch': 8.481175518035888}
step: 37220 @ episode report: {'average_total_reward': 11.275001, 'reward_variance': 1.1653849, 'max_total_reward': 13.45, 'min_total_reward': 10.01, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3104228496551515, 'actor_loss': -5.741572570800781, 'hyper_actor_loss': 0.01299385903403163, 'behavior_loss': 0.27273700684309005, 'mean_batch': 8.097983837127686, 'min_batch': 7.695208883285522, 'max_batch': 8.438888549804688}
step: 37230 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 2.8818812, 'max_total_reward': 14.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.236728417873382, 'actor_loss': -5.757307434082032, 'hyper_actor_loss': 0.012997201830148696, 'behavior_loss': 0.2661574691534042, 'mean_batch': 8.16866159439087, 'min_batch': 7.749268102645874, 'max_batch': 8.5389084815979}
step: 37240 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 5.5017214, 'max_total_reward': 15.67, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.140862035751343, 'actor_loss': -5.754079055786133, 'hyper_actor_loss': 0.01296546943485737, 'behavior_loss': 0.2547864764928818, 'mean_batch': 8.164698696136474, 'min_batch': 7.728244066238403, 'max_batch': 8.470891857147217}
step: 37250 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.746324, 'max_total_reward': 12.339999, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.919434928894043, 'actor_loss': -5.740343904495239, 'hyper_actor_loss': 0.012890733126550914, 'behavior_loss': 0.2557971358299255, 'mean_batch': 8.118994045257569, 'min_batch': 7.667670106887817, 'max_batch': 8.45550603866577}
step: 37260 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 1.6683851, 'max_total_reward': 12.23, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7277975559234617, 'actor_loss': -5.769267654418945, 'hyper_actor_loss': 0.012749696895480157, 'behavior_loss': 0.26423233300447463, 'mean_batch': 8.224918174743653, 'min_batch': 7.789593172073364, 'max_batch': 8.62122402191162}
step: 37270 @ episode report: {'average_total_reward': 11.02, 'reward_variance': 3.7765992, 'max_total_reward': 14.339999, 'min_total_reward': 7.4599996, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.992746448516845, 'actor_loss': -5.728268575668335, 'hyper_actor_loss': 0.01278451019898057, 'behavior_loss': 0.2515167221426964, 'mean_batch': 8.080343580245971, 'min_batch': 7.618215847015381, 'max_batch': 8.433012771606446}
step: 37280 @ episode report: {'average_total_reward': 10.320001, 'reward_variance': 2.13136, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.781452751159668, 'actor_loss': -5.7406346797943115, 'hyper_actor_loss': 0.012878688611090183, 'behavior_loss': 0.25329053699970244, 'mean_batch': 8.07303261756897, 'min_batch': 7.7116302967071535, 'max_batch': 8.39103832244873}
step: 37290 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 1.3089355, 'max_total_reward': 11.23, 'min_total_reward': 7.6800003, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.132983946800232, 'actor_loss': -5.775936889648437, 'hyper_actor_loss': 0.012968391366302966, 'behavior_loss': 0.2589361771941185, 'mean_batch': 8.2174222946167, 'min_batch': 7.848130989074707, 'max_batch': 8.550201034545898}
step: 37300 @ episode report: {'average_total_reward': 10.964001, 'reward_variance': 2.693544, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.456901597976684, 'actor_loss': -5.71713171005249, 'hyper_actor_loss': 0.013068800512701272, 'behavior_loss': 0.2526523157954216, 'mean_batch': 8.0536208152771, 'min_batch': 7.5554115772247314, 'max_batch': 8.397324466705323}
step: 37310 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 3.7011364, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.088480377197266, 'actor_loss': -5.72747392654419, 'hyper_actor_loss': 0.012934425845742226, 'behavior_loss': 0.26929864585399627, 'mean_batch': 8.021561193466187, 'min_batch': 7.6599023818969725, 'max_batch': 8.324300765991211}
step: 37320 @ episode report: {'average_total_reward': 10.653, 'reward_variance': 7.285201, 'max_total_reward': 15.559999, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.112133002281189, 'actor_loss': -5.746329021453858, 'hyper_actor_loss': 0.013384635839611293, 'behavior_loss': 0.27275736927986144, 'mean_batch': 8.116447448730469, 'min_batch': 7.716495227813721, 'max_batch': 8.434715175628662}
step: 37330 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 1.1502488, 'max_total_reward': 12.23, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.162745487689972, 'actor_loss': -5.7346968173980715, 'hyper_actor_loss': 0.013584124483168125, 'behavior_loss': 0.2606055349111557, 'mean_batch': 8.037340450286866, 'min_batch': 7.700152015686035, 'max_batch': 8.354088592529298}
step: 37340 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 4.390189, 'max_total_reward': 14.45, 'min_total_reward': 5.6800003, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.177457046508789, 'actor_loss': -5.718194437026978, 'hyper_actor_loss': 0.013533372338861227, 'behavior_loss': 0.25029481053352354, 'mean_batch': 8.008766603469848, 'min_batch': 7.601686286926269, 'max_batch': 8.382428455352784}
step: 37350 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 3.9664848, 'max_total_reward': 12.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4978800296783445, 'actor_loss': -5.74073486328125, 'hyper_actor_loss': 0.012945562321692704, 'behavior_loss': 0.2757094442844391, 'mean_batch': 8.107383155822754, 'min_batch': 7.6795806884765625, 'max_batch': 8.46076021194458}
step: 37360 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 1.1960211, 'max_total_reward': 11.230001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.984260892868042, 'actor_loss': -5.716136693954468, 'hyper_actor_loss': 0.012824635393917561, 'behavior_loss': 0.2623010978102684, 'mean_batch': 8.03662281036377, 'min_batch': 7.56112232208252, 'max_batch': 8.384663295745849}
step: 37370 @ episode report: {'average_total_reward': 10.442, 'reward_variance': 5.075876, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.503416419029236, 'actor_loss': -5.739546442031861, 'hyper_actor_loss': 0.012749423272907734, 'behavior_loss': 0.2705876722931862, 'mean_batch': 8.080720996856689, 'min_batch': 7.695734739303589, 'max_batch': 8.422496032714843}
step: 37380 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 4.277329, 'max_total_reward': 14.34, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.88059720993042, 'actor_loss': -5.726426982879639, 'hyper_actor_loss': 0.012739033624529838, 'behavior_loss': 0.25539143234491346, 'mean_batch': 8.049102878570556, 'min_batch': 7.628828620910644, 'max_batch': 8.449559879302978}
step: 37390 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 5.0992856, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.297913861274719, 'actor_loss': -5.7013801574707035, 'hyper_actor_loss': 0.012828490883111953, 'behavior_loss': 0.2616639405488968, 'mean_batch': 7.978924512863159, 'min_batch': 7.50771803855896, 'max_batch': 8.377114582061768}
step: 37400 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 2.0894606, 'max_total_reward': 12.230001, 'min_total_reward': 7.68, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6459341049194336, 'actor_loss': -5.7021355628967285, 'hyper_actor_loss': 0.012638153228908777, 'behavior_loss': 0.2603227883577347, 'mean_batch': 7.997745943069458, 'min_batch': 7.495975399017334, 'max_batch': 8.464963722229005}
step: 37410 @ episode report: {'average_total_reward': 9.543001, 'reward_variance': 6.2973013, 'max_total_reward': 12.230001, 'min_total_reward': 3.35, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.649021816253662, 'actor_loss': -5.7270091533660885, 'hyper_actor_loss': 0.012498296331614256, 'behavior_loss': 0.24695250988006592, 'mean_batch': 8.156701469421387, 'min_batch': 7.538429689407349, 'max_batch': 8.491637897491454}
step: 37420 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 1.0642642, 'max_total_reward': 11.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.338217830657959, 'actor_loss': -5.704038524627686, 'hyper_actor_loss': 0.012466130126267672, 'behavior_loss': 0.2582948327064514, 'mean_batch': 8.098464679718017, 'min_batch': 7.43642225265503, 'max_batch': 8.47878360748291}
step: 37430 @ episode report: {'average_total_reward': 10.465001, 'reward_variance': 3.4585843, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.592132520675659, 'actor_loss': -5.730957651138306, 'hyper_actor_loss': 0.012225394882261754, 'behavior_loss': 0.25151128619909285, 'mean_batch': 8.042771053314208, 'min_batch': 7.665968799591065, 'max_batch': 8.385353469848633}
step: 37440 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 4.8034697, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.383444356918335, 'actor_loss': -5.717104911804199, 'hyper_actor_loss': 0.012252824939787388, 'behavior_loss': 0.2571555182337761, 'mean_batch': 8.044821453094482, 'min_batch': 7.563410043716431, 'max_batch': 8.37237195968628}
step: 37450 @ episode report: {'average_total_reward': 9.932, 'reward_variance': 3.7974753, 'max_total_reward': 13.450001, 'min_total_reward': 6.680001, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.864433979988098, 'actor_loss': -5.719572687149048, 'hyper_actor_loss': 0.012644234206527471, 'behavior_loss': 0.25545230358839033, 'mean_batch': 8.082464122772217, 'min_batch': 7.544648218154907, 'max_batch': 8.414079952239991}
step: 37460 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 1.6694006, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.769697332382202, 'actor_loss': -5.716608381271362, 'hyper_actor_loss': 0.012538001872599125, 'behavior_loss': 0.2660987973213196, 'mean_batch': 8.02402858734131, 'min_batch': 7.57584319114685, 'max_batch': 8.390425682067871}
step: 37470 @ episode report: {'average_total_reward': 11.541, 'reward_variance': 2.0246894, 'max_total_reward': 14.56, 'min_total_reward': 10.009999, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.426643526554107, 'actor_loss': -5.737372159957886, 'hyper_actor_loss': 0.012612264975905419, 'behavior_loss': 0.2635489717125893, 'mean_batch': 8.135980892181397, 'min_batch': 7.631709957122803, 'max_batch': 8.532391452789307}
step: 37480 @ episode report: {'average_total_reward': 10.6640005, 'reward_variance': 1.4801643, 'max_total_reward': 13.34, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.174348163604736, 'actor_loss': -5.690070247650146, 'hyper_actor_loss': 0.012553547881543637, 'behavior_loss': 0.2482660010457039, 'mean_batch': 7.929623699188232, 'min_batch': 7.470471000671386, 'max_batch': 8.280412864685058}
step: 37490 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 6.092796, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.017911970615387, 'actor_loss': -5.664289236068726, 'hyper_actor_loss': 0.012284697405993939, 'behavior_loss': 0.24663898050785066, 'mean_batch': 7.905132627487182, 'min_batch': 7.312334966659546, 'max_batch': 8.234474372863769}
step: 37500 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 3.6047013, 'max_total_reward': 13.450001, 'min_total_reward': 6.3499994, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.459243249893189, 'actor_loss': -5.6662393569946286, 'hyper_actor_loss': 0.011828931421041489, 'behavior_loss': 0.27583651393651965, 'mean_batch': 7.906452655792236, 'min_batch': 7.316714096069336, 'max_batch': 8.278262042999268}
step: 37510 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 6.520499, 'max_total_reward': 15.67, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.763520503044129, 'actor_loss': -5.730039739608765, 'hyper_actor_loss': 0.011791101936250926, 'behavior_loss': 0.25427242666482924, 'mean_batch': 8.058987808227538, 'min_batch': 7.644325304031372, 'max_batch': 8.393633079528808}
step: 37520 @ episode report: {'average_total_reward': 10.532001, 'reward_variance': 6.692956, 'max_total_reward': 15.45, 'min_total_reward': 7.5699997, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5030347347259525, 'actor_loss': -5.708521699905395, 'hyper_actor_loss': 0.012167111411690712, 'behavior_loss': 0.26899781078100204, 'mean_batch': 7.975711488723755, 'min_batch': 7.559354972839356, 'max_batch': 8.423519802093505}
step: 37530 @ episode report: {'average_total_reward': 8.811, 'reward_variance': 10.203969, 'max_total_reward': 13.339999, 'min_total_reward': 2.1299999, 'average_n_step': 9.9, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6292458295822145, 'actor_loss': -5.691623640060425, 'hyper_actor_loss': 0.011957539152354002, 'behavior_loss': 0.27196737974882124, 'mean_batch': 7.972865867614746, 'min_batch': 7.441915893554688, 'max_batch': 8.295870399475097}
step: 37540 @ episode report: {'average_total_reward': 10.321001, 'reward_variance': 0.97058904, 'max_total_reward': 11.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7473037004470826, 'actor_loss': -5.72939920425415, 'hyper_actor_loss': 0.011753447260707617, 'behavior_loss': 0.26392098516225815, 'mean_batch': 8.032126808166504, 'min_batch': 7.664086246490479, 'max_batch': 8.442264080047607}
step: 37550 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 3.9790058, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.437538456916809, 'actor_loss': -5.702599000930786, 'hyper_actor_loss': 0.012114094849675894, 'behavior_loss': 0.25430112779140474, 'mean_batch': 7.985147428512573, 'min_batch': 7.515557813644409, 'max_batch': 8.346362495422364}
step: 37560 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 4.246502, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6787326335906982, 'actor_loss': -5.700982141494751, 'hyper_actor_loss': 0.011714453250169754, 'behavior_loss': 0.26883876919746397, 'mean_batch': 7.977158069610596, 'min_batch': 7.510019969940186, 'max_batch': 8.283272457122802}
step: 37570 @ episode report: {'average_total_reward': 8.755, 'reward_variance': 3.698066, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.0284394979476925, 'actor_loss': -5.680145025253296, 'hyper_actor_loss': 0.012009654939174653, 'behavior_loss': 0.2812801167368889, 'mean_batch': 8.078695011138915, 'min_batch': 7.263387203216553, 'max_batch': 8.433202934265136}
step: 37580 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 4.2328043, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.693787217140198, 'actor_loss': -5.712712049484253, 'hyper_actor_loss': 0.011753022577613592, 'behavior_loss': 0.2702219903469086, 'mean_batch': 7.996284770965576, 'min_batch': 7.5713237762451175, 'max_batch': 8.370224475860596}
step: 37590 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 2.1938806, 'max_total_reward': 12.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.342965102195739, 'actor_loss': -5.7047912120819095, 'hyper_actor_loss': 0.011846798937767744, 'behavior_loss': 0.2628380715847015, 'mean_batch': 8.012858343124389, 'min_batch': 7.507657718658447, 'max_batch': 8.345107746124267}
step: 37600 @ episode report: {'average_total_reward': 10.765001, 'reward_variance': 1.6413851, 'max_total_reward': 12.23, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3560585021972655, 'actor_loss': -5.693107318878174, 'hyper_actor_loss': 0.01158148916438222, 'behavior_loss': 0.2527155354619026, 'mean_batch': 8.033218812942504, 'min_batch': 7.400206232070923, 'max_batch': 8.422447109222412}
step: 37610 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 4.431805, 'max_total_reward': 13.12, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1412485361099245, 'actor_loss': -5.737867116928101, 'hyper_actor_loss': 0.01132701812312007, 'behavior_loss': 0.2593380197882652, 'mean_batch': 8.056819534301757, 'min_batch': 7.705779981613159, 'max_batch': 8.462987327575684}
step: 37620 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 3.0403004, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.935519242286682, 'actor_loss': -5.708993864059448, 'hyper_actor_loss': 0.011419155914336444, 'behavior_loss': 0.24708029329776765, 'mean_batch': 7.966987085342407, 'min_batch': 7.572614574432373, 'max_batch': 8.35842456817627}
step: 37630 @ episode report: {'average_total_reward': 10.875001, 'reward_variance': 5.818426, 'max_total_reward': 14.560001, 'min_total_reward': 5.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.160104286670685, 'actor_loss': -5.672660827636719, 'hyper_actor_loss': 0.011422313190996647, 'behavior_loss': 0.26935783326625823, 'mean_batch': 7.8694051742553714, 'min_batch': 7.396083164215088, 'max_batch': 8.211828136444092}
step: 37640 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 1.44452, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.300424242019654, 'actor_loss': -5.718150520324707, 'hyper_actor_loss': 0.011646341998130083, 'behavior_loss': 0.26581378281116486, 'mean_batch': 8.0105486869812, 'min_batch': 7.601058626174927, 'max_batch': 8.346861553192138}
step: 37650 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 3.1240287, 'max_total_reward': 14.45, 'min_total_reward': 8.79, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.476400923728943, 'actor_loss': -5.690532112121582, 'hyper_actor_loss': 0.01194510068744421, 'behavior_loss': 0.28100458830595015, 'mean_batch': 8.028460597991943, 'min_batch': 7.391504001617432, 'max_batch': 8.359851169586182}
step: 37660 @ episode report: {'average_total_reward': 10.664999, 'reward_variance': 2.0289044, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.03060564994812, 'actor_loss': -5.690823364257812, 'hyper_actor_loss': 0.012225135788321495, 'behavior_loss': 0.25641795843839643, 'mean_batch': 7.929709100723267, 'min_batch': 7.47019362449646, 'max_batch': 8.244212913513184}
step: 37670 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 2.874001, 'max_total_reward': 12.339999, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.490075731277466, 'actor_loss': -5.708119058609009, 'hyper_actor_loss': 0.01200530044734478, 'behavior_loss': 0.27128338515758516, 'mean_batch': 7.9712584018707275, 'min_batch': 7.561045169830322, 'max_batch': 8.325403690338135}
step: 37680 @ episode report: {'average_total_reward': 9.444, 'reward_variance': 2.5826838, 'max_total_reward': 12.12, 'min_total_reward': 6.6800003, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.757585763931274, 'actor_loss': -5.7102821350097654, 'hyper_actor_loss': 0.011808591336011887, 'behavior_loss': 0.2668078526854515, 'mean_batch': 8.036724996566772, 'min_batch': 7.521015214920044, 'max_batch': 8.370173072814941}
step: 37690 @ episode report: {'average_total_reward': 10.354, 'reward_variance': 2.948383, 'max_total_reward': 13.45, 'min_total_reward': 7.9000006, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.847561717033386, 'actor_loss': -5.678595876693725, 'hyper_actor_loss': 0.011927238199859858, 'behavior_loss': 0.2566265493631363, 'mean_batch': 7.917860507965088, 'min_batch': 7.393868398666382, 'max_batch': 8.257012271881104}
step: 37700 @ episode report: {'average_total_reward': 11.231, 'reward_variance': 2.6824493, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.532116627693176, 'actor_loss': -5.697378158569336, 'hyper_actor_loss': 0.011890609096735717, 'behavior_loss': 0.26420393735170367, 'mean_batch': 7.934426307678223, 'min_batch': 7.516182088851929, 'max_batch': 8.302261924743652}
step: 37710 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 1.2376162, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4315267324447634, 'actor_loss': -5.72899374961853, 'hyper_actor_loss': 0.011866539623588324, 'behavior_loss': 0.2512419506907463, 'mean_batch': 8.06699161529541, 'min_batch': 7.637740898132324, 'max_batch': 8.403791236877442}
step: 37720 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.00167, 'max_total_reward': 13.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5034056305885315, 'actor_loss': -5.7607416152954105, 'hyper_actor_loss': 0.011465428117662668, 'behavior_loss': 0.2677598237991333, 'mean_batch': 8.156414127349853, 'min_batch': 7.787580776214599, 'max_batch': 8.530343055725098}
step: 37730 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 3.3451648, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.185740542411804, 'actor_loss': -5.70367660522461, 'hyper_actor_loss': 0.01190970977768302, 'behavior_loss': 0.27727479487657547, 'mean_batch': 8.05371036529541, 'min_batch': 7.457709503173828, 'max_batch': 8.43232307434082}
step: 37740 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 2.6822486, 'max_total_reward': 13.23, 'min_total_reward': 6.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.327750182151794, 'actor_loss': -5.715320110321045, 'hyper_actor_loss': 0.011901242472231389, 'behavior_loss': 0.27135197818279266, 'mean_batch': 8.017952013015748, 'min_batch': 7.574086236953735, 'max_batch': 8.402799510955811}
step: 37750 @ episode report: {'average_total_reward': 9.797999, 'reward_variance': 7.0520754, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.142577290534973, 'actor_loss': -5.7315832614898685, 'hyper_actor_loss': 0.011784692108631135, 'behavior_loss': 0.2642114371061325, 'mean_batch': 8.05817813873291, 'min_batch': 7.657800769805908, 'max_batch': 8.363277816772461}
step: 37760 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 5.1567006, 'max_total_reward': 13.449999, 'min_total_reward': 5.7900004, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.727176833152771, 'actor_loss': -5.7210855960845945, 'hyper_actor_loss': 0.012234429363161325, 'behavior_loss': 0.2579739257693291, 'mean_batch': 8.091147232055665, 'min_batch': 7.553137111663818, 'max_batch': 8.368250274658203}
step: 37770 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 5.6604967, 'max_total_reward': 14.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.953661489486694, 'actor_loss': -5.731910943984985, 'hyper_actor_loss': 0.012062680907547474, 'behavior_loss': 0.24953879415988922, 'mean_batch': 8.048784446716308, 'min_batch': 7.669644784927368, 'max_batch': 8.34230146408081}
step: 37780 @ episode report: {'average_total_reward': 11.1640005, 'reward_variance': 4.8626847, 'max_total_reward': 15.45, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.92438440322876, 'actor_loss': -5.66890664100647, 'hyper_actor_loss': 0.011967033613473177, 'behavior_loss': 0.25728033035993575, 'mean_batch': 7.859412717819214, 'min_batch': 7.377832889556885, 'max_batch': 8.149924182891846}
step: 37790 @ episode report: {'average_total_reward': 9.022, 'reward_variance': 8.587297, 'max_total_reward': 11.9, 'min_total_reward': 1.24, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.228607439994812, 'actor_loss': -5.70356330871582, 'hyper_actor_loss': 0.012304444052278995, 'behavior_loss': 0.26514101028442383, 'mean_batch': 7.993748807907105, 'min_batch': 7.509419965744018, 'max_batch': 8.357894611358642}
step: 37800 @ episode report: {'average_total_reward': 10.875, 'reward_variance': 1.2072852, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6888877868652346, 'actor_loss': -5.756203460693359, 'hyper_actor_loss': 0.012193928472697735, 'behavior_loss': 0.24867810159921647, 'mean_batch': 8.170215320587157, 'min_batch': 7.73954496383667, 'max_batch': 8.555685806274415}
step: 37810 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 5.0784154, 'max_total_reward': 14.559999, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.691967415809631, 'actor_loss': -5.743048667907715, 'hyper_actor_loss': 0.012168876826763153, 'behavior_loss': 0.2510648131370544, 'mean_batch': 8.154585456848144, 'min_batch': 7.658257055282593, 'max_batch': 8.475447845458984}
step: 37820 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 2.7785766, 'max_total_reward': 13.23, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.658316826820373, 'actor_loss': -5.722442865371704, 'hyper_actor_loss': 0.01169585008174181, 'behavior_loss': 0.26131938844919206, 'mean_batch': 8.001359939575195, 'min_batch': 7.641727685928345, 'max_batch': 8.316447734832764}
step: 37830 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 5.0808363, 'max_total_reward': 14.559999, 'min_total_reward': 6.6800003, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4962326169013975, 'actor_loss': -5.694877004623413, 'hyper_actor_loss': 0.011768985167145729, 'behavior_loss': 0.2554846003651619, 'mean_batch': 7.908371162414551, 'min_batch': 7.520183801651001, 'max_batch': 8.232394218444824}
step: 37840 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 6.1390295, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.013886952400208, 'actor_loss': -5.7025713443756105, 'hyper_actor_loss': 0.012074492406100035, 'behavior_loss': 0.2667605459690094, 'mean_batch': 8.01882095336914, 'min_batch': 7.486544942855835, 'max_batch': 8.365347480773925}
step: 37850 @ episode report: {'average_total_reward': 10.331, 'reward_variance': 5.426769, 'max_total_reward': 15.67, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.67109215259552, 'actor_loss': -5.70971565246582, 'hyper_actor_loss': 0.012005269806832076, 'behavior_loss': 0.27433020174503325, 'mean_batch': 7.989437913894653, 'min_batch': 7.556943035125732, 'max_batch': 8.313069248199463}
step: 37860 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 2.3578355, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.95311758518219, 'actor_loss': -5.726124048233032, 'hyper_actor_loss': 0.012185330968350172, 'behavior_loss': 0.2624179020524025, 'mean_batch': 8.041154956817627, 'min_batch': 7.630493402481079, 'max_batch': 8.417520809173585}
step: 37870 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 5.7049613, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7469476699829105, 'actor_loss': -5.717669534683227, 'hyper_actor_loss': 0.011777814012020826, 'behavior_loss': 0.2832381188869476, 'mean_batch': 8.057534885406493, 'min_batch': 7.556720447540283, 'max_batch': 8.38796272277832}
step: 37880 @ episode report: {'average_total_reward': 10.776001, 'reward_variance': 2.1092238, 'max_total_reward': 13.34, 'min_total_reward': 8.68, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.111740016937256, 'actor_loss': -5.730800151824951, 'hyper_actor_loss': 0.011895484384149313, 'behavior_loss': 0.2543757528066635, 'mean_batch': 8.050220346450805, 'min_batch': 7.6576659202575685, 'max_batch': 8.427762222290038}
step: 37890 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 2.8395164, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.941775214672089, 'actor_loss': -5.694341135025025, 'hyper_actor_loss': 0.011800286173820496, 'behavior_loss': 0.25645833313465116, 'mean_batch': 7.967692041397095, 'min_batch': 7.466641283035278, 'max_batch': 8.327736568450927}
step: 37900 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 0.6963491, 'max_total_reward': 11.2300005, 'min_total_reward': 8.570001, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6880899310112, 'actor_loss': -5.719471836090088, 'hyper_actor_loss': 0.011340981163084508, 'behavior_loss': 0.25291264355182647, 'mean_batch': 7.991044235229492, 'min_batch': 7.627318668365478, 'max_batch': 8.360878849029541}
step: 37910 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 1.0302095, 'max_total_reward': 11.2300005, 'min_total_reward': 7.7899995, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.913525605201721, 'actor_loss': -5.720383644104004, 'hyper_actor_loss': 0.011130508314818145, 'behavior_loss': 0.23717134743928908, 'mean_batch': 8.005558824539184, 'min_batch': 7.620845651626587, 'max_batch': 8.397543716430665}
step: 37920 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 5.9688096, 'max_total_reward': 14.450001, 'min_total_reward': 5.68, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.891638684272766, 'actor_loss': -5.713268661499024, 'hyper_actor_loss': 0.011304677929729223, 'behavior_loss': 0.26457124650478364, 'mean_batch': 7.963449954986572, 'min_batch': 7.606781959533691, 'max_batch': 8.326150894165039}
step: 37930 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 3.6836295, 'max_total_reward': 14.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9558890104293822, 'actor_loss': -5.700829124450683, 'hyper_actor_loss': 0.011422579828649759, 'behavior_loss': 0.2665438875555992, 'mean_batch': 7.977586889266968, 'min_batch': 7.502417755126953, 'max_batch': 8.37778434753418}
step: 37940 @ episode report: {'average_total_reward': 10.875001, 'reward_variance': 4.1179056, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7137348890304565, 'actor_loss': -5.725830459594727, 'hyper_actor_loss': 0.011512511130422353, 'behavior_loss': 0.24078359752893447, 'mean_batch': 8.095744037628174, 'min_batch': 7.58244481086731, 'max_batch': 8.455882263183593}
step: 37950 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 2.643556, 'max_total_reward': 12.34, 'min_total_reward': 7.57, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.567040050029755, 'actor_loss': -5.750211572647094, 'hyper_actor_loss': 0.011699206661432981, 'behavior_loss': 0.25067647397518156, 'mean_batch': 8.157204914093018, 'min_batch': 7.705730199813843, 'max_batch': 8.509676074981689}
step: 37960 @ episode report: {'average_total_reward': 10.554001, 'reward_variance': 1.7679443, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9585976600646973, 'actor_loss': -5.7318830490112305, 'hyper_actor_loss': 0.011750935204327106, 'behavior_loss': 0.24453259110450745, 'mean_batch': 8.070525550842286, 'min_batch': 7.647532987594604, 'max_batch': 8.42270736694336}
step: 37970 @ episode report: {'average_total_reward': 11.0529995, 'reward_variance': 6.3399615, 'max_total_reward': 15.56, 'min_total_reward': 5.79, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.660362505912781, 'actor_loss': -5.745689487457275, 'hyper_actor_loss': 0.011716198362410068, 'behavior_loss': 0.27323317229747773, 'mean_batch': 8.100540351867675, 'min_batch': 7.724294567108155, 'max_batch': 8.493644332885742}
step: 37980 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 3.333669, 'max_total_reward': 13.45, 'min_total_reward': 9.009999, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.728758478164673, 'actor_loss': -5.745426797866822, 'hyper_actor_loss': 0.012078969366848468, 'behavior_loss': 0.262461519241333, 'mean_batch': 8.121283149719238, 'min_batch': 7.703506708145142, 'max_batch': 8.49246711730957}
step: 37990 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 3.7743008, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.542485070228577, 'actor_loss': -5.722489738464356, 'hyper_actor_loss': 0.01250116592273116, 'behavior_loss': 0.27499056458473203, 'mean_batch': 8.026815223693848, 'min_batch': 7.616716098785401, 'max_batch': 8.346505451202393}
step: 38000 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 4.016422, 'max_total_reward': 14.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.225585222244263, 'actor_loss': -5.738534832000733, 'hyper_actor_loss': 0.012529471609741449, 'behavior_loss': 0.2603785037994385, 'mean_batch': 8.092259407043457, 'min_batch': 7.677587795257568, 'max_batch': 8.401433372497559}
step: 38010 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 1.9620415, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.600915801525116, 'actor_loss': -5.78556456565857, 'hyper_actor_loss': 0.012284765020012856, 'behavior_loss': 0.24676418751478196, 'mean_batch': 8.269280910491943, 'min_batch': 7.874413299560547, 'max_batch': 8.57860803604126}
step: 38020 @ episode report: {'average_total_reward': 11.386, 'reward_variance': 4.179124, 'max_total_reward': 14.34, 'min_total_reward': 6.7900004, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.933884501457214, 'actor_loss': -5.742899084091187, 'hyper_actor_loss': 0.012129388842731714, 'behavior_loss': 0.267646835744381, 'mean_batch': 8.20793113708496, 'min_batch': 7.6119067668914795, 'max_batch': 8.535942268371581}
step: 38030 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 2.510616, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.324718236923218, 'actor_loss': -5.733759880065918, 'hyper_actor_loss': 0.01177124734967947, 'behavior_loss': 0.2535051807761192, 'mean_batch': 8.067371463775634, 'min_batch': 7.66512360572815, 'max_batch': 8.35503568649292}
step: 38040 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 5.3128858, 'max_total_reward': 12.2300005, 'min_total_reward': 4.24, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6019145250320435, 'actor_loss': -5.7757104396820065, 'hyper_actor_loss': 0.012125046830624342, 'behavior_loss': 0.2623233526945114, 'mean_batch': 8.220226669311524, 'min_batch': 7.8446629524230955, 'max_batch': 8.541014194488525}
step: 38050 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 5.332645, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4453044652938845, 'actor_loss': -5.798058414459229, 'hyper_actor_loss': 0.01236236011609435, 'behavior_loss': 0.25065110325813295, 'mean_batch': 8.331822776794434, 'min_batch': 7.914783573150634, 'max_batch': 8.631347751617431}
step: 38060 @ episode report: {'average_total_reward': 10.731, 'reward_variance': 2.5433488, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3404754281044005, 'actor_loss': -5.773448324203491, 'hyper_actor_loss': 0.012504665087908507, 'behavior_loss': 0.26554553806781767, 'mean_batch': 8.21753282546997, 'min_batch': 7.8297632217407225, 'max_batch': 8.525235748291015}
step: 38070 @ episode report: {'average_total_reward': 10.176, 'reward_variance': 8.243044, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.832049417495727, 'actor_loss': -5.74599871635437, 'hyper_actor_loss': 0.012394738756120205, 'behavior_loss': 0.2726545438170433, 'mean_batch': 8.115422439575195, 'min_batch': 7.713944625854492, 'max_batch': 8.425390148162842}
step: 38080 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.992189, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.08815176486969, 'actor_loss': -5.742841386795044, 'hyper_actor_loss': 0.012668471410870552, 'behavior_loss': 0.24966604262590408, 'mean_batch': 8.095986366271973, 'min_batch': 7.706569480895996, 'max_batch': 8.401926040649414}
step: 38090 @ episode report: {'average_total_reward': 10.309001, 'reward_variance': 0.7071688, 'max_total_reward': 11.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.250957405567169, 'actor_loss': -5.736209869384766, 'hyper_actor_loss': 0.012357916962355376, 'behavior_loss': 0.26994492262601855, 'mean_batch': 8.112765407562256, 'min_batch': 7.6425323486328125, 'max_batch': 8.462541961669922}
step: 38100 @ episode report: {'average_total_reward': 11.83, 'reward_variance': 2.9506204, 'max_total_reward': 15.56, 'min_total_reward': 10.01, 'average_n_step': 12.6, 'max_n_step': 16.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.850982141494751, 'actor_loss': -5.740894889831543, 'hyper_actor_loss': 0.011851794458925724, 'behavior_loss': 0.2596589908003807, 'mean_batch': 8.084866905212403, 'min_batch': 7.70393934249878, 'max_batch': 8.449113941192627}
step: 38110 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 5.724045, 'max_total_reward': 15.56, 'min_total_reward': 5.68, 'average_n_step': 11.0, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.274664998054504, 'actor_loss': -5.732373142242432, 'hyper_actor_loss': 0.011824146006256342, 'behavior_loss': 0.25826077461242675, 'mean_batch': 8.05027813911438, 'min_batch': 7.6697791576385494, 'max_batch': 8.34899263381958}
step: 38120 @ episode report: {'average_total_reward': 11.7300005, 'reward_variance': 4.7905016, 'max_total_reward': 15.56, 'min_total_reward': 7.9, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7942585706710816, 'actor_loss': -5.7120872974395756, 'hyper_actor_loss': 0.0117900051176548, 'behavior_loss': 0.2678267523646355, 'mean_batch': 8.024585485458374, 'min_batch': 7.545290946960449, 'max_batch': 8.313751983642579}
step: 38130 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.2651165, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.706528377532959, 'actor_loss': -5.715103244781494, 'hyper_actor_loss': 0.011757134459912777, 'behavior_loss': 0.25859859585762024, 'mean_batch': 8.057111930847167, 'min_batch': 7.535078477859497, 'max_batch': 8.359728717803955}
step: 38140 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 3.809649, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.115342712402343, 'actor_loss': -5.706551027297974, 'hyper_actor_loss': 0.011894306354224681, 'behavior_loss': 0.24967545717954637, 'mean_batch': 8.011792993545532, 'min_batch': 7.517423105239868, 'max_batch': 8.271996593475341}
step: 38150 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 1.9235961, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.041168308258056, 'actor_loss': -5.730197381973267, 'hyper_actor_loss': 0.011707429215312004, 'behavior_loss': 0.2724508598446846, 'mean_batch': 8.038690328598022, 'min_batch': 7.667600631713867, 'max_batch': 8.363101196289062}
step: 38160 @ episode report: {'average_total_reward': 11.175, 'reward_variance': 9.500786, 'max_total_reward': 14.560001, 'min_total_reward': 2.46, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.864081454277039, 'actor_loss': -5.689674806594849, 'hyper_actor_loss': 0.01181434914469719, 'behavior_loss': 0.26291452497243883, 'mean_batch': 7.940692663192749, 'min_batch': 7.458689165115357, 'max_batch': 8.249905586242676}
step: 38170 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 5.0155354, 'max_total_reward': 15.45, 'min_total_reward': 6.680001, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.427604293823242, 'actor_loss': -5.687974071502685, 'hyper_actor_loss': 0.01208944283425808, 'behavior_loss': 0.2531187549233437, 'mean_batch': 7.935665321350098, 'min_batch': 7.452754020690918, 'max_batch': 8.210866928100586}
step: 38180 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 3.3083205, 'max_total_reward': 14.34, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.05574654340744, 'actor_loss': -5.715661573410034, 'hyper_actor_loss': 0.012009847071021795, 'behavior_loss': 0.25995844453573225, 'mean_batch': 8.00636920928955, 'min_batch': 7.5850217819213865, 'max_batch': 8.31738739013672}
step: 38190 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 4.1143, 'max_total_reward': 14.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7165054023265838, 'actor_loss': -5.708924007415772, 'hyper_actor_loss': 0.011804299522191286, 'behavior_loss': 0.25064105838537215, 'mean_batch': 8.155700778961181, 'min_batch': 7.418968152999878, 'max_batch': 8.484719467163085}
step: 38200 @ episode report: {'average_total_reward': 11.286, 'reward_variance': 2.3755841, 'max_total_reward': 13.45, 'min_total_reward': 9.009999, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.071528136730194, 'actor_loss': -5.732450246810913, 'hyper_actor_loss': 0.01161681730300188, 'behavior_loss': 0.2579758822917938, 'mean_batch': 8.123143863677978, 'min_batch': 7.607063436508179, 'max_batch': 8.422136592864991}
step: 38210 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.9178843, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.932604956626892, 'actor_loss': -5.72748122215271, 'hyper_actor_loss': 0.01154609750956297, 'behavior_loss': 0.2610802039504051, 'mean_batch': 8.091798400878906, 'min_batch': 7.5973814010620115, 'max_batch': 8.382862281799316}
step: 38220 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 4.418916, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.403235447406769, 'actor_loss': -5.730815505981445, 'hyper_actor_loss': 0.011362523771822453, 'behavior_loss': 0.2601714745163918, 'mean_batch': 8.110826206207275, 'min_batch': 7.609255456924439, 'max_batch': 8.433703517913818}
step: 38230 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 2.9128356, 'max_total_reward': 13.34, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.326533794403076, 'actor_loss': -5.742619466781616, 'hyper_actor_loss': 0.011145094316452742, 'behavior_loss': 0.26189486384391786, 'mean_batch': 8.105839824676513, 'min_batch': 7.698504066467285, 'max_batch': 8.434852981567383}
step: 38240 @ episode report: {'average_total_reward': 11.386, 'reward_variance': 3.0983844, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.465011882781982, 'actor_loss': -5.7042521953582765, 'hyper_actor_loss': 0.011255608219653369, 'behavior_loss': 0.27255338430404663, 'mean_batch': 7.997903442382812, 'min_batch': 7.509076690673828, 'max_batch': 8.3871018409729}
step: 38250 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.5051637, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.27242728471756, 'actor_loss': -5.706831598281861, 'hyper_actor_loss': 0.011035546939820052, 'behavior_loss': 0.26030154824256896, 'mean_batch': 7.979810285568237, 'min_batch': 7.542427253723145, 'max_batch': 8.295143985748291}
step: 38260 @ episode report: {'average_total_reward': 11.075, 'reward_variance': 3.358745, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.11811740398407, 'actor_loss': -5.66643533706665, 'hyper_actor_loss': 0.010852853674441576, 'behavior_loss': 0.2532378494739532, 'mean_batch': 7.82960205078125, 'min_batch': 7.386849403381348, 'max_batch': 8.15253210067749}
step: 38270 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 1.9983895, 'max_total_reward': 11.120001, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.767806720733643, 'actor_loss': -5.649381971359253, 'hyper_actor_loss': 0.010853402502834796, 'behavior_loss': 0.27793373763561247, 'mean_batch': 7.775641441345215, 'min_batch': 7.313893842697143, 'max_batch': 8.066421175003052}
step: 38280 @ episode report: {'average_total_reward': 10.698, 'reward_variance': 1.9492762, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7820027112960815, 'actor_loss': -5.671224546432495, 'hyper_actor_loss': 0.010793665889650583, 'behavior_loss': 0.26665181666612625, 'mean_batch': 7.9063780307769775, 'min_batch': 7.350563192367554, 'max_batch': 8.21560525894165}
step: 38290 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 5.3221807, 'max_total_reward': 14.56, 'min_total_reward': 6.68, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.567411363124847, 'actor_loss': -5.735080814361572, 'hyper_actor_loss': 0.01107194209471345, 'behavior_loss': 0.26107302606105803, 'mean_batch': 8.113532066345215, 'min_batch': 7.637583875656128, 'max_batch': 8.451645851135254}
step: 38300 @ episode report: {'average_total_reward': 10.598, 'reward_variance': 2.052556, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.067553377151489, 'actor_loss': -5.664551448822022, 'hyper_actor_loss': 0.011459400411695242, 'behavior_loss': 0.2548250213265419, 'mean_batch': 7.888244199752807, 'min_batch': 7.320414781570435, 'max_batch': 8.205673217773438}
step: 38310 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 6.247264, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4646517395973206, 'actor_loss': -5.711686754226685, 'hyper_actor_loss': 0.010897663328796625, 'behavior_loss': 0.24438747465610505, 'mean_batch': 7.971742248535156, 'min_batch': 7.589707851409912, 'max_batch': 8.298410892486572}
step: 38320 @ episode report: {'average_total_reward': 9.388, 'reward_variance': 7.922975, 'max_total_reward': 13.45, 'min_total_reward': 2.3500001, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.009083533287049, 'actor_loss': -5.7394531726837155, 'hyper_actor_loss': 0.011093328706920147, 'behavior_loss': 0.24753956198692323, 'mean_batch': 8.19299373626709, 'min_batch': 7.5942340850830075, 'max_batch': 8.507774448394775}
step: 38330 @ episode report: {'average_total_reward': 9.554, 'reward_variance': 2.9122648, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7899995, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9300805926322937, 'actor_loss': -5.707062578201294, 'hyper_actor_loss': 0.0107350361533463, 'behavior_loss': 0.24900932759046554, 'mean_batch': 8.020989179611206, 'min_batch': 7.51006178855896, 'max_batch': 8.3650616645813}
step: 38340 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 2.8122058, 'max_total_reward': 13.450001, 'min_total_reward': 7.35, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.405827355384827, 'actor_loss': -5.70798020362854, 'hyper_actor_loss': 0.010558144841343164, 'behavior_loss': 0.2506107077002525, 'mean_batch': 8.020057487487794, 'min_batch': 7.518432521820069, 'max_batch': 8.343791389465332}
step: 38350 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 3.768216, 'max_total_reward': 14.56, 'min_total_reward': 6.7900004, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8842650175094606, 'actor_loss': -5.741010570526123, 'hyper_actor_loss': 0.010568051412701607, 'behavior_loss': 0.25547180622816085, 'mean_batch': 8.071123790740966, 'min_batch': 7.716452980041504, 'max_batch': 8.4667537689209}
step: 38360 @ episode report: {'average_total_reward': 11.153001, 'reward_variance': 4.5137815, 'max_total_reward': 14.56, 'min_total_reward': 7.68, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.832284164428711, 'actor_loss': -5.759646415710449, 'hyper_actor_loss': 0.010451964102685452, 'behavior_loss': 0.25696354657411574, 'mean_batch': 8.140025615692139, 'min_batch': 7.794814348220825, 'max_batch': 8.488098335266113}
step: 38370 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 1.6346041, 'max_total_reward': 12.23, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3411786437034605, 'actor_loss': -5.743174123764038, 'hyper_actor_loss': 0.010730300378054381, 'behavior_loss': 0.25483043789863585, 'mean_batch': 8.136300849914551, 'min_batch': 7.675090265274048, 'max_batch': 8.499865818023682}
step: 38380 @ episode report: {'average_total_reward': 11.453001, 'reward_variance': 3.108401, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.985943853855133, 'actor_loss': -5.721842908859253, 'hyper_actor_loss': 0.010734671261161566, 'behavior_loss': 0.24746566265821457, 'mean_batch': 8.0737811088562, 'min_batch': 7.581898212432861, 'max_batch': 8.419077682495118}
step: 38390 @ episode report: {'average_total_reward': 10.465, 'reward_variance': 4.8957253, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4339477062225345, 'actor_loss': -5.724185848236084, 'hyper_actor_loss': 0.010700430814176798, 'behavior_loss': 0.2695026010274887, 'mean_batch': 8.033888578414917, 'min_batch': 7.623383569717407, 'max_batch': 8.343911170959473}
step: 38400 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 5.468389, 'max_total_reward': 13.34, 'min_total_reward': 4.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.44993634223938, 'actor_loss': -5.7250360488891605, 'hyper_actor_loss': 0.010915007162839174, 'behavior_loss': 0.254879979789257, 'mean_batch': 8.067420387268067, 'min_batch': 7.598576068878174, 'max_batch': 8.403879261016845}
step: 38410 @ episode report: {'average_total_reward': 10.398, 'reward_variance': 3.9458566, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3384528994560245, 'actor_loss': -5.7343206882476805, 'hyper_actor_loss': 0.01089456994086504, 'behavior_loss': 0.26353808790445327, 'mean_batch': 8.08461103439331, 'min_batch': 7.652951049804687, 'max_batch': 8.438992500305176}
step: 38420 @ episode report: {'average_total_reward': 10.653001, 'reward_variance': 2.281321, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.367867517471313, 'actor_loss': -5.72164249420166, 'hyper_actor_loss': 0.011226223595440388, 'behavior_loss': 0.2705006986856461, 'mean_batch': 8.053219652175903, 'min_batch': 7.587576627731323, 'max_batch': 8.391257667541504}
step: 38430 @ episode report: {'average_total_reward': 10.909001, 'reward_variance': 3.1940496, 'max_total_reward': 13.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.490294241905213, 'actor_loss': -5.700415325164795, 'hyper_actor_loss': 0.01124696871265769, 'behavior_loss': 0.2563865229487419, 'mean_batch': 7.934664487838745, 'min_batch': 7.536822938919068, 'max_batch': 8.300905227661133}
step: 38440 @ episode report: {'average_total_reward': 11.6640005, 'reward_variance': 3.2587845, 'max_total_reward': 15.56, 'min_total_reward': 8.79, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1152048945426944, 'actor_loss': -5.720425319671631, 'hyper_actor_loss': 0.011401390470564366, 'behavior_loss': 0.26663424968719485, 'mean_batch': 8.105630493164062, 'min_batch': 7.533098840713501, 'max_batch': 8.445798587799072}
step: 38450 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 1.9814835, 'max_total_reward': 13.12, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.032403206825256, 'actor_loss': -5.7385826587677, 'hyper_actor_loss': 0.010965860262513161, 'behavior_loss': 0.2584677472710609, 'mean_batch': 8.115772151947022, 'min_batch': 7.657214879989624, 'max_batch': 8.442637634277343}
step: 38460 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 3.223002, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6189568281173705, 'actor_loss': -5.725769853591919, 'hyper_actor_loss': 0.011163395643234254, 'behavior_loss': 0.2528922662138939, 'mean_batch': 8.056319618225098, 'min_batch': 7.614656448364258, 'max_batch': 8.365869140625}
step: 38470 @ episode report: {'average_total_reward': 11.597, 'reward_variance': 2.767041, 'max_total_reward': 14.34, 'min_total_reward': 7.9, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2454143285751345, 'actor_loss': -5.749034881591797, 'hyper_actor_loss': 0.010825502034276725, 'behavior_loss': 0.2525346755981445, 'mean_batch': 8.126700019836425, 'min_batch': 7.725694274902343, 'max_batch': 8.409013938903808}
step: 38480 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 3.298664, 'max_total_reward': 14.34, 'min_total_reward': 9.009999, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.609398651123047, 'actor_loss': -5.730204105377197, 'hyper_actor_loss': 0.010663703735917806, 'behavior_loss': 0.26324501633644104, 'mean_batch': 8.047979736328125, 'min_batch': 7.6579807758331295, 'max_batch': 8.354388236999512}
step: 38490 @ episode report: {'average_total_reward': 11.164, 'reward_variance': 2.8134246, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.248590183258057, 'actor_loss': -5.698374509811401, 'hyper_actor_loss': 0.010616648755967618, 'behavior_loss': 0.27186853885650636, 'mean_batch': 7.9093822002410885, 'min_batch': 7.545702362060547, 'max_batch': 8.235069942474365}
step: 38500 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 2.5081606, 'max_total_reward': 13.34, 'min_total_reward': 7.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.551472020149231, 'actor_loss': -5.6961493492126465, 'hyper_actor_loss': 0.010835429653525352, 'behavior_loss': 0.24716625064611436, 'mean_batch': 7.920629549026489, 'min_batch': 7.519121599197388, 'max_batch': 8.227521324157715}
step: 38510 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 1.9498806, 'max_total_reward': 12.339999, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.387914144992829, 'actor_loss': -5.7257507801055905, 'hyper_actor_loss': 0.0106953339651227, 'behavior_loss': 0.2497401624917984, 'mean_batch': 8.056486701965332, 'min_batch': 7.6142998218536375, 'max_batch': 8.405709743499756}
step: 38520 @ episode report: {'average_total_reward': 10.353001, 'reward_variance': 7.266261, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.0123944759368895, 'actor_loss': -5.698238706588745, 'hyper_actor_loss': 0.010870772320777178, 'behavior_loss': 0.2592430844902992, 'mean_batch': 8.046492671966552, 'min_batch': 7.424537086486817, 'max_batch': 8.376343154907227}
step: 38530 @ episode report: {'average_total_reward': 11.33, 'reward_variance': 2.5541997, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.764203643798828, 'actor_loss': -5.699893522262573, 'hyper_actor_loss': 0.010708150081336498, 'behavior_loss': 0.24826848655939102, 'mean_batch': 7.999025011062622, 'min_batch': 7.474262523651123, 'max_batch': 8.305466079711914}
step: 38540 @ episode report: {'average_total_reward': 10.975, 'reward_variance': 4.5717454, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.0255141973495485, 'actor_loss': -5.683750486373901, 'hyper_actor_loss': 0.010329060815274715, 'behavior_loss': 0.2542170912027359, 'mean_batch': 7.970682573318482, 'min_batch': 7.388573789596558, 'max_batch': 8.310836791992188}
step: 38550 @ episode report: {'average_total_reward': 10.265, 'reward_variance': 6.150365, 'max_total_reward': 15.559999, 'min_total_reward': 6.68, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.068876850605011, 'actor_loss': -5.719002676010132, 'hyper_actor_loss': 0.010175392869859934, 'behavior_loss': 0.258101686835289, 'mean_batch': 8.07301893234253, 'min_batch': 7.549411344528198, 'max_batch': 8.422330951690673}
step: 38560 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 2.3280036, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.941307783126831, 'actor_loss': -5.721889638900757, 'hyper_actor_loss': 0.010007674805819988, 'behavior_loss': 0.2577651336789131, 'mean_batch': 8.075980758666992, 'min_batch': 7.570433950424194, 'max_batch': 8.408680057525634}
step: 38570 @ episode report: {'average_total_reward': 10.742002, 'reward_variance': 1.2940557, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.30442316532135, 'actor_loss': -5.6890302181243895, 'hyper_actor_loss': 0.01019835527986288, 'behavior_loss': 0.2619141906499863, 'mean_batch': 8.045171165466309, 'min_batch': 7.354404926300049, 'max_batch': 8.357096958160401}
step: 38580 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 1.2130042, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.650702691078186, 'actor_loss': -5.713568162918091, 'hyper_actor_loss': 0.009928098693490029, 'behavior_loss': 0.2518653735518456, 'mean_batch': 7.979152965545654, 'min_batch': 7.595898866653442, 'max_batch': 8.261812210083008}
step: 38590 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 3.1043994, 'max_total_reward': 14.45, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.774887442588806, 'actor_loss': -5.723611879348755, 'hyper_actor_loss': 0.0101496497169137, 'behavior_loss': 0.2674637034535408, 'mean_batch': 8.071101856231689, 'min_batch': 7.587607955932617, 'max_batch': 8.400368976593018}
step: 38600 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 4.4424243, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.275610494613647, 'actor_loss': -5.722903108596801, 'hyper_actor_loss': 0.010081556160002947, 'behavior_loss': 0.24750887602567673, 'mean_batch': 8.009553861618041, 'min_batch': 7.6362205982208256, 'max_batch': 8.32922134399414}
step: 38610 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 1.0692966, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.648313975334167, 'actor_loss': -5.726482915878296, 'hyper_actor_loss': 0.01062600240111351, 'behavior_loss': 0.26494853794574735, 'mean_batch': 8.09046573638916, 'min_batch': 7.5906081199646, 'max_batch': 8.405410003662109}
step: 38620 @ episode report: {'average_total_reward': 10.5529995, 'reward_variance': 4.080761, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.186233472824097, 'actor_loss': -5.716436767578125, 'hyper_actor_loss': 0.01066459333524108, 'behavior_loss': 0.2679009005427361, 'mean_batch': 8.004147005081176, 'min_batch': 7.595405101776123, 'max_batch': 8.289047145843506}
step: 38630 @ episode report: {'average_total_reward': 9.033001, 'reward_variance': 6.917281, 'max_total_reward': 12.2300005, 'min_total_reward': 2.3500001, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8182411909103395, 'actor_loss': -5.742842769622802, 'hyper_actor_loss': 0.010432630311697721, 'behavior_loss': 0.2732353746891022, 'mean_batch': 8.13932819366455, 'min_batch': 7.669538068771362, 'max_batch': 8.502910709381103}
step: 38640 @ episode report: {'average_total_reward': 9.144, 'reward_variance': 1.3723441, 'max_total_reward': 10.12, 'min_total_reward': 6.68, 'average_n_step': 10.2, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.715723717212677, 'actor_loss': -5.740104532241821, 'hyper_actor_loss': 0.01025606393814087, 'behavior_loss': 0.25074026733636856, 'mean_batch': 8.204872226715088, 'min_batch': 7.594235944747925, 'max_batch': 8.613655948638916}
step: 38650 @ episode report: {'average_total_reward': 9.022, 'reward_variance': 1.975736, 'max_total_reward': 10.9, 'min_total_reward': 5.68, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3747450590133665, 'actor_loss': -5.73710618019104, 'hyper_actor_loss': 0.010004125814884902, 'behavior_loss': 0.2542829900979996, 'mean_batch': 8.082229328155517, 'min_batch': 7.677630805969239, 'max_batch': 8.450920486450196}
step: 38660 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.5950656, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.53178653717041, 'actor_loss': -5.760378694534301, 'hyper_actor_loss': 0.010121327731758356, 'behavior_loss': 0.26551511883735657, 'mean_batch': 8.15002965927124, 'min_batch': 7.790960645675659, 'max_batch': 8.566230010986327}
step: 38670 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 8.60961, 'max_total_reward': 13.450001, 'min_total_reward': 4.57, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.348972010612488, 'actor_loss': -5.756870555877685, 'hyper_actor_loss': 0.009880845248699189, 'behavior_loss': 0.25079428851604463, 'mean_batch': 8.180922794342042, 'min_batch': 7.73490834236145, 'max_batch': 8.536983966827393}
step: 38680 @ episode report: {'average_total_reward': 11.1310005, 'reward_variance': 4.84653, 'max_total_reward': 14.56, 'min_total_reward': 7.4599996, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.537235879898072, 'actor_loss': -5.7380413055419925, 'hyper_actor_loss': 0.009890261385589839, 'behavior_loss': 0.2610048443078995, 'mean_batch': 8.09146957397461, 'min_batch': 7.677161598205567, 'max_batch': 8.429806137084961}
step: 38690 @ episode report: {'average_total_reward': 10.443, 'reward_variance': 5.244641, 'max_total_reward': 14.339999, 'min_total_reward': 7.68, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.324181389808655, 'actor_loss': -5.715059280395508, 'hyper_actor_loss': 0.010012605786323547, 'behavior_loss': 0.2549332156777382, 'mean_batch': 8.030915069580079, 'min_batch': 7.561523151397705, 'max_batch': 8.441635036468506}
step: 38700 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 2.3909361, 'max_total_reward': 13.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.267863011360168, 'actor_loss': -5.700151586532593, 'hyper_actor_loss': 0.010049299150705338, 'behavior_loss': 0.259447880089283, 'mean_batch': 7.938311624526977, 'min_batch': 7.533641195297241, 'max_batch': 8.24421272277832}
step: 38710 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 1.4596559, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8989526867866515, 'actor_loss': -5.692303085327149, 'hyper_actor_loss': 0.009854450821876526, 'behavior_loss': 0.26937616616487503, 'mean_batch': 7.910805559158325, 'min_batch': 7.499553108215332, 'max_batch': 8.197723865509033}
step: 38720 @ episode report: {'average_total_reward': 10.109, 'reward_variance': 5.080649, 'max_total_reward': 13.450001, 'min_total_reward': 5.6800003, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.0028284072875975, 'actor_loss': -5.739505863189697, 'hyper_actor_loss': 0.009931174106895924, 'behavior_loss': 0.26852240562438967, 'mean_batch': 8.121138095855713, 'min_batch': 7.6589850902557375, 'max_batch': 8.455960750579834}
step: 38730 @ episode report: {'average_total_reward': 11.053001, 'reward_variance': 2.0777612, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.863489055633545, 'actor_loss': -5.7061089992523195, 'hyper_actor_loss': 0.01004659840837121, 'behavior_loss': 0.2624417394399643, 'mean_batch': 8.04439868927002, 'min_batch': 7.488274621963501, 'max_batch': 8.395277500152588}
step: 38740 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 3.4623096, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.226886940002442, 'actor_loss': -5.723780870437622, 'hyper_actor_loss': 0.009962150175124408, 'behavior_loss': 0.25164338648319245, 'mean_batch': 8.003475141525268, 'min_batch': 7.648494148254395, 'max_batch': 8.336161613464355}
step: 38750 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 5.868549, 'max_total_reward': 13.34, 'min_total_reward': 5.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.129150462150574, 'actor_loss': -5.718419790267944, 'hyper_actor_loss': 0.009908669907599688, 'behavior_loss': 0.2620571866631508, 'mean_batch': 8.021736145019531, 'min_batch': 7.594723463058472, 'max_batch': 8.33985185623169}
step: 38760 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 4.0798016, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.589503276348114, 'actor_loss': -5.745801591873169, 'hyper_actor_loss': 0.009885855671018361, 'behavior_loss': 0.2572423592209816, 'mean_batch': 8.174482536315917, 'min_batch': 7.661999130249024, 'max_batch': 8.515300750732422}
step: 38770 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 3.7578492, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.794278264045715, 'actor_loss': -5.749532651901245, 'hyper_actor_loss': 0.009796776250004769, 'behavior_loss': 0.2610526219010353, 'mean_batch': 8.134832572937011, 'min_batch': 7.7238623142242435, 'max_batch': 8.491482830047607}
step: 38780 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 1.7249361, 'max_total_reward': 13.45, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.197792410850525, 'actor_loss': -5.709835147857666, 'hyper_actor_loss': 0.010186731070280074, 'behavior_loss': 0.25711347758769987, 'mean_batch': 8.026715946197509, 'min_batch': 7.528523206710815, 'max_batch': 8.348172378540038}
step: 38790 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.5999048, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.319883799552917, 'actor_loss': -5.693013000488281, 'hyper_actor_loss': 0.0100647309795022, 'behavior_loss': 0.2406153202056885, 'mean_batch': 7.955768489837647, 'min_batch': 7.4657622337341305, 'max_batch': 8.298750400543213}
step: 38800 @ episode report: {'average_total_reward': 11.264, 'reward_variance': 2.4068246, 'max_total_reward': 14.450001, 'min_total_reward': 9.79, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.699876141548157, 'actor_loss': -5.7152244567871096, 'hyper_actor_loss': 0.010332904290407896, 'behavior_loss': 0.2522177711129189, 'mean_batch': 8.084042358398438, 'min_batch': 7.5128716945648195, 'max_batch': 8.468924617767334}
step: 38810 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 2.2688403, 'max_total_reward': 13.23, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9383453726768494, 'actor_loss': -5.740653085708618, 'hyper_actor_loss': 0.010052511282265187, 'behavior_loss': 0.25566658228635786, 'mean_batch': 8.121051597595216, 'min_batch': 7.673980951309204, 'max_batch': 8.450067138671875}
step: 38820 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 6.106165, 'max_total_reward': 12.2300005, 'min_total_reward': 3.5700002, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.682616806030273, 'actor_loss': -5.732604694366455, 'hyper_actor_loss': 0.009737615287303925, 'behavior_loss': 0.2569586902856827, 'mean_batch': 8.036065530776977, 'min_batch': 7.68499789237976, 'max_batch': 8.380757045745849}
step: 38830 @ episode report: {'average_total_reward': 11.397, 'reward_variance': 4.9065604, 'max_total_reward': 15.56, 'min_total_reward': 7.7900004, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.307674288749695, 'actor_loss': -5.726661920547485, 'hyper_actor_loss': 0.010000738035887479, 'behavior_loss': 0.2522183254361153, 'mean_batch': 8.022046756744384, 'min_batch': 7.653407907485962, 'max_batch': 8.338263702392577}
step: 38840 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 3.0328403, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.271441149711609, 'actor_loss': -5.720863294601441, 'hyper_actor_loss': 0.010038246400654316, 'behavior_loss': 0.2753835767507553, 'mean_batch': 8.089743041992188, 'min_batch': 7.556285858154297, 'max_batch': 8.41962547302246}
step: 38850 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.6101036, 'max_total_reward': 13.45, 'min_total_reward': 6.9000006, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.163124144077301, 'actor_loss': -5.698322439193726, 'hyper_actor_loss': 0.010089769680052995, 'behavior_loss': 0.2669203832745552, 'mean_batch': 8.046922492980958, 'min_batch': 7.424471282958985, 'max_batch': 8.401792240142822}
step: 38860 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.3753839, 'max_total_reward': 13.23, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.688946795463562, 'actor_loss': -5.72889666557312, 'hyper_actor_loss': 0.00986154517158866, 'behavior_loss': 0.26472271233797073, 'mean_batch': 8.089057159423827, 'min_batch': 7.608710527420044, 'max_batch': 8.482687950134277}
step: 38870 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 3.2619834, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.168519866466522, 'actor_loss': -5.734551095962525, 'hyper_actor_loss': 0.009732561185956001, 'behavior_loss': 0.2653882592916489, 'mean_batch': 8.11246223449707, 'min_batch': 7.633880949020385, 'max_batch': 8.49276351928711}
step: 38880 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 8.478142, 'max_total_reward': 12.009999, 'min_total_reward': 1.24, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 3.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.140397262573242, 'actor_loss': -5.724883365631103, 'hyper_actor_loss': 0.009852832928299905, 'behavior_loss': 0.2632528215646744, 'mean_batch': 8.055242872238159, 'min_batch': 7.6171417236328125, 'max_batch': 8.415097999572755}
step: 38890 @ episode report: {'average_total_reward': 9.809999, 'reward_variance': 3.42178, 'max_total_reward': 13.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.884505105018616, 'actor_loss': -5.7073921203613285, 'hyper_actor_loss': 0.009946519695222377, 'behavior_loss': 0.2616766393184662, 'mean_batch': 8.02893943786621, 'min_batch': 7.50381989479065, 'max_batch': 8.370344161987305}
step: 38900 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 4.3528433, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.174659276008606, 'actor_loss': -5.7541115283966064, 'hyper_actor_loss': 0.009753149375319481, 'behavior_loss': 0.2604761034250259, 'mean_batch': 8.151468563079835, 'min_batch': 7.741006517410279, 'max_batch': 8.546981239318848}
step: 38910 @ episode report: {'average_total_reward': 10.542, 'reward_variance': 3.5206356, 'max_total_reward': 14.559999, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.934989356994629, 'actor_loss': -5.698791265487671, 'hyper_actor_loss': 0.010085386037826539, 'behavior_loss': 0.25595518946647644, 'mean_batch': 8.063274383544922, 'min_batch': 7.410340785980225, 'max_batch': 8.501951313018798}
step: 38920 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 4.4140825, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.13184962272644, 'actor_loss': -5.721202659606933, 'hyper_actor_loss': 0.010072330106049776, 'behavior_loss': 0.24769893586635588, 'mean_batch': 8.148197269439697, 'min_batch': 7.504508781433105, 'max_batch': 8.537042236328125}
step: 38930 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 2.4501767, 'max_total_reward': 14.450001, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.46969702243805, 'actor_loss': -5.721749258041382, 'hyper_actor_loss': 0.009804003313183785, 'behavior_loss': 0.25111742317676544, 'mean_batch': 8.07546329498291, 'min_batch': 7.570660638809204, 'max_batch': 8.414369487762452}
step: 38940 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 1.2125158, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.186733055114746, 'actor_loss': -5.73360686302185, 'hyper_actor_loss': 0.009896785952150822, 'behavior_loss': 0.24300654232501984, 'mean_batch': 8.109333324432374, 'min_batch': 7.626670074462891, 'max_batch': 8.538941669464112}
step: 38950 @ episode report: {'average_total_reward': 11.7300005, 'reward_variance': 3.2363002, 'max_total_reward': 15.56, 'min_total_reward': 9.01, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8922576189041136, 'actor_loss': -5.762696695327759, 'hyper_actor_loss': 0.009833090286701918, 'behavior_loss': 0.25826604962348937, 'mean_batch': 8.223824787139893, 'min_batch': 7.738775014877319, 'max_batch': 8.650836658477782}
step: 38960 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 2.033316, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.211776041984558, 'actor_loss': -5.772281837463379, 'hyper_actor_loss': 0.009769984614104032, 'behavior_loss': 0.25491328686475756, 'mean_batch': 8.228201007843017, 'min_batch': 7.8101836204528805, 'max_batch': 8.629666996002197}
step: 38970 @ episode report: {'average_total_reward': 10.321001, 'reward_variance': 1.9391094, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.88025689125061, 'actor_loss': -5.745890951156616, 'hyper_actor_loss': 0.009870349429547787, 'behavior_loss': 0.25094338357448576, 'mean_batch': 8.210263442993163, 'min_batch': 7.641125440597534, 'max_batch': 8.589790534973144}
step: 38980 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 2.4578693, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7631996154785154, 'actor_loss': -5.720124340057373, 'hyper_actor_loss': 0.010326955653727054, 'behavior_loss': 0.25842864215373995, 'mean_batch': 8.109735870361328, 'min_batch': 7.528763341903686, 'max_batch': 8.43389596939087}
step: 38990 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 3.0846207, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3141032457351685, 'actor_loss': -5.693840408325196, 'hyper_actor_loss': 0.010215226840227843, 'behavior_loss': 0.26025805771350863, 'mean_batch': 8.119058799743652, 'min_batch': 7.346020269393921, 'max_batch': 8.538996410369872}
step: 39000 @ episode report: {'average_total_reward': 9.887001, 'reward_variance': 3.1748009, 'max_total_reward': 13.450001, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.023715674877167, 'actor_loss': -5.724076461791992, 'hyper_actor_loss': 0.010027663316577673, 'behavior_loss': 0.24018950760364532, 'mean_batch': 8.119981670379639, 'min_batch': 7.567976093292236, 'max_batch': 8.553414916992187}
step: 39010 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.8241253, 'max_total_reward': 12.12, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.135860085487366, 'actor_loss': -5.770937776565551, 'hyper_actor_loss': 0.010066962614655495, 'behavior_loss': 0.2669243097305298, 'mean_batch': 8.224526405334473, 'min_batch': 7.803152465820313, 'max_batch': 8.591708278656006}
step: 39020 @ episode report: {'average_total_reward': 10.631001, 'reward_variance': 5.3904886, 'max_total_reward': 15.67, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.94854507446289, 'actor_loss': -5.765131521224975, 'hyper_actor_loss': 0.009863200224936008, 'behavior_loss': 0.2538845404982567, 'mean_batch': 8.21770715713501, 'min_batch': 7.764793348312378, 'max_batch': 8.653759002685547}
step: 39030 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 1.1350685, 'max_total_reward': 11.23, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.541524267196655, 'actor_loss': -5.7366608619689945, 'hyper_actor_loss': 0.010034427605569362, 'behavior_loss': 0.2650716722011566, 'mean_batch': 8.102163505554199, 'min_batch': 7.6574243068695065, 'max_batch': 8.456920337677001}
step: 39040 @ episode report: {'average_total_reward': 11.63, 'reward_variance': 4.009561, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2928616285324095, 'actor_loss': -5.756210279464722, 'hyper_actor_loss': 0.010237860027700663, 'behavior_loss': 0.25609821677207945, 'mean_batch': 8.165727138519287, 'min_batch': 7.74386830329895, 'max_batch': 8.515074253082275}
step: 39050 @ episode report: {'average_total_reward': 11.719, 'reward_variance': 3.343649, 'max_total_reward': 14.56, 'min_total_reward': 8.900001, 'average_n_step': 12.5, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8359890460968016, 'actor_loss': -5.789169406890869, 'hyper_actor_loss': 0.010619975160807371, 'behavior_loss': 0.2640845522284508, 'mean_batch': 8.314584636688233, 'min_batch': 7.862228536605835, 'max_batch': 8.645769786834716}
step: 39060 @ episode report: {'average_total_reward': 10.154, 'reward_variance': 1.4627247, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.371345674991607, 'actor_loss': -5.795478773117066, 'hyper_actor_loss': 0.010563319269567727, 'behavior_loss': 0.27091805785894396, 'mean_batch': 8.293272495269775, 'min_batch': 7.929812431335449, 'max_batch': 8.666466999053956}
step: 39070 @ episode report: {'average_total_reward': 10.188001, 'reward_variance': 2.3031366, 'max_total_reward': 12.2300005, 'min_total_reward': 7.4599996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.925800585746765, 'actor_loss': -5.740921115875244, 'hyper_actor_loss': 0.010593245550990105, 'behavior_loss': 0.2557153865695, 'mean_batch': 8.21385498046875, 'min_batch': 7.58813214302063, 'max_batch': 8.549510097503662}
step: 39080 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 2.4829164, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.630886602401733, 'actor_loss': -5.764214134216308, 'hyper_actor_loss': 0.010724648833274841, 'behavior_loss': 0.2600651130080223, 'mean_batch': 8.254802227020264, 'min_batch': 7.730861186981201, 'max_batch': 8.625479316711425}
step: 39090 @ episode report: {'average_total_reward': 10.886, 'reward_variance': 6.293325, 'max_total_reward': 15.67, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.417385745048523, 'actor_loss': -5.72992525100708, 'hyper_actor_loss': 0.010702060721814632, 'behavior_loss': 0.2697157979011536, 'mean_batch': 8.151839542388917, 'min_batch': 7.561411571502686, 'max_batch': 8.462636947631836}
step: 39100 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 4.6625614, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.326128387451172, 'actor_loss': -5.734095621109009, 'hyper_actor_loss': 0.010596292279660701, 'behavior_loss': 0.24430826753377916, 'mean_batch': 8.081140804290772, 'min_batch': 7.655498313903808, 'max_batch': 8.404896545410157}
step: 39110 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 3.3522007, 'max_total_reward': 12.23, 'min_total_reward': 6.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.097720336914063, 'actor_loss': -5.725099515914917, 'hyper_actor_loss': 0.010432395525276661, 'behavior_loss': 0.2550565302371979, 'mean_batch': 8.137710571289062, 'min_batch': 7.539896297454834, 'max_batch': 8.57100191116333}
step: 39120 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 3.7793846, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.131394958496093, 'actor_loss': -5.72250771522522, 'hyper_actor_loss': 0.010505741368979216, 'behavior_loss': 0.26050114184617995, 'mean_batch': 8.123394775390626, 'min_batch': 7.531367921829224, 'max_batch': 8.498601245880128}
step: 39130 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 1.8158562, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.809004259109497, 'actor_loss': -5.724059009552002, 'hyper_actor_loss': 0.010421238467097282, 'behavior_loss': 0.2652971461415291, 'mean_batch': 8.106343030929565, 'min_batch': 7.556673955917359, 'max_batch': 8.476198482513428}
step: 39140 @ episode report: {'average_total_reward': 10.731, 'reward_variance': 2.9605093, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.057044339179993, 'actor_loss': -5.6858282566070555, 'hyper_actor_loss': 0.010198871232569217, 'behavior_loss': 0.2586298421025276, 'mean_batch': 8.067178344726562, 'min_batch': 7.327669858932495, 'max_batch': 8.414819812774658}
step: 39150 @ episode report: {'average_total_reward': 9.110001, 'reward_variance': 4.92314, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.30101330280304, 'actor_loss': -5.738189029693603, 'hyper_actor_loss': 0.010055298078805208, 'behavior_loss': 0.2559257000684738, 'mean_batch': 8.31080961227417, 'min_batch': 7.526821517944336, 'max_batch': 8.692214107513427}
step: 39160 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 3.2363045, 'max_total_reward': 13.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.424854516983032, 'actor_loss': -5.7595165252685545, 'hyper_actor_loss': 0.01000288426876068, 'behavior_loss': 0.2576780587434769, 'mean_batch': 8.247967147827149, 'min_batch': 7.6972737312316895, 'max_batch': 8.615624618530273}
step: 39170 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 4.677981, 'max_total_reward': 13.450001, 'min_total_reward': 6.7899995, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.484482991695404, 'actor_loss': -5.783782863616944, 'hyper_actor_loss': 0.009973655454814434, 'behavior_loss': 0.2635020360350609, 'mean_batch': 8.292218971252442, 'min_batch': 7.841099500656128, 'max_batch': 8.633278274536133}
step: 39180 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 3.1132011, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4644339084625244, 'actor_loss': -5.786889934539795, 'hyper_actor_loss': 0.009832683764398099, 'behavior_loss': 0.26066545099020005, 'mean_batch': 8.368240070343017, 'min_batch': 7.803316831588745, 'max_batch': 8.726739311218262}
step: 39190 @ episode report: {'average_total_reward': 12.184999, 'reward_variance': 3.6073852, 'max_total_reward': 15.56, 'min_total_reward': 9.01, 'average_n_step': 12.9, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.02867112159729, 'actor_loss': -5.759328126907349, 'hyper_actor_loss': 0.009719713125377893, 'behavior_loss': 0.2564853474497795, 'mean_batch': 8.299685668945312, 'min_batch': 7.653708028793335, 'max_batch': 8.726545810699463}
step: 39200 @ episode report: {'average_total_reward': 11.5529995, 'reward_variance': 2.470442, 'max_total_reward': 14.450001, 'min_total_reward': 8.789999, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.601166772842407, 'actor_loss': -5.769367027282715, 'hyper_actor_loss': 0.009338620211929083, 'behavior_loss': 0.25800181180238724, 'mean_batch': 8.193871212005615, 'min_batch': 7.8192877769470215, 'max_batch': 8.538536834716798}
step: 39210 @ episode report: {'average_total_reward': 9.599, 'reward_variance': 3.0210094, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.290716993808746, 'actor_loss': -5.760116243362427, 'hyper_actor_loss': 0.009461549948900938, 'behavior_loss': 0.2649630829691887, 'mean_batch': 8.229468250274659, 'min_batch': 7.726209688186645, 'max_batch': 8.561134624481202}
step: 39220 @ episode report: {'average_total_reward': 10.420001, 'reward_variance': 3.1670406, 'max_total_reward': 12.340001, 'min_total_reward': 5.68, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6154883861541744, 'actor_loss': -5.751472330093383, 'hyper_actor_loss': 0.009679388534277678, 'behavior_loss': 0.2671988859772682, 'mean_batch': 8.218875312805176, 'min_batch': 7.667570447921753, 'max_batch': 8.538791465759278}
step: 39230 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 3.0971398, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.21181753873825, 'actor_loss': -5.75477237701416, 'hyper_actor_loss': 0.00975081892684102, 'behavior_loss': 0.2543156087398529, 'mean_batch': 8.122403812408447, 'min_batch': 7.773632478713989, 'max_batch': 8.448626041412354}
step: 39240 @ episode report: {'average_total_reward': 10.764001, 'reward_variance': 4.269664, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.858598065376282, 'actor_loss': -5.759045124053955, 'hyper_actor_loss': 0.009764956310391426, 'behavior_loss': 0.26337661743164065, 'mean_batch': 8.190298175811767, 'min_batch': 7.747541809082032, 'max_batch': 8.566510677337646}
step: 39250 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.4700887, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.194827246665954, 'actor_loss': -5.773086214065552, 'hyper_actor_loss': 0.009806753788143396, 'behavior_loss': 0.24522582739591597, 'mean_batch': 8.219401359558105, 'min_batch': 7.824821901321411, 'max_batch': 8.59656810760498}
step: 39260 @ episode report: {'average_total_reward': 9.144, 'reward_variance': 4.1707644, 'max_total_reward': 12.230001, 'min_total_reward': 4.6800003, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.073146343231201, 'actor_loss': -5.790417766571045, 'hyper_actor_loss': 0.009956315997987986, 'behavior_loss': 0.25017965734004977, 'mean_batch': 8.366588020324707, 'min_batch': 7.822814083099365, 'max_batch': 8.80378074645996}
step: 39270 @ episode report: {'average_total_reward': 10.353999, 'reward_variance': 2.3140643, 'max_total_reward': 13.23, 'min_total_reward': 8.679999, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3713874578475953, 'actor_loss': -5.777731990814209, 'hyper_actor_loss': 0.00979519346728921, 'behavior_loss': 0.2714087277650833, 'mean_batch': 8.26165542602539, 'min_batch': 7.82076096534729, 'max_batch': 8.645077419281005}
step: 39280 @ episode report: {'average_total_reward': 10.653001, 'reward_variance': 1.3444815, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.008719384670258, 'actor_loss': -5.705775547027588, 'hyper_actor_loss': 0.009998843725770711, 'behavior_loss': 0.2531958267092705, 'mean_batch': 8.181410980224609, 'min_batch': 7.376738500595093, 'max_batch': 8.525970077514648}
step: 39290 @ episode report: {'average_total_reward': 10.231001, 'reward_variance': 3.0679293, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.266713953018188, 'actor_loss': -5.768058824539184, 'hyper_actor_loss': 0.009912928007543087, 'behavior_loss': 0.250241194665432, 'mean_batch': 8.271287631988525, 'min_batch': 7.741660833358765, 'max_batch': 8.60774564743042}
step: 39300 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 1.291781, 'max_total_reward': 13.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.838947224617004, 'actor_loss': -5.770047855377197, 'hyper_actor_loss': 0.009903671499341727, 'behavior_loss': 0.27323122769594194, 'mean_batch': 8.286379337310791, 'min_batch': 7.750007200241089, 'max_batch': 8.669573020935058}
step: 39310 @ episode report: {'average_total_reward': 8.877001, 'reward_variance': 6.736861, 'max_total_reward': 12.34, 'min_total_reward': 2.3500001, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2219088792800905, 'actor_loss': -5.782518577575684, 'hyper_actor_loss': 0.010114738810807466, 'behavior_loss': 0.25865892618894576, 'mean_batch': 8.335615062713623, 'min_batch': 7.802999544143677, 'max_batch': 8.73421106338501}
step: 39320 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 2.6188293, 'max_total_reward': 12.2300005, 'min_total_reward': 5.6800003, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.061202478408814, 'actor_loss': -5.751689624786377, 'hyper_actor_loss': 0.010349002853035926, 'behavior_loss': 0.2597583085298538, 'mean_batch': 8.261075401306153, 'min_batch': 7.633787202835083, 'max_batch': 8.715496349334718}
step: 39330 @ episode report: {'average_total_reward': 9.654, 'reward_variance': 3.4910445, 'max_total_reward': 12.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.784057068824768, 'actor_loss': -5.761754369735717, 'hyper_actor_loss': 0.010328670032322407, 'behavior_loss': 0.26514771580696106, 'mean_batch': 8.350225162506103, 'min_batch': 7.6397809982299805, 'max_batch': 8.805852127075195}
step: 39340 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.8744884, 'max_total_reward': 12.23, 'min_total_reward': 5.6800003, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.855666780471802, 'actor_loss': -5.793963813781739, 'hyper_actor_loss': 0.010023617185652256, 'behavior_loss': 0.26668636351823805, 'mean_batch': 8.416586112976074, 'min_batch': 7.814809417724609, 'max_batch': 8.84556541442871}
step: 39350 @ episode report: {'average_total_reward': 8.633, 'reward_variance': 5.7292604, 'max_total_reward': 10.120001, 'min_total_reward': 2.3500001, 'average_n_step': 9.7, 'max_n_step': 11.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.018214702606201, 'actor_loss': -5.771048831939697, 'hyper_actor_loss': 0.010139483027160168, 'behavior_loss': 0.27399964481592176, 'mean_batch': 8.201803874969482, 'min_batch': 7.8247870922088625, 'max_batch': 8.616981887817383}
step: 39360 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 3.6244857, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.544088160991669, 'actor_loss': -5.822856521606445, 'hyper_actor_loss': 0.01030351324006915, 'behavior_loss': 0.25230385065078736, 'mean_batch': 8.424881076812744, 'min_batch': 8.02428650856018, 'max_batch': 8.808051586151123}
step: 39370 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 1.3233604, 'max_total_reward': 12.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.409815812110901, 'actor_loss': -5.822411823272705, 'hyper_actor_loss': 0.010672657284885645, 'behavior_loss': 0.26575205773115157, 'mean_batch': 8.621545791625977, 'min_batch': 7.853565692901611, 'max_batch': 9.054110145568847}
step: 39380 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 1.4917085, 'max_total_reward': 12.23, 'min_total_reward': 7.6800003, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.839983534812927, 'actor_loss': -5.786309385299683, 'hyper_actor_loss': 0.010424061119556427, 'behavior_loss': 0.27611966133117677, 'mean_batch': 8.328188228607178, 'min_batch': 7.828588247299194, 'max_batch': 8.74688425064087}
step: 39390 @ episode report: {'average_total_reward': 10.465001, 'reward_variance': 1.6531248, 'max_total_reward': 13.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0753710746765135, 'actor_loss': -5.765264701843262, 'hyper_actor_loss': 0.010736102145165205, 'behavior_loss': 0.2560256808996201, 'mean_batch': 8.190245151519775, 'min_batch': 7.7912917137146, 'max_batch': 8.544049549102784}
step: 39400 @ episode report: {'average_total_reward': 10.631001, 'reward_variance': 0.53292894, 'max_total_reward': 12.34, 'min_total_reward': 10.01, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.800486612319946, 'actor_loss': -5.769439315795898, 'hyper_actor_loss': 0.010841561947017908, 'behavior_loss': 0.25650182366371155, 'mean_batch': 8.402756214141846, 'min_batch': 7.638681697845459, 'max_batch': 8.795465564727783}
step: 39410 @ episode report: {'average_total_reward': 11.93, 'reward_variance': 3.9331398, 'max_total_reward': 15.56, 'min_total_reward': 9.01, 'average_n_step': 12.7, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.568304276466369, 'actor_loss': -5.795675420761109, 'hyper_actor_loss': 0.010662665497511626, 'behavior_loss': 0.2620658800005913, 'mean_batch': 8.33370246887207, 'min_batch': 7.8930168628692625, 'max_batch': 8.73525791168213}
step: 39420 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.7911444, 'max_total_reward': 11.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2293184995651245, 'actor_loss': -5.78018708229065, 'hyper_actor_loss': 0.010790303349494934, 'behavior_loss': 0.26679767668247223, 'mean_batch': 8.36352825164795, 'min_batch': 7.755986833572388, 'max_batch': 8.739660358428955}
step: 39430 @ episode report: {'average_total_reward': 10.875001, 'reward_variance': 3.6519046, 'max_total_reward': 14.559999, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.824176502227783, 'actor_loss': -5.76980152130127, 'hyper_actor_loss': 0.010367131233215332, 'behavior_loss': 0.254494646191597, 'mean_batch': 8.347579956054688, 'min_batch': 7.696611976623535, 'max_batch': 8.706413078308106}
step: 39440 @ episode report: {'average_total_reward': 9.998001, 'reward_variance': 4.545097, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.440898489952088, 'actor_loss': -5.789549112319946, 'hyper_actor_loss': 0.01034797439351678, 'behavior_loss': 0.2649790748953819, 'mean_batch': 8.311040782928467, 'min_batch': 7.867833852767944, 'max_batch': 8.667037105560302}
step: 39450 @ episode report: {'average_total_reward': 10.598, 'reward_variance': 3.926436, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.429116725921631, 'actor_loss': -5.7825263977050785, 'hyper_actor_loss': 0.010341342072933912, 'behavior_loss': 0.24983224421739578, 'mean_batch': 8.303912925720216, 'min_batch': 7.820129919052124, 'max_batch': 8.663472175598145}
step: 39460 @ episode report: {'average_total_reward': 10.686999, 'reward_variance': 2.094661, 'max_total_reward': 13.12, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.08995041847229, 'actor_loss': -5.7882002830505375, 'hyper_actor_loss': 0.010493364930152894, 'behavior_loss': 0.26086794286966325, 'mean_batch': 8.327804660797119, 'min_batch': 7.840598678588867, 'max_batch': 8.676681423187256}
step: 39470 @ episode report: {'average_total_reward': 11.1310005, 'reward_variance': 3.8656888, 'max_total_reward': 15.67, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4038808107376095, 'actor_loss': -5.8018279552459715, 'hyper_actor_loss': 0.010526082757860423, 'behavior_loss': 0.27072938829660415, 'mean_batch': 8.381822776794433, 'min_batch': 7.902892684936523, 'max_batch': 8.746820735931397}
step: 39480 @ episode report: {'average_total_reward': 10.986001, 'reward_variance': 2.3338249, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.044381761550904, 'actor_loss': -5.773642826080322, 'hyper_actor_loss': 0.010745553206652403, 'behavior_loss': 0.28447089344263077, 'mean_batch': 8.491185283660888, 'min_batch': 7.610670375823974, 'max_batch': 8.870026206970214}
step: 39490 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 3.6254563, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.725457310676575, 'actor_loss': -5.8028069019317625, 'hyper_actor_loss': 0.011040865071117878, 'behavior_loss': 0.27144208252429963, 'mean_batch': 8.46589765548706, 'min_batch': 7.841205263137818, 'max_batch': 8.834932327270508}
step: 39500 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 4.595383, 'max_total_reward': 13.339999, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.371628761291504, 'actor_loss': -5.821537494659424, 'hyper_actor_loss': 0.010795287508517503, 'behavior_loss': 0.25553533881902696, 'mean_batch': 8.45840539932251, 'min_batch': 7.982407093048096, 'max_batch': 8.828588390350342}
step: 39510 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 1.2912294, 'max_total_reward': 10.120001, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.44000027179718, 'actor_loss': -5.846449327468872, 'hyper_actor_loss': 0.01061415858566761, 'behavior_loss': 0.26636615842580796, 'mean_batch': 8.601847839355468, 'min_batch': 8.056879091262818, 'max_batch': 8.997486019134522}
step: 39520 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 6.569003, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.618074941635132, 'actor_loss': -5.789642190933227, 'hyper_actor_loss': 0.010371843166649342, 'behavior_loss': 0.26399110853672025, 'mean_batch': 8.441232013702393, 'min_batch': 7.772534132003784, 'max_batch': 8.848925590515137}
step: 39530 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 2.8821557, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.532666635513306, 'actor_loss': -5.805664730072022, 'hyper_actor_loss': 0.010430634766817094, 'behavior_loss': 0.25191301107406616, 'mean_batch': 8.438535785675048, 'min_batch': 7.883072137832642, 'max_batch': 8.807504844665527}
step: 39540 @ episode report: {'average_total_reward': 9.144, 'reward_variance': 4.7197046, 'max_total_reward': 13.2300005, 'min_total_reward': 5.35, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3473076820373535, 'actor_loss': -5.795339059829712, 'hyper_actor_loss': 0.010354932770133019, 'behavior_loss': 0.2593771442770958, 'mean_batch': 8.397605895996094, 'min_batch': 7.835621118545532, 'max_batch': 8.75488338470459}
step: 39550 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 4.2364893, 'max_total_reward': 15.56, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.5550463676452635, 'actor_loss': -5.800685214996338, 'hyper_actor_loss': 0.009977134689688683, 'behavior_loss': 0.2796678513288498, 'mean_batch': 8.327931022644043, 'min_batch': 7.938197946548462, 'max_batch': 8.653553581237793}
step: 39560 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 4.5287614, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.350701010227203, 'actor_loss': -5.755489444732666, 'hyper_actor_loss': 0.010567031241953373, 'behavior_loss': 0.26874764561653136, 'mean_batch': 8.26954460144043, 'min_batch': 7.660853004455566, 'max_batch': 8.630268573760986}
step: 39570 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 2.5616405, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6101163625717163, 'actor_loss': -5.8484642028808596, 'hyper_actor_loss': 0.010080319177359343, 'behavior_loss': 0.2389526531100273, 'mean_batch': 8.516012573242188, 'min_batch': 8.142800569534302, 'max_batch': 8.862347221374511}
step: 39580 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 2.727444, 'max_total_reward': 12.12, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.768296802043915, 'actor_loss': -5.80420069694519, 'hyper_actor_loss': 0.009933208301663398, 'behavior_loss': 0.2584370121359825, 'mean_batch': 8.454070091247559, 'min_batch': 7.855090951919555, 'max_batch': 8.801655578613282}
step: 39590 @ episode report: {'average_total_reward': 10.143, 'reward_variance': 0.908141, 'max_total_reward': 11.230001, 'min_total_reward': 8.79, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.812774014472962, 'actor_loss': -5.762157201766968, 'hyper_actor_loss': 0.010150693636387587, 'behavior_loss': 0.25009704679250716, 'mean_batch': 8.37354393005371, 'min_batch': 7.631496620178223, 'max_batch': 8.724823665618896}
step: 39600 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 2.2454169, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.171942472457886, 'actor_loss': -5.7483762264251705, 'hyper_actor_loss': 0.010243682283908128, 'behavior_loss': 0.27358281016349795, 'mean_batch': 8.387961673736573, 'min_batch': 7.512058925628662, 'max_batch': 8.773570346832276}
step: 39610 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 3.6500008, 'max_total_reward': 14.450001, 'min_total_reward': 7.9000006, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.352682065963745, 'actor_loss': -5.794347333908081, 'hyper_actor_loss': 0.010020611342042685, 'behavior_loss': 0.284068888425827, 'mean_batch': 8.385501098632812, 'min_batch': 7.841301822662354, 'max_batch': 8.727866935729981}
step: 39620 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 4.42599, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.0871228814125065, 'actor_loss': -5.753630495071411, 'hyper_actor_loss': 0.010623884852975607, 'behavior_loss': 0.25773662626743316, 'mean_batch': 8.410356998443604, 'min_batch': 7.523279333114624, 'max_batch': 8.830211448669434}
step: 39630 @ episode report: {'average_total_reward': 11.286001, 'reward_variance': 3.2831643, 'max_total_reward': 13.450001, 'min_total_reward': 7.7899995, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.195397186279297, 'actor_loss': -5.816395902633667, 'hyper_actor_loss': 0.009905861504375935, 'behavior_loss': 0.2566481366753578, 'mean_batch': 8.403529834747314, 'min_batch': 7.991151666641235, 'max_batch': 8.803433990478515}
step: 39640 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 3.1829216, 'max_total_reward': 12.34, 'min_total_reward': 5.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.18881664276123, 'actor_loss': -5.754800748825073, 'hyper_actor_loss': 0.010008074808865786, 'behavior_loss': 0.25830280482769014, 'mean_batch': 8.307960891723633, 'min_batch': 7.610294008255005, 'max_batch': 8.711787033081055}
step: 39650 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.4750447, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.932720804214478, 'actor_loss': -5.798116016387939, 'hyper_actor_loss': 0.009697060752660035, 'behavior_loss': 0.2548069432377815, 'mean_batch': 8.34857006072998, 'min_batch': 7.89865288734436, 'max_batch': 8.66065845489502}
step: 39660 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 1.896209, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.715726971626282, 'actor_loss': -5.786886310577392, 'hyper_actor_loss': 0.009820536896586417, 'behavior_loss': 0.27349192649126053, 'mean_batch': 8.452365112304687, 'min_batch': 7.744198608398437, 'max_batch': 8.798682689666748}
step: 39670 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 4.634944, 'max_total_reward': 13.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.002661848068238, 'actor_loss': -5.758278799057007, 'hyper_actor_loss': 0.00963010536506772, 'behavior_loss': 0.2573009178042412, 'mean_batch': 8.23664150238037, 'min_batch': 7.701587057113647, 'max_batch': 8.598981761932373}
step: 39680 @ episode report: {'average_total_reward': 11.419001, 'reward_variance': 4.705789, 'max_total_reward': 15.67, 'min_total_reward': 6.9, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.131206774711609, 'actor_loss': -5.765988349914551, 'hyper_actor_loss': 0.009940793365240097, 'behavior_loss': 0.2598370373249054, 'mean_batch': 8.251976013183594, 'min_batch': 7.742868375778198, 'max_batch': 8.630472087860108}
step: 39690 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 2.0637841, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.395155715942383, 'actor_loss': -5.841397953033447, 'hyper_actor_loss': 0.010004093963652849, 'behavior_loss': 0.24234416633844375, 'mean_batch': 8.5265531539917, 'min_batch': 8.076226091384887, 'max_batch': 8.934156608581542}
step: 39700 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 3.4773967, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.951589894294739, 'actor_loss': -5.807969808578491, 'hyper_actor_loss': 0.009810626227408647, 'behavior_loss': 0.249331334233284, 'mean_batch': 8.411037921905518, 'min_batch': 7.918235635757446, 'max_batch': 8.825457954406739}
step: 39710 @ episode report: {'average_total_reward': 10.753, 'reward_variance': 3.0039814, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.241071903705597, 'actor_loss': -5.824469947814942, 'hyper_actor_loss': 0.010060626361519099, 'behavior_loss': 0.24876440465450286, 'mean_batch': 8.47389621734619, 'min_batch': 7.989805889129639, 'max_batch': 8.918246936798095}
step: 39720 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 1.5166442, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.311762201786041, 'actor_loss': -5.787948226928711, 'hyper_actor_loss': 0.010163664165884257, 'behavior_loss': 0.2751657158136368, 'mean_batch': 8.367923259735107, 'min_batch': 7.8132603645324705, 'max_batch': 8.698928356170654}
step: 39730 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 2.3742287, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9000006, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.181995916366577, 'actor_loss': -5.79601035118103, 'hyper_actor_loss': 0.009962568152695894, 'behavior_loss': 0.254923976957798, 'mean_batch': 8.405838298797608, 'min_batch': 7.8384240627288815, 'max_batch': 8.742077159881593}
step: 39740 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 4.4088645, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.259381556510926, 'actor_loss': -5.821656274795532, 'hyper_actor_loss': 0.010027741082012653, 'behavior_loss': 0.2622247412800789, 'mean_batch': 8.46951503753662, 'min_batch': 7.9824730396270756, 'max_batch': 8.74431324005127}
step: 39750 @ episode report: {'average_total_reward': 11.7300005, 'reward_variance': 4.2659807, 'max_total_reward': 15.67, 'min_total_reward': 8.9, 'average_n_step': 12.5, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6624036550521852, 'actor_loss': -5.780507326126099, 'hyper_actor_loss': 0.010408652946352959, 'behavior_loss': 0.25440878570079806, 'mean_batch': 8.317799949645996, 'min_batch': 7.795252799987793, 'max_batch': 8.646296119689941}
step: 39760 @ episode report: {'average_total_reward': 10.986, 'reward_variance': 3.470665, 'max_total_reward': 14.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.190104925632477, 'actor_loss': -5.79900279045105, 'hyper_actor_loss': 0.010021876636892557, 'behavior_loss': 0.26596893817186357, 'mean_batch': 8.37651538848877, 'min_batch': 7.884801530838013, 'max_batch': 8.680667304992676}
step: 39770 @ episode report: {'average_total_reward': 10.120001, 'reward_variance': 7.3312407, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.491775488853454, 'actor_loss': -5.7757305145263675, 'hyper_actor_loss': 0.01045650327578187, 'behavior_loss': 0.2597368597984314, 'mean_batch': 8.280993366241455, 'min_batch': 7.79296612739563, 'max_batch': 8.652055263519287}
step: 39780 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.5463245, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.230039381980896, 'actor_loss': -5.816571950912476, 'hyper_actor_loss': 0.00992050589993596, 'behavior_loss': 0.2672840416431427, 'mean_batch': 8.411844158172608, 'min_batch': 7.984832811355591, 'max_batch': 8.783951568603516}
step: 39790 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 3.972102, 'max_total_reward': 15.67, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.389588713645935, 'actor_loss': -5.75666184425354, 'hyper_actor_loss': 0.010022734943777322, 'behavior_loss': 0.2677742183208466, 'mean_batch': 8.184937477111816, 'min_batch': 7.735385990142822, 'max_batch': 8.515125465393066}
step: 39800 @ episode report: {'average_total_reward': 10.009, 'reward_variance': 2.7262487, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5567448258399965, 'actor_loss': -5.80543532371521, 'hyper_actor_loss': 0.009814594872295856, 'behavior_loss': 0.25721807181835177, 'mean_batch': 8.414727020263673, 'min_batch': 7.902754831314087, 'max_batch': 8.766324234008788}
step: 39810 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.9376206, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.072992277145386, 'actor_loss': -5.820985460281372, 'hyper_actor_loss': 0.010021246038377285, 'behavior_loss': 0.27275881767272947, 'mean_batch': 8.449402809143066, 'min_batch': 7.98548731803894, 'max_batch': 8.82598524093628}
step: 39820 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.6231046, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.703529977798462, 'actor_loss': -5.8260517597198485, 'hyper_actor_loss': 0.010259743873029947, 'behavior_loss': 0.261637382209301, 'mean_batch': 8.486624717712402, 'min_batch': 7.991024208068848, 'max_batch': 8.839132595062257}
step: 39830 @ episode report: {'average_total_reward': 11.297001, 'reward_variance': 5.249542, 'max_total_reward': 14.56, 'min_total_reward': 5.68, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.569418036937714, 'actor_loss': -5.794209289550781, 'hyper_actor_loss': 0.01011934895068407, 'behavior_loss': 0.2753656417131424, 'mean_batch': 8.378199768066406, 'min_batch': 7.846969890594482, 'max_batch': 8.723366832733154}
step: 39840 @ episode report: {'average_total_reward': 11.275, 'reward_variance': 1.7141253, 'max_total_reward': 13.23, 'min_total_reward': 7.8999996, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.852279210090638, 'actor_loss': -5.824768829345703, 'hyper_actor_loss': 0.009968727827072144, 'behavior_loss': 0.26080216020345687, 'mean_batch': 8.45520486831665, 'min_batch': 8.009793376922607, 'max_batch': 8.844446849822997}
step: 39850 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 5.9146013, 'max_total_reward': 12.2300005, 'min_total_reward': 3.3500001, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.586494898796081, 'actor_loss': -5.840912532806397, 'hyper_actor_loss': 0.01004246799275279, 'behavior_loss': 0.2408122316002846, 'mean_batch': 8.562358379364014, 'min_batch': 8.040238904953004, 'max_batch': 8.965174579620362}
step: 39860 @ episode report: {'average_total_reward': 9.099001, 'reward_variance': 3.3992696, 'max_total_reward': 11.2300005, 'min_total_reward': 5.4600005, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.551355648040771, 'actor_loss': -5.848968505859375, 'hyper_actor_loss': 0.009939572587609292, 'behavior_loss': 0.25950231552124026, 'mean_batch': 8.572641086578368, 'min_batch': 8.094984149932861, 'max_batch': 8.960601806640625}
step: 39870 @ episode report: {'average_total_reward': 10.920001, 'reward_variance': 1.5238799, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.673373281955719, 'actor_loss': -5.852048730850219, 'hyper_actor_loss': 0.0099036636762321, 'behavior_loss': 0.2533216506242752, 'mean_batch': 8.597320652008056, 'min_batch': 8.09758996963501, 'max_batch': 8.970150756835938}
step: 39880 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.762364, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0561511516571045, 'actor_loss': -5.845912885665894, 'hyper_actor_loss': 0.009570165444165469, 'behavior_loss': 0.2586463108658791, 'mean_batch': 8.530048179626466, 'min_batch': 8.108761978149413, 'max_batch': 8.935527324676514}
step: 39890 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.565904, 'max_total_reward': 12.339999, 'min_total_reward': 7.7900004, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.55428102016449, 'actor_loss': -5.842644691467285, 'hyper_actor_loss': 0.01000206582248211, 'behavior_loss': 0.2763864830136299, 'mean_batch': 8.544629859924317, 'min_batch': 8.068810558319091, 'max_batch': 8.886200428009033}
step: 39900 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 5.092066, 'max_total_reward': 13.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.632768619060516, 'actor_loss': -5.855332851409912, 'hyper_actor_loss': 0.010341910179704428, 'behavior_loss': 0.2513734996318817, 'mean_batch': 8.594494342803955, 'min_batch': 8.1264319896698, 'max_batch': 8.945732593536377}
step: 39910 @ episode report: {'average_total_reward': 10.764, 'reward_variance': 1.0417845, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.49868688583374, 'actor_loss': -5.8388340950012205, 'hyper_actor_loss': 0.010853125900030135, 'behavior_loss': 0.2755348727107048, 'mean_batch': 8.548712253570557, 'min_batch': 8.03765697479248, 'max_batch': 8.87166223526001}
step: 39920 @ episode report: {'average_total_reward': 9.455, 'reward_variance': 3.2063248, 'max_total_reward': 12.01, 'min_total_reward': 6.5699997, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.707845735549927, 'actor_loss': -5.807363605499267, 'hyper_actor_loss': 0.010757153294980526, 'behavior_loss': 0.26418074071407316, 'mean_batch': 8.498530006408691, 'min_batch': 7.835812664031982, 'max_batch': 8.833962631225585}
step: 39930 @ episode report: {'average_total_reward': 10.998, 'reward_variance': 1.4804759, 'max_total_reward': 13.01, 'min_total_reward': 8.900001, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.612520527839661, 'actor_loss': -5.804465436935425, 'hyper_actor_loss': 0.01075544161722064, 'behavior_loss': 0.2585525274276733, 'mean_batch': 8.476930522918702, 'min_batch': 7.844632863998413, 'max_batch': 8.849080467224121}
step: 39940 @ episode report: {'average_total_reward': 11.175, 'reward_variance': 2.5477445, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7944424629211424, 'actor_loss': -5.8579206466674805, 'hyper_actor_loss': 0.01062726266682148, 'behavior_loss': 0.2629654183983803, 'mean_batch': 8.587955284118653, 'min_batch': 8.153177499771118, 'max_batch': 8.938702201843261}
step: 39950 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 4.521329, 'max_total_reward': 13.23, 'min_total_reward': 5.6800003, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.687138271331787, 'actor_loss': -5.865535020828247, 'hyper_actor_loss': 0.010631268844008446, 'behavior_loss': 0.26422388702630994, 'mean_batch': 8.704256153106689, 'min_batch': 8.113147687911987, 'max_batch': 9.066326713562011}
step: 39960 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 4.355981, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.837601161003112, 'actor_loss': -5.841327238082886, 'hyper_actor_loss': 0.010411442443728446, 'behavior_loss': 0.2672293305397034, 'mean_batch': 8.542483615875245, 'min_batch': 8.060803413391113, 'max_batch': 8.885349369049072}
step: 39970 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 1.1972959, 'max_total_reward': 12.12, 'min_total_reward': 8.68, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.439288806915283, 'actor_loss': -5.816163539886475, 'hyper_actor_loss': 0.010301787871867418, 'behavior_loss': 0.27052188515663145, 'mean_batch': 8.43477659225464, 'min_batch': 7.959868001937866, 'max_batch': 8.789549636840821}
step: 39980 @ episode report: {'average_total_reward': 10.931, 'reward_variance': 6.5017676, 'max_total_reward': 16.779999, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 17.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.010822689533233, 'actor_loss': -5.8491312026977536, 'hyper_actor_loss': 0.010421664081513881, 'behavior_loss': 0.2545261010527611, 'mean_batch': 8.545409870147704, 'min_batch': 8.12070345878601, 'max_batch': 8.915615653991699}
step: 39990 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 3.260081, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.334775066375732, 'actor_loss': -5.82330961227417, 'hyper_actor_loss': 0.01050600064918399, 'behavior_loss': 0.25000271052122114, 'mean_batch': 8.516752815246582, 'min_batch': 7.946332740783691, 'max_batch': 8.921067047119141}
step: 40000 @ episode report: {'average_total_reward': 11.153001, 'reward_variance': 2.1371608, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.555116462707519, 'actor_loss': -5.790870428085327, 'hyper_actor_loss': 0.010095424205064773, 'behavior_loss': 0.27212427109479903, 'mean_batch': 8.370894050598144, 'min_batch': 7.825312328338623, 'max_batch': 8.686083126068116}
step: 40010 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 3.1142435, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.006600880622864, 'actor_loss': -5.811952114105225, 'hyper_actor_loss': 0.010247306618839502, 'behavior_loss': 0.2842760533094406, 'mean_batch': 8.515570163726807, 'min_batch': 7.858949422836304, 'max_batch': 8.910000133514405}
step: 40020 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.623836, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.616934204101563, 'actor_loss': -5.849664306640625, 'hyper_actor_loss': 0.010634181555360556, 'behavior_loss': 0.27301652878522875, 'mean_batch': 8.554394340515136, 'min_batch': 8.116428327560424, 'max_batch': 8.906790065765382}
step: 40030 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 1.7712238, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.197563910484314, 'actor_loss': -5.836313629150391, 'hyper_actor_loss': 0.010592520143836737, 'behavior_loss': 0.26420732140541076, 'mean_batch': 8.580360794067383, 'min_batch': 7.995873546600341, 'max_batch': 8.974542713165283}
step: 40040 @ episode report: {'average_total_reward': 10.930999, 'reward_variance': 2.690429, 'max_total_reward': 13.12, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.671265435218811, 'actor_loss': -5.854338645935059, 'hyper_actor_loss': 0.010772394947707653, 'behavior_loss': 0.24918127655982972, 'mean_batch': 8.739098358154298, 'min_batch': 7.996189165115356, 'max_batch': 9.120412254333496}
step: 40050 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 3.3230565, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.785324764251709, 'actor_loss': -5.853857898712159, 'hyper_actor_loss': 0.010336852818727493, 'behavior_loss': 0.2546171694993973, 'mean_batch': 8.723559761047364, 'min_batch': 8.004272985458375, 'max_batch': 9.103761577606202}
step: 40060 @ episode report: {'average_total_reward': 11.963, 'reward_variance': 2.2281213, 'max_total_reward': 14.450001, 'min_total_reward': 10.01, 'average_n_step': 12.7, 'max_n_step': 15.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.822673439979553, 'actor_loss': -5.862068796157837, 'hyper_actor_loss': 0.010096052568405867, 'behavior_loss': 0.24080405682325362, 'mean_batch': 8.633514976501464, 'min_batch': 8.144401597976685, 'max_batch': 9.108956050872802}
step: 40070 @ episode report: {'average_total_reward': 10.209, 'reward_variance': 1.3009696, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.009206604957581, 'actor_loss': -5.824046230316162, 'hyper_actor_loss': 0.009950714278966188, 'behavior_loss': 0.2677267551422119, 'mean_batch': 8.60087423324585, 'min_batch': 7.889673185348511, 'max_batch': 8.993341445922852}
step: 40080 @ episode report: {'average_total_reward': 10.298, 'reward_variance': 3.2254555, 'max_total_reward': 13.45, 'min_total_reward': 6.680001, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.307538628578186, 'actor_loss': -5.855667209625244, 'hyper_actor_loss': 0.010011953767389059, 'behavior_loss': 0.25025912672281264, 'mean_batch': 8.596797561645507, 'min_batch': 8.125805997848511, 'max_batch': 8.945832633972168}
step: 40090 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 3.3725097, 'max_total_reward': 12.340001, 'min_total_reward': 5.46, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.472089576721191, 'actor_loss': -5.8621000289917, 'hyper_actor_loss': 0.010077579226344825, 'behavior_loss': 0.2773466154932976, 'mean_batch': 8.632446670532227, 'min_batch': 8.144862937927247, 'max_batch': 9.003344917297364}
step: 40100 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 3.9551044, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.745667433738708, 'actor_loss': -5.865705251693726, 'hyper_actor_loss': 0.010281483829021453, 'behavior_loss': 0.2664111256599426, 'mean_batch': 8.61966152191162, 'min_batch': 8.185113143920898, 'max_batch': 8.967287731170654}
step: 40110 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 2.1674495, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.195885944366455, 'actor_loss': -5.848340559005737, 'hyper_actor_loss': 0.01015589265152812, 'behavior_loss': 0.24966394454240798, 'mean_batch': 8.551464366912843, 'min_batch': 8.109019327163697, 'max_batch': 8.862972450256347}
step: 40120 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 1.8798841, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.128792190551758, 'actor_loss': -5.830971097946167, 'hyper_actor_loss': 0.010170145519077778, 'behavior_loss': 0.26997087001800535, 'mean_batch': 8.534611415863036, 'min_batch': 7.992945861816406, 'max_batch': 8.89210376739502}
step: 40130 @ episode report: {'average_total_reward': 10.853001, 'reward_variance': 3.5869622, 'max_total_reward': 14.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.711300802230835, 'actor_loss': -5.856466484069824, 'hyper_actor_loss': 0.010281848907470702, 'behavior_loss': 0.27042717635631563, 'mean_batch': 8.58438482284546, 'min_batch': 8.145524311065675, 'max_batch': 8.921604347229003}
step: 40140 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 4.13072, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.500107407569885, 'actor_loss': -5.865031003952026, 'hyper_actor_loss': 0.01023788470774889, 'behavior_loss': 0.25137819647789, 'mean_batch': 8.58882703781128, 'min_batch': 8.208512783050537, 'max_batch': 8.926297283172607}
step: 40150 @ episode report: {'average_total_reward': 10.188001, 'reward_variance': 1.8881967, 'max_total_reward': 12.340001, 'min_total_reward': 8.68, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.527928042411804, 'actor_loss': -5.8608513355255125, 'hyper_actor_loss': 0.010109250899404287, 'behavior_loss': 0.2603387847542763, 'mean_batch': 8.599783611297607, 'min_batch': 8.164547443389893, 'max_batch': 8.940699005126953}
step: 40160 @ episode report: {'average_total_reward': 10.942, 'reward_variance': 2.957036, 'max_total_reward': 14.56, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.065571975708008, 'actor_loss': -5.874349737167359, 'hyper_actor_loss': 0.010356871038675308, 'behavior_loss': 0.2713513717055321, 'mean_batch': 8.638199996948241, 'min_batch': 8.237952136993409, 'max_batch': 9.002425861358642}
step: 40170 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 1.5558038, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9000006, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9136338591575623, 'actor_loss': -5.89540057182312, 'hyper_actor_loss': 0.010580432042479515, 'behavior_loss': 0.26967177987098695, 'mean_batch': 8.74318332672119, 'min_batch': 8.312367630004882, 'max_batch': 9.090976238250732}
step: 40180 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 3.7429092, 'max_total_reward': 13.23, 'min_total_reward': 5.7899995, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.553460144996643, 'actor_loss': -5.898421669006348, 'hyper_actor_loss': 0.010571750346571207, 'behavior_loss': 0.2707232773303986, 'mean_batch': 8.764475345611572, 'min_batch': 8.318071174621583, 'max_batch': 9.1091383934021}
step: 40190 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 1.9707502, 'max_total_reward': 11.120002, 'min_total_reward': 6.8999996, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.117320203781128, 'actor_loss': -5.905129051208496, 'hyper_actor_loss': 0.010386957693845034, 'behavior_loss': 0.24468348026275635, 'mean_batch': 8.800943088531493, 'min_batch': 8.34134030342102, 'max_batch': 9.1245436668396}
step: 40200 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 2.3169212, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.988999509811402, 'actor_loss': -5.89117431640625, 'hyper_actor_loss': 0.01054523717612028, 'behavior_loss': 0.26721593737602234, 'mean_batch': 8.793189239501952, 'min_batch': 8.238153791427612, 'max_batch': 9.124545001983643}
step: 40210 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 4.7526846, 'max_total_reward': 13.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.618375277519226, 'actor_loss': -5.850353145599366, 'hyper_actor_loss': 0.010767124313861131, 'behavior_loss': 0.2531188830733299, 'mean_batch': 8.636948394775391, 'min_batch': 8.05116548538208, 'max_batch': 8.961627674102782}
step: 40220 @ episode report: {'average_total_reward': 11.663, 'reward_variance': 7.3794813, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.143707323074341, 'actor_loss': -5.865094757080078, 'hyper_actor_loss': 0.010273962561041117, 'behavior_loss': 0.259876523911953, 'mean_batch': 8.560453796386719, 'min_batch': 8.236185455322266, 'max_batch': 8.862743473052978}
step: 40230 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 3.9109826, 'max_total_reward': 13.340001, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6725232124328615, 'actor_loss': -5.836544132232666, 'hyper_actor_loss': 0.010332113597542048, 'behavior_loss': 0.2696350485086441, 'mean_batch': 8.591872501373292, 'min_batch': 7.98888201713562, 'max_batch': 8.911935710906983}
step: 40240 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 2.1782253, 'max_total_reward': 13.120001, 'min_total_reward': 7.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.296158742904663, 'actor_loss': -5.87828221321106, 'hyper_actor_loss': 0.01031255703419447, 'behavior_loss': 0.26326285153627393, 'mean_batch': 8.672664737701416, 'min_batch': 8.238423728942871, 'max_batch': 9.010866260528564}
step: 40250 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 2.4007409, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.564595723152161, 'actor_loss': -5.8518171310424805, 'hyper_actor_loss': 0.010331840813159942, 'behavior_loss': 0.26954931020736694, 'mean_batch': 8.640942764282226, 'min_batch': 8.062850904464721, 'max_batch': 9.005144023895264}
step: 40260 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.9721684, 'max_total_reward': 13.449999, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.170720767974854, 'actor_loss': -5.861233568191528, 'hyper_actor_loss': 0.010078698582947253, 'behavior_loss': 0.2671390548348427, 'mean_batch': 8.58708143234253, 'min_batch': 8.179280662536621, 'max_batch': 8.959350681304931}
step: 40270 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 2.3666198, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.836778068542481, 'actor_loss': -5.853824663162231, 'hyper_actor_loss': 0.009858171083033085, 'behavior_loss': 0.2632197842001915, 'mean_batch': 8.566425800323486, 'min_batch': 8.138272666931153, 'max_batch': 8.901354885101318}
step: 40280 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 1.4048498, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.01580445766449, 'actor_loss': -5.871937084197998, 'hyper_actor_loss': 0.009985662437975407, 'behavior_loss': 0.2761576667428017, 'mean_batch': 8.688249969482422, 'min_batch': 8.174162864685059, 'max_batch': 9.056607246398926}
step: 40290 @ episode report: {'average_total_reward': 11.0529995, 'reward_variance': 3.4271214, 'max_total_reward': 15.67, 'min_total_reward': 8.9, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.644837498664856, 'actor_loss': -5.821192407608033, 'hyper_actor_loss': 0.01027023047208786, 'behavior_loss': 0.2666504353284836, 'mean_batch': 8.596922779083252, 'min_batch': 7.862444019317627, 'max_batch': 8.97209529876709}
step: 40300 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 7.572669, 'max_total_reward': 15.67, 'min_total_reward': 5.7900004, 'average_n_step': 10.3, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.448985993862152, 'actor_loss': -5.83098201751709, 'hyper_actor_loss': 0.009968728572130204, 'behavior_loss': 0.26996037662029265, 'mean_batch': 8.588454151153565, 'min_batch': 7.948173236846924, 'max_batch': 8.999185848236085}
step: 40310 @ episode report: {'average_total_reward': 10.842, 'reward_variance': 3.4774349, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.780288028717041, 'actor_loss': -5.8193823337554935, 'hyper_actor_loss': 0.009628799930214881, 'behavior_loss': 0.2541554823517799, 'mean_batch': 8.482413291931152, 'min_batch': 7.955820608139038, 'max_batch': 8.86740026473999}
step: 40320 @ episode report: {'average_total_reward': 11.120001, 'reward_variance': 1.4686203, 'max_total_reward': 13.340001, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.484720349311829, 'actor_loss': -5.850863742828369, 'hyper_actor_loss': 0.00953171206638217, 'behavior_loss': 0.2602930426597595, 'mean_batch': 8.676600456237793, 'min_batch': 8.023752593994141, 'max_batch': 9.107041072845458}
step: 40330 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 1.8310444, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0567481994628904, 'actor_loss': -5.894600057601929, 'hyper_actor_loss': 0.009659718722105026, 'behavior_loss': 0.26253504008054734, 'mean_batch': 8.827117347717286, 'min_batch': 8.231765413284302, 'max_batch': 9.295316410064697}
step: 40340 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 4.309249, 'max_total_reward': 13.12, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.423096323013306, 'actor_loss': -5.872884702682495, 'hyper_actor_loss': 0.009367011487483978, 'behavior_loss': 0.2548889949917793, 'mean_batch': 8.734389877319336, 'min_batch': 8.142251539230347, 'max_batch': 9.191006755828857}
step: 40350 @ episode report: {'average_total_reward': 9.8880005, 'reward_variance': 2.429217, 'max_total_reward': 12.010001, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.951917243003845, 'actor_loss': -5.838243198394776, 'hyper_actor_loss': 0.009513755701482296, 'behavior_loss': 0.2552822679281235, 'mean_batch': 8.612159919738769, 'min_batch': 7.979150009155274, 'max_batch': 9.05514907836914}
step: 40360 @ episode report: {'average_total_reward': 10.853001, 'reward_variance': 3.7090611, 'max_total_reward': 14.45, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.058848237991333, 'actor_loss': -5.796633577346801, 'hyper_actor_loss': 0.009185790177434682, 'behavior_loss': 0.2698857143521309, 'mean_batch': 8.467069721221923, 'min_batch': 7.799826955795288, 'max_batch': 8.852115726470947}
step: 40370 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 3.2964454, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.319032955169678, 'actor_loss': -5.867249202728272, 'hyper_actor_loss': 0.00964055983349681, 'behavior_loss': 0.2692787408828735, 'mean_batch': 8.695687961578368, 'min_batch': 8.126986837387085, 'max_batch': 9.080566787719727}
step: 40380 @ episode report: {'average_total_reward': 11.175, 'reward_variance': 3.599425, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.192987585067749, 'actor_loss': -5.881568336486817, 'hyper_actor_loss': 0.010090912878513335, 'behavior_loss': 0.26180401295423505, 'mean_batch': 8.790630531311034, 'min_batch': 8.16952109336853, 'max_batch': 9.189253616333009}
step: 40390 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 2.0817409, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.604721331596375, 'actor_loss': -5.851120138168335, 'hyper_actor_loss': 0.009662715438753366, 'behavior_loss': 0.2495941162109375, 'mean_batch': 8.547783851623535, 'min_batch': 8.134507083892823, 'max_batch': 8.880427837371826}
step: 40400 @ episode report: {'average_total_reward': 9.754, 'reward_variance': 4.3138046, 'max_total_reward': 13.45, 'min_total_reward': 6.4599996, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.895601511001587, 'actor_loss': -5.827753067016602, 'hyper_actor_loss': 0.00953885493800044, 'behavior_loss': 0.2669295459985733, 'mean_batch': 8.488099193572998, 'min_batch': 8.00637345314026, 'max_batch': 8.80967321395874}
step: 40410 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 3.916024, 'max_total_reward': 14.559999, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.660146164894104, 'actor_loss': -5.872123718261719, 'hyper_actor_loss': 0.009405827708542347, 'behavior_loss': 0.2662725657224655, 'mean_batch': 8.61208896636963, 'min_batch': 8.245014667510986, 'max_batch': 8.975896263122559}
step: 40420 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 0.7713838, 'max_total_reward': 12.12, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1257117748260494, 'actor_loss': -5.886796665191651, 'hyper_actor_loss': 0.009731358848512173, 'behavior_loss': 0.2557471603155136, 'mean_batch': 8.708527565002441, 'min_batch': 8.273877239227295, 'max_batch': 9.063675212860108}
step: 40430 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.668424, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.371975111961365, 'actor_loss': -5.878469324111938, 'hyper_actor_loss': 0.009610885102301837, 'behavior_loss': 0.25772403478622435, 'mean_batch': 8.63031463623047, 'min_batch': 8.279655170440673, 'max_batch': 9.010737228393555}
step: 40440 @ episode report: {'average_total_reward': 8.877001, 'reward_variance': 6.124541, 'max_total_reward': 12.34, 'min_total_reward': 4.35, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.553843069076538, 'actor_loss': -5.821107053756714, 'hyper_actor_loss': 0.009621434565633535, 'behavior_loss': 0.26571509391069414, 'mean_batch': 8.468752574920654, 'min_batch': 7.9691071033477785, 'max_batch': 8.84500331878662}
step: 40450 @ episode report: {'average_total_reward': 11.075001, 'reward_variance': 7.4455657, 'max_total_reward': 15.67, 'min_total_reward': 6.68, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.59355411529541, 'actor_loss': -5.891673469543457, 'hyper_actor_loss': 0.009406897332519292, 'behavior_loss': 0.24374806582927705, 'mean_batch': 8.720739650726319, 'min_batch': 8.302715396881103, 'max_batch': 9.125265121459961}
step: 40460 @ episode report: {'average_total_reward': 10.109001, 'reward_variance': 1.2331893, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.394236826896668, 'actor_loss': -5.855957984924316, 'hyper_actor_loss': 0.009409057255834342, 'behavior_loss': 0.27235479056835177, 'mean_batch': 8.557502555847169, 'min_batch': 8.16503348350525, 'max_batch': 8.94889497756958}
step: 40470 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 3.1550765, 'max_total_reward': 14.56, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.247863149642944, 'actor_loss': -5.849587488174438, 'hyper_actor_loss': 0.009196042362600566, 'behavior_loss': 0.25863882154226303, 'mean_batch': 8.509897422790527, 'min_batch': 8.157902908325195, 'max_batch': 8.910313320159911}
step: 40480 @ episode report: {'average_total_reward': 11.375, 'reward_variance': 1.5951252, 'max_total_reward': 13.2300005, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.072700715065002, 'actor_loss': -5.8940356254577635, 'hyper_actor_loss': 0.009131580870598555, 'behavior_loss': 0.256813308596611, 'mean_batch': 8.749912452697753, 'min_batch': 8.299661350250243, 'max_batch': 9.134050273895264}
step: 40490 @ episode report: {'average_total_reward': 10.432001, 'reward_variance': 0.9756964, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3864504337310795, 'actor_loss': -5.888807392120361, 'hyper_actor_loss': 0.009530581068247557, 'behavior_loss': 0.24608348906040192, 'mean_batch': 8.683004760742188, 'min_batch': 8.314954566955567, 'max_batch': 9.063754081726074}
step: 40500 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 6.8870454, 'max_total_reward': 13.450001, 'min_total_reward': 3.46, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.556936168670655, 'actor_loss': -5.837650346755981, 'hyper_actor_loss': 0.009482099302113056, 'behavior_loss': 0.26381251513957976, 'mean_batch': 8.537644100189208, 'min_batch': 8.037998723983765, 'max_batch': 8.953229331970215}
step: 40510 @ episode report: {'average_total_reward': 10.320001, 'reward_variance': 1.4165196, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7002214908599855, 'actor_loss': -5.852735090255737, 'hyper_actor_loss': 0.009279859904199838, 'behavior_loss': 0.2697692856192589, 'mean_batch': 8.547074222564698, 'min_batch': 8.148628091812133, 'max_batch': 8.89860496520996}
step: 40520 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.7400014, 'max_total_reward': 12.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.315667986869812, 'actor_loss': -5.847588777542114, 'hyper_actor_loss': 0.009407953824847937, 'behavior_loss': 0.2828326940536499, 'mean_batch': 8.524048328399658, 'min_batch': 8.128700780868531, 'max_batch': 8.82457914352417}
step: 40530 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 1.1588361, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.707517957687378, 'actor_loss': -5.858384227752685, 'hyper_actor_loss': 0.009478027559816837, 'behavior_loss': 0.2563537463545799, 'mean_batch': 8.561737632751464, 'min_batch': 8.18025770187378, 'max_batch': 8.93283462524414}
step: 40540 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 2.6988153, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.272726547718048, 'actor_loss': -5.855256366729736, 'hyper_actor_loss': 0.009842851385474204, 'behavior_loss': 0.25554530024528505, 'mean_batch': 8.745969009399413, 'min_batch': 8.011158847808838, 'max_batch': 9.088754558563233}
step: 40550 @ episode report: {'average_total_reward': 10.941999, 'reward_variance': 2.1933563, 'max_total_reward': 13.340001, 'min_total_reward': 7.7900004, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.662925171852112, 'actor_loss': -5.853245401382447, 'hyper_actor_loss': 0.009373727347701788, 'behavior_loss': 0.26871643364429476, 'mean_batch': 8.579001903533936, 'min_batch': 8.12442684173584, 'max_batch': 8.886703968048096}
step: 40560 @ episode report: {'average_total_reward': 11.164, 'reward_variance': 7.7733054, 'max_total_reward': 15.56, 'min_total_reward': 6.8999996, 'average_n_step': 12.0, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5523429870605465, 'actor_loss': -5.851246070861817, 'hyper_actor_loss': 0.009350573364645242, 'behavior_loss': 0.2577491194009781, 'mean_batch': 8.588399696350098, 'min_batch': 8.101189374923706, 'max_batch': 8.902483940124512}
step: 40570 @ episode report: {'average_total_reward': 10.209002, 'reward_variance': 3.669909, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.965625882148743, 'actor_loss': -5.876624870300293, 'hyper_actor_loss': 0.009417148772627115, 'behavior_loss': 0.2600300073623657, 'mean_batch': 8.673005962371827, 'min_batch': 8.225501585006715, 'max_batch': 9.005090427398681}
step: 40580 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 2.070445, 'max_total_reward': 12.34, 'min_total_reward': 7.569999, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.272520589828491, 'actor_loss': -5.866532230377198, 'hyper_actor_loss': 0.009299693536013365, 'behavior_loss': 0.26235451400279997, 'mean_batch': 8.610893440246581, 'min_batch': 8.199755382537841, 'max_batch': 8.985921096801757}
step: 40590 @ episode report: {'average_total_reward': 10.587, 'reward_variance': 4.0230017, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.66670982837677, 'actor_loss': -5.889251804351806, 'hyper_actor_loss': 0.009403748530894518, 'behavior_loss': 0.2683152109384537, 'mean_batch': 8.711261367797851, 'min_batch': 8.292129039764404, 'max_batch': 9.089585781097412}
step: 40600 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 0.61490107, 'max_total_reward': 12.2300005, 'min_total_reward': 9.79, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.0289838254451755, 'actor_loss': -5.864150476455689, 'hyper_actor_loss': 0.009275003336369991, 'behavior_loss': 0.255854032933712, 'mean_batch': 8.672493934631348, 'min_batch': 8.128940057754516, 'max_batch': 9.119340896606445}
step: 40610 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 3.0266643, 'max_total_reward': 12.34, 'min_total_reward': 6.9000006, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.803104054927826, 'actor_loss': -5.865121698379516, 'hyper_actor_loss': 0.009578063897788525, 'behavior_loss': 0.2674844145774841, 'mean_batch': 8.642780017852782, 'min_batch': 8.160672426223755, 'max_batch': 9.029727745056153}
step: 40620 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.8191442, 'max_total_reward': 12.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.414373254776001, 'actor_loss': -5.856288099288941, 'hyper_actor_loss': 0.009199295379221439, 'behavior_loss': 0.25754462331533434, 'mean_batch': 8.562766647338867, 'min_batch': 8.162970638275146, 'max_batch': 8.920772361755372}
step: 40630 @ episode report: {'average_total_reward': 10.521, 'reward_variance': 6.0175295, 'max_total_reward': 14.56, 'min_total_reward': 6.7900004, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.374638271331787, 'actor_loss': -5.842078018188476, 'hyper_actor_loss': 0.009062347561120987, 'behavior_loss': 0.27364360690116885, 'mean_batch': 8.487702751159668, 'min_batch': 8.118127155303956, 'max_batch': 8.88747205734253}
step: 40640 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 4.4269037, 'max_total_reward': 12.34, 'min_total_reward': 6.57, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.585348129272461, 'actor_loss': -5.84211950302124, 'hyper_actor_loss': 0.00909571275115013, 'behavior_loss': 0.2581056982278824, 'mean_batch': 8.553926753997803, 'min_batch': 8.057592058181763, 'max_batch': 8.928505992889404}
step: 40650 @ episode report: {'average_total_reward': 11.519, 'reward_variance': 2.5087295, 'max_total_reward': 14.559999, 'min_total_reward': 8.9, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.868643510341644, 'actor_loss': -5.830935716629028, 'hyper_actor_loss': 0.008913405146449805, 'behavior_loss': 0.2728349730372429, 'mean_batch': 8.564055633544921, 'min_batch': 7.966523265838623, 'max_batch': 8.903873443603516}
step: 40660 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 1.4958236, 'max_total_reward': 12.23, 'min_total_reward': 7.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.974744510650635, 'actor_loss': -5.78773980140686, 'hyper_actor_loss': 0.008939080126583576, 'behavior_loss': 0.26051890999078753, 'mean_batch': 8.412012577056885, 'min_batch': 7.771097660064697, 'max_batch': 8.748770713806152}
step: 40670 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 2.0274222, 'max_total_reward': 12.340001, 'min_total_reward': 7.7899995, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.471792352199555, 'actor_loss': -5.842200136184692, 'hyper_actor_loss': 0.008731525857001543, 'behavior_loss': 0.2661611780524254, 'mean_batch': 8.531528854370118, 'min_batch': 8.079210042953491, 'max_batch': 8.91965627670288}
step: 40680 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 2.5684557, 'max_total_reward': 13.23, 'min_total_reward': 7.899999, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.512299597263336, 'actor_loss': -5.865514516830444, 'hyper_actor_loss': 0.008516875375062228, 'behavior_loss': 0.25472617894411087, 'mean_batch': 8.591494274139404, 'min_batch': 8.2100399017334, 'max_batch': 8.96047239303589}
step: 40690 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.4893638, 'max_total_reward': 12.23, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.715573501586914, 'actor_loss': -5.835202264785766, 'hyper_actor_loss': 0.008784237504005431, 'behavior_loss': 0.2604474797844887, 'mean_batch': 8.549824333190918, 'min_batch': 8.009243202209472, 'max_batch': 8.899508285522462}
step: 40700 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 7.819968, 'max_total_reward': 13.45, 'min_total_reward': 4.68, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.729469919204712, 'actor_loss': -5.868591070175171, 'hyper_actor_loss': 0.00878687361255288, 'behavior_loss': 0.2621989756822586, 'mean_batch': 8.645883369445801, 'min_batch': 8.185365152359008, 'max_batch': 8.957761573791505}
step: 40710 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 4.044645, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.965557098388672, 'actor_loss': -5.900570678710937, 'hyper_actor_loss': 0.008810637705028056, 'behavior_loss': 0.2749131962656975, 'mean_batch': 8.765027332305909, 'min_batch': 8.335400676727295, 'max_batch': 9.0944655418396}
step: 40720 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 6.1730766, 'max_total_reward': 13.34, 'min_total_reward': 3.46, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.750491046905518, 'actor_loss': -5.84830412864685, 'hyper_actor_loss': 0.008875609282404185, 'behavior_loss': 0.2537648886442184, 'mean_batch': 8.521105670928955, 'min_batch': 8.13752007484436, 'max_batch': 8.871877861022949}
step: 40730 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 1.0673639, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0558572769165036, 'actor_loss': -5.808758878707886, 'hyper_actor_loss': 0.009244570136070251, 'behavior_loss': 0.2711154863238335, 'mean_batch': 8.434456062316894, 'min_batch': 7.905373764038086, 'max_batch': 8.74074182510376}
step: 40740 @ episode report: {'average_total_reward': 10.542002, 'reward_variance': 4.903896, 'max_total_reward': 14.56, 'min_total_reward': 5.7900004, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.617253351211548, 'actor_loss': -5.8714946746826175, 'hyper_actor_loss': 0.009350266866385936, 'behavior_loss': 0.2602342441678047, 'mean_batch': 8.677532958984376, 'min_batch': 8.181355857849121, 'max_batch': 9.012432765960693}
step: 40750 @ episode report: {'average_total_reward': 11.264001, 'reward_variance': 1.6603038, 'max_total_reward': 12.34, 'min_total_reward': 7.7900004, 'average_n_step': 12.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.532634305953979, 'actor_loss': -5.878650093078614, 'hyper_actor_loss': 0.009122174326330423, 'behavior_loss': 0.26832130551338196, 'mean_batch': 8.670276260375976, 'min_batch': 8.243195629119873, 'max_batch': 9.039901638031006}
step: 40760 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 3.3339844, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.66856153011322, 'actor_loss': -5.84743185043335, 'hyper_actor_loss': 0.009176565427333116, 'behavior_loss': 0.2564109668135643, 'mean_batch': 8.5503080368042, 'min_batch': 8.10290207862854, 'max_batch': 8.890810871124268}
step: 40770 @ episode report: {'average_total_reward': 10.320002, 'reward_variance': 4.2074594, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.720151805877686, 'actor_loss': -5.8566954135894775, 'hyper_actor_loss': 0.009073492791503667, 'behavior_loss': 0.27798696905374526, 'mean_batch': 8.574641704559326, 'min_batch': 8.154995155334472, 'max_batch': 8.897146415710449}
step: 40780 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 4.320325, 'max_total_reward': 14.34, 'min_total_reward': 7.6800003, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.816098737716675, 'actor_loss': -5.844975233078003, 'hyper_actor_loss': 0.009264830872416497, 'behavior_loss': 0.2619451925158501, 'mean_batch': 8.533723640441895, 'min_batch': 8.097868824005127, 'max_batch': 8.904204559326171}
step: 40790 @ episode report: {'average_total_reward': 9.577, 'reward_variance': 4.2321215, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.084792375564575, 'actor_loss': -5.83510389328003, 'hyper_actor_loss': 0.009216483868658542, 'behavior_loss': 0.2533345267176628, 'mean_batch': 8.543456935882569, 'min_batch': 8.00959358215332, 'max_batch': 9.022225666046143}
step: 40800 @ episode report: {'average_total_reward': 11.208, 'reward_variance': 2.7369764, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5935911417007445, 'actor_loss': -5.868312740325928, 'hyper_actor_loss': 0.008829833287745715, 'behavior_loss': 0.2777590870857239, 'mean_batch': 8.640309524536132, 'min_batch': 8.186696863174438, 'max_batch': 9.025931549072265}
step: 40810 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 1.4420998, 'max_total_reward': 12.23, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.825840282440185, 'actor_loss': -5.835268783569336, 'hyper_actor_loss': 0.009278511349111795, 'behavior_loss': 0.2875508427619934, 'mean_batch': 8.590494537353516, 'min_batch': 7.979043865203858, 'max_batch': 8.995357990264893}
step: 40820 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 3.650956, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.419537782669067, 'actor_loss': -5.83574595451355, 'hyper_actor_loss': 0.009130549896508456, 'behavior_loss': 0.2529642105102539, 'mean_batch': 8.530845737457275, 'min_batch': 8.028221607208252, 'max_batch': 8.92278757095337}
step: 40830 @ episode report: {'average_total_reward': 10.775, 'reward_variance': 7.6552057, 'max_total_reward': 14.56, 'min_total_reward': 3.46, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7206141471862795, 'actor_loss': -5.847904014587402, 'hyper_actor_loss': 0.008741084672510623, 'behavior_loss': 0.27079697102308276, 'mean_batch': 8.585906600952148, 'min_batch': 8.073093605041503, 'max_batch': 8.917265701293946}
step: 40840 @ episode report: {'average_total_reward': 11.142, 'reward_variance': 3.2078164, 'max_total_reward': 14.56, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7478396654129025, 'actor_loss': -5.834803295135498, 'hyper_actor_loss': 0.008754738233983516, 'behavior_loss': 0.2546286016702652, 'mean_batch': 8.495940017700196, 'min_batch': 8.051240587234497, 'max_batch': 8.887506484985352}
step: 40850 @ episode report: {'average_total_reward': 9.321, 'reward_variance': 7.3577285, 'max_total_reward': 13.45, 'min_total_reward': 3.5700002, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.569826316833496, 'actor_loss': -5.848694276809693, 'hyper_actor_loss': 0.008757037576287985, 'behavior_loss': 0.2398779958486557, 'mean_batch': 8.543735980987549, 'min_batch': 8.118279266357423, 'max_batch': 8.949841117858886}
step: 40860 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 4.63015, 'max_total_reward': 15.450001, 'min_total_reward': 8.570001, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.1689917087554935, 'actor_loss': -5.835926961898804, 'hyper_actor_loss': 0.009085026662796735, 'behavior_loss': 0.25638180524110793, 'mean_batch': 8.508871936798096, 'min_batch': 8.049075031280518, 'max_batch': 8.882842540740967}
step: 40870 @ episode report: {'average_total_reward': 10.920001, 'reward_variance': 1.4506202, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.739695429801941, 'actor_loss': -5.813708305358887, 'hyper_actor_loss': 0.009206030983477831, 'behavior_loss': 0.2721498027443886, 'mean_batch': 8.497285652160645, 'min_batch': 7.891631984710694, 'max_batch': 8.835508346557617}
step: 40880 @ episode report: {'average_total_reward': 10.408999, 'reward_variance': 1.8962088, 'max_total_reward': 13.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7358301162719725, 'actor_loss': -5.840997886657715, 'hyper_actor_loss': 0.009131237864494324, 'behavior_loss': 0.26689624786376953, 'mean_batch': 8.579711055755615, 'min_batch': 8.026993036270142, 'max_batch': 8.941888618469239}
step: 40890 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 4.3621006, 'max_total_reward': 12.12, 'min_total_reward': 5.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.795162868499756, 'actor_loss': -5.830547904968261, 'hyper_actor_loss': 0.00883625615388155, 'behavior_loss': 0.279301680624485, 'mean_batch': 8.506618022918701, 'min_batch': 8.013394451141357, 'max_batch': 8.844274425506592}
step: 40900 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 4.6575556, 'max_total_reward': 11.23, 'min_total_reward': 3.46, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.794959783554077, 'actor_loss': -5.832927274703979, 'hyper_actor_loss': 0.009218103624880314, 'behavior_loss': 0.2601108193397522, 'mean_batch': 8.491774845123292, 'min_batch': 8.040974283218384, 'max_batch': 8.86465139389038}
step: 40910 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 3.5559807, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.16797034740448, 'actor_loss': -5.842698860168457, 'hyper_actor_loss': 0.009349353425204755, 'behavior_loss': 0.2712701022624969, 'mean_batch': 8.64703140258789, 'min_batch': 7.987943029403686, 'max_batch': 9.09275188446045}
step: 40920 @ episode report: {'average_total_reward': 11.353001, 'reward_variance': 2.3427005, 'max_total_reward': 14.34, 'min_total_reward': 9.01, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.274791741371155, 'actor_loss': -5.877953433990479, 'hyper_actor_loss': 0.009127394761890173, 'behavior_loss': 0.26016887575387954, 'mean_batch': 8.721132183074952, 'min_batch': 8.196598482131957, 'max_batch': 9.112569904327392}
step: 40930 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 3.9239357, 'max_total_reward': 14.559999, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.992808246612549, 'actor_loss': -5.866826820373535, 'hyper_actor_loss': 0.009231678303331136, 'behavior_loss': 0.2807955786585808, 'mean_batch': 8.585880184173584, 'min_batch': 8.226408958435059, 'max_batch': 8.912110519409179}
step: 40940 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 9.276682, 'max_total_reward': 13.450001, 'min_total_reward': 2.24, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0805723667144775, 'actor_loss': -5.810100269317627, 'hyper_actor_loss': 0.009186749067157506, 'behavior_loss': 0.2657729238271713, 'mean_batch': 8.417569255828857, 'min_batch': 7.929602527618409, 'max_batch': 8.786809349060059}
step: 40950 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.6773162, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.191561055183411, 'actor_loss': -5.8327775478363035, 'hyper_actor_loss': 0.009319441020488739, 'behavior_loss': 0.2407487601041794, 'mean_batch': 8.631786346435547, 'min_batch': 7.953798007965088, 'max_batch': 8.994354438781738}
step: 40960 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 1.4982439, 'max_total_reward': 12.339999, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.00492314696312, 'actor_loss': -5.8761660099029545, 'hyper_actor_loss': 0.009416775498539209, 'behavior_loss': 0.26913001090288163, 'mean_batch': 8.660499095916748, 'min_batch': 8.233829402923584, 'max_batch': 9.03280553817749}
step: 40970 @ episode report: {'average_total_reward': 10.408999, 'reward_variance': 8.052069, 'max_total_reward': 14.559999, 'min_total_reward': 3.35, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.81095552444458, 'actor_loss': -5.862938690185547, 'hyper_actor_loss': 0.009358150139451026, 'behavior_loss': 0.2708753257989883, 'mean_batch': 8.572093677520751, 'min_batch': 8.207582092285156, 'max_batch': 8.881377696990967}
step: 40980 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 1.4633849, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.091767406463623, 'actor_loss': -5.8288709163665775, 'hyper_actor_loss': 0.009471236262470484, 'behavior_loss': 0.2613525360822678, 'mean_batch': 8.597780704498291, 'min_batch': 7.92154541015625, 'max_batch': 8.956723976135255}
step: 40990 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 1.2150615, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.793862533569336, 'actor_loss': -5.879438877105713, 'hyper_actor_loss': 0.009074158873409033, 'behavior_loss': 0.2712818458676338, 'mean_batch': 8.70825777053833, 'min_batch': 8.213517475128175, 'max_batch': 9.083450889587402}
step: 41000 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 5.4349046, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.673411655426025, 'actor_loss': -5.886632776260376, 'hyper_actor_loss': 0.009207922220230102, 'behavior_loss': 0.24823179394006728, 'mean_batch': 8.755290603637695, 'min_batch': 8.23146367073059, 'max_batch': 9.098277759552001}
step: 41010 @ episode report: {'average_total_reward': 10.297999, 'reward_variance': 4.2670364, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.599592924118042, 'actor_loss': -5.823002481460572, 'hyper_actor_loss': 0.008791553229093552, 'behavior_loss': 0.2602457642555237, 'mean_batch': 8.45102949142456, 'min_batch': 7.999795198440552, 'max_batch': 8.777737808227538}
step: 41020 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.3661845, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.981754899024963, 'actor_loss': -5.857534742355346, 'hyper_actor_loss': 0.008865701593458652, 'behavior_loss': 0.26480031460523606, 'mean_batch': 8.586026763916015, 'min_batch': 8.151653003692626, 'max_batch': 9.026250076293945}
step: 41030 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 2.2882009, 'max_total_reward': 12.339999, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5093665599823, 'actor_loss': -5.863292074203491, 'hyper_actor_loss': 0.00884826947003603, 'behavior_loss': 0.2751652434468269, 'mean_batch': 8.65086669921875, 'min_batch': 8.13862681388855, 'max_batch': 8.987731170654296}
step: 41040 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 2.0286644, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0504943370819095, 'actor_loss': -5.858635759353637, 'hyper_actor_loss': 0.008765034098178148, 'behavior_loss': 0.25135874301195144, 'mean_batch': 8.582559585571289, 'min_batch': 8.162283611297607, 'max_batch': 8.96971378326416}
step: 41050 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 2.2939155, 'max_total_reward': 13.339999, 'min_total_reward': 7.9000006, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.128310203552246, 'actor_loss': -5.8300268173217775, 'hyper_actor_loss': 0.008768909890204669, 'behavior_loss': 0.25544115900993347, 'mean_batch': 8.510686302185059, 'min_batch': 8.003684139251709, 'max_batch': 8.859464931488038}
step: 41060 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 5.3188205, 'max_total_reward': 13.340001, 'min_total_reward': 5.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5818137884140016, 'actor_loss': -5.870866060256958, 'hyper_actor_loss': 0.0087734529748559, 'behavior_loss': 0.2577835440635681, 'mean_batch': 8.651413726806641, 'min_batch': 8.20047698020935, 'max_batch': 8.98613748550415}
step: 41070 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 4.3541803, 'max_total_reward': 14.56, 'min_total_reward': 7.68, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.794572877883911, 'actor_loss': -5.896708917617798, 'hyper_actor_loss': 0.008423601090908051, 'behavior_loss': 0.26077875792980193, 'mean_batch': 8.71275224685669, 'min_batch': 8.352308464050292, 'max_batch': 9.070876979827881}
step: 41080 @ episode report: {'average_total_reward': 9.754, 'reward_variance': 3.6696033, 'max_total_reward': 13.449999, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5683772504329685, 'actor_loss': -5.84736819267273, 'hyper_actor_loss': 0.00875769816339016, 'behavior_loss': 0.2585447981953621, 'mean_batch': 8.51199655532837, 'min_batch': 8.137702655792236, 'max_batch': 8.776387023925782}
step: 41090 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 3.4798553, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.618920993804932, 'actor_loss': -5.8279579162597654, 'hyper_actor_loss': 0.008783942181617021, 'behavior_loss': 0.26806572526693345, 'mean_batch': 8.500504875183106, 'min_batch': 7.996072244644165, 'max_batch': 8.878311729431152}
step: 41100 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 3.502189, 'max_total_reward': 14.559999, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4061225891113285, 'actor_loss': -5.828628635406494, 'hyper_actor_loss': 0.008607054781168699, 'behavior_loss': 0.2728870496153831, 'mean_batch': 8.559641075134277, 'min_batch': 7.956466770172119, 'max_batch': 8.912992000579834}
step: 41110 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 5.9384437, 'max_total_reward': 14.34, 'min_total_reward': 4.57, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.679893803596497, 'actor_loss': -5.872284460067749, 'hyper_actor_loss': 0.0085304937325418, 'behavior_loss': 0.2646892458200455, 'mean_batch': 8.629675674438477, 'min_batch': 8.229310989379883, 'max_batch': 8.932926750183105}
step: 41120 @ episode report: {'average_total_reward': 9.877, 'reward_variance': 3.6209812, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.324482035636902, 'actor_loss': -5.829355192184448, 'hyper_actor_loss': 0.008534888178110123, 'behavior_loss': 0.2755894660949707, 'mean_batch': 8.56537389755249, 'min_batch': 7.953163146972656, 'max_batch': 8.892919731140136}
step: 41130 @ episode report: {'average_total_reward': 10.876001, 'reward_variance': 1.9334042, 'max_total_reward': 14.23, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.911407160758972, 'actor_loss': -5.815002727508545, 'hyper_actor_loss': 0.008517677057534456, 'behavior_loss': 0.24582609087228774, 'mean_batch': 8.466558933258057, 'min_batch': 7.928199338912964, 'max_batch': 8.789339923858643}
step: 41140 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 2.615356, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.638895893096924, 'actor_loss': -5.836043787002564, 'hyper_actor_loss': 0.008354790229350328, 'behavior_loss': 0.26942460536956786, 'mean_batch': 8.503082275390625, 'min_batch': 8.060210371017456, 'max_batch': 8.858760356903076}
step: 41150 @ episode report: {'average_total_reward': 10.608999, 'reward_variance': 4.82681, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.879883503913879, 'actor_loss': -5.834140920639038, 'hyper_actor_loss': 0.008323497045785189, 'behavior_loss': 0.24150197803974152, 'mean_batch': 8.559203243255615, 'min_batch': 7.991674184799194, 'max_batch': 8.875508785247803}
step: 41160 @ episode report: {'average_total_reward': 11.297, 'reward_variance': 5.964382, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.857618117332459, 'actor_loss': -5.858253145217896, 'hyper_actor_loss': 0.008357588574290276, 'behavior_loss': 0.2656342923641205, 'mean_batch': 8.595545673370362, 'min_batch': 8.151963376998902, 'max_batch': 8.900988864898682}
step: 41170 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 1.6982435, 'max_total_reward': 12.23, 'min_total_reward': 7.6800003, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.010720038414002, 'actor_loss': -5.888165140151978, 'hyper_actor_loss': 0.008504080958664418, 'behavior_loss': 0.23518934845924377, 'mean_batch': 8.687118816375733, 'min_batch': 8.30596170425415, 'max_batch': 9.033153629302978}
step: 41180 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 1.5917366, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.220892238616943, 'actor_loss': -5.894224214553833, 'hyper_actor_loss': 0.008585726097226142, 'behavior_loss': 0.26554860919713974, 'mean_batch': 8.760651969909668, 'min_batch': 8.285929107666016, 'max_batch': 9.089803314208984}
step: 41190 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 1.4111485, 'max_total_reward': 13.23, 'min_total_reward': 9.01, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.12824285030365, 'actor_loss': -5.870021963119507, 'hyper_actor_loss': 0.00894249975681305, 'behavior_loss': 0.26694250851869583, 'mean_batch': 8.632801723480224, 'min_batch': 8.2086772441864, 'max_batch': 8.94829626083374}
step: 41200 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 9.099985, 'max_total_reward': 12.34, 'min_total_reward': 2.2400002, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.686741852760315, 'actor_loss': -5.843776512145996, 'hyper_actor_loss': 0.00879158517345786, 'behavior_loss': 0.25546569675207137, 'mean_batch': 8.501042461395263, 'min_batch': 8.11926965713501, 'max_batch': 8.822025203704834}
step: 41210 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 4.582969, 'max_total_reward': 14.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.0923259973526, 'actor_loss': -5.885299634933472, 'hyper_actor_loss': 0.00868006907403469, 'behavior_loss': 0.2723619550466537, 'mean_batch': 8.663109397888183, 'min_batch': 8.30466194152832, 'max_batch': 8.977212524414062}
step: 41220 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 4.877589, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.156318831443786, 'actor_loss': -5.893834066390991, 'hyper_actor_loss': 0.008438295032829047, 'behavior_loss': 0.25609290450811384, 'mean_batch': 8.706661796569824, 'min_batch': 8.333877182006836, 'max_batch': 9.065610599517822}
step: 41230 @ episode report: {'average_total_reward': 10.831001, 'reward_variance': 3.4968288, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.405606269836426, 'actor_loss': -5.861686754226684, 'hyper_actor_loss': 0.00853884955868125, 'behavior_loss': 0.26322462409734726, 'mean_batch': 8.576652717590331, 'min_batch': 8.193435335159302, 'max_batch': 8.889217567443847}
step: 41240 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 5.311916, 'max_total_reward': 14.2300005, 'min_total_reward': 7.7899995, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.758358311653137, 'actor_loss': -5.8139266014099125, 'hyper_actor_loss': 0.008419846603646874, 'behavior_loss': 0.260373392701149, 'mean_batch': 8.44693307876587, 'min_batch': 7.942568397521972, 'max_batch': 8.744299697875977}
step: 41250 @ episode report: {'average_total_reward': 9.222001, 'reward_variance': 6.269217, 'max_total_reward': 12.2300005, 'min_total_reward': 3.02, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.755245089530945, 'actor_loss': -5.876341009140015, 'hyper_actor_loss': 0.008305242378264665, 'behavior_loss': 0.26153710633516314, 'mean_batch': 8.610231113433837, 'min_batch': 8.281271171569824, 'max_batch': 8.920332336425782}
step: 41260 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 4.577384, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.324892830848694, 'actor_loss': -5.893068599700928, 'hyper_actor_loss': 0.008275444339960813, 'behavior_loss': 0.2578207850456238, 'mean_batch': 8.693927001953124, 'min_batch': 8.340467929840088, 'max_batch': 8.990443706512451}
step: 41270 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 1.5504358, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.991638016700745, 'actor_loss': -5.858648872375488, 'hyper_actor_loss': 0.008130554761737584, 'behavior_loss': 0.2613390862941742, 'mean_batch': 8.571547794342042, 'min_batch': 8.173779344558715, 'max_batch': 8.914529800415039}
step: 41280 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 1.5589567, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5290216445922855, 'actor_loss': -5.880377244949341, 'hyper_actor_loss': 0.008241224102675915, 'behavior_loss': 0.2724257245659828, 'mean_batch': 8.657991027832031, 'min_batch': 8.26889762878418, 'max_batch': 9.021128082275391}
step: 41290 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 3.7774956, 'max_total_reward': 14.45, 'min_total_reward': 6.680001, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.435448718070984, 'actor_loss': -5.87696328163147, 'hyper_actor_loss': 0.00802363627590239, 'behavior_loss': 0.26779956966638563, 'mean_batch': 8.632592391967773, 'min_batch': 8.265126609802246, 'max_batch': 8.959390544891358}
step: 41300 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 1.23557, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.228948736190796, 'actor_loss': -5.861484384536743, 'hyper_actor_loss': 0.00824646968394518, 'behavior_loss': 0.2527708739042282, 'mean_batch': 8.639399147033691, 'min_batch': 8.13607931137085, 'max_batch': 9.025260066986084}
step: 41310 @ episode report: {'average_total_reward': 11.031, 'reward_variance': 1.8987488, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.406588625907898, 'actor_loss': -5.828030443191528, 'hyper_actor_loss': 0.008173382887616754, 'behavior_loss': 0.2731160491704941, 'mean_batch': 8.567714595794678, 'min_batch': 7.938140773773194, 'max_batch': 8.938022041320801}
step: 41320 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 5.9373655, 'max_total_reward': 14.450001, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.587466526031494, 'actor_loss': -5.803456354141235, 'hyper_actor_loss': 0.0081053102388978, 'behavior_loss': 0.25103569477796556, 'mean_batch': 8.440569114685058, 'min_batch': 7.8661058902740475, 'max_batch': 8.80023136138916}
step: 41330 @ episode report: {'average_total_reward': 11.209002, 'reward_variance': 3.19927, 'max_total_reward': 14.450001, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.150691676139831, 'actor_loss': -5.835574960708618, 'hyper_actor_loss': 0.008157180529087782, 'behavior_loss': 0.2693342760205269, 'mean_batch': 8.510135936737061, 'min_batch': 8.045226955413819, 'max_batch': 8.848310565948486}
step: 41340 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 2.01831, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.882974219322205, 'actor_loss': -5.8626597881317135, 'hyper_actor_loss': 0.007942427741363644, 'behavior_loss': 0.26033723801374437, 'mean_batch': 8.616636753082275, 'min_batch': 8.163807201385499, 'max_batch': 8.951640319824218}
step: 41350 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 0.9047495, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.95243272781372, 'actor_loss': -5.842697238922119, 'hyper_actor_loss': 0.008100706897675992, 'behavior_loss': 0.2716182813048363, 'mean_batch': 8.587342166900635, 'min_batch': 8.034019613265992, 'max_batch': 8.897322082519532}
step: 41360 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 3.1718807, 'max_total_reward': 14.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.61585978269577, 'actor_loss': -5.848336315155029, 'hyper_actor_loss': 0.007767086289823056, 'behavior_loss': 0.2647827982902527, 'mean_batch': 8.550755310058594, 'min_batch': 8.110398721694946, 'max_batch': 8.918582344055176}
step: 41370 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 2.6843011, 'max_total_reward': 11.2300005, 'min_total_reward': 5.6800003, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.311911249160767, 'actor_loss': -5.84482421875, 'hyper_actor_loss': 0.00759371193125844, 'behavior_loss': 0.2855521574616432, 'mean_batch': 8.530007934570312, 'min_batch': 8.100166130065919, 'max_batch': 8.91499366760254}
step: 41380 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 3.9338365, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.681115746498108, 'actor_loss': -5.820251321792602, 'hyper_actor_loss': 0.007881884789094329, 'behavior_loss': 0.275480629503727, 'mean_batch': 8.50316505432129, 'min_batch': 7.941854524612427, 'max_batch': 8.843945789337159}
step: 41390 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 1.5082641, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.967270183563232, 'actor_loss': -5.804198312759399, 'hyper_actor_loss': 0.007579978788271546, 'behavior_loss': 0.26529795229434966, 'mean_batch': 8.430871772766114, 'min_batch': 7.880092144012451, 'max_batch': 8.704412746429444}
step: 41400 @ episode report: {'average_total_reward': 10.376, 'reward_variance': 2.5083437, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.87071213722229, 'actor_loss': -5.806978034973144, 'hyper_actor_loss': 0.0075253150425851345, 'behavior_loss': 0.26870093047618865, 'mean_batch': 8.364564895629883, 'min_batch': 7.954142332077026, 'max_batch': 8.711772155761718}
step: 41410 @ episode report: {'average_total_reward': 11.0529995, 'reward_variance': 3.0610206, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0893336772918705, 'actor_loss': -5.825104379653931, 'hyper_actor_loss': 0.007535378541797399, 'behavior_loss': 0.2531602829694748, 'mean_batch': 8.424145126342774, 'min_batch': 8.041555738449096, 'max_batch': 8.826135635375977}
step: 41420 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 5.245559, 'max_total_reward': 13.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.34172477722168, 'actor_loss': -5.8071794509887695, 'hyper_actor_loss': 0.007595179788768292, 'behavior_loss': 0.26839872151613237, 'mean_batch': 8.328048610687256, 'min_batch': 7.989865827560425, 'max_batch': 8.67635669708252}
step: 41430 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 1.6909403, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.584997940063476, 'actor_loss': -5.810654067993164, 'hyper_actor_loss': 0.0077076646964997055, 'behavior_loss': 0.2563903331756592, 'mean_batch': 8.455312061309815, 'min_batch': 7.907748889923096, 'max_batch': 8.8626238822937}
step: 41440 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 3.4572608, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.503171336650849, 'actor_loss': -5.800205135345459, 'hyper_actor_loss': 0.007592112850397825, 'behavior_loss': 0.2623294934630394, 'mean_batch': 8.412413120269775, 'min_batch': 7.871942520141602, 'max_batch': 8.797470855712891}
step: 41450 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 1.2197845, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.162426900863648, 'actor_loss': -5.779891538619995, 'hyper_actor_loss': 0.007789039611816406, 'behavior_loss': 0.25735261738300325, 'mean_batch': 8.288770866394042, 'min_batch': 7.813495063781739, 'max_batch': 8.640012645721436}
step: 41460 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 5.2897615, 'max_total_reward': 12.340001, 'min_total_reward': 6.57, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.415982818603515, 'actor_loss': -5.830305862426758, 'hyper_actor_loss': 0.007715468294918537, 'behavior_loss': 0.2723583191633224, 'mean_batch': 8.53816261291504, 'min_batch': 7.9834472179412845, 'max_batch': 8.900533866882324}
step: 41470 @ episode report: {'average_total_reward': 9.676001, 'reward_variance': 6.661045, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.103838348388672, 'actor_loss': -5.83508791923523, 'hyper_actor_loss': 0.00783988879993558, 'behavior_loss': 0.2815358445048332, 'mean_batch': 8.537887573242188, 'min_batch': 8.02235131263733, 'max_batch': 8.895949554443359}
step: 41480 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.2274652, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.980867767333985, 'actor_loss': -5.818877220153809, 'hyper_actor_loss': 0.007969398470595478, 'behavior_loss': 0.2850016444921494, 'mean_batch': 8.447706317901611, 'min_batch': 7.970252227783203, 'max_batch': 8.816774940490722}
step: 41490 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 4.991325, 'max_total_reward': 13.34, 'min_total_reward': 4.57, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.842111945152283, 'actor_loss': -5.853767156600952, 'hyper_actor_loss': 0.007928469590842724, 'behavior_loss': 0.24611360132694243, 'mean_batch': 8.602260494232178, 'min_batch': 8.104751062393188, 'max_batch': 8.980387496948243}
step: 41500 @ episode report: {'average_total_reward': 9.742999, 'reward_variance': 3.045281, 'max_total_reward': 13.23, 'min_total_reward': 6.7899995, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.495702409744263, 'actor_loss': -5.853046083450318, 'hyper_actor_loss': 0.007800831738859415, 'behavior_loss': 0.26653836369514466, 'mean_batch': 8.552029228210449, 'min_batch': 8.14579906463623, 'max_batch': 8.95400037765503}
step: 41510 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 3.4983253, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.530440175533295, 'actor_loss': -5.847472429275513, 'hyper_actor_loss': 0.00816195560619235, 'behavior_loss': 0.26314573287963866, 'mean_batch': 8.542637348175049, 'min_batch': 8.110551786422729, 'max_batch': 8.9370698928833}
step: 41520 @ episode report: {'average_total_reward': 10.998001, 'reward_variance': 3.2960362, 'max_total_reward': 13.450001, 'min_total_reward': 7.6800003, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.558873891830444, 'actor_loss': -5.8461113452911375, 'hyper_actor_loss': 0.00802991553209722, 'behavior_loss': 0.2715719074010849, 'mean_batch': 8.515106582641602, 'min_batch': 8.124838972091675, 'max_batch': 8.847025966644287}
step: 41530 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.2974846, 'max_total_reward': 13.450001, 'min_total_reward': 7.9000006, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.1493168592453005, 'actor_loss': -5.803767251968384, 'hyper_actor_loss': 0.008350006304681301, 'behavior_loss': 0.2736571982502937, 'mean_batch': 8.413432693481445, 'min_batch': 7.888884162902832, 'max_batch': 8.751633167266846}
step: 41540 @ episode report: {'average_total_reward': 10.398, 'reward_variance': 4.523857, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.583697366714477, 'actor_loss': -5.8175395965576175, 'hyper_actor_loss': 0.008410555962473153, 'behavior_loss': 0.2583503007888794, 'mean_batch': 8.454768848419189, 'min_batch': 7.9591700553894045, 'max_batch': 8.815819549560548}
step: 41550 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 1.3006643, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.042156934738159, 'actor_loss': -5.833551645278931, 'hyper_actor_loss': 0.008516030106693506, 'behavior_loss': 0.2399675190448761, 'mean_batch': 8.490933895111084, 'min_batch': 8.046907997131347, 'max_batch': 8.854396533966064}
step: 41560 @ episode report: {'average_total_reward': 10.997, 'reward_variance': 1.4254405, 'max_total_reward': 12.34, 'min_total_reward': 9.01, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.755282795429229, 'actor_loss': -5.854990243911743, 'hyper_actor_loss': 0.008740530349314213, 'behavior_loss': 0.2392302691936493, 'mean_batch': 8.6122465133667, 'min_batch': 8.106148433685302, 'max_batch': 9.010930919647217}
step: 41570 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 5.005542, 'max_total_reward': 14.450001, 'min_total_reward': 7.68, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.501938450336456, 'actor_loss': -5.860446834564209, 'hyper_actor_loss': 0.008894552662968635, 'behavior_loss': 0.26920942962169647, 'mean_batch': 8.577729606628418, 'min_batch': 8.181297111511231, 'max_batch': 8.934893321990966}
step: 41580 @ episode report: {'average_total_reward': 11.042, 'reward_variance': 5.485476, 'max_total_reward': 14.45, 'min_total_reward': 6.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.995607137680054, 'actor_loss': -5.825886154174805, 'hyper_actor_loss': 0.008725405763834715, 'behavior_loss': 0.2696008518338203, 'mean_batch': 8.437997150421143, 'min_batch': 8.035266208648682, 'max_batch': 8.793817329406739}
step: 41590 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 3.1326156, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.156597328186035, 'actor_loss': -5.810376453399658, 'hyper_actor_loss': 0.009054422285407782, 'behavior_loss': 0.2641509920358658, 'mean_batch': 8.371915149688721, 'min_batch': 7.97382926940918, 'max_batch': 8.695577335357665}
step: 41600 @ episode report: {'average_total_reward': 9.266, 'reward_variance': 7.1753845, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.149589610099793, 'actor_loss': -5.8652222633361815, 'hyper_actor_loss': 0.00851470110937953, 'behavior_loss': 0.2640883281826973, 'mean_batch': 8.614585494995117, 'min_batch': 8.186216354370117, 'max_batch': 8.991668510437012}
step: 41610 @ episode report: {'average_total_reward': 10.72, 'reward_variance': 1.9941998, 'max_total_reward': 12.34, 'min_total_reward': 8.789999, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.83513081073761, 'actor_loss': -5.875926876068116, 'hyper_actor_loss': 0.00835472410544753, 'behavior_loss': 0.2642300441861153, 'mean_batch': 8.65504722595215, 'min_batch': 8.235143756866455, 'max_batch': 9.024227905273438}
step: 41620 @ episode report: {'average_total_reward': 9.987001, 'reward_variance': 3.0649815, 'max_total_reward': 12.340001, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6586547255516053, 'actor_loss': -5.85120644569397, 'hyper_actor_loss': 0.008483738638460636, 'behavior_loss': 0.25328895449638367, 'mean_batch': 8.638592529296876, 'min_batch': 8.055741119384766, 'max_batch': 9.000978660583495}
step: 41630 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 3.8416457, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.168919467926026, 'actor_loss': -5.902532243728638, 'hyper_actor_loss': 0.008407380525022745, 'behavior_loss': 0.2630064100027084, 'mean_batch': 8.781125164031982, 'min_batch': 8.336228561401366, 'max_batch': 9.121437931060791}
step: 41640 @ episode report: {'average_total_reward': 10.653001, 'reward_variance': 1.739641, 'max_total_reward': 12.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.019257640838623, 'actor_loss': -5.8857227802276615, 'hyper_actor_loss': 0.008249727822840214, 'behavior_loss': 0.2517984643578529, 'mean_batch': 8.69242525100708, 'min_batch': 8.28084945678711, 'max_batch': 9.07505407333374}
step: 41650 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 3.101209, 'max_total_reward': 13.23, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.832063436508179, 'actor_loss': -5.879017114639282, 'hyper_actor_loss': 0.008302053902298212, 'behavior_loss': 0.26033464074134827, 'mean_batch': 8.65192174911499, 'min_batch': 8.263452434539795, 'max_batch': 9.000077438354491}
step: 41660 @ episode report: {'average_total_reward': 11.342001, 'reward_variance': 3.1931162, 'max_total_reward': 15.560001, 'min_total_reward': 8.900001, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.620405459403992, 'actor_loss': -5.893213701248169, 'hyper_actor_loss': 0.008302892185747623, 'behavior_loss': 0.2627713859081268, 'mean_batch': 8.758126258850098, 'min_batch': 8.286098670959472, 'max_batch': 9.080320072174072}
step: 41670 @ episode report: {'average_total_reward': 11.453, 'reward_variance': 2.344721, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.688091826438904, 'actor_loss': -5.8860467910766605, 'hyper_actor_loss': 0.008178453985601663, 'behavior_loss': 0.2724165678024292, 'mean_batch': 8.70666675567627, 'min_batch': 8.272201108932496, 'max_batch': 9.008297634124755}
step: 41680 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 1.8709961, 'max_total_reward': 12.12, 'min_total_reward': 7.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.742637205123901, 'actor_loss': -5.855318975448609, 'hyper_actor_loss': 0.008247878355905413, 'behavior_loss': 0.2516303971409798, 'mean_batch': 8.591580486297607, 'min_batch': 8.12674584388733, 'max_batch': 8.92751054763794}
step: 41690 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.5934815, 'max_total_reward': 13.340001, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.878257966041565, 'actor_loss': -5.87127947807312, 'hyper_actor_loss': 0.008224500948563218, 'behavior_loss': 0.2596560478210449, 'mean_batch': 8.600580787658691, 'min_batch': 8.248850917816162, 'max_batch': 8.907063388824463}
step: 41700 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 2.2618802, 'max_total_reward': 12.12, 'min_total_reward': 7.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.691535687446594, 'actor_loss': -5.889861583709717, 'hyper_actor_loss': 0.00828937473706901, 'behavior_loss': 0.26412010490894317, 'mean_batch': 8.69687795639038, 'min_batch': 8.310310363769531, 'max_batch': 9.05235424041748}
step: 41710 @ episode report: {'average_total_reward': 9.943, 'reward_variance': 8.093961, 'max_total_reward': 14.34, 'min_total_reward': 3.5700002, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.459414386749268, 'actor_loss': -5.84907169342041, 'hyper_actor_loss': 0.008347565168514847, 'behavior_loss': 0.25618822276592257, 'mean_batch': 8.63691987991333, 'min_batch': 8.045108127593995, 'max_batch': 8.996000671386719}
step: 41720 @ episode report: {'average_total_reward': 10.631, 'reward_variance': 3.1702888, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.958135986328125, 'actor_loss': -5.872264766693116, 'hyper_actor_loss': 0.008349707629531623, 'behavior_loss': 0.2715067073702812, 'mean_batch': 8.66296100616455, 'min_batch': 8.197698068618774, 'max_batch': 9.041790962219238}
step: 41730 @ episode report: {'average_total_reward': 10.465, 'reward_variance': 2.8924854, 'max_total_reward': 13.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.908815574645996, 'actor_loss': -5.872963523864746, 'hyper_actor_loss': 0.008387895207852126, 'behavior_loss': 0.2687594711780548, 'mean_batch': 8.66884126663208, 'min_batch': 8.199490165710449, 'max_batch': 9.054593276977538}
step: 41740 @ episode report: {'average_total_reward': 10.442001, 'reward_variance': 3.3020978, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.026143205165863, 'actor_loss': -5.909234046936035, 'hyper_actor_loss': 0.008244575280696154, 'behavior_loss': 0.2748636037111282, 'mean_batch': 8.792288208007813, 'min_batch': 8.38098955154419, 'max_batch': 9.138003826141357}
step: 41750 @ episode report: {'average_total_reward': 11.751999, 'reward_variance': 2.911297, 'max_total_reward': 14.450001, 'min_total_reward': 9.01, 'average_n_step': 12.5, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.209499859809876, 'actor_loss': -5.89953727722168, 'hyper_actor_loss': 0.00834247637540102, 'behavior_loss': 0.2749119073152542, 'mean_batch': 8.762516021728516, 'min_batch': 8.328935623168945, 'max_batch': 9.085945224761963}
step: 41760 @ episode report: {'average_total_reward': 10.442, 'reward_variance': 2.4849367, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.061045384407043, 'actor_loss': -5.8862354278564455, 'hyper_actor_loss': 0.008206669008359313, 'behavior_loss': 0.27568422853946684, 'mean_batch': 8.694730663299561, 'min_batch': 8.283359479904174, 'max_batch': 9.039266777038574}
step: 41770 @ episode report: {'average_total_reward': 8.866, 'reward_variance': 5.8369246, 'max_total_reward': 13.450001, 'min_total_reward': 4.68, 'average_n_step': 9.9, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.583248853683472, 'actor_loss': -5.88181357383728, 'hyper_actor_loss': 0.008359789615496993, 'behavior_loss': 0.25614524483680723, 'mean_batch': 8.746268177032471, 'min_batch': 8.207617092132569, 'max_batch': 9.085668849945069}
step: 41780 @ episode report: {'average_total_reward': 11.797, 'reward_variance': 2.797603, 'max_total_reward': 14.450001, 'min_total_reward': 8.9, 'average_n_step': 12.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.273844075202942, 'actor_loss': -5.902094316482544, 'hyper_actor_loss': 0.00825553028844297, 'behavior_loss': 0.25811838954687116, 'mean_batch': 8.767653465270996, 'min_batch': 8.344721698760987, 'max_batch': 9.10992078781128}
step: 41790 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 3.1375809, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.148376739025116, 'actor_loss': -5.9159036636352536, 'hyper_actor_loss': 0.00804402087815106, 'behavior_loss': 0.2529012158513069, 'mean_batch': 8.803482818603516, 'min_batch': 8.4264967918396, 'max_batch': 9.136494350433349}
step: 41800 @ episode report: {'average_total_reward': 11.053, 'reward_variance': 5.115121, 'max_total_reward': 14.559999, 'min_total_reward': 5.7900004, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.211648750305176, 'actor_loss': -5.888714265823364, 'hyper_actor_loss': 0.008127983193844557, 'behavior_loss': 0.27768607884645463, 'mean_batch': 8.68848695755005, 'min_batch': 8.308756065368652, 'max_batch': 9.026684379577636}
step: 41810 @ episode report: {'average_total_reward': 10.820001, 'reward_variance': 3.9159794, 'max_total_reward': 13.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.762619686126709, 'actor_loss': -5.892389822006225, 'hyper_actor_loss': 0.008193721435964108, 'behavior_loss': 0.25221601575613023, 'mean_batch': 8.778671550750733, 'min_batch': 8.2546555519104, 'max_batch': 9.133693313598632}
step: 41820 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 3.7531445, 'max_total_reward': 11.120001, 'min_total_reward': 4.6800003, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.036332535743713, 'actor_loss': -5.918791627883911, 'hyper_actor_loss': 0.008170702075585724, 'behavior_loss': 0.25751948952674864, 'mean_batch': 8.868957328796387, 'min_batch': 8.388819789886474, 'max_batch': 9.218690586090087}
step: 41830 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 3.8654594, 'max_total_reward': 15.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.377780628204346, 'actor_loss': -5.912033224105835, 'hyper_actor_loss': 0.008197311777621508, 'behavior_loss': 0.2737077161669731, 'mean_batch': 8.812696552276611, 'min_batch': 8.384890460968018, 'max_batch': 9.190339946746827}
step: 41840 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 0.74426126, 'max_total_reward': 11.2300005, 'min_total_reward': 8.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.2999086618423465, 'actor_loss': -5.8983283042907715, 'hyper_actor_loss': 0.008033823734149338, 'behavior_loss': 0.2827775597572327, 'mean_batch': 8.775783443450928, 'min_batch': 8.305792331695557, 'max_batch': 9.155710315704345}
step: 41850 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 2.3288054, 'max_total_reward': 11.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.018768835067749, 'actor_loss': -5.865758180618286, 'hyper_actor_loss': 0.00789662622846663, 'behavior_loss': 0.26139409393072127, 'mean_batch': 8.700657272338868, 'min_batch': 8.115176439285278, 'max_batch': 9.032249069213867}
step: 41860 @ episode report: {'average_total_reward': 11.042002, 'reward_variance': 1.4600163, 'max_total_reward': 13.34, 'min_total_reward': 9.009999, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.873520255088806, 'actor_loss': -5.870363235473633, 'hyper_actor_loss': 0.007921122340485453, 'behavior_loss': 0.2648207455873489, 'mean_batch': 8.708311367034913, 'min_batch': 8.147386932373047, 'max_batch': 9.107991981506348}
step: 41870 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 2.599564, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.897038459777832, 'actor_loss': -5.940118980407715, 'hyper_actor_loss': 0.007798908976837993, 'behavior_loss': 0.2589558869600296, 'mean_batch': 8.935664463043214, 'min_batch': 8.505429935455322, 'max_batch': 9.265657997131347}
step: 41880 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 3.1518645, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 9.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.801740407943726, 'actor_loss': -5.908467817306518, 'hyper_actor_loss': 0.007867842772975564, 'behavior_loss': 0.272665348649025, 'mean_batch': 8.87633171081543, 'min_batch': 8.301676607131958, 'max_batch': 9.23593978881836}
step: 41890 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 2.0469568, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7899995, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.436371088027954, 'actor_loss': -5.89768648147583, 'hyper_actor_loss': 0.00792541834525764, 'behavior_loss': 0.2691740825772285, 'mean_batch': 8.744100666046142, 'min_batch': 8.331191539764404, 'max_batch': 9.11957893371582}
step: 41900 @ episode report: {'average_total_reward': 10.054, 'reward_variance': 3.6600444, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.644740772247315, 'actor_loss': -5.906932020187378, 'hyper_actor_loss': 0.008013695012778044, 'behavior_loss': 0.2593847826123238, 'mean_batch': 8.811190605163574, 'min_batch': 8.344037818908692, 'max_batch': 9.148133563995362}
step: 41910 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 1.468624, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.897271966934204, 'actor_loss': -5.908084487915039, 'hyper_actor_loss': 0.007907017366960645, 'behavior_loss': 0.26708109080791476, 'mean_batch': 8.810587120056152, 'min_batch': 8.3545241355896, 'max_batch': 9.2142972946167}
step: 41920 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 1.018449, 'max_total_reward': 11.23, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.281670236587525, 'actor_loss': -5.879682302474976, 'hyper_actor_loss': 0.007707783905789256, 'behavior_loss': 0.27167453765869143, 'mean_batch': 8.695627784729004, 'min_batch': 8.227434349060058, 'max_batch': 9.080609130859376}
step: 41930 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 2.9668043, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.18911657333374, 'actor_loss': -5.873657989501953, 'hyper_actor_loss': 0.007913762517273427, 'behavior_loss': 0.2656816244125366, 'mean_batch': 8.700614833831787, 'min_batch': 8.17376413345337, 'max_batch': 9.125630569458007}
step: 41940 @ episode report: {'average_total_reward': 11.009001, 'reward_variance': 6.0126505, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.4651731014251705, 'actor_loss': -5.888599061965943, 'hyper_actor_loss': 0.007687747105956077, 'behavior_loss': 0.2711216419935226, 'mean_batch': 8.742264366149902, 'min_batch': 8.256845092773437, 'max_batch': 9.198301029205322}
step: 41950 @ episode report: {'average_total_reward': 9.809999, 'reward_variance': 5.1005006, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 10.8, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.70331871509552, 'actor_loss': -5.859031867980957, 'hyper_actor_loss': 0.00804618103429675, 'behavior_loss': 0.24807541966438293, 'mean_batch': 8.64328212738037, 'min_batch': 8.110032415390014, 'max_batch': 9.121816158294678}
step: 41960 @ episode report: {'average_total_reward': 8.455999, 'reward_variance': 2.3935838, 'max_total_reward': 10.12, 'min_total_reward': 5.57, 'average_n_step': 9.6, 'max_n_step': 11.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.758423328399658, 'actor_loss': -5.869771099090576, 'hyper_actor_loss': 0.00764922690577805, 'behavior_loss': 0.2556042268872261, 'mean_batch': 8.677725028991699, 'min_batch': 8.163894653320312, 'max_batch': 9.112507629394532}
step: 41970 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.0750155, 'max_total_reward': 13.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.380580139160156, 'actor_loss': -5.814715242385864, 'hyper_actor_loss': 0.0076662797015160326, 'behavior_loss': 0.26443333029747007, 'mean_batch': 8.413878917694092, 'min_batch': 7.968895435333252, 'max_batch': 8.829097270965576}
step: 41980 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 2.4113605, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.44940459728241, 'actor_loss': -5.875135660171509, 'hyper_actor_loss': 0.007571827014908194, 'behavior_loss': 0.2645305022597313, 'mean_batch': 8.715039539337159, 'min_batch': 8.1758722782135, 'max_batch': 9.082963180541991}
step: 41990 @ episode report: {'average_total_reward': 12.296, 'reward_variance': 7.124663, 'max_total_reward': 16.779999, 'min_total_reward': 7.9, 'average_n_step': 13.0, 'max_n_step': 17.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.162746024131775, 'actor_loss': -5.916106224060059, 'hyper_actor_loss': 0.00773045951500535, 'behavior_loss': 0.26072274446487426, 'mean_batch': 8.818980312347412, 'min_batch': 8.413552856445312, 'max_batch': 9.164625930786134}
step: 42000 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 10.635408, 'max_total_reward': 15.67, 'min_total_reward': 4.68, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.493633794784546, 'actor_loss': -5.912335681915283, 'hyper_actor_loss': 0.007868063868954778, 'behavior_loss': 0.26163643449544904, 'mean_batch': 8.814931297302246, 'min_batch': 8.385678482055663, 'max_batch': 9.146882247924804}
step: 42010 @ episode report: {'average_total_reward': 8.733, 'reward_variance': 2.3251014, 'max_total_reward': 12.2300005, 'min_total_reward': 6.68, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.977219080924987, 'actor_loss': -5.876212549209595, 'hyper_actor_loss': 0.007999283773824573, 'behavior_loss': 0.2627986565232277, 'mean_batch': 8.7230731010437, 'min_batch': 8.178460502624512, 'max_batch': 9.061400508880615}
step: 42020 @ episode report: {'average_total_reward': 10.820002, 'reward_variance': 2.0178802, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.360225701332093, 'actor_loss': -5.888142061233521, 'hyper_actor_loss': 0.008134940220043064, 'behavior_loss': 0.25943395495414734, 'mean_batch': 8.763701820373536, 'min_batch': 8.235199689865112, 'max_batch': 9.16544599533081}
step: 42030 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 7.5710845, 'max_total_reward': 13.34, 'min_total_reward': 3.46, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.836265325546265, 'actor_loss': -5.890736055374146, 'hyper_actor_loss': 0.007706869253888726, 'behavior_loss': 0.2609511435031891, 'mean_batch': 8.713833236694336, 'min_batch': 8.301498413085938, 'max_batch': 9.1139084815979}
step: 42040 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 1.5825452, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.417578101158142, 'actor_loss': -5.864785432815552, 'hyper_actor_loss': 0.007965631550177932, 'behavior_loss': 0.255710506439209, 'mean_batch': 8.663238048553467, 'min_batch': 8.13878355026245, 'max_batch': 9.029011821746826}
step: 42050 @ episode report: {'average_total_reward': 11.0529995, 'reward_variance': 3.8537624, 'max_total_reward': 15.56, 'min_total_reward': 9.009999, 'average_n_step': 11.9, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.678035163879395, 'actor_loss': -5.888616561889648, 'hyper_actor_loss': 0.007420120574533939, 'behavior_loss': 0.251559841632843, 'mean_batch': 8.696765995025634, 'min_batch': 8.300007343292236, 'max_batch': 9.057498455047607}
step: 42060 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 0.7896558, 'max_total_reward': 11.900001, 'min_total_reward': 9.01, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.676218855381012, 'actor_loss': -5.877524995803833, 'hyper_actor_loss': 0.007773617235943675, 'behavior_loss': 0.2619961380958557, 'mean_batch': 8.727815532684327, 'min_batch': 8.183533191680908, 'max_batch': 9.131120586395264}
step: 42070 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 3.5851293, 'max_total_reward': 11.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.493370437622071, 'actor_loss': -5.873054838180542, 'hyper_actor_loss': 0.007523434655740857, 'behavior_loss': 0.28582981526851653, 'mean_batch': 8.635708808898926, 'min_batch': 8.230133819580079, 'max_batch': 8.976875400543213}
step: 42080 @ episode report: {'average_total_reward': 11.042, 'reward_variance': 4.7609572, 'max_total_reward': 16.560001, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 17.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.921289658546447, 'actor_loss': -5.843828010559082, 'hyper_actor_loss': 0.007653883006423712, 'behavior_loss': 0.2726791173219681, 'mean_batch': 8.50344820022583, 'min_batch': 8.117136478424072, 'max_batch': 8.831995010375977}
step: 42090 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 3.7212498, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.768494582176208, 'actor_loss': -5.881006526947021, 'hyper_actor_loss': 0.007580916117876768, 'behavior_loss': 0.2561009287834167, 'mean_batch': 8.659463500976562, 'min_batch': 8.272699737548828, 'max_batch': 9.006481266021728}
step: 42100 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 2.6043897, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.282164430618286, 'actor_loss': -5.876023197174073, 'hyper_actor_loss': 0.007553054159507156, 'behavior_loss': 0.2707986950874329, 'mean_batch': 8.65062141418457, 'min_batch': 8.240893125534058, 'max_batch': 8.971387767791748}
step: 42110 @ episode report: {'average_total_reward': 11.0980015, 'reward_variance': 2.8976164, 'max_total_reward': 14.2300005, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.486807847023011, 'actor_loss': -5.900931453704834, 'hyper_actor_loss': 0.007503294525668025, 'behavior_loss': 0.2659493342041969, 'mean_batch': 8.737048244476318, 'min_batch': 8.364676570892334, 'max_batch': 9.04619779586792}
step: 42120 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 4.0738554, 'max_total_reward': 13.449999, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.097551929950714, 'actor_loss': -5.901484060287475, 'hyper_actor_loss': 0.0076176221016794445, 'behavior_loss': 0.2683959737420082, 'mean_batch': 8.785621547698975, 'min_batch': 8.326056957244873, 'max_batch': 9.138738822937011}
step: 42130 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 4.768846, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.645541167259216, 'actor_loss': -5.871863842010498, 'hyper_actor_loss': 0.0075415696017444135, 'behavior_loss': 0.25899227857589724, 'mean_batch': 8.614796447753907, 'min_batch': 8.239849472045899, 'max_batch': 8.894886112213134}
step: 42140 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 2.3510644, 'max_total_reward': 13.45, 'min_total_reward': 7.9000006, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.471834135055542, 'actor_loss': -5.879996490478516, 'hyper_actor_loss': 0.007448794692754746, 'behavior_loss': 0.2677853271365166, 'mean_batch': 8.664061450958252, 'min_batch': 8.261560678482056, 'max_batch': 9.009600925445557}
step: 42150 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 3.403457, 'max_total_reward': 12.340001, 'min_total_reward': 5.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7775291204452515, 'actor_loss': -5.881476974487304, 'hyper_actor_loss': 0.007435355661436915, 'behavior_loss': 0.2739930137991905, 'mean_batch': 8.655686187744141, 'min_batch': 8.280241203308105, 'max_batch': 8.986212539672852}
step: 42160 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 1.6653602, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.525665235519409, 'actor_loss': -5.912905311584472, 'hyper_actor_loss': 0.007709672208875418, 'behavior_loss': 0.2770740032196045, 'mean_batch': 8.816422843933106, 'min_batch': 8.389766025543214, 'max_batch': 9.178678417205811}
step: 42170 @ episode report: {'average_total_reward': 10.720001, 'reward_variance': 4.65356, 'max_total_reward': 14.450001, 'min_total_reward': 6.7900004, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9275386333465576, 'actor_loss': -5.921645927429199, 'hyper_actor_loss': 0.007586929108947515, 'behavior_loss': 0.25475057065486906, 'mean_batch': 8.852457332611085, 'min_batch': 8.428078937530518, 'max_batch': 9.197154331207276}
step: 42180 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 2.523329, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.053087377548218, 'actor_loss': -5.918218612670898, 'hyper_actor_loss': 0.0078376988414675, 'behavior_loss': 0.28627312034368513, 'mean_batch': 8.799788093566894, 'min_batch': 8.449267292022705, 'max_batch': 9.122382640838623}
step: 42190 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 1.9548765, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8810725808143616, 'actor_loss': -5.889489364624024, 'hyper_actor_loss': 0.007831944106146693, 'behavior_loss': 0.28492663353681563, 'mean_batch': 8.729928016662598, 'min_batch': 8.277142143249511, 'max_batch': 9.099117469787597}
step: 42200 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 4.3527207, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.927623629570007, 'actor_loss': -5.927439832687378, 'hyper_actor_loss': 0.00782630597241223, 'behavior_loss': 0.2741633728146553, 'mean_batch': 8.887856769561768, 'min_batch': 8.44332046508789, 'max_batch': 9.208976459503173}
step: 42210 @ episode report: {'average_total_reward': 10.909, 'reward_variance': 1.891309, 'max_total_reward': 13.34, 'min_total_reward': 8.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.98681902885437, 'actor_loss': -5.87585039138794, 'hyper_actor_loss': 0.007914993399754166, 'behavior_loss': 0.2649259552359581, 'mean_batch': 8.720427799224854, 'min_batch': 8.180495929718017, 'max_batch': 9.053514671325683}
step: 42220 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 3.483942, 'max_total_reward': 15.560001, 'min_total_reward': 7.9000006, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.295326554775238, 'actor_loss': -5.886117649078369, 'hyper_actor_loss': 0.007637191284447909, 'behavior_loss': 0.24818823039531707, 'mean_batch': 8.657424449920654, 'min_batch': 8.316801071166992, 'max_batch': 8.94339485168457}
step: 42230 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 3.5450845, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.690772914886475, 'actor_loss': -5.8925042152404785, 'hyper_actor_loss': 0.007563322642818093, 'behavior_loss': 0.25203138738870623, 'mean_batch': 8.70080099105835, 'min_batch': 8.328708934783936, 'max_batch': 9.029202842712403}
step: 42240 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 3.5618424, 'max_total_reward': 13.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.006954312324524, 'actor_loss': -5.868939304351807, 'hyper_actor_loss': 0.007672384288161993, 'behavior_loss': 0.25582275688648226, 'mean_batch': 8.635676002502441, 'min_batch': 8.199451971054078, 'max_batch': 8.978091430664062}
step: 42250 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 3.9879246, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.796728134155273, 'actor_loss': -5.882702398300171, 'hyper_actor_loss': 0.0076022166293114425, 'behavior_loss': 0.2633392170071602, 'mean_batch': 8.682259368896485, 'min_batch': 8.266035413742065, 'max_batch': 9.029617500305175}
step: 42260 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.0749295, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.365079128742218, 'actor_loss': -5.894475412368775, 'hyper_actor_loss': 0.007600966095924378, 'behavior_loss': 0.25163726657629015, 'mean_batch': 8.717242622375489, 'min_batch': 8.329259395599365, 'max_batch': 9.050440406799316}
step: 42270 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 3.9957893, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.562027502059936, 'actor_loss': -5.877164125442505, 'hyper_actor_loss': 0.007795923994854093, 'behavior_loss': 0.2830559089779854, 'mean_batch': 8.632149505615235, 'min_batch': 8.26736764907837, 'max_batch': 8.986534786224365}
step: 42280 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 3.5817304, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.615358567237854, 'actor_loss': -5.845378875732422, 'hyper_actor_loss': 0.007928867964074016, 'behavior_loss': 0.2678079977631569, 'mean_batch': 8.54366397857666, 'min_batch': 8.095308351516724, 'max_batch': 8.837944221496581}
step: 42290 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 5.160085, 'max_total_reward': 14.560001, 'min_total_reward': 6.68, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.566788911819458, 'actor_loss': -5.859679651260376, 'hyper_actor_loss': 0.007726985542103648, 'behavior_loss': 0.2519449949264526, 'mean_batch': 8.5427490234375, 'min_batch': 8.20875597000122, 'max_batch': 8.868867778778077}
step: 42300 @ episode report: {'average_total_reward': 10.165, 'reward_variance': 6.8621054, 'max_total_reward': 14.34, 'min_total_reward': 6.68, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.854919195175171, 'actor_loss': -5.896944665908814, 'hyper_actor_loss': 0.007684361655265093, 'behavior_loss': 0.272602804005146, 'mean_batch': 8.723109149932862, 'min_batch': 8.345928812026978, 'max_batch': 9.044523525238038}
step: 42310 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 1.2580764, 'max_total_reward': 11.900001, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.738009285926819, 'actor_loss': -5.879038381576538, 'hyper_actor_loss': 0.007910648547112941, 'behavior_loss': 0.25440303385257723, 'mean_batch': 8.688664817810059, 'min_batch': 8.23422555923462, 'max_batch': 8.985643196105958}
step: 42320 @ episode report: {'average_total_reward': 8.966001, 'reward_variance': 1.9839436, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.365879774093628, 'actor_loss': -5.873801231384277, 'hyper_actor_loss': 0.007917275046929717, 'behavior_loss': 0.2654404014348984, 'mean_batch': 8.647649002075195, 'min_batch': 8.226357889175414, 'max_batch': 8.944375038146973}
step: 42330 @ episode report: {'average_total_reward': 10.864001, 'reward_variance': 1.5202448, 'max_total_reward': 13.450001, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.379583716392517, 'actor_loss': -5.903978395462036, 'hyper_actor_loss': 0.007980101276189089, 'behavior_loss': 0.2737999722361565, 'mean_batch': 8.820036125183105, 'min_batch': 8.31586308479309, 'max_batch': 9.103764724731445}
step: 42340 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 0.73736906, 'max_total_reward': 11.12, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.005592966079712, 'actor_loss': -5.883378696441651, 'hyper_actor_loss': 0.008165966160595417, 'behavior_loss': 0.2617440715432167, 'mean_batch': 8.700303173065185, 'min_batch': 8.254480934143066, 'max_batch': 9.001768016815186}
step: 42350 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 4.258645, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.772293388843536, 'actor_loss': -5.860224008560181, 'hyper_actor_loss': 0.007533385418355465, 'behavior_loss': 0.28410778641700746, 'mean_batch': 8.542586708068848, 'min_batch': 8.213577461242675, 'max_batch': 8.83050708770752}
step: 42360 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 1.7566242, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.706605458259583, 'actor_loss': -5.883016586303711, 'hyper_actor_loss': 0.0077318648342043165, 'behavior_loss': 0.260591921210289, 'mean_batch': 8.654774856567382, 'min_batch': 8.294271755218507, 'max_batch': 8.941007995605469}
step: 42370 @ episode report: {'average_total_reward': 9.999001, 'reward_variance': 1.3867682, 'max_total_reward': 11.12, 'min_total_reward': 7.7900004, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.780303049087524, 'actor_loss': -5.858503580093384, 'hyper_actor_loss': 0.007630342897027731, 'behavior_loss': 0.27865772545337675, 'mean_batch': 8.577408504486083, 'min_batch': 8.168751287460328, 'max_batch': 8.891084003448487}
step: 42380 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 1.584136, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.956297111511231, 'actor_loss': -5.845679044723511, 'hyper_actor_loss': 0.007722914079204201, 'behavior_loss': 0.2645731881260872, 'mean_batch': 8.50054578781128, 'min_batch': 8.135147619247437, 'max_batch': 8.785241794586181}
step: 42390 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 1.576721, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.288696646690369, 'actor_loss': -5.905437755584717, 'hyper_actor_loss': 0.00775567414239049, 'behavior_loss': 0.26560640186071394, 'mean_batch': 8.730430793762206, 'min_batch': 8.408732986450195, 'max_batch': 9.015356922149659}
step: 42400 @ episode report: {'average_total_reward': 10.698001, 'reward_variance': 3.476637, 'max_total_reward': 14.450001, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.200148272514343, 'actor_loss': -5.896482276916504, 'hyper_actor_loss': 0.008029787754639982, 'behavior_loss': 0.24938452690839769, 'mean_batch': 8.775180435180664, 'min_batch': 8.297983503341674, 'max_batch': 9.058046054840087}
step: 42410 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 0.48572367, 'max_total_reward': 10.12, 'min_total_reward': 7.9000006, 'average_n_step': 10.7, 'max_n_step': 11.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.875801062583923, 'actor_loss': -5.891180181503296, 'hyper_actor_loss': 0.008047753665596246, 'behavior_loss': 0.24669358730316163, 'mean_batch': 8.743326473236085, 'min_batch': 8.282786417007447, 'max_batch': 9.039951992034911}
step: 42420 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 4.851245, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.8405715227127075, 'actor_loss': -5.854852199554443, 'hyper_actor_loss': 0.007987221283838154, 'behavior_loss': 0.28712800294160845, 'mean_batch': 8.570250701904296, 'min_batch': 8.145265197753906, 'max_batch': 8.863489532470703}
step: 42430 @ episode report: {'average_total_reward': 8.067, 'reward_variance': 6.9749823, 'max_total_reward': 11.2300005, 'min_total_reward': 3.46, 'average_n_step': 9.2, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.654519653320312, 'actor_loss': -5.855138778686523, 'hyper_actor_loss': 0.007998875016346574, 'behavior_loss': 0.25588672012090685, 'mean_batch': 8.517510032653808, 'min_batch': 8.195721435546876, 'max_batch': 8.800959491729737}
step: 42440 @ episode report: {'average_total_reward': 7.5340004, 'reward_variance': 4.215705, 'max_total_reward': 10.120001, 'min_total_reward': 3.46, 'average_n_step': 8.7, 'max_n_step': 11.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.09040002822876, 'actor_loss': -5.889672803878784, 'hyper_actor_loss': 0.008195731323212385, 'behavior_loss': 0.26401699632406234, 'mean_batch': 8.7019362449646, 'min_batch': 8.305955362319946, 'max_batch': 8.997501945495605}
step: 42450 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 1.6238245, 'max_total_reward': 12.12, 'min_total_reward': 7.7899995, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.855777490139007, 'actor_loss': -5.916498517990112, 'hyper_actor_loss': 0.007967876177281142, 'behavior_loss': 0.2712268218398094, 'mean_batch': 8.804449272155761, 'min_batch': 8.430498600006104, 'max_batch': 9.099926662445068}
step: 42460 @ episode report: {'average_total_reward': 10.531001, 'reward_variance': 2.6500688, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.96824266910553, 'actor_loss': -5.877499341964722, 'hyper_actor_loss': 0.007693990366533399, 'behavior_loss': 0.2821855828166008, 'mean_batch': 8.660626697540284, 'min_batch': 8.244072484970093, 'max_batch': 8.957876205444336}
step: 42470 @ episode report: {'average_total_reward': 9.854, 'reward_variance': 1.2662841, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.969444298744202, 'actor_loss': -5.863084220886231, 'hyper_actor_loss': 0.007821920188143849, 'behavior_loss': 0.2683150678873062, 'mean_batch': 8.6155029296875, 'min_batch': 8.172194862365723, 'max_batch': 8.924736785888673}
step: 42480 @ episode report: {'average_total_reward': 9.655001, 'reward_variance': 4.7179055, 'max_total_reward': 12.23, 'min_total_reward': 4.5699997, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.404990863800049, 'actor_loss': -5.887525939941407, 'hyper_actor_loss': 0.007932281121611595, 'behavior_loss': 0.2697001427412033, 'mean_batch': 8.647945976257324, 'min_batch': 8.3378080368042, 'max_batch': 8.939755821228028}
step: 42490 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 3.6261768, 'max_total_reward': 13.340001, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.218118023872376, 'actor_loss': -5.867376661300659, 'hyper_actor_loss': 0.007814376102760433, 'behavior_loss': 0.27815775722265246, 'mean_batch': 8.583608055114746, 'min_batch': 8.232618522644042, 'max_batch': 8.910072708129883}
step: 42500 @ episode report: {'average_total_reward': 10.31, 'reward_variance': 0.4341998, 'max_total_reward': 11.23, 'min_total_reward': 9.01, 'average_n_step': 11.3, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.733681464195252, 'actor_loss': -5.879208993911743, 'hyper_actor_loss': 0.00797614105977118, 'behavior_loss': 0.2596636340022087, 'mean_batch': 8.632554912567139, 'min_batch': 8.284716320037841, 'max_batch': 8.937592124938964}
step: 42510 @ episode report: {'average_total_reward': 9.444, 'reward_variance': 5.3812838, 'max_total_reward': 14.559999, 'min_total_reward': 5.4599996, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.844341230392456, 'actor_loss': -5.856233930587768, 'hyper_actor_loss': 0.007743699429556728, 'behavior_loss': 0.26968543231487274, 'mean_batch': 8.604020404815675, 'min_batch': 8.127585172653198, 'max_batch': 8.890631580352784}
step: 42520 @ episode report: {'average_total_reward': 8.4, 'reward_variance': 2.1942995, 'max_total_reward': 11.23, 'min_total_reward': 5.79, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.030854272842407, 'actor_loss': -5.847648429870605, 'hyper_actor_loss': 0.007613860676065088, 'behavior_loss': 0.24838686883449554, 'mean_batch': 8.553084468841552, 'min_batch': 8.104263639450073, 'max_batch': 8.84360294342041}
step: 42530 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 4.859496, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.867279958724976, 'actor_loss': -5.9104938983917235, 'hyper_actor_loss': 0.007215226860716939, 'behavior_loss': 0.2578309878706932, 'mean_batch': 8.792974376678467, 'min_batch': 8.391307926177978, 'max_batch': 9.13961706161499}
step: 42540 @ episode report: {'average_total_reward': 10.01, 'reward_variance': 4.4083, 'max_total_reward': 13.01, 'min_total_reward': 6.68, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.739916896820068, 'actor_loss': -5.899543571472168, 'hyper_actor_loss': 0.007424993580207229, 'behavior_loss': 0.2746614426374435, 'mean_batch': 8.746097564697266, 'min_batch': 8.344323825836181, 'max_batch': 9.065196418762207}
step: 42550 @ episode report: {'average_total_reward': 9.709999, 'reward_variance': 2.8521996, 'max_total_reward': 13.23, 'min_total_reward': 7.9, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.068588829040527, 'actor_loss': -5.86579647064209, 'hyper_actor_loss': 0.007696198066696525, 'behavior_loss': 0.26784505546092985, 'mean_batch': 8.664555740356445, 'min_batch': 8.147923612594605, 'max_batch': 8.953761959075928}
step: 42560 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 1.4931233, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.372951555252075, 'actor_loss': -5.874172878265381, 'hyper_actor_loss': 0.007549161231145263, 'behavior_loss': 0.25694472193717954, 'mean_batch': 8.675642395019532, 'min_batch': 8.202555656433105, 'max_batch': 8.956752586364747}
step: 42570 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 2.4142165, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.6410552859306335, 'actor_loss': -5.911675643920899, 'hyper_actor_loss': 0.007451079692691565, 'behavior_loss': 0.2612732246518135, 'mean_batch': 8.844566917419433, 'min_batch': 8.35737509727478, 'max_batch': 9.126336097717285}
step: 42580 @ episode report: {'average_total_reward': 9.511, 'reward_variance': 1.9820887, 'max_total_reward': 11.120001, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.246103644371033, 'actor_loss': -5.892021369934082, 'hyper_actor_loss': 0.007718609692528844, 'behavior_loss': 0.2845145300030708, 'mean_batch': 8.77694673538208, 'min_batch': 8.255209636688232, 'max_batch': 9.081378746032716}
step: 42590 @ episode report: {'average_total_reward': 9.221001, 'reward_variance': 3.58215, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.309534883499145, 'actor_loss': -5.886579370498657, 'hyper_actor_loss': 0.007618530234321952, 'behavior_loss': 0.27804064750671387, 'mean_batch': 8.74965591430664, 'min_batch': 8.236448001861572, 'max_batch': 9.063453865051269}
step: 42600 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 3.9568455, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.9956470966339115, 'actor_loss': -5.901445102691651, 'hyper_actor_loss': 0.007416017167270183, 'behavior_loss': 0.2661440268158913, 'mean_batch': 8.72179889678955, 'min_batch': 8.383084392547607, 'max_batch': 8.988539695739746}
step: 42610 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 1.7865417, 'max_total_reward': 11.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.415500640869141, 'actor_loss': -5.909872007369995, 'hyper_actor_loss': 0.007640563091263175, 'behavior_loss': 0.27401258796453476, 'mean_batch': 8.794235134124756, 'min_batch': 8.38501329421997, 'max_batch': 9.0580265045166}
step: 42620 @ episode report: {'average_total_reward': 11.275001, 'reward_variance': 2.7486453, 'max_total_reward': 14.56, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.23590657711029, 'actor_loss': -5.926988220214843, 'hyper_actor_loss': 0.007510359957814216, 'behavior_loss': 0.2778580725193024, 'mean_batch': 8.832156372070312, 'min_batch': 8.492652893066406, 'max_batch': 9.118051910400391}
step: 42630 @ episode report: {'average_total_reward': 11.164, 'reward_variance': 2.7135246, 'max_total_reward': 14.45, 'min_total_reward': 8.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0330376625061035, 'actor_loss': -5.883188962936401, 'hyper_actor_loss': 0.007830416271463036, 'behavior_loss': 0.26154931634664536, 'mean_batch': 8.740829753875733, 'min_batch': 8.225399208068847, 'max_batch': 9.019721031188965}
step: 42640 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 2.467141, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.53962767124176, 'actor_loss': -5.882078218460083, 'hyper_actor_loss': 0.007802171446382999, 'behavior_loss': 0.2762571215629578, 'mean_batch': 8.626567554473876, 'min_batch': 8.313172340393066, 'max_batch': 8.895527744293213}
step: 42650 @ episode report: {'average_total_reward': 9.788, 'reward_variance': 1.3438561, 'max_total_reward': 11.2300005, 'min_total_reward': 7.57, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7726599216461185, 'actor_loss': -5.893654012680054, 'hyper_actor_loss': 0.007750858087092638, 'behavior_loss': 0.26109946370124815, 'mean_batch': 8.708526992797852, 'min_batch': 8.332040452957154, 'max_batch': 9.016211986541748}
step: 42660 @ episode report: {'average_total_reward': 11.009001, 'reward_variance': 2.1431892, 'max_total_reward': 13.450001, 'min_total_reward': 7.6800003, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.960268259048462, 'actor_loss': -5.9176054954528805, 'hyper_actor_loss': 0.008070821594446897, 'behavior_loss': 0.26240752786397936, 'mean_batch': 8.810007095336914, 'min_batch': 8.434428405761718, 'max_batch': 9.120887756347656}
step: 42670 @ episode report: {'average_total_reward': 10.187001, 'reward_variance': 2.246081, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.107369399070739, 'actor_loss': -5.874753332138061, 'hyper_actor_loss': 0.008042480936273933, 'behavior_loss': 0.28191118240356444, 'mean_batch': 8.642348480224609, 'min_batch': 8.241615581512452, 'max_batch': 8.916121101379394}
step: 42680 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 7.4203553, 'max_total_reward': 12.34, 'min_total_reward': 3.3500001, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.746379017829895, 'actor_loss': -5.87427544593811, 'hyper_actor_loss': 0.007919186865910888, 'behavior_loss': 0.25898187756538393, 'mean_batch': 8.612039947509766, 'min_batch': 8.263470363616943, 'max_batch': 8.913883018493653}
step: 42690 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 7.4492292, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.134962821006775, 'actor_loss': -5.900479173660278, 'hyper_actor_loss': 0.007906918181106448, 'behavior_loss': 0.2708431616425514, 'mean_batch': 8.792530345916749, 'min_batch': 8.309722137451171, 'max_batch': 9.092624759674072}
step: 42700 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 2.859322, 'max_total_reward': 13.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.399550056457519, 'actor_loss': -5.8713884353637695, 'hyper_actor_loss': 0.007752325478941202, 'behavior_loss': 0.2749720558524132, 'mean_batch': 8.63332004547119, 'min_batch': 8.223459768295289, 'max_batch': 8.969041442871093}
step: 42710 @ episode report: {'average_total_reward': 10.621, 'reward_variance': 3.8337693, 'max_total_reward': 14.23, 'min_total_reward': 7.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.843434476852417, 'actor_loss': -5.8566930294036865, 'hyper_actor_loss': 0.007500288868322968, 'behavior_loss': 0.24596761763095856, 'mean_batch': 8.559301853179932, 'min_batch': 8.169768142700196, 'max_batch': 8.842435932159423}
step: 42720 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 1.4383041, 'max_total_reward': 10.12, 'min_total_reward': 6.57, 'average_n_step': 10.1, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.422619247436524, 'actor_loss': -5.914681386947632, 'hyper_actor_loss': 0.00757543658837676, 'behavior_loss': 0.258054094016552, 'mean_batch': 8.808443355560303, 'min_batch': 8.4114408493042, 'max_batch': 9.087810897827149}
step: 42730 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 2.466781, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.972112417221069, 'actor_loss': -5.877405405044556, 'hyper_actor_loss': 0.0073929181788116695, 'behavior_loss': 0.25902438908815384, 'mean_batch': 8.591933536529542, 'min_batch': 8.308597660064697, 'max_batch': 8.844808387756348}
step: 42740 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 1.9148495, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.549485921859741, 'actor_loss': -5.861229801177979, 'hyper_actor_loss': 0.007386985747143626, 'behavior_loss': 0.2478674665093422, 'mean_batch': 8.535828876495362, 'min_batch': 8.228097724914551, 'max_batch': 8.80434513092041}
step: 42750 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 3.5853848, 'max_total_reward': 12.119999, 'min_total_reward': 5.6800003, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.16095232963562, 'actor_loss': -5.864913082122802, 'hyper_actor_loss': 0.00765442824922502, 'behavior_loss': 0.2833687633275986, 'mean_batch': 8.61497621536255, 'min_batch': 8.184173440933227, 'max_batch': 8.894378185272217}
step: 42760 @ episode report: {'average_total_reward': 10.709002, 'reward_variance': 1.0448091, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.591531276702881, 'actor_loss': -5.871906375885009, 'hyper_actor_loss': 0.007519932091236114, 'behavior_loss': 0.2734736829996109, 'mean_batch': 8.582116794586181, 'min_batch': 8.271621036529542, 'max_batch': 8.862692070007324}
step: 42770 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 2.6272256, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.937444472312928, 'actor_loss': -5.8561450958251955, 'hyper_actor_loss': 0.007713324436917901, 'behavior_loss': 0.271981018781662, 'mean_batch': 8.554329299926758, 'min_batch': 8.16954951286316, 'max_batch': 8.829380702972411}
step: 42780 @ episode report: {'average_total_reward': 11.508, 'reward_variance': 2.565016, 'max_total_reward': 13.45, 'min_total_reward': 8.9, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.501010322570801, 'actor_loss': -5.870851850509643, 'hyper_actor_loss': 0.007627626834437251, 'behavior_loss': 0.28032479286193845, 'mean_batch': 8.673579692840576, 'min_batch': 8.185406589508057, 'max_batch': 8.971171855926514}
step: 42790 @ episode report: {'average_total_reward': 11.941, 'reward_variance': 3.7943084, 'max_total_reward': 15.45, 'min_total_reward': 7.9000006, 'average_n_step': 12.7, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.47524094581604, 'actor_loss': -5.870067930221557, 'hyper_actor_loss': 0.007693774765357375, 'behavior_loss': 0.27027214914560316, 'mean_batch': 8.581631183624268, 'min_batch': 8.256693363189697, 'max_batch': 8.855582523345948}
step: 42800 @ episode report: {'average_total_reward': 10.664, 'reward_variance': 5.2985635, 'max_total_reward': 15.67, 'min_total_reward': 7.7900004, 'average_n_step': 11.5, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.376987862586975, 'actor_loss': -5.886412525177002, 'hyper_actor_loss': 0.0077481276355683805, 'behavior_loss': 0.26042251437902453, 'mean_batch': 8.72436809539795, 'min_batch': 8.256961250305176, 'max_batch': 9.021239757537842}
step: 42810 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 1.8231413, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.162986087799072, 'actor_loss': -5.906071615219116, 'hyper_actor_loss': 0.007709378050640226, 'behavior_loss': 0.2736674785614014, 'mean_batch': 8.832141399383545, 'min_batch': 8.329570388793945, 'max_batch': 9.13882007598877}
step: 42820 @ episode report: {'average_total_reward': 9.910001, 'reward_variance': 4.037321, 'max_total_reward': 13.450001, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.418556165695191, 'actor_loss': -5.8270713806152346, 'hyper_actor_loss': 0.007709708996117115, 'behavior_loss': 0.2780386537313461, 'mean_batch': 8.434975719451904, 'min_batch': 8.04807186126709, 'max_batch': 8.725634384155274}
step: 42830 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 1.9458802, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.663981032371521, 'actor_loss': -5.842563009262085, 'hyper_actor_loss': 0.007497123815119267, 'behavior_loss': 0.27603609412908553, 'mean_batch': 8.494783306121827, 'min_batch': 8.11640772819519, 'max_batch': 8.745841789245606}
step: 42840 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.632908, 'max_total_reward': 13.23, 'min_total_reward': 6.9000006, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.573485779762268, 'actor_loss': -5.895942068099975, 'hyper_actor_loss': 0.00765028796158731, 'behavior_loss': 0.2571148037910461, 'mean_batch': 8.73690071105957, 'min_batch': 8.323046684265137, 'max_batch': 9.014729881286621}
step: 42850 @ episode report: {'average_total_reward': 9.033, 'reward_variance': 1.2764611, 'max_total_reward': 11.120001, 'min_total_reward': 6.7900004, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.263299870491028, 'actor_loss': -5.88247709274292, 'hyper_actor_loss': 0.007380023831501603, 'behavior_loss': 0.267491389811039, 'mean_batch': 8.646592617034912, 'min_batch': 8.2970552444458, 'max_batch': 8.90455894470215}
step: 42860 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 2.539796, 'max_total_reward': 12.23, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.808281993865966, 'actor_loss': -5.889552211761474, 'hyper_actor_loss': 0.007370586507022381, 'behavior_loss': 0.2653640240430832, 'mean_batch': 8.680240249633789, 'min_batch': 8.323650455474853, 'max_batch': 8.981617164611816}
step: 42870 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 0.59198064, 'max_total_reward': 11.23, 'min_total_reward': 9.01, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.431685996055603, 'actor_loss': -5.882469415664673, 'hyper_actor_loss': 0.007587450696155429, 'behavior_loss': 0.26560491770505906, 'mean_batch': 8.701281833648682, 'min_batch': 8.249752807617188, 'max_batch': 8.978732299804687}
step: 42880 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 8.682405, 'max_total_reward': 14.450001, 'min_total_reward': 4.46, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.898360908031464, 'actor_loss': -5.873476362228393, 'hyper_actor_loss': 0.007455539936199784, 'behavior_loss': 0.26898723393678664, 'mean_batch': 8.610387802124023, 'min_batch': 8.257315731048584, 'max_batch': 8.922126770019531}
step: 42890 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.2198642, 'max_total_reward': 11.2300005, 'min_total_reward': 8.79, 'average_n_step': 11.2, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.013304281234741, 'actor_loss': -5.882380819320678, 'hyper_actor_loss': 0.007391115371137858, 'behavior_loss': 0.2642700269818306, 'mean_batch': 8.684891510009766, 'min_batch': 8.261462497711182, 'max_batch': 8.989588260650635}
step: 42900 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 2.7941613, 'max_total_reward': 13.45, 'min_total_reward': 7.6800003, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.763503193855286, 'actor_loss': -5.9194666862487795, 'hyper_actor_loss': 0.00736276893876493, 'behavior_loss': 0.26477191150188445, 'mean_batch': 8.793974018096923, 'min_batch': 8.465671157836914, 'max_batch': 9.076397514343261}
step: 42910 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 4.2259803, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.372596883773804, 'actor_loss': -5.900525712966919, 'hyper_actor_loss': 0.007401206297799945, 'behavior_loss': 0.2592606857419014, 'mean_batch': 8.724910449981689, 'min_batch': 8.372287178039551, 'max_batch': 9.020978832244873}
step: 42920 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 1.4000089, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.340642738342285, 'actor_loss': -5.883307552337646, 'hyper_actor_loss': 0.007309154747053981, 'behavior_loss': 0.27570507675409317, 'mean_batch': 8.739054012298585, 'min_batch': 8.22494330406189, 'max_batch': 9.043325710296632}
step: 42930 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 4.7296457, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6942784786224365, 'actor_loss': -5.9068787574768065, 'hyper_actor_loss': 0.00723869502544403, 'behavior_loss': 0.2635696053504944, 'mean_batch': 8.772264862060547, 'min_batch': 8.380763339996339, 'max_batch': 9.079519557952882}
step: 42940 @ episode report: {'average_total_reward': 10.842, 'reward_variance': 1.2620754, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.69273533821106, 'actor_loss': -5.92095193862915, 'hyper_actor_loss': 0.007294796453788876, 'behavior_loss': 0.25705544501543043, 'mean_batch': 8.86632776260376, 'min_batch': 8.415982437133788, 'max_batch': 9.156615352630615}
step: 42950 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 2.096025, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.976347422599792, 'actor_loss': -5.916483688354492, 'hyper_actor_loss': 0.007379379868507385, 'behavior_loss': 0.27213472723960874, 'mean_batch': 8.851284217834472, 'min_batch': 8.387268161773681, 'max_batch': 9.193879985809327}
step: 42960 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 2.0980961, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.483735394477844, 'actor_loss': -5.9105753898620605, 'hyper_actor_loss': 0.007395790517330169, 'behavior_loss': 0.27303394973278045, 'mean_batch': 8.825434398651122, 'min_batch': 8.362273502349854, 'max_batch': 9.104593563079835}
step: 42970 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 3.8841846, 'max_total_reward': 12.34, 'min_total_reward': 7.57, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.331685638427734, 'actor_loss': -5.912112045288086, 'hyper_actor_loss': 0.007452394207939505, 'behavior_loss': 0.2747340351343155, 'mean_batch': 8.77721710205078, 'min_batch': 8.419838333129883, 'max_batch': 9.10534086227417}
step: 42980 @ episode report: {'average_total_reward': 10.608999, 'reward_variance': 4.0120697, 'max_total_reward': 14.56, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.541031169891357, 'actor_loss': -5.896941423416138, 'hyper_actor_loss': 0.007643849076703191, 'behavior_loss': 0.2699234649538994, 'mean_batch': 8.765563678741454, 'min_batch': 8.306678247451782, 'max_batch': 9.05117654800415}
step: 42990 @ episode report: {'average_total_reward': 9.932, 'reward_variance': 0.9966359, 'max_total_reward': 11.2300005, 'min_total_reward': 8.57, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.386094331741333, 'actor_loss': -5.911821603775024, 'hyper_actor_loss': 0.007481447607278824, 'behavior_loss': 0.27042187601327894, 'mean_batch': 8.773864555358887, 'min_batch': 8.42053689956665, 'max_batch': 9.065011501312256}
step: 43000 @ episode report: {'average_total_reward': 9.577001, 'reward_variance': 3.0827613, 'max_total_reward': 13.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.27194983959198, 'actor_loss': -5.905069780349732, 'hyper_actor_loss': 0.007398022757843137, 'behavior_loss': 0.27164727449417114, 'mean_batch': 8.763152599334717, 'min_batch': 8.374370288848876, 'max_batch': 9.061106300354004}
step: 43010 @ episode report: {'average_total_reward': 10.542, 'reward_variance': 2.0980163, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.115989136695862, 'actor_loss': -5.846038866043091, 'hyper_actor_loss': 0.0074614820070564745, 'behavior_loss': 0.2765438809990883, 'mean_batch': 8.476717376708985, 'min_batch': 8.161342906951905, 'max_batch': 8.76056785583496}
step: 43020 @ episode report: {'average_total_reward': 11.975, 'reward_variance': 3.5103645, 'max_total_reward': 14.56, 'min_total_reward': 8.900001, 'average_n_step': 12.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.339484560489654, 'actor_loss': -5.879234027862549, 'hyper_actor_loss': 0.007413927605375648, 'behavior_loss': 0.2810518264770508, 'mean_batch': 8.633795261383057, 'min_batch': 8.283636856079102, 'max_batch': 8.931076431274414}
step: 43030 @ episode report: {'average_total_reward': 9.455, 'reward_variance': 2.1915848, 'max_total_reward': 11.12, 'min_total_reward': 5.46, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.222079181671143, 'actor_loss': -5.939592933654785, 'hyper_actor_loss': 0.007553397910669446, 'behavior_loss': 0.27780441045761106, 'mean_batch': 8.895232772827148, 'min_batch': 8.53939151763916, 'max_batch': 9.196924877166747}
step: 43040 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 7.6758246, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6579315066337585, 'actor_loss': -5.860927581787109, 'hyper_actor_loss': 0.007624231278896332, 'behavior_loss': 0.27598064988851545, 'mean_batch': 8.595937824249267, 'min_batch': 8.1740957736969, 'max_batch': 8.854253768920898}
step: 43050 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 4.3723097, 'max_total_reward': 13.120001, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.808095693588257, 'actor_loss': -5.868621349334717, 'hyper_actor_loss': 0.00789315733127296, 'behavior_loss': 0.2640675321221352, 'mean_batch': 8.574436950683594, 'min_batch': 8.251971912384032, 'max_batch': 8.826669216156006}
step: 43060 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.0109098, 'max_total_reward': 11.2300005, 'min_total_reward': 7.7899995, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.781489276885987, 'actor_loss': -5.877417469024659, 'hyper_actor_loss': 0.007913714507594705, 'behavior_loss': 0.26875169724226, 'mean_batch': 8.656652736663819, 'min_batch': 8.24797215461731, 'max_batch': 8.921336936950684}
step: 43070 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 3.95301, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.4566603899002075, 'actor_loss': -5.873950958251953, 'hyper_actor_loss': 0.007875678781419992, 'behavior_loss': 0.2861528918147087, 'mean_batch': 8.601333904266358, 'min_batch': 8.270140743255615, 'max_batch': 8.865751266479492}
step: 43080 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 7.1623254, 'max_total_reward': 15.670001, 'min_total_reward': 6.68, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.48217294216156, 'actor_loss': -5.8679115772247314, 'hyper_actor_loss': 0.007770884269848466, 'behavior_loss': 0.24537623673677444, 'mean_batch': 8.573917388916016, 'min_batch': 8.247104406356812, 'max_batch': 8.84441785812378}
step: 43090 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 4.496056, 'max_total_reward': 14.56, 'min_total_reward': 7.9000006, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.40635199546814, 'actor_loss': -5.846952295303344, 'hyper_actor_loss': 0.007728971494361758, 'behavior_loss': 0.257136395573616, 'mean_batch': 8.54465684890747, 'min_batch': 8.108554983139038, 'max_batch': 8.837656116485595}
step: 43100 @ episode report: {'average_total_reward': 10.887001, 'reward_variance': 2.4012203, 'max_total_reward': 12.34, 'min_total_reward': 6.680001, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.996822881698608, 'actor_loss': -5.867061901092529, 'hyper_actor_loss': 0.007824907684698701, 'behavior_loss': 0.25686802715063095, 'mean_batch': 8.592646503448487, 'min_batch': 8.221764945983887, 'max_batch': 8.911667919158935}
step: 43110 @ episode report: {'average_total_reward': 10.187, 'reward_variance': 4.3686004, 'max_total_reward': 14.45, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.891949892044067, 'actor_loss': -5.893842172622681, 'hyper_actor_loss': 0.007752970606088638, 'behavior_loss': 0.24514121413230897, 'mean_batch': 8.739741134643555, 'min_batch': 8.305707645416259, 'max_batch': 9.022310352325439}
step: 43120 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 3.4399009, 'max_total_reward': 14.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.900248432159424, 'actor_loss': -5.885422611236573, 'hyper_actor_loss': 0.007710658991709351, 'behavior_loss': 0.28001657128334045, 'mean_batch': 8.712088489532471, 'min_batch': 8.261717796325684, 'max_batch': 9.007256984710693}
step: 43130 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 4.695684, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.440245509147644, 'actor_loss': -5.885971307754517, 'hyper_actor_loss': 0.007836833549663424, 'behavior_loss': 0.27442819625139236, 'mean_batch': 8.713244247436524, 'min_batch': 8.266087436676026, 'max_batch': 9.079281520843505}
step: 43140 @ episode report: {'average_total_reward': 9.998001, 'reward_variance': 3.6397362, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.247455179691315, 'actor_loss': -5.886043739318848, 'hyper_actor_loss': 0.007932719681411982, 'behavior_loss': 0.2718973934650421, 'mean_batch': 8.721082782745361, 'min_batch': 8.255688571929932, 'max_batch': 9.074467849731445}
step: 43150 @ episode report: {'average_total_reward': 11.364, 'reward_variance': 1.301924, 'max_total_reward': 12.340001, 'min_total_reward': 8.900001, 'average_n_step': 12.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.77564959526062, 'actor_loss': -5.917872142791748, 'hyper_actor_loss': 0.007722575310617685, 'behavior_loss': 0.26701870411634443, 'mean_batch': 8.843374156951905, 'min_batch': 8.405166339874267, 'max_batch': 9.212449932098389}
step: 43160 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 3.8226457, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.698406744003296, 'actor_loss': -5.898051452636719, 'hyper_actor_loss': 0.007478834642097354, 'behavior_loss': 0.2733685463666916, 'mean_batch': 8.767031002044678, 'min_batch': 8.31235761642456, 'max_batch': 9.11988697052002}
step: 43170 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.8343246, 'max_total_reward': 12.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.812328338623047, 'actor_loss': -5.854589748382568, 'hyper_actor_loss': 0.007629685429856181, 'behavior_loss': 0.29171792715787886, 'mean_batch': 8.56724157333374, 'min_batch': 8.150784921646117, 'max_batch': 8.90283432006836}
step: 43180 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.319041, 'max_total_reward': 13.450001, 'min_total_reward': 8.899999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.807540512084961, 'actor_loss': -5.87351508140564, 'hyper_actor_loss': 0.00751975211314857, 'behavior_loss': 0.26762061566114426, 'mean_batch': 8.588987445831298, 'min_batch': 8.278264808654786, 'max_batch': 8.867969417572022}
step: 43190 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.8925457, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.028199958801269, 'actor_loss': -5.879997444152832, 'hyper_actor_loss': 0.007796781836077571, 'behavior_loss': 0.2767432630062103, 'mean_batch': 8.66068344116211, 'min_batch': 8.263790273666382, 'max_batch': 8.939866733551025}
step: 43200 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 1.9088295, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.972922611236572, 'actor_loss': -5.886402750015259, 'hyper_actor_loss': 0.007600165018811822, 'behavior_loss': 0.2684689849615097, 'mean_batch': 8.660336017608643, 'min_batch': 8.31652364730835, 'max_batch': 8.966328144073486}
step: 43210 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.9448419, 'max_total_reward': 13.340001, 'min_total_reward': 7.5699997, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2840689063072204, 'actor_loss': -5.901927375793457, 'hyper_actor_loss': 0.007927186554297805, 'behavior_loss': 0.28062046468257906, 'mean_batch': 8.785723876953124, 'min_batch': 8.327248477935791, 'max_batch': 9.119311618804932}
step: 43220 @ episode report: {'average_total_reward': 10.297999, 'reward_variance': 4.2718763, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.247957384586334, 'actor_loss': -5.9320862770080565, 'hyper_actor_loss': 0.007518116105347872, 'behavior_loss': 0.2635307475924492, 'mean_batch': 8.855725288391113, 'min_batch': 8.51319932937622, 'max_batch': 9.164308738708495}
step: 43230 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 2.825005, 'max_total_reward': 13.450001, 'min_total_reward': 7.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.835208702087402, 'actor_loss': -5.8596233367919925, 'hyper_actor_loss': 0.0073387451935559515, 'behavior_loss': 0.2709246352314949, 'mean_batch': 8.59143419265747, 'min_batch': 8.16382555961609, 'max_batch': 8.840170955657959}
step: 43240 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 5.92167, 'max_total_reward': 12.2300005, 'min_total_reward': 3.57, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.436993432044983, 'actor_loss': -5.85882043838501, 'hyper_actor_loss': 0.007390035362914204, 'behavior_loss': 0.2748138099908829, 'mean_batch': 8.562175369262695, 'min_batch': 8.183733177185058, 'max_batch': 8.846362972259522}
step: 43250 @ episode report: {'average_total_reward': 9.565001, 'reward_variance': 3.6870656, 'max_total_reward': 13.45, 'min_total_reward': 5.7899995, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.298660659790039, 'actor_loss': -5.903498554229737, 'hyper_actor_loss': 0.007276917621493339, 'behavior_loss': 0.2510586306452751, 'mean_batch': 8.729613971710204, 'min_batch': 8.392879486083984, 'max_batch': 9.033623600006104}
step: 43260 @ episode report: {'average_total_reward': 10.931, 'reward_variance': 3.295889, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.508269453048706, 'actor_loss': -5.861346673965454, 'hyper_actor_loss': 0.007330118585377932, 'behavior_loss': 0.26100476533174516, 'mean_batch': 8.599927806854248, 'min_batch': 8.171785306930541, 'max_batch': 8.838556861877441}
step: 43270 @ episode report: {'average_total_reward': 10.264999, 'reward_variance': 3.3200645, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.324937736988067, 'actor_loss': -5.822475910186768, 'hyper_actor_loss': 0.007384884729981422, 'behavior_loss': 0.2711639076471329, 'mean_batch': 8.434360790252686, 'min_batch': 8.015151214599609, 'max_batch': 8.686032676696778}
step: 43280 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 1.9368893, 'max_total_reward': 13.450001, 'min_total_reward': 8.68, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4942204594612125, 'actor_loss': -5.86129789352417, 'hyper_actor_loss': 0.007313992641866207, 'behavior_loss': 0.26535888612270353, 'mean_batch': 8.59424057006836, 'min_batch': 8.173374557495118, 'max_batch': 8.889329051971435}
step: 43290 @ episode report: {'average_total_reward': 9.577001, 'reward_variance': 9.582922, 'max_total_reward': 13.34, 'min_total_reward': 2.02, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7512928247451782, 'actor_loss': -5.880529069900513, 'hyper_actor_loss': 0.007380764791741967, 'behavior_loss': 0.2637856140732765, 'mean_batch': 8.69050407409668, 'min_batch': 8.241278791427613, 'max_batch': 8.978575706481934}
step: 43300 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 1.3747089, 'max_total_reward': 11.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.9854421377182, 'actor_loss': -5.8818521976470945, 'hyper_actor_loss': 0.007365027535706758, 'behavior_loss': 0.27368954569101334, 'mean_batch': 8.68154411315918, 'min_batch': 8.260528945922852, 'max_batch': 8.95688009262085}
step: 43310 @ episode report: {'average_total_reward': 10.864001, 'reward_variance': 3.4986644, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.805796205997467, 'actor_loss': -5.883758640289306, 'hyper_actor_loss': 0.007356568984687328, 'behavior_loss': 0.2620567426085472, 'mean_batch': 8.662424278259277, 'min_batch': 8.292510032653809, 'max_batch': 8.964131450653076}
step: 43320 @ episode report: {'average_total_reward': 9.01, 'reward_variance': 3.3326194, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.074371290206909, 'actor_loss': -5.877025508880616, 'hyper_actor_loss': 0.0074452509637922045, 'behavior_loss': 0.2555067136883736, 'mean_batch': 8.663539409637451, 'min_batch': 8.237684345245361, 'max_batch': 8.977226638793946}
step: 43330 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 1.263901, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.446549725532532, 'actor_loss': -5.897975301742553, 'hyper_actor_loss': 0.007334978971630335, 'behavior_loss': 0.2618603572249413, 'mean_batch': 8.718507289886475, 'min_batch': 8.357199954986573, 'max_batch': 9.006786155700684}
step: 43340 @ episode report: {'average_total_reward': 9.288, 'reward_variance': 2.8869166, 'max_total_reward': 11.120001, 'min_total_reward': 4.5699997, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.831974363327026, 'actor_loss': -5.871709632873535, 'hyper_actor_loss': 0.007428989140316844, 'behavior_loss': 0.27238817512989044, 'mean_batch': 8.629416751861573, 'min_batch': 8.224557685852051, 'max_batch': 8.925823497772218}
step: 43350 @ episode report: {'average_total_reward': 9.466, 'reward_variance': 1.9362637, 'max_total_reward': 12.339999, 'min_total_reward': 7.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.749356698989868, 'actor_loss': -5.882521867752075, 'hyper_actor_loss': 0.0076933235861361025, 'behavior_loss': 0.2855738878250122, 'mean_batch': 8.6770263671875, 'min_batch': 8.268636417388915, 'max_batch': 8.972101783752441}
step: 43360 @ episode report: {'average_total_reward': 10.876001, 'reward_variance': 1.8209839, 'max_total_reward': 14.01, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.659114122390747, 'actor_loss': -5.884577083587646, 'hyper_actor_loss': 0.007722409488633275, 'behavior_loss': 0.2731172561645508, 'mean_batch': 8.718008708953857, 'min_batch': 8.246927261352539, 'max_batch': 9.09282169342041}
step: 43370 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 2.7001052, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.845836973190307, 'actor_loss': -5.897851753234863, 'hyper_actor_loss': 0.007593481242656708, 'behavior_loss': 0.2722815066576004, 'mean_batch': 8.758721542358398, 'min_batch': 8.318367385864258, 'max_batch': 9.079697036743164}
step: 43380 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 4.0585046, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.193503737449646, 'actor_loss': -5.91833176612854, 'hyper_actor_loss': 0.007574213063344359, 'behavior_loss': 0.2741532862186432, 'mean_batch': 8.8755784034729, 'min_batch': 8.379172706604004, 'max_batch': 9.227197360992431}
step: 43390 @ episode report: {'average_total_reward': 11.641, 'reward_variance': 3.2845879, 'max_total_reward': 15.67, 'min_total_reward': 9.010001, 'average_n_step': 12.4, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.071470189094543, 'actor_loss': -5.891216278076172, 'hyper_actor_loss': 0.007723110681399703, 'behavior_loss': 0.2794643461704254, 'mean_batch': 8.739450073242187, 'min_batch': 8.285117292404175, 'max_batch': 9.048651695251465}
step: 43400 @ episode report: {'average_total_reward': 10.831001, 'reward_variance': 2.9597898, 'max_total_reward': 13.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.452009439468384, 'actor_loss': -5.876071977615356, 'hyper_actor_loss': 0.007817701064050197, 'behavior_loss': 0.27122402340173724, 'mean_batch': 8.704463005065918, 'min_batch': 8.191418170928955, 'max_batch': 9.018383026123047}
step: 43410 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 0.76508373, 'max_total_reward': 11.2300005, 'min_total_reward': 8.68, 'average_n_step': 11.2, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.255254578590393, 'actor_loss': -5.891870355606079, 'hyper_actor_loss': 0.007645007316023111, 'behavior_loss': 0.2719417497515678, 'mean_batch': 8.715085697174072, 'min_batch': 8.309783554077148, 'max_batch': 9.075089836120606}
step: 43420 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 3.1301956, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.2143714427948, 'actor_loss': -5.902101612091064, 'hyper_actor_loss': 0.007763427123427391, 'behavior_loss': 0.27405831813812254, 'mean_batch': 8.75239896774292, 'min_batch': 8.359603881835938, 'max_batch': 9.096168518066406}
step: 43430 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 4.097389, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.5215315341949465, 'actor_loss': -5.885279703140259, 'hyper_actor_loss': 0.007835451839491725, 'behavior_loss': 0.2644939452409744, 'mean_batch': 8.724553966522217, 'min_batch': 8.2476478099823, 'max_batch': 9.058409309387207}
step: 43440 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 4.328589, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.678834390640259, 'actor_loss': -5.922750616073609, 'hyper_actor_loss': 0.008126412332057954, 'behavior_loss': 0.24766386896371842, 'mean_batch': 8.881074619293212, 'min_batch': 8.410436725616455, 'max_batch': 9.210611820220947}
step: 43450 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 4.10872, 'max_total_reward': 13.23, 'min_total_reward': 6.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.232864832878112, 'actor_loss': -5.9007305145263675, 'hyper_actor_loss': 0.00797902951017022, 'behavior_loss': 0.2840648487210274, 'mean_batch': 8.837519264221191, 'min_batch': 8.27590594291687, 'max_batch': 9.171166324615479}
step: 43460 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 4.1951394, 'max_total_reward': 14.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6183696508407595, 'actor_loss': -5.873715877532959, 'hyper_actor_loss': 0.007814671704545617, 'behavior_loss': 0.27506620436906815, 'mean_batch': 8.620916557312011, 'min_batch': 8.250212097167969, 'max_batch': 8.917299747467041}
step: 43470 @ episode report: {'average_total_reward': 9.099, 'reward_variance': 6.7710495, 'max_total_reward': 12.340001, 'min_total_reward': 2.3500001, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0510424137115475, 'actor_loss': -5.917747688293457, 'hyper_actor_loss': 0.00822957749478519, 'behavior_loss': 0.25172713547945025, 'mean_batch': 8.861832809448241, 'min_batch': 8.38703670501709, 'max_batch': 9.195512390136718}
step: 43480 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 2.5647006, 'max_total_reward': 12.23, 'min_total_reward': 6.6800003, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.440774774551391, 'actor_loss': -5.92389988899231, 'hyper_actor_loss': 0.007728300569579005, 'behavior_loss': 0.2637033089995384, 'mean_batch': 8.856143188476562, 'min_batch': 8.44363021850586, 'max_batch': 9.166912269592284}
step: 43490 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 5.2724447, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.899408936500549, 'actor_loss': -5.907017230987549, 'hyper_actor_loss': 0.008078058110550046, 'behavior_loss': 0.2641085430979729, 'mean_batch': 8.808180809020996, 'min_batch': 8.349984407424927, 'max_batch': 9.17001838684082}
step: 43500 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 4.572495, 'max_total_reward': 13.23, 'min_total_reward': 5.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3884097814559935, 'actor_loss': -5.88027057647705, 'hyper_actor_loss': 0.008317127684131264, 'behavior_loss': 0.2668402135372162, 'mean_batch': 8.68757734298706, 'min_batch': 8.240013027191162, 'max_batch': 8.973495960235596}
step: 43510 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 5.7749815, 'max_total_reward': 12.34, 'min_total_reward': 3.5700002, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.529419636726379, 'actor_loss': -5.89917368888855, 'hyper_actor_loss': 0.007729252567514777, 'behavior_loss': 0.2571773290634155, 'mean_batch': 8.748509407043457, 'min_batch': 8.338574409484863, 'max_batch': 9.06575403213501}
step: 43520 @ episode report: {'average_total_reward': 10.931, 'reward_variance': 3.054109, 'max_total_reward': 14.45, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3456552743911745, 'actor_loss': -5.876709413528443, 'hyper_actor_loss': 0.007658155355602503, 'behavior_loss': 0.2749897912144661, 'mean_batch': 8.620238018035888, 'min_batch': 8.274565029144288, 'max_batch': 8.884832096099853}
step: 43530 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 1.3668162, 'max_total_reward': 12.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.348242902755738, 'actor_loss': -5.893674039840699, 'hyper_actor_loss': 0.0077525261789560315, 'behavior_loss': 0.2602648943662643, 'mean_batch': 8.728823947906495, 'min_batch': 8.313512372970582, 'max_batch': 8.990140628814697}
step: 43540 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 1.4423809, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.761101007461548, 'actor_loss': -5.895882844924927, 'hyper_actor_loss': 0.00773265678435564, 'behavior_loss': 0.2660267546772957, 'mean_batch': 8.699513721466065, 'min_batch': 8.359114789962769, 'max_batch': 8.95730094909668}
step: 43550 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 1.1564164, 'max_total_reward': 12.34, 'min_total_reward': 9.009999, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.559671449661255, 'actor_loss': -5.906462955474853, 'hyper_actor_loss': 0.00774618755094707, 'behavior_loss': 0.25886507481336596, 'mean_batch': 8.750409126281738, 'min_batch': 8.398055076599121, 'max_batch': 9.033894348144532}
step: 43560 @ episode report: {'average_total_reward': 9.343, 'reward_variance': 3.5913606, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.816305780410767, 'actor_loss': -5.9152919292449955, 'hyper_actor_loss': 0.007797974534332753, 'behavior_loss': 0.2618234843015671, 'mean_batch': 8.799528503417969, 'min_batch': 8.425199127197265, 'max_batch': 9.115258312225341}
step: 43570 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 2.9822564, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5927252769470215, 'actor_loss': -5.924211549758911, 'hyper_actor_loss': 0.007795938290655613, 'behavior_loss': 0.26528420895338056, 'mean_batch': 8.859802341461181, 'min_batch': 8.443520069122314, 'max_batch': 9.145782089233398}
step: 43580 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 3.8898358, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.12083899974823, 'actor_loss': -5.935803318023682, 'hyper_actor_loss': 0.008054213831201196, 'behavior_loss': 0.2634600818157196, 'mean_batch': 8.936784267425537, 'min_batch': 8.46834716796875, 'max_batch': 9.216415977478027}
step: 43590 @ episode report: {'average_total_reward': 9.577001, 'reward_variance': 0.9578211, 'max_total_reward': 11.12, 'min_total_reward': 7.9, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.607941621541977, 'actor_loss': -5.91972074508667, 'hyper_actor_loss': 0.007878236239776015, 'behavior_loss': 0.26726626604795456, 'mean_batch': 8.86100902557373, 'min_batch': 8.40826849937439, 'max_batch': 9.16517219543457}
step: 43600 @ episode report: {'average_total_reward': 10.487001, 'reward_variance': 2.8719807, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2133636236190797, 'actor_loss': -5.944724464416504, 'hyper_actor_loss': 0.007881474355235696, 'behavior_loss': 0.2699041202664375, 'mean_batch': 8.93035430908203, 'min_batch': 8.549710559844971, 'max_batch': 9.185885143280029}
step: 43610 @ episode report: {'average_total_reward': 10.742002, 'reward_variance': 2.0113168, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.007143652439117, 'actor_loss': -5.9507276058197025, 'hyper_actor_loss': 0.007721761055290699, 'behavior_loss': 0.2647932216525078, 'mean_batch': 8.940512943267823, 'min_batch': 8.591127872467041, 'max_batch': 9.187398624420165}
step: 43620 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 0.9814016, 'max_total_reward': 11.230001, 'min_total_reward': 8.68, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.244167327880859, 'actor_loss': -5.888865375518799, 'hyper_actor_loss': 0.007723078038543463, 'behavior_loss': 0.2726051837205887, 'mean_batch': 8.655331707000732, 'min_batch': 8.342865371704102, 'max_batch': 8.8924485206604}
step: 43630 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 4.4898405, 'max_total_reward': 14.559999, 'min_total_reward': 7.5700006, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.635618209838867, 'actor_loss': -5.870123720169067, 'hyper_actor_loss': 0.0077519506681710485, 'behavior_loss': 0.27321556210517883, 'mean_batch': 8.58233060836792, 'min_batch': 8.256794738769532, 'max_batch': 8.884966945648193}
step: 43640 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 1.9763216, 'max_total_reward': 13.450001, 'min_total_reward': 8.900001, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.130448222160339, 'actor_loss': -5.935514307022094, 'hyper_actor_loss': 0.007780381152406335, 'behavior_loss': 0.2682365894317627, 'mean_batch': 8.88610906600952, 'min_batch': 8.514749431610108, 'max_batch': 9.170120239257812}
step: 43650 @ episode report: {'average_total_reward': 9.377, 'reward_variance': 3.7042809, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.154738736152649, 'actor_loss': -5.9106286525726315, 'hyper_actor_loss': 0.007927349163219332, 'behavior_loss': 0.25255501866340635, 'mean_batch': 8.802548503875732, 'min_batch': 8.383201694488525, 'max_batch': 9.112472820281983}
step: 43660 @ episode report: {'average_total_reward': 8.955001, 'reward_variance': 4.6821647, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.105148410797119, 'actor_loss': -5.880957412719726, 'hyper_actor_loss': 0.007842968357726932, 'behavior_loss': 0.25560000240802766, 'mean_batch': 8.644935894012452, 'min_batch': 8.28666787147522, 'max_batch': 8.924659633636475}
step: 43670 @ episode report: {'average_total_reward': 10.886001, 'reward_variance': 5.4808035, 'max_total_reward': 14.559999, 'min_total_reward': 6.9000006, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.746960282325745, 'actor_loss': -5.886311197280884, 'hyper_actor_loss': 0.0077547294087707995, 'behavior_loss': 0.2696141391992569, 'mean_batch': 8.660696506500244, 'min_batch': 8.315676879882812, 'max_batch': 8.947332382202148}
step: 43680 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 4.045361, 'max_total_reward': 13.340001, 'min_total_reward': 6.57, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.622796034812927, 'actor_loss': -5.882734727859497, 'hyper_actor_loss': 0.00787289896979928, 'behavior_loss': 0.2626400277018547, 'mean_batch': 8.64777488708496, 'min_batch': 8.298519515991211, 'max_batch': 8.915336418151856}
step: 43690 @ episode report: {'average_total_reward': 10.365, 'reward_variance': 2.1271653, 'max_total_reward': 13.450001, 'min_total_reward': 8.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.924262619018554, 'actor_loss': -5.865529727935791, 'hyper_actor_loss': 0.007616000110283494, 'behavior_loss': 0.2858303636312485, 'mean_batch': 8.55303602218628, 'min_batch': 8.246806335449218, 'max_batch': 8.788673686981202}
step: 43700 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 1.508496, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.776631426811218, 'actor_loss': -5.877575874328613, 'hyper_actor_loss': 0.007739553274586797, 'behavior_loss': 0.2602727487683296, 'mean_batch': 8.616874504089356, 'min_batch': 8.285204982757568, 'max_batch': 8.868109321594238}
step: 43710 @ episode report: {'average_total_reward': 9.655001, 'reward_variance': 1.3390653, 'max_total_reward': 12.2300005, 'min_total_reward': 7.5699997, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.973266053199768, 'actor_loss': -5.8936646461486815, 'hyper_actor_loss': 0.007766201393678784, 'behavior_loss': 0.27180017083883284, 'mean_batch': 8.684854984283447, 'min_batch': 8.353569507598877, 'max_batch': 8.934797859191894}
step: 43720 @ episode report: {'average_total_reward': 10.343, 'reward_variance': 5.01114, 'max_total_reward': 14.339999, 'min_total_reward': 5.68, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.184847354888916, 'actor_loss': -5.89432692527771, 'hyper_actor_loss': 0.007944383006542922, 'behavior_loss': 0.2688517883419991, 'mean_batch': 8.68479127883911, 'min_batch': 8.359026336669922, 'max_batch': 8.93537359237671}
step: 43730 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 6.76083, 'max_total_reward': 14.450001, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0507004737854, 'actor_loss': -5.898369026184082, 'hyper_actor_loss': 0.007714207796379924, 'behavior_loss': 0.2700316995382309, 'mean_batch': 8.719795417785644, 'min_batch': 8.360227680206298, 'max_batch': 9.011654949188232}
step: 43740 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 2.0859413, 'max_total_reward': 11.23, 'min_total_reward': 5.7899995, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.544612979888916, 'actor_loss': -5.907681322097778, 'hyper_actor_loss': 0.007847759593278169, 'behavior_loss': 0.2743235841393471, 'mean_batch': 8.745166206359864, 'min_batch': 8.41290979385376, 'max_batch': 9.021218013763427}
step: 43750 @ episode report: {'average_total_reward': 9.421, 'reward_variance': 1.340069, 'max_total_reward': 11.2300005, 'min_total_reward': 7.68, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.597959446907043, 'actor_loss': -5.91432671546936, 'hyper_actor_loss': 0.007944902265444398, 'behavior_loss': 0.2760047227144241, 'mean_batch': 8.781478595733642, 'min_batch': 8.43410701751709, 'max_batch': 9.113492488861084}
step: 43760 @ episode report: {'average_total_reward': 9.099999, 'reward_variance': 2.9843998, 'max_total_reward': 12.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.227854990959168, 'actor_loss': -5.94650297164917, 'hyper_actor_loss': 0.00802501505240798, 'behavior_loss': 0.28129329085350036, 'mean_batch': 8.92994556427002, 'min_batch': 8.565084075927734, 'max_batch': 9.247521305084229}
step: 43770 @ episode report: {'average_total_reward': 10.1310005, 'reward_variance': 7.00317, 'max_total_reward': 14.559999, 'min_total_reward': 5.7899995, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.95647292137146, 'actor_loss': -5.919622087478638, 'hyper_actor_loss': 0.008055181009694934, 'behavior_loss': 0.26621517688035967, 'mean_batch': 8.834717178344727, 'min_batch': 8.433416604995728, 'max_batch': 9.116050624847412}
step: 43780 @ episode report: {'average_total_reward': 9.110001, 'reward_variance': 6.77482, 'max_total_reward': 12.339999, 'min_total_reward': 2.46, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.335087716579437, 'actor_loss': -5.907204437255859, 'hyper_actor_loss': 0.007864250568673015, 'behavior_loss': 0.27208728939294813, 'mean_batch': 8.740680980682374, 'min_batch': 8.413450717926025, 'max_batch': 8.986651515960693}
step: 43790 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 1.4093848, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.843607521057129, 'actor_loss': -5.916497135162354, 'hyper_actor_loss': 0.008244863292202354, 'behavior_loss': 0.2556812509894371, 'mean_batch': 8.775617504119873, 'min_batch': 8.458367729187012, 'max_batch': 9.020135402679443}
step: 43800 @ episode report: {'average_total_reward': 10.809001, 'reward_variance': 3.637209, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.663750195503235, 'actor_loss': -5.910509920120239, 'hyper_actor_loss': 0.008292057365179063, 'behavior_loss': 0.2709969535470009, 'mean_batch': 8.748550605773925, 'min_batch': 8.434881591796875, 'max_batch': 8.984750843048095}
step: 43810 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 2.0977051, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.437755155563354, 'actor_loss': -5.866358232498169, 'hyper_actor_loss': 0.008118320535868407, 'behavior_loss': 0.26714444905519485, 'mean_batch': 8.552498054504394, 'min_batch': 8.254356861114502, 'max_batch': 8.784793376922607}
step: 43820 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 1.3539959, 'max_total_reward': 11.12, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.806451439857483, 'actor_loss': -5.8729283809661865, 'hyper_actor_loss': 0.008439854998141528, 'behavior_loss': 0.27579387575387954, 'mean_batch': 8.579338073730469, 'min_batch': 8.282891082763673, 'max_batch': 8.825441074371337}
step: 43830 @ episode report: {'average_total_reward': 10.421, 'reward_variance': 1.3033289, 'max_total_reward': 12.339999, 'min_total_reward': 8.79, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.714499187469483, 'actor_loss': -5.885753965377807, 'hyper_actor_loss': 0.007939528487622739, 'behavior_loss': 0.2625479385256767, 'mean_batch': 8.649805068969727, 'min_batch': 8.32120485305786, 'max_batch': 8.920362186431884}
step: 43840 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 2.0020237, 'max_total_reward': 12.340001, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.9528114795684814, 'actor_loss': -5.882058906555176, 'hyper_actor_loss': 0.00848806076683104, 'behavior_loss': 0.26806323826313017, 'mean_batch': 8.67600736618042, 'min_batch': 8.267878198623658, 'max_batch': 8.929853630065917}
step: 43850 @ episode report: {'average_total_reward': 10.564001, 'reward_variance': 4.6360054, 'max_total_reward': 13.450002, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.436932015419006, 'actor_loss': -5.9158408641815186, 'hyper_actor_loss': 0.008289833180606365, 'behavior_loss': 0.26769287288188937, 'mean_batch': 8.78572940826416, 'min_batch': 8.442729568481445, 'max_batch': 9.072835063934326}
step: 43860 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 3.539889, 'max_total_reward': 12.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.805469036102295, 'actor_loss': -5.904452896118164, 'hyper_actor_loss': 0.008329789433628321, 'behavior_loss': 0.280465467274189, 'mean_batch': 8.731232643127441, 'min_batch': 8.3992338180542, 'max_batch': 8.977468967437744}
step: 43870 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 1.9139292, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.580702590942383, 'actor_loss': -5.8839195728302, 'hyper_actor_loss': 0.008001173427328468, 'behavior_loss': 0.26247635930776597, 'mean_batch': 8.612600135803223, 'min_batch': 8.341872692108154, 'max_batch': 8.864648628234864}
step: 43880 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 5.0347033, 'max_total_reward': 12.34, 'min_total_reward': 5.46, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.06865348815918, 'actor_loss': -5.864350938796997, 'hyper_actor_loss': 0.008090027840808034, 'behavior_loss': 0.2642363220453262, 'mean_batch': 8.563051509857178, 'min_batch': 8.227502155303956, 'max_batch': 8.81838617324829}
step: 43890 @ episode report: {'average_total_reward': 10.742002, 'reward_variance': 1.4744762, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.982729721069336, 'actor_loss': -5.884520530700684, 'hyper_actor_loss': 0.00807742727920413, 'behavior_loss': 0.25039627254009245, 'mean_batch': 8.68814296722412, 'min_batch': 8.275055551528931, 'max_batch': 9.002907752990723}
step: 43900 @ episode report: {'average_total_reward': 10.743001, 'reward_variance': 3.838221, 'max_total_reward': 13.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.921382665634155, 'actor_loss': -5.905465936660766, 'hyper_actor_loss': 0.007845752174034715, 'behavior_loss': 0.27342344969511034, 'mean_batch': 8.732593059539795, 'min_batch': 8.406631755828858, 'max_batch': 9.019680500030518}
step: 43910 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.3762045, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.283652591705322, 'actor_loss': -5.908441638946533, 'hyper_actor_loss': 0.008137232065200806, 'behavior_loss': 0.26286785304546356, 'mean_batch': 8.760906505584718, 'min_batch': 8.404410457611084, 'max_batch': 9.069370460510253}
step: 43920 @ episode report: {'average_total_reward': 8.789, 'reward_variance': 2.560349, 'max_total_reward': 11.230001, 'min_total_reward': 5.5700006, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.352197384834289, 'actor_loss': -5.903995561599731, 'hyper_actor_loss': 0.007970005040988326, 'behavior_loss': 0.26414293646812437, 'mean_batch': 8.751055049896241, 'min_batch': 8.376601886749267, 'max_batch': 9.071519565582275}
step: 43930 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 4.880545, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.200913667678833, 'actor_loss': -5.906492710113525, 'hyper_actor_loss': 0.007844866439700126, 'behavior_loss': 0.2514808148145676, 'mean_batch': 8.747402477264405, 'min_batch': 8.401046466827392, 'max_batch': 9.035870265960693}
step: 43940 @ episode report: {'average_total_reward': 10.098001, 'reward_variance': 5.7474966, 'max_total_reward': 13.45, 'min_total_reward': 5.7899995, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.744655466079712, 'actor_loss': -5.883709669113159, 'hyper_actor_loss': 0.007981546083465218, 'behavior_loss': 0.27067367881536486, 'mean_batch': 8.639826011657714, 'min_batch': 8.313788795471192, 'max_batch': 8.916540908813477}
step: 43950 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 6.8636255, 'max_total_reward': 13.34, 'min_total_reward': 3.3500001, 'average_n_step': 10.0, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.215550565719605, 'actor_loss': -5.892207431793213, 'hyper_actor_loss': 0.008142777113243937, 'behavior_loss': 0.26363588571548463, 'mean_batch': 8.68976583480835, 'min_batch': 8.336645984649659, 'max_batch': 9.011348152160645}
step: 43960 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 7.068722, 'max_total_reward': 12.340001, 'min_total_reward': 3.13, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.39944748878479, 'actor_loss': -5.901407384872437, 'hyper_actor_loss': 0.007883190736174583, 'behavior_loss': 0.2628584250807762, 'mean_batch': 8.72015438079834, 'min_batch': 8.384458827972413, 'max_batch': 8.99963836669922}
step: 43970 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 2.293261, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.4892781496047975, 'actor_loss': -5.896511077880859, 'hyper_actor_loss': 0.008078814670443534, 'behavior_loss': 0.26743220537900925, 'mean_batch': 8.733617496490478, 'min_batch': 8.332232666015624, 'max_batch': 8.999290370941162}
step: 43980 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 1.3437493, 'max_total_reward': 11.120001, 'min_total_reward': 7.8999996, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.653596067428589, 'actor_loss': -5.861876344680786, 'hyper_actor_loss': 0.00789124662987888, 'behavior_loss': 0.2589821755886078, 'mean_batch': 8.540459156036377, 'min_batch': 8.228930759429932, 'max_batch': 8.798180198669433}
step: 43990 @ episode report: {'average_total_reward': 10.352999, 'reward_variance': 5.6924806, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.67966902256012, 'actor_loss': -5.853730821609497, 'hyper_actor_loss': 0.007871837168931962, 'behavior_loss': 0.2575881764292717, 'mean_batch': 8.557795524597168, 'min_batch': 8.147182130813599, 'max_batch': 8.831106376647949}
step: 44000 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 4.6780834, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.3575031042099, 'actor_loss': -5.878444957733154, 'hyper_actor_loss': 0.00800040173344314, 'behavior_loss': 0.2713112398982048, 'mean_batch': 8.635480213165284, 'min_batch': 8.275350046157836, 'max_batch': 8.899523448944091}
step: 44010 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 3.1821353, 'max_total_reward': 14.45, 'min_total_reward': 6.7900004, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.621872687339783, 'actor_loss': -5.889374303817749, 'hyper_actor_loss': 0.007721707224845886, 'behavior_loss': 0.25080770403146746, 'mean_batch': 8.663801670074463, 'min_batch': 8.337794208526612, 'max_batch': 8.937129878997803}
step: 44020 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 4.154586, 'max_total_reward': 12.340001, 'min_total_reward': 6.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.453685677051544, 'actor_loss': -5.902336978912354, 'hyper_actor_loss': 0.007626449316740036, 'behavior_loss': 0.2690632537007332, 'mean_batch': 8.735004043579101, 'min_batch': 8.378277206420899, 'max_batch': 9.010494136810303}
step: 44030 @ episode report: {'average_total_reward': 10.110001, 'reward_variance': 5.1281805, 'max_total_reward': 13.450001, 'min_total_reward': 6.57, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.14914391040802, 'actor_loss': -5.903134346008301, 'hyper_actor_loss': 0.007748348126187921, 'behavior_loss': 0.27528850734233856, 'mean_batch': 8.726406478881836, 'min_batch': 8.392761135101319, 'max_batch': 8.992786884307861}
step: 44040 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 4.5970087, 'max_total_reward': 14.34, 'min_total_reward': 6.57, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.947429883480072, 'actor_loss': -5.871941089630127, 'hyper_actor_loss': 0.007715937914326787, 'behavior_loss': 0.25929385870695115, 'mean_batch': 8.59141435623169, 'min_batch': 8.263198089599609, 'max_batch': 8.854741191864013}
step: 44050 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 3.770081, 'max_total_reward': 13.450001, 'min_total_reward': 6.7900004, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.528249883651734, 'actor_loss': -5.8943277359008786, 'hyper_actor_loss': 0.007721865689381957, 'behavior_loss': 0.27008253037929536, 'mean_batch': 8.69313678741455, 'min_batch': 8.351249027252198, 'max_batch': 9.009035110473633}
step: 44060 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 2.8812242, 'max_total_reward': 11.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.863958930969238, 'actor_loss': -5.882791757583618, 'hyper_actor_loss': 0.0077712108381092545, 'behavior_loss': 0.26766239255666735, 'mean_batch': 8.731497478485107, 'min_batch': 8.224666166305543, 'max_batch': 9.01182861328125}
step: 44070 @ episode report: {'average_total_reward': 9.665, 'reward_variance': 3.3952243, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6235234260559084, 'actor_loss': -5.895709085464477, 'hyper_actor_loss': 0.007530406909063458, 'behavior_loss': 0.2636056557297707, 'mean_batch': 8.688811016082763, 'min_batch': 8.36689920425415, 'max_batch': 8.99121160507202}
step: 44080 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.4188569, 'max_total_reward': 13.340001, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7037759780883786, 'actor_loss': -5.888934659957886, 'hyper_actor_loss': 0.007325698295608163, 'behavior_loss': 0.246746264398098, 'mean_batch': 8.682236194610596, 'min_batch': 8.317237186431885, 'max_batch': 9.019045639038087}
step: 44090 @ episode report: {'average_total_reward': 8.8220005, 'reward_variance': 2.0285363, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.234544348716736, 'actor_loss': -5.8694991111755375, 'hyper_actor_loss': 0.007311363238841295, 'behavior_loss': 0.2585844933986664, 'mean_batch': 8.597930145263671, 'min_batch': 8.237473249435425, 'max_batch': 8.887540245056153}
step: 44100 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 5.9758677, 'max_total_reward': 14.339999, 'min_total_reward': 5.79, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.560660195350647, 'actor_loss': -5.864557695388794, 'hyper_actor_loss': 0.007236887980252504, 'behavior_loss': 0.26655319184064863, 'mean_batch': 8.564103889465333, 'min_batch': 8.228215312957763, 'max_batch': 8.881973838806152}
step: 44110 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 3.2199645, 'max_total_reward': 13.339999, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4853835821151735, 'actor_loss': -5.866502857208252, 'hyper_actor_loss': 0.007150148088112473, 'behavior_loss': 0.27007668763399123, 'mean_batch': 8.58876142501831, 'min_batch': 8.221494817733765, 'max_batch': 8.89831771850586}
step: 44120 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 2.2114491, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.291942381858826, 'actor_loss': -5.895786237716675, 'hyper_actor_loss': 0.007064543943852186, 'behavior_loss': 0.25305216312408446, 'mean_batch': 8.712939453125, 'min_batch': 8.344539165496826, 'max_batch': 9.030558490753174}
step: 44130 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.7202618, 'max_total_reward': 13.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.152784752845764, 'actor_loss': -5.889837312698364, 'hyper_actor_loss': 0.0072348169982433316, 'behavior_loss': 0.263185553252697, 'mean_batch': 8.670605850219726, 'min_batch': 8.33542242050171, 'max_batch': 8.961662578582764}
step: 44140 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 4.4737244, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.716986632347107, 'actor_loss': -5.8706702709198, 'hyper_actor_loss': 0.00705901300534606, 'behavior_loss': 0.25838243812322614, 'mean_batch': 8.593613433837891, 'min_batch': 8.250193977355957, 'max_batch': 8.86792631149292}
step: 44150 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 1.1882215, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.244097638130188, 'actor_loss': -5.884627056121826, 'hyper_actor_loss': 0.007162520661950111, 'behavior_loss': 0.2698584824800491, 'mean_batch': 8.68886070251465, 'min_batch': 8.276848983764648, 'max_batch': 8.980713844299316}
step: 44160 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 2.66746, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.792186331748963, 'actor_loss': -5.884012460708618, 'hyper_actor_loss': 0.007003530347719789, 'behavior_loss': 0.2785369291901588, 'mean_batch': 8.637597370147706, 'min_batch': 8.31857852935791, 'max_batch': 8.974003219604493}
step: 44170 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.4012291, 'max_total_reward': 12.2300005, 'min_total_reward': 6.6800003, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8336337566375733, 'actor_loss': -5.875785541534424, 'hyper_actor_loss': 0.006981744384393096, 'behavior_loss': 0.2760131508111954, 'mean_batch': 8.651751232147216, 'min_batch': 8.238658142089843, 'max_batch': 8.965758132934571}
step: 44180 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 5.451961, 'max_total_reward': 13.450001, 'min_total_reward': 5.68, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.628139758110047, 'actor_loss': -5.914112234115601, 'hyper_actor_loss': 0.007275902107357979, 'behavior_loss': 0.2819768786430359, 'mean_batch': 8.767008972167968, 'min_batch': 8.446184253692627, 'max_batch': 9.038234996795655}
step: 44190 @ episode report: {'average_total_reward': 10.831001, 'reward_variance': 0.6885293, 'max_total_reward': 12.2300005, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.186914086341858, 'actor_loss': -5.90684700012207, 'hyper_actor_loss': 0.00717791304923594, 'behavior_loss': 0.27787916362285614, 'mean_batch': 8.73287000656128, 'min_batch': 8.417579650878906, 'max_batch': 9.011615371704101}
step: 44200 @ episode report: {'average_total_reward': 11.253001, 'reward_variance': 2.3305616, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.422111546993255, 'actor_loss': -5.902578258514405, 'hyper_actor_loss': 0.007327641872689128, 'behavior_loss': 0.26533318758010865, 'mean_batch': 8.744639587402343, 'min_batch': 8.371926879882812, 'max_batch': 9.065371799468995}
step: 44210 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.660696, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7720431089401245, 'actor_loss': -5.894958114624023, 'hyper_actor_loss': 0.007540118927136063, 'behavior_loss': 0.2688444808125496, 'mean_batch': 8.700647449493408, 'min_batch': 8.34957504272461, 'max_batch': 8.981795024871825}
step: 44220 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 3.0034041, 'max_total_reward': 13.339999, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7658703327178955, 'actor_loss': -5.891805791854859, 'hyper_actor_loss': 0.007418812718242407, 'behavior_loss': 0.2595579817891121, 'mean_batch': 8.682998561859131, 'min_batch': 8.33988904953003, 'max_batch': 8.990060615539551}
step: 44230 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 0.9662611, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.265104198455811, 'actor_loss': -5.879510402679443, 'hyper_actor_loss': 0.007340901810675859, 'behavior_loss': 0.27266238033771517, 'mean_batch': 8.631319427490235, 'min_batch': 8.287017250061036, 'max_batch': 8.90560188293457}
step: 44240 @ episode report: {'average_total_reward': 10.109001, 'reward_variance': 2.8408685, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.876309132575988, 'actor_loss': -5.878148698806763, 'hyper_actor_loss': 0.0074577996041625735, 'behavior_loss': 0.27994508743286134, 'mean_batch': 8.635039710998536, 'min_batch': 8.272466373443603, 'max_batch': 8.93145456314087}
step: 44250 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 3.0477166, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.118557810783386, 'actor_loss': -5.888077211380005, 'hyper_actor_loss': 0.007521705236285925, 'behavior_loss': 0.2703398436307907, 'mean_batch': 8.660730266571045, 'min_batch': 8.329992198944092, 'max_batch': 8.949724674224854}
step: 44260 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 4.3261695, 'max_total_reward': 12.2300005, 'min_total_reward': 5.5699997, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.136822938919067, 'actor_loss': -5.879225349426269, 'hyper_actor_loss': 0.007214376935735345, 'behavior_loss': 0.27237015068531034, 'mean_batch': 8.62585744857788, 'min_batch': 8.290102291107178, 'max_batch': 8.886547470092774}
step: 44270 @ episode report: {'average_total_reward': 9.676001, 'reward_variance': 4.047904, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.963496232032776, 'actor_loss': -5.852448987960815, 'hyper_actor_loss': 0.007404237240552902, 'behavior_loss': 0.27823197543621064, 'mean_batch': 8.564754676818847, 'min_batch': 8.13090968132019, 'max_batch': 8.844398975372314}
step: 44280 @ episode report: {'average_total_reward': 9.554001, 'reward_variance': 4.759305, 'max_total_reward': 12.34, 'min_total_reward': 4.46, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.793004512786865, 'actor_loss': -5.852023458480835, 'hyper_actor_loss': 0.007139430055394769, 'behavior_loss': 0.26443127542734146, 'mean_batch': 8.516726016998291, 'min_batch': 8.17094144821167, 'max_batch': 8.796595001220703}
step: 44290 @ episode report: {'average_total_reward': 8.211, 'reward_variance': 5.6965694, 'max_total_reward': 11.120001, 'min_total_reward': 3.46, 'average_n_step': 9.3, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.438918662071228, 'actor_loss': -5.875736379623413, 'hyper_actor_loss': 0.007419810350984335, 'behavior_loss': 0.2677649512887001, 'mean_batch': 8.603176879882813, 'min_batch': 8.283151149749756, 'max_batch': 8.882264328002929}
step: 44300 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 2.1944494, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.536096239089966, 'actor_loss': -5.903135204315186, 'hyper_actor_loss': 0.007724930485710502, 'behavior_loss': 0.27690276205539704, 'mean_batch': 8.738370037078857, 'min_batch': 8.381307220458984, 'max_batch': 9.079797077178956}
step: 44310 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 3.063849, 'max_total_reward': 13.34, 'min_total_reward': 6.7900004, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.117518949508667, 'actor_loss': -5.922215986251831, 'hyper_actor_loss': 0.007477725017815828, 'behavior_loss': 0.2875243976712227, 'mean_batch': 8.83365077972412, 'min_batch': 8.451181602478027, 'max_batch': 9.159730148315429}
step: 44320 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 2.6428761, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3223333835601805, 'actor_loss': -5.883014488220215, 'hyper_actor_loss': 0.008083255169913173, 'behavior_loss': 0.26232428699731825, 'mean_batch': 8.67665376663208, 'min_batch': 8.273911714553833, 'max_batch': 9.016989421844482}
step: 44330 @ episode report: {'average_total_reward': 8.444, 'reward_variance': 2.3754234, 'max_total_reward': 11.12, 'min_total_reward': 6.79, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.762826538085937, 'actor_loss': -5.8849327087402346, 'hyper_actor_loss': 0.007950765313580632, 'behavior_loss': 0.27923483699560164, 'mean_batch': 8.669284915924072, 'min_batch': 8.295614051818848, 'max_batch': 9.02721586227417}
step: 44340 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 5.5412483, 'max_total_reward': 15.559999, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.730459976196289, 'actor_loss': -5.867751836776733, 'hyper_actor_loss': 0.008041026256978511, 'behavior_loss': 0.2784772843122482, 'mean_batch': 8.642591857910157, 'min_batch': 8.181927585601807, 'max_batch': 9.026055908203125}
step: 44350 @ episode report: {'average_total_reward': 10.386999, 'reward_variance': 3.6384208, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.698928451538086, 'actor_loss': -5.831566715240479, 'hyper_actor_loss': 0.007945368252694606, 'behavior_loss': 0.26795335710048673, 'mean_batch': 8.455792427062988, 'min_batch': 8.063729286193848, 'max_batch': 8.803855419158936}
step: 44360 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.2265007, 'max_total_reward': 12.34, 'min_total_reward': 6.9000006, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0596688985824585, 'actor_loss': -5.890220785140992, 'hyper_actor_loss': 0.00813727816566825, 'behavior_loss': 0.2695693328976631, 'mean_batch': 8.730004501342773, 'min_batch': 8.283211517333985, 'max_batch': 9.130441474914551}
step: 44370 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 1.9036572, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.51143627166748, 'actor_loss': -5.872046852111817, 'hyper_actor_loss': 0.007678230991587043, 'behavior_loss': 0.28331445455551146, 'mean_batch': 8.65342674255371, 'min_batch': 8.209138822555541, 'max_batch': 8.93364667892456}
step: 44380 @ episode report: {'average_total_reward': 10.454, 'reward_variance': 5.382725, 'max_total_reward': 13.34, 'min_total_reward': 4.35, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.084668445587158, 'actor_loss': -5.871326017379761, 'hyper_actor_loss': 0.007723722187802195, 'behavior_loss': 0.28623405545949937, 'mean_batch': 8.634688568115234, 'min_batch': 8.218434715270996, 'max_batch': 8.917700672149659}
step: 44390 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 2.7995496, 'max_total_reward': 13.450001, 'min_total_reward': 7.899999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.358907151222229, 'actor_loss': -5.864746522903443, 'hyper_actor_loss': 0.00802124715410173, 'behavior_loss': 0.27713452726602555, 'mean_batch': 8.670071411132813, 'min_batch': 8.137015676498413, 'max_batch': 8.986778354644775}
step: 44400 @ episode report: {'average_total_reward': 8.733, 'reward_variance': 8.980662, 'max_total_reward': 12.2300005, 'min_total_reward': 2.3500001, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.98002986907959, 'actor_loss': -5.8819074630737305, 'hyper_actor_loss': 0.007576887449249625, 'behavior_loss': 0.2765502631664276, 'mean_batch': 8.632681941986084, 'min_batch': 8.30570945739746, 'max_batch': 8.966788291931152}
step: 44410 @ episode report: {'average_total_reward': 9.766, 'reward_variance': 8.435385, 'max_total_reward': 13.23, 'min_total_reward': 2.35, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7032828569412235, 'actor_loss': -5.8926314353942875, 'hyper_actor_loss': 0.007941406732425094, 'behavior_loss': 0.2582630515098572, 'mean_batch': 8.721822166442871, 'min_batch': 8.309854698181152, 'max_batch': 9.096306610107423}
step: 44420 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 1.3321162, 'max_total_reward': 11.23, 'min_total_reward': 7.68, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.755843710899353, 'actor_loss': -5.887186098098755, 'hyper_actor_loss': 0.007735146582126618, 'behavior_loss': 0.2730603739619255, 'mean_batch': 8.694038677215577, 'min_batch': 8.2912766456604, 'max_batch': 9.049312973022461}
step: 44430 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 3.5592575, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7899995, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.383487176895142, 'actor_loss': -5.863429689407349, 'hyper_actor_loss': 0.007713736593723297, 'behavior_loss': 0.2665052816271782, 'mean_batch': 8.585677146911621, 'min_batch': 8.19838352203369, 'max_batch': 8.909063243865967}
step: 44440 @ episode report: {'average_total_reward': 10.609001, 'reward_variance': 2.7555492, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.423968100547791, 'actor_loss': -5.869119930267334, 'hyper_actor_loss': 0.0077181817963719365, 'behavior_loss': 0.2658945396542549, 'mean_batch': 8.622619724273681, 'min_batch': 8.211785316467285, 'max_batch': 8.946218585968017}
step: 44450 @ episode report: {'average_total_reward': 9.554001, 'reward_variance': 2.841425, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.438843202590943, 'actor_loss': -5.8118894577026365, 'hyper_actor_loss': 0.007300637848675251, 'behavior_loss': 0.26959832906723025, 'mean_batch': 8.36202507019043, 'min_batch': 7.995217752456665, 'max_batch': 8.64841594696045}
step: 44460 @ episode report: {'average_total_reward': 10.099001, 'reward_variance': 2.7522297, 'max_total_reward': 12.01, 'min_total_reward': 5.68, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.815988683700562, 'actor_loss': -5.81579818725586, 'hyper_actor_loss': 0.007467569457367063, 'behavior_loss': 0.27066804766654967, 'mean_batch': 8.356746768951416, 'min_batch': 8.032848644256593, 'max_batch': 8.68742389678955}
step: 44470 @ episode report: {'average_total_reward': 11.020001, 'reward_variance': 3.96166, 'max_total_reward': 14.56, 'min_total_reward': 6.7900004, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.872375273704529, 'actor_loss': -5.838229608535767, 'hyper_actor_loss': 0.007214585412293672, 'behavior_loss': 0.2649844527244568, 'mean_batch': 8.492824935913086, 'min_batch': 8.083791923522949, 'max_batch': 8.821771144866943}
step: 44480 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 2.8924048, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.932281899452209, 'actor_loss': -5.851117897033691, 'hyper_actor_loss': 0.0073335158172994856, 'behavior_loss': 0.27344992756843567, 'mean_batch': 8.502644252777099, 'min_batch': 8.176933670043946, 'max_batch': 8.826115226745605}
step: 44490 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 2.2774608, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.308686017990112, 'actor_loss': -5.870538854598999, 'hyper_actor_loss': 0.007337541645392775, 'behavior_loss': 0.2646468266844749, 'mean_batch': 8.607122039794922, 'min_batch': 8.236902093887329, 'max_batch': 8.936693096160889}
step: 44500 @ episode report: {'average_total_reward': 11.153, 'reward_variance': 2.842522, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.706301856040954, 'actor_loss': -5.872459363937378, 'hyper_actor_loss': 0.007163454638794064, 'behavior_loss': 0.27031819969415666, 'mean_batch': 8.620378780364991, 'min_batch': 8.240002822875976, 'max_batch': 8.97051420211792}
step: 44510 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 3.0129364, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.631120753288269, 'actor_loss': -5.854135179519654, 'hyper_actor_loss': 0.0073237526696175335, 'behavior_loss': 0.26953778862953187, 'mean_batch': 8.596826839447022, 'min_batch': 8.11542854309082, 'max_batch': 8.961011028289795}
step: 44520 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 1.1949157, 'max_total_reward': 13.45, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.60315465927124, 'actor_loss': -5.851249408721924, 'hyper_actor_loss': 0.007368086744099856, 'behavior_loss': 0.27761838138103484, 'mean_batch': 8.55376501083374, 'min_batch': 8.130849075317382, 'max_batch': 8.975097942352296}
step: 44530 @ episode report: {'average_total_reward': 10.554001, 'reward_variance': 3.8075233, 'max_total_reward': 14.34, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.301583385467529, 'actor_loss': -5.859636354446411, 'hyper_actor_loss': 0.0073076055850833654, 'behavior_loss': 0.2667272508144379, 'mean_batch': 8.577258586883545, 'min_batch': 8.17596492767334, 'max_batch': 8.936403560638428}
step: 44540 @ episode report: {'average_total_reward': 9.665001, 'reward_variance': 6.676585, 'max_total_reward': 13.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.529500532150268, 'actor_loss': -5.836896514892578, 'hyper_actor_loss': 0.007399758975952864, 'behavior_loss': 0.27745348364114764, 'mean_batch': 8.533111095428467, 'min_batch': 8.035175228118897, 'max_batch': 8.84796085357666}
step: 44550 @ episode report: {'average_total_reward': 8.944, 'reward_variance': 2.1474047, 'max_total_reward': 11.120001, 'min_total_reward': 6.24, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.744743895530701, 'actor_loss': -5.871106767654419, 'hyper_actor_loss': 0.007446543732658029, 'behavior_loss': 0.2602140918374062, 'mean_batch': 8.587055015563966, 'min_batch': 8.260398960113525, 'max_batch': 8.863049030303955}
step: 44560 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 1.3686041, 'max_total_reward': 12.12, 'min_total_reward': 8.789999, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.521482014656067, 'actor_loss': -5.847755384445191, 'hyper_actor_loss': 0.0071990403812378645, 'behavior_loss': 0.2546565726399422, 'mean_batch': 8.502421569824218, 'min_batch': 8.150067901611328, 'max_batch': 8.794286346435547}
step: 44570 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 5.7203813, 'max_total_reward': 12.2300005, 'min_total_reward': 3.46, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.635834336280823, 'actor_loss': -5.864570617675781, 'hyper_actor_loss': 0.007201321050524711, 'behavior_loss': 0.2667966946959496, 'mean_batch': 8.55487585067749, 'min_batch': 8.237395095825196, 'max_batch': 8.810773468017578}
step: 44580 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.2222841, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.43614890575409, 'actor_loss': -5.857844495773316, 'hyper_actor_loss': 0.007057742914184928, 'behavior_loss': 0.2697764426469803, 'mean_batch': 8.544813346862792, 'min_batch': 8.191498947143554, 'max_batch': 8.823127269744873}
step: 44590 @ episode report: {'average_total_reward': 11.064001, 'reward_variance': 3.0904238, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.7834924221038815, 'actor_loss': -5.840827894210816, 'hyper_actor_loss': 0.007050246233120561, 'behavior_loss': 0.2881359741091728, 'mean_batch': 8.468437194824219, 'min_batch': 8.126091003417969, 'max_batch': 8.77846555709839}
step: 44600 @ episode report: {'average_total_reward': 11.231001, 'reward_variance': 4.6316085, 'max_total_reward': 15.45, 'min_total_reward': 8.79, 'average_n_step': 12.1, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0318848371505736, 'actor_loss': -5.840744590759277, 'hyper_actor_loss': 0.00720683615654707, 'behavior_loss': 0.2590640425682068, 'mean_batch': 8.446258449554444, 'min_batch': 8.146737957000733, 'max_batch': 8.73992919921875}
step: 44610 @ episode report: {'average_total_reward': 10.62, 'reward_variance': 3.1119804, 'max_total_reward': 14.56, 'min_total_reward': 7.6800003, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.84330427646637, 'actor_loss': -5.860610723495483, 'hyper_actor_loss': 0.0072282832115888596, 'behavior_loss': 0.2780649557709694, 'mean_batch': 8.533295631408691, 'min_batch': 8.225231552124024, 'max_batch': 8.84230089187622}
step: 44620 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 3.7278965, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.871772646903992, 'actor_loss': -5.864998245239258, 'hyper_actor_loss': 0.007254750514402985, 'behavior_loss': 0.27392145693302156, 'mean_batch': 8.567989540100097, 'min_batch': 8.228283023834228, 'max_batch': 8.854210662841798}
step: 44630 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.017164, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.555516219139099, 'actor_loss': -5.883006238937378, 'hyper_actor_loss': 0.0077432014513760805, 'behavior_loss': 0.2766811057925224, 'mean_batch': 8.684365177154541, 'min_batch': 8.268199253082276, 'max_batch': 9.015693092346192}
step: 44640 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 2.95999, 'max_total_reward': 14.56, 'min_total_reward': 8.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.580525350570679, 'actor_loss': -5.906888055801391, 'hyper_actor_loss': 0.007236853754147887, 'behavior_loss': 0.2796703577041626, 'mean_batch': 8.775584506988526, 'min_batch': 8.377665138244629, 'max_batch': 9.091851139068604}
step: 44650 @ episode report: {'average_total_reward': 9.643001, 'reward_variance': 2.8134613, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.301825618743896, 'actor_loss': -5.896755075454712, 'hyper_actor_loss': 0.0072796734049916266, 'behavior_loss': 0.25579890310764314, 'mean_batch': 8.72643575668335, 'min_batch': 8.339449977874756, 'max_batch': 9.010526275634765}
step: 44660 @ episode report: {'average_total_reward': 8.8550005, 'reward_variance': 4.2513847, 'max_total_reward': 12.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.423741888999939, 'actor_loss': -5.866977739334106, 'hyper_actor_loss': 0.0076265694107860325, 'behavior_loss': 0.27896165698766706, 'mean_batch': 8.60298662185669, 'min_batch': 8.212103605270386, 'max_batch': 8.886958503723145}
step: 44670 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 4.032804, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.488956356048584, 'actor_loss': -5.85169415473938, 'hyper_actor_loss': 0.007249982235953212, 'behavior_loss': 0.27397263795137405, 'mean_batch': 8.555948543548585, 'min_batch': 8.134910106658936, 'max_batch': 8.84001054763794}
step: 44680 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 7.1076293, 'max_total_reward': 13.340001, 'min_total_reward': 4.46, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.684849810600281, 'actor_loss': -5.90120759010315, 'hyper_actor_loss': 0.0074002540204674006, 'behavior_loss': 0.2751640468835831, 'mean_batch': 8.723530673980713, 'min_batch': 8.37939224243164, 'max_batch': 9.011011600494385}
step: 44690 @ episode report: {'average_total_reward': 10.654001, 'reward_variance': 2.1445053, 'max_total_reward': 13.340001, 'min_total_reward': 8.46, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.132459282875061, 'actor_loss': -5.896089124679565, 'hyper_actor_loss': 0.007176016410812736, 'behavior_loss': 0.2800820037722588, 'mean_batch': 8.709914493560792, 'min_batch': 8.349841690063476, 'max_batch': 8.98616819381714}
step: 44700 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 1.0404093, 'max_total_reward': 12.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.015401291847229, 'actor_loss': -5.885444784164429, 'hyper_actor_loss': 0.007212427724152803, 'behavior_loss': 0.265545029938221, 'mean_batch': 8.659554862976075, 'min_batch': 8.309569263458252, 'max_batch': 8.943184185028077}
step: 44710 @ episode report: {'average_total_reward': 10.964002, 'reward_variance': 3.8523846, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.26366229057312, 'actor_loss': -5.872296285629273, 'hyper_actor_loss': 0.0074688699562102554, 'behavior_loss': 0.2642057850956917, 'mean_batch': 8.613021183013917, 'min_batch': 8.244991683959961, 'max_batch': 8.892775535583496}
step: 44720 @ episode report: {'average_total_reward': 10.986, 'reward_variance': 3.4660244, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.2498455286026005, 'actor_loss': -5.8749680519104, 'hyper_actor_loss': 0.007628402579575777, 'behavior_loss': 0.2786870777606964, 'mean_batch': 8.623630809783936, 'min_batch': 8.259337186813354, 'max_batch': 8.892407512664795}
step: 44730 @ episode report: {'average_total_reward': 9.655001, 'reward_variance': 2.4367447, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.381795430183411, 'actor_loss': -5.861773729324341, 'hyper_actor_loss': 0.0074791173916310075, 'behavior_loss': 0.2905996963381767, 'mean_batch': 8.558355712890625, 'min_batch': 8.211073017120361, 'max_batch': 8.835974311828613}
step: 44740 @ episode report: {'average_total_reward': 9.332001, 'reward_variance': 3.528937, 'max_total_reward': 11.230001, 'min_total_reward': 6.7899995, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.985905385017395, 'actor_loss': -5.848535776138306, 'hyper_actor_loss': 0.007636648509651423, 'behavior_loss': 0.26297758519649506, 'mean_batch': 8.5144757270813, 'min_batch': 8.144748163223266, 'max_batch': 8.81781530380249}
step: 44750 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 1.2628207, 'max_total_reward': 10.12, 'min_total_reward': 6.79, 'average_n_step': 10.1, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.258840131759643, 'actor_loss': -5.8521997928619385, 'hyper_actor_loss': 0.007831917423754931, 'behavior_loss': 0.2760176002979279, 'mean_batch': 8.557837963104248, 'min_batch': 8.137427425384521, 'max_batch': 8.855705738067627}
step: 44760 @ episode report: {'average_total_reward': 10.52, 'reward_variance': 2.1673608, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.9386285781860355, 'actor_loss': -5.838751220703125, 'hyper_actor_loss': 0.007899381499737502, 'behavior_loss': 0.2590318351984024, 'mean_batch': 8.468506145477296, 'min_batch': 8.109547472000122, 'max_batch': 8.754595088958741}
step: 44770 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 2.3256688, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.970123314857483, 'actor_loss': -5.85992398262024, 'hyper_actor_loss': 0.007929396629333497, 'behavior_loss': 0.27218315452337266, 'mean_batch': 8.578819942474365, 'min_batch': 8.179289150238038, 'max_batch': 8.8752366065979}
step: 44780 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 3.9801292, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.79241201877594, 'actor_loss': -5.86176028251648, 'hyper_actor_loss': 0.007581574423238635, 'behavior_loss': 0.2664512857794762, 'mean_batch': 8.590597438812257, 'min_batch': 8.18074860572815, 'max_batch': 8.933452224731445}
step: 44790 @ episode report: {'average_total_reward': 9.799001, 'reward_variance': 2.9038293, 'max_total_reward': 12.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.990770864486694, 'actor_loss': -5.8320495128631595, 'hyper_actor_loss': 0.007869166508316993, 'behavior_loss': 0.2825448110699654, 'mean_batch': 8.481491661071777, 'min_batch': 8.046194744110107, 'max_batch': 8.78444175720215}
step: 44800 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 8.317729, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.747698593139648, 'actor_loss': -5.842326688766479, 'hyper_actor_loss': 0.007675327826291323, 'behavior_loss': 0.27733073830604554, 'mean_batch': 8.524794864654542, 'min_batch': 8.086001920700074, 'max_batch': 8.89217767715454}
step: 44810 @ episode report: {'average_total_reward': 9.443, 'reward_variance': 1.3410804, 'max_total_reward': 11.23, 'min_total_reward': 6.6800003, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.567021274566651, 'actor_loss': -5.8614755153656, 'hyper_actor_loss': 0.007578986184671521, 'behavior_loss': 0.2725667700171471, 'mean_batch': 8.594651985168458, 'min_batch': 8.175754356384278, 'max_batch': 8.904915046691894}
step: 44820 @ episode report: {'average_total_reward': 9.466001, 'reward_variance': 2.326584, 'max_total_reward': 12.12, 'min_total_reward': 6.7900004, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3644920825958256, 'actor_loss': -5.8850971221923825, 'hyper_actor_loss': 0.007629787456244231, 'behavior_loss': 0.26285530924797057, 'mean_batch': 8.682043361663819, 'min_batch': 8.285008525848388, 'max_batch': 9.013391876220703}
step: 44830 @ episode report: {'average_total_reward': 10.087001, 'reward_variance': 2.5424213, 'max_total_reward': 12.340001, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7731325149536135, 'actor_loss': -5.9090142250061035, 'hyper_actor_loss': 0.007453051162883639, 'behavior_loss': 0.28022841215133665, 'mean_batch': 8.771774101257325, 'min_batch': 8.39869384765625, 'max_batch': 9.06089391708374}
step: 44840 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 7.5694284, 'max_total_reward': 15.559999, 'min_total_reward': 4.35, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.620123624801636, 'actor_loss': -5.89897928237915, 'hyper_actor_loss': 0.0075667274184525015, 'behavior_loss': 0.2711020663380623, 'mean_batch': 8.715581798553467, 'min_batch': 8.368385791778564, 'max_batch': 8.998524475097657}
step: 44850 @ episode report: {'average_total_reward': 11.086, 'reward_variance': 3.582824, 'max_total_reward': 14.56, 'min_total_reward': 9.01, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.153893828392029, 'actor_loss': -5.890204334259034, 'hyper_actor_loss': 0.00770714357495308, 'behavior_loss': 0.28112259954214097, 'mean_batch': 8.708558464050293, 'min_batch': 8.30239658355713, 'max_batch': 9.011845207214355}
step: 44860 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 4.6719637, 'max_total_reward': 13.34, 'min_total_reward': 4.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.288967037200928, 'actor_loss': -5.871088218688965, 'hyper_actor_loss': 0.007785052433609963, 'behavior_loss': 0.26816940158605573, 'mean_batch': 8.62956953048706, 'min_batch': 8.220125198364258, 'max_batch': 8.916325950622559}
step: 44870 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 3.0089767, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.829921674728394, 'actor_loss': -5.856334924697876, 'hyper_actor_loss': 0.0076515881810337305, 'behavior_loss': 0.2679041504859924, 'mean_batch': 8.53554859161377, 'min_batch': 8.189413928985596, 'max_batch': 8.813643646240234}
step: 44880 @ episode report: {'average_total_reward': 10.608999, 'reward_variance': 6.434691, 'max_total_reward': 14.450001, 'min_total_reward': 5.7900004, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.461925840377807, 'actor_loss': -5.8806281089782715, 'hyper_actor_loss': 0.007759715197607875, 'behavior_loss': 0.2667230755090714, 'mean_batch': 8.651537704467774, 'min_batch': 8.277369689941406, 'max_batch': 8.897998428344726}
step: 44890 @ episode report: {'average_total_reward': 8.833, 'reward_variance': 7.206562, 'max_total_reward': 12.2300005, 'min_total_reward': 3.02, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.966184091567993, 'actor_loss': -5.880399894714356, 'hyper_actor_loss': 0.007780182361602783, 'behavior_loss': 0.2612860083580017, 'mean_batch': 8.616620922088623, 'min_batch': 8.308733558654785, 'max_batch': 8.874722480773926}
step: 44900 @ episode report: {'average_total_reward': 9.977001, 'reward_variance': 4.1355605, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.666333651542663, 'actor_loss': -5.85994701385498, 'hyper_actor_loss': 0.008349499246105552, 'behavior_loss': 0.27411207407712934, 'mean_batch': 8.608069229125977, 'min_batch': 8.152130317687988, 'max_batch': 8.864851188659667}
step: 44910 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 3.1879044, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.19424340724945, 'actor_loss': -5.909642934799194, 'hyper_actor_loss': 0.008054890390485524, 'behavior_loss': 0.25235895216465, 'mean_batch': 8.766395759582519, 'min_batch': 8.409036540985108, 'max_batch': 9.051787853240967}
step: 44920 @ episode report: {'average_total_reward': 10.298001, 'reward_variance': 2.3640952, 'max_total_reward': 13.34, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.000452542304993, 'actor_loss': -5.891566371917724, 'hyper_actor_loss': 0.007994978921487927, 'behavior_loss': 0.2728965938091278, 'mean_batch': 8.703213310241699, 'min_batch': 8.318648433685302, 'max_batch': 9.020588207244874}
step: 44930 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 4.537264, 'max_total_reward': 13.34, 'min_total_reward': 6.6800003, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.378068137168884, 'actor_loss': -5.8910118579864506, 'hyper_actor_loss': 0.007943835714831949, 'behavior_loss': 0.26628987640142443, 'mean_batch': 8.744613933563233, 'min_batch': 8.28146047592163, 'max_batch': 9.027660942077636}
step: 44940 @ episode report: {'average_total_reward': 9.521, 'reward_variance': 5.263749, 'max_total_reward': 12.34, 'min_total_reward': 5.5700006, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.010707926750183, 'actor_loss': -5.895443868637085, 'hyper_actor_loss': 0.007528067100793123, 'behavior_loss': 0.27252689003944397, 'mean_batch': 8.699004745483398, 'min_batch': 8.355130767822265, 'max_batch': 8.970628643035889}
step: 44950 @ episode report: {'average_total_reward': 9.210001, 'reward_variance': 4.79798, 'max_total_reward': 13.450001, 'min_total_reward': 5.6800003, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.11895866394043, 'actor_loss': -5.878211879730225, 'hyper_actor_loss': 0.007822250109165907, 'behavior_loss': 0.28306673765182494, 'mean_batch': 8.624455165863036, 'min_batch': 8.283428192138672, 'max_batch': 8.878857040405274}
step: 44960 @ episode report: {'average_total_reward': 10.654001, 'reward_variance': 2.310185, 'max_total_reward': 13.45, 'min_total_reward': 7.8999996, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.229670214653015, 'actor_loss': -5.871352863311768, 'hyper_actor_loss': 0.008139285538345576, 'behavior_loss': 0.26681222915649416, 'mean_batch': 8.643602561950683, 'min_batch': 8.21015977859497, 'max_batch': 8.899857425689698}
step: 44970 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 5.2756643, 'max_total_reward': 12.340001, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.616996788978577, 'actor_loss': -5.883908224105835, 'hyper_actor_loss': 0.008155564265325665, 'behavior_loss': 0.2671933963894844, 'mean_batch': 8.641194915771484, 'min_batch': 8.314285182952881, 'max_batch': 8.88967399597168}
step: 44980 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 3.7094162, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.893148303031921, 'actor_loss': -5.855235624313354, 'hyper_actor_loss': 0.007846079813316465, 'behavior_loss': 0.25164557099342344, 'mean_batch': 8.516786766052245, 'min_batch': 8.197440052032471, 'max_batch': 8.782973194122315}
step: 44990 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.4598439, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.776193916797638, 'actor_loss': -5.866834592819214, 'hyper_actor_loss': 0.007814189745113253, 'behavior_loss': 0.271931466460228, 'mean_batch': 8.554428577423096, 'min_batch': 8.25637445449829, 'max_batch': 8.786121273040772}
step: 45000 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 1.2469399, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.90266056060791, 'actor_loss': -5.868951797485352, 'hyper_actor_loss': 0.007870812993496656, 'behavior_loss': 0.25533612370491027, 'mean_batch': 8.640579795837402, 'min_batch': 8.194852304458617, 'max_batch': 8.905578422546387}
step: 45010 @ episode report: {'average_total_reward': 10.01, 'reward_variance': 2.3104005, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.77284574508667, 'actor_loss': -5.860280895233155, 'hyper_actor_loss': 0.007878014491871, 'behavior_loss': 0.2788711369037628, 'mean_batch': 8.600630950927734, 'min_batch': 8.158899354934693, 'max_batch': 8.872695541381836}
step: 45020 @ episode report: {'average_total_reward': 10.276, 'reward_variance': 1.7663835, 'max_total_reward': 12.34, 'min_total_reward': 8.68, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.818127632141113, 'actor_loss': -5.885272550582886, 'hyper_actor_loss': 0.008063012501224875, 'behavior_loss': 0.2694381535053253, 'mean_batch': 8.67101469039917, 'min_batch': 8.296959400177002, 'max_batch': 8.97185459136963}
step: 45030 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.6873603, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.4362986326217655, 'actor_loss': -5.874771070480347, 'hyper_actor_loss': 0.007827916601672768, 'behavior_loss': 0.29119276702404023, 'mean_batch': 8.625843715667724, 'min_batch': 8.253393745422363, 'max_batch': 8.951601314544678}
step: 45040 @ episode report: {'average_total_reward': 8.966001, 'reward_variance': 4.128463, 'max_total_reward': 12.23, 'min_total_reward': 5.68, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.505610203742981, 'actor_loss': -5.860565567016602, 'hyper_actor_loss': 0.007719385204836726, 'behavior_loss': 0.2643448069691658, 'mean_batch': 8.558991050720214, 'min_batch': 8.200754928588868, 'max_batch': 8.809588050842285}
step: 45050 @ episode report: {'average_total_reward': 9.809999, 'reward_variance': 3.9753594, 'max_total_reward': 13.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.872558176517487, 'actor_loss': -5.84845118522644, 'hyper_actor_loss': 0.00791502553038299, 'behavior_loss': 0.26841228604316714, 'mean_batch': 8.526328945159912, 'min_batch': 8.133652400970458, 'max_batch': 8.790640926361084}
step: 45060 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 2.4694896, 'max_total_reward': 12.230001, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.586838912963867, 'actor_loss': -5.856778812408447, 'hyper_actor_loss': 0.00795781183987856, 'behavior_loss': 0.2557038709521294, 'mean_batch': 8.540242767333984, 'min_batch': 8.188452816009521, 'max_batch': 8.807837677001952}
step: 45070 @ episode report: {'average_total_reward': 11.331001, 'reward_variance': 2.4745688, 'max_total_reward': 14.559999, 'min_total_reward': 8.79, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.300695943832397, 'actor_loss': -5.858146286010742, 'hyper_actor_loss': 0.007871245779097081, 'behavior_loss': 0.27119836062192915, 'mean_batch': 8.555005168914795, 'min_batch': 8.18458251953125, 'max_batch': 8.826101112365723}
step: 45080 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 1.7233595, 'max_total_reward': 11.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.628258740901947, 'actor_loss': -5.8921630859375, 'hyper_actor_loss': 0.0078005586750805374, 'behavior_loss': 0.26461445093154906, 'mean_batch': 8.681006336212159, 'min_batch': 8.34503402709961, 'max_batch': 8.950152397155762}
step: 45090 @ episode report: {'average_total_reward': 10.742001, 'reward_variance': 2.501736, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.347789072990418, 'actor_loss': -5.907914733886718, 'hyper_actor_loss': 0.007435424905270338, 'behavior_loss': 0.2545676499605179, 'mean_batch': 8.762318515777588, 'min_batch': 8.398571586608886, 'max_batch': 9.056567096710205}
step: 45100 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 4.6429048, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.43127589225769, 'actor_loss': -5.899128580093384, 'hyper_actor_loss': 0.007633746182546019, 'behavior_loss': 0.26863841265439986, 'mean_batch': 8.72899284362793, 'min_batch': 8.356964588165283, 'max_batch': 8.989330196380616}
step: 45110 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 1.4892887, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.354545474052429, 'actor_loss': -5.857947206497192, 'hyper_actor_loss': 0.007654803432524204, 'behavior_loss': 0.2582701474428177, 'mean_batch': 8.559838390350341, 'min_batch': 8.180098533630371, 'max_batch': 8.801823902130128}
step: 45120 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 2.5166638, 'max_total_reward': 13.12, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.776354956626892, 'actor_loss': -5.84758448600769, 'hyper_actor_loss': 0.0076148475520312784, 'behavior_loss': 0.2770145878195763, 'mean_batch': 8.51392183303833, 'min_batch': 8.140150260925292, 'max_batch': 8.776906299591065}
step: 45130 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 4.192637, 'max_total_reward': 12.2300005, 'min_total_reward': 5.68, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.352278399467468, 'actor_loss': -5.878536891937256, 'hyper_actor_loss': 0.007529387809336185, 'behavior_loss': 0.26024393886327746, 'mean_batch': 8.615466785430907, 'min_batch': 8.294267654418945, 'max_batch': 8.875965976715088}
step: 45140 @ episode report: {'average_total_reward': 8.8550005, 'reward_variance': 5.783785, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.934671187400818, 'actor_loss': -5.862738800048828, 'hyper_actor_loss': 0.0075817782897502186, 'behavior_loss': 0.2566558003425598, 'mean_batch': 8.553176879882812, 'min_batch': 8.22377405166626, 'max_batch': 8.843503856658936}
step: 45150 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 3.3375454, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.347787690162659, 'actor_loss': -5.873793888092041, 'hyper_actor_loss': 0.007616847148165106, 'behavior_loss': 0.2769421935081482, 'mean_batch': 8.604617595672607, 'min_batch': 8.265629482269286, 'max_batch': 8.849854564666748}
step: 45160 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 1.8042008, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.5876538276672365, 'actor_loss': -5.8542767524719235, 'hyper_actor_loss': 0.007569797290489078, 'behavior_loss': 0.25860960483551027, 'mean_batch': 8.575629043579102, 'min_batch': 8.136423635482789, 'max_batch': 8.835517501831054}
step: 45170 @ episode report: {'average_total_reward': 9.666, 'reward_variance': 2.067644, 'max_total_reward': 12.34, 'min_total_reward': 7.46, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.658703255653381, 'actor_loss': -5.862204074859619, 'hyper_actor_loss': 0.007561748567968607, 'behavior_loss': 0.2879945024847984, 'mean_batch': 8.587168216705322, 'min_batch': 8.187663125991822, 'max_batch': 8.898733425140382}
step: 45180 @ episode report: {'average_total_reward': 9.921, 'reward_variance': 2.1304288, 'max_total_reward': 12.119999, 'min_total_reward': 7.46, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.779503178596497, 'actor_loss': -5.86912088394165, 'hyper_actor_loss': 0.007718327920883894, 'behavior_loss': 0.24990388005971909, 'mean_batch': 8.616608619689941, 'min_batch': 8.215659713745117, 'max_batch': 8.930757999420166}
step: 45190 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 9.318142, 'max_total_reward': 14.56, 'min_total_reward': 5.5700006, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.206536841392517, 'actor_loss': -5.873240184783936, 'hyper_actor_loss': 0.007740301406010985, 'behavior_loss': 0.27094483375549316, 'mean_batch': 8.656003093719482, 'min_batch': 8.21459403038025, 'max_batch': 8.948104858398438}
step: 45200 @ episode report: {'average_total_reward': 9.91, 'reward_variance': 3.4224002, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.15125002861023, 'actor_loss': -5.862466859817505, 'hyper_actor_loss': 0.0073276786133646965, 'behavior_loss': 0.27399401664733886, 'mean_batch': 8.597893238067627, 'min_batch': 8.179041385650635, 'max_batch': 8.953060054779053}
step: 45210 @ episode report: {'average_total_reward': 10.565001, 'reward_variance': 0.78854537, 'max_total_reward': 12.01, 'min_total_reward': 8.9, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.850264263153076, 'actor_loss': -5.870782661437988, 'hyper_actor_loss': 0.0075480184517800804, 'behavior_loss': 0.2680178418755531, 'mean_batch': 8.600952434539796, 'min_batch': 8.244140815734863, 'max_batch': 8.912901210784913}
step: 45220 @ episode report: {'average_total_reward': 8.655001, 'reward_variance': 3.4101257, 'max_total_reward': 12.12, 'min_total_reward': 4.68, 'average_n_step': 9.7, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.555868458747864, 'actor_loss': -5.83931245803833, 'hyper_actor_loss': 0.007791695930063724, 'behavior_loss': 0.2753802627325058, 'mean_batch': 8.473570442199707, 'min_batch': 8.109093761444091, 'max_batch': 8.798347282409669}
step: 45230 @ episode report: {'average_total_reward': 10.409, 'reward_variance': 3.0772493, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.853389465808869, 'actor_loss': -5.840908241271973, 'hyper_actor_loss': 0.007396354014053941, 'behavior_loss': 0.2592871427536011, 'mean_batch': 8.490213680267335, 'min_batch': 8.106000947952271, 'max_batch': 8.794442844390868}
step: 45240 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 4.579604, 'max_total_reward': 13.45, 'min_total_reward': 5.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.905261659622193, 'actor_loss': -5.878578853607178, 'hyper_actor_loss': 0.007702114433050156, 'behavior_loss': 0.28495232611894605, 'mean_batch': 8.632938385009766, 'min_batch': 8.278185844421387, 'max_batch': 8.901029586791992}
step: 45250 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 1.6606455, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.947327709197998, 'actor_loss': -5.848761796951294, 'hyper_actor_loss': 0.007708277553319931, 'behavior_loss': 0.2643597170710564, 'mean_batch': 8.524264717102051, 'min_batch': 8.13898000717163, 'max_batch': 8.797292613983155}
step: 45260 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 3.0680816, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.071222496032715, 'actor_loss': -5.849278497695923, 'hyper_actor_loss': 0.00773541908711195, 'behavior_loss': 0.2743291735649109, 'mean_batch': 8.515691184997559, 'min_batch': 8.151798534393311, 'max_batch': 8.765377521514893}
step: 45270 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.5083854, 'max_total_reward': 11.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8119961500167845, 'actor_loss': -5.866621732711792, 'hyper_actor_loss': 0.007662402465939522, 'behavior_loss': 0.2504192963242531, 'mean_batch': 8.560974407196046, 'min_batch': 8.24829559326172, 'max_batch': 8.835884761810302}
step: 45280 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.6294842, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5220766186714174, 'actor_loss': -5.881771898269653, 'hyper_actor_loss': 0.0075894961133599285, 'behavior_loss': 0.2669410198926926, 'mean_batch': 8.644014263153077, 'min_batch': 8.29410982131958, 'max_batch': 8.907517147064208}
step: 45290 @ episode report: {'average_total_reward': 9.665, 'reward_variance': 4.7076445, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.232367777824402, 'actor_loss': -5.85292682647705, 'hyper_actor_loss': 0.007848802721127868, 'behavior_loss': 0.27585250586271287, 'mean_batch': 8.564776515960693, 'min_batch': 8.13692889213562, 'max_batch': 8.85417537689209}
step: 45300 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 1.0100957, 'max_total_reward': 10.12, 'min_total_reward': 6.6800003, 'average_n_step': 10.2, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.833971977233887, 'actor_loss': -5.815668249130249, 'hyper_actor_loss': 0.007794145355001092, 'behavior_loss': 0.2781191602349281, 'mean_batch': 8.357958126068116, 'min_batch': 8.028815984725952, 'max_batch': 8.615333557128906}
step: 45310 @ episode report: {'average_total_reward': 10.342001, 'reward_variance': 3.5273356, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.700831818580627, 'actor_loss': -5.825402736663818, 'hyper_actor_loss': 0.007628599787130952, 'behavior_loss': 0.27897903472185137, 'mean_batch': 8.398953533172607, 'min_batch': 8.068013525009155, 'max_batch': 8.66949462890625}
step: 45320 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 4.374396, 'max_total_reward': 12.34, 'min_total_reward': 4.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.262472939491272, 'actor_loss': -5.84648380279541, 'hyper_actor_loss': 0.007670506043359638, 'behavior_loss': 0.28380504697561265, 'mean_batch': 8.50468339920044, 'min_batch': 8.138009119033814, 'max_batch': 8.78957748413086}
step: 45330 @ episode report: {'average_total_reward': 10.92, 'reward_variance': 1.3993604, 'max_total_reward': 12.2300005, 'min_total_reward': 8.789999, 'average_n_step': 11.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5923113346099855, 'actor_loss': -5.8262858390808105, 'hyper_actor_loss': 0.00785734998062253, 'behavior_loss': 0.25957804173231125, 'mean_batch': 8.42395076751709, 'min_batch': 8.052074813842774, 'max_batch': 8.750750637054443}
step: 45340 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 5.200316, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.332610034942627, 'actor_loss': -5.84208116531372, 'hyper_actor_loss': 0.007743170624598861, 'behavior_loss': 0.27010744661092756, 'mean_batch': 8.485369396209716, 'min_batch': 8.120229816436767, 'max_batch': 8.758746242523193}
step: 45350 @ episode report: {'average_total_reward': 11.797001, 'reward_variance': 2.2387614, 'max_total_reward': 14.450001, 'min_total_reward': 9.01, 'average_n_step': 12.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6211421370506285, 'actor_loss': -5.866952896118164, 'hyper_actor_loss': 0.007853250205516814, 'behavior_loss': 0.27339715212583543, 'mean_batch': 8.609774398803712, 'min_batch': 8.205153703689575, 'max_batch': 8.895223236083984}
step: 45360 @ episode report: {'average_total_reward': 9.421, 'reward_variance': 7.8470902, 'max_total_reward': 13.450001, 'min_total_reward': 3.35, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.366425728797912, 'actor_loss': -5.864994812011719, 'hyper_actor_loss': 0.007823892822489142, 'behavior_loss': 0.2910246968269348, 'mean_batch': 8.562324047088623, 'min_batch': 8.233645057678222, 'max_batch': 8.83848009109497}
step: 45370 @ episode report: {'average_total_reward': 10.309001, 'reward_variance': 5.24041, 'max_total_reward': 14.56, 'min_total_reward': 6.68, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.898734593391419, 'actor_loss': -5.841594409942627, 'hyper_actor_loss': 0.007958807377144694, 'behavior_loss': 0.2823855340480804, 'mean_batch': 8.503009128570557, 'min_batch': 8.099376726150513, 'max_batch': 8.839311885833741}
step: 45380 @ episode report: {'average_total_reward': 9.776, 'reward_variance': 3.9536445, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.584007358551025, 'actor_loss': -5.844151353836059, 'hyper_actor_loss': 0.007753587095066905, 'behavior_loss': 0.29839304089546204, 'mean_batch': 8.529109001159668, 'min_batch': 8.098142385482788, 'max_batch': 8.839916896820068}
step: 45390 @ episode report: {'average_total_reward': 9.776, 'reward_variance': 3.7802842, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.249897170066833, 'actor_loss': -5.854271745681762, 'hyper_actor_loss': 0.007657942455261945, 'behavior_loss': 0.2678620398044586, 'mean_batch': 8.553934288024902, 'min_batch': 8.15382719039917, 'max_batch': 8.839740753173828}
step: 45400 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 5.974106, 'max_total_reward': 15.67, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.023095870018006, 'actor_loss': -5.875063085556031, 'hyper_actor_loss': 0.007622665166854859, 'behavior_loss': 0.2771803990006447, 'mean_batch': 8.625085830688477, 'min_batch': 8.2561785697937, 'max_batch': 8.921597862243653}
step: 45410 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 3.7253215, 'max_total_reward': 13.2300005, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.633234667778015, 'actor_loss': -5.873143339157105, 'hyper_actor_loss': 0.00783271910622716, 'behavior_loss': 0.2723057925701141, 'mean_batch': 8.615775203704834, 'min_batch': 8.24986753463745, 'max_batch': 8.913204288482666}
step: 45420 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 4.5698442, 'max_total_reward': 14.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.176574921607971, 'actor_loss': -5.89103217124939, 'hyper_actor_loss': 0.007808584300801158, 'behavior_loss': 0.26672322005033494, 'mean_batch': 8.70889368057251, 'min_batch': 8.308588790893555, 'max_batch': 9.00494213104248}
step: 45430 @ episode report: {'average_total_reward': 9.499001, 'reward_variance': 5.5953298, 'max_total_reward': 13.340001, 'min_total_reward': 5.68, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.65017421245575, 'actor_loss': -5.889566278457641, 'hyper_actor_loss': 0.007475396897643804, 'behavior_loss': 0.28911367505788804, 'mean_batch': 8.697606945037842, 'min_batch': 8.3071533203125, 'max_batch': 8.969454097747803}
step: 45440 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 5.311324, 'max_total_reward': 14.559999, 'min_total_reward': 6.68, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.871000289916992, 'actor_loss': -5.850428915023803, 'hyper_actor_loss': 0.0075731197837740185, 'behavior_loss': 0.28595295995473863, 'mean_batch': 8.542846298217773, 'min_batch': 8.13325114250183, 'max_batch': 8.794463062286377}
step: 45450 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 1.7113606, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.788786792755127, 'actor_loss': -5.841725397109985, 'hyper_actor_loss': 0.007626217463985086, 'behavior_loss': 0.26355492174625395, 'mean_batch': 8.498736095428466, 'min_batch': 8.104299640655517, 'max_batch': 8.77849235534668}
step: 45460 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 1.0400764, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.563598799705505, 'actor_loss': -5.845721960067749, 'hyper_actor_loss': 0.007645731372758746, 'behavior_loss': 0.2713031440973282, 'mean_batch': 8.47491102218628, 'min_batch': 8.159858798980713, 'max_batch': 8.76264123916626}
step: 45470 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 2.498444, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.380571460723877, 'actor_loss': -5.842133808135986, 'hyper_actor_loss': 0.007304126815870404, 'behavior_loss': 0.26422588229179383, 'mean_batch': 8.459438133239747, 'min_batch': 8.145517444610595, 'max_batch': 8.774739742279053}
step: 45480 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 4.3456693, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.573185420036316, 'actor_loss': -5.846724319458008, 'hyper_actor_loss': 0.007449532439932227, 'behavior_loss': 0.2799110904335976, 'mean_batch': 8.505791187286377, 'min_batch': 8.1385066986084, 'max_batch': 8.870939159393311}
step: 45490 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 1.3614213, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.378648114204407, 'actor_loss': -5.874761152267456, 'hyper_actor_loss': 0.0074414136353880165, 'behavior_loss': 0.29337533712387087, 'mean_batch': 8.622743892669678, 'min_batch': 8.256132507324219, 'max_batch': 8.93778190612793}
step: 45500 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 1.5658166, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.147509837150574, 'actor_loss': -5.874085283279419, 'hyper_actor_loss': 0.0075236526783555744, 'behavior_loss': 0.2869968757033348, 'mean_batch': 8.653273963928223, 'min_batch': 8.221626567840577, 'max_batch': 8.971583080291747}
step: 45510 @ episode report: {'average_total_reward': 9.8880005, 'reward_variance': 0.7704759, 'max_total_reward': 11.23, 'min_total_reward': 7.9, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.346687173843383, 'actor_loss': -5.8856849193573, 'hyper_actor_loss': 0.0076578488573431965, 'behavior_loss': 0.2716726645827293, 'mean_batch': 8.686081790924073, 'min_batch': 8.28661298751831, 'max_batch': 9.00929307937622}
step: 45520 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 2.13835, 'max_total_reward': 13.450002, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.108090353012085, 'actor_loss': -5.8572837829589846, 'hyper_actor_loss': 0.007523336308076977, 'behavior_loss': 0.2834253653883934, 'mean_batch': 8.558199214935303, 'min_batch': 8.174718761444092, 'max_batch': 8.84685697555542}
step: 45530 @ episode report: {'average_total_reward': 10.643, 'reward_variance': 1.7621807, 'max_total_reward': 13.45, 'min_total_reward': 8.68, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.121362388134003, 'actor_loss': -5.853675031661988, 'hyper_actor_loss': 0.00755888493731618, 'behavior_loss': 0.27657222002744675, 'mean_batch': 8.57203369140625, 'min_batch': 8.13324589729309, 'max_batch': 8.85997257232666}
step: 45540 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.9794285, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.548110795021057, 'actor_loss': -5.865299987792969, 'hyper_actor_loss': 0.007286005793139339, 'behavior_loss': 0.2613856911659241, 'mean_batch': 8.598276138305664, 'min_batch': 8.202040481567384, 'max_batch': 8.895827960968017}
step: 45550 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 2.7505758, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.345728850364685, 'actor_loss': -5.865568733215332, 'hyper_actor_loss': 0.007349032396450639, 'behavior_loss': 0.25709944069385526, 'mean_batch': 8.582988071441651, 'min_batch': 8.218389129638672, 'max_batch': 8.848409748077392}
step: 45560 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 3.8726814, 'max_total_reward': 12.34, 'min_total_reward': 5.4599996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.129206848144531, 'actor_loss': -5.859869384765625, 'hyper_actor_loss': 0.007113664411008358, 'behavior_loss': 0.2620590075850487, 'mean_batch': 8.555214118957519, 'min_batch': 8.198374557495118, 'max_batch': 8.8334228515625}
step: 45570 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 2.6906457, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.7957035303115845, 'actor_loss': -5.833222913742065, 'hyper_actor_loss': 0.007135535543784499, 'behavior_loss': 0.27418372929096224, 'mean_batch': 8.436719799041748, 'min_batch': 8.094954538345338, 'max_batch': 8.735440731048584}
step: 45580 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 2.3718092, 'max_total_reward': 12.009999, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.417016768455506, 'actor_loss': -5.877843570709229, 'hyper_actor_loss': 0.007008033012971282, 'behavior_loss': 0.270096455514431, 'mean_batch': 8.633178806304931, 'min_batch': 8.27212495803833, 'max_batch': 8.940338802337646}
step: 45590 @ episode report: {'average_total_reward': 10.798001, 'reward_variance': 2.7920964, 'max_total_reward': 13.340001, 'min_total_reward': 7.9000006, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.296340370178223, 'actor_loss': -5.894251966476441, 'hyper_actor_loss': 0.007311674579977989, 'behavior_loss': 0.27301399409770966, 'mean_batch': 8.706707382202149, 'min_batch': 8.337700939178466, 'max_batch': 8.997094917297364}
step: 45600 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 0.9816802, 'max_total_reward': 12.12, 'min_total_reward': 9.009999, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.904127478599548, 'actor_loss': -5.854626083374024, 'hyper_actor_loss': 0.007325098244473338, 'behavior_loss': 0.2656047478318214, 'mean_batch': 8.55210485458374, 'min_batch': 8.158857345581055, 'max_batch': 8.86022424697876}
step: 45610 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 3.8338852, 'max_total_reward': 13.340001, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9344168663024903, 'actor_loss': -5.847457790374756, 'hyper_actor_loss': 0.0074407773092389105, 'behavior_loss': 0.26627944260835645, 'mean_batch': 8.499015426635742, 'min_batch': 8.151016235351562, 'max_batch': 8.766266632080079}
step: 45620 @ episode report: {'average_total_reward': 10.776001, 'reward_variance': 2.9554448, 'max_total_reward': 13.120001, 'min_total_reward': 6.8999996, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.382734537124634, 'actor_loss': -5.86415114402771, 'hyper_actor_loss': 0.007235618075355887, 'behavior_loss': 0.28411845266819, 'mean_batch': 8.580334091186524, 'min_batch': 8.209676265716553, 'max_batch': 8.860613155364991}
step: 45630 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 2.103656, 'max_total_reward': 12.34, 'min_total_reward': 6.9000006, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.626606845855713, 'actor_loss': -5.847209882736206, 'hyper_actor_loss': 0.007200897578150034, 'behavior_loss': 0.2648485913872719, 'mean_batch': 8.489455032348634, 'min_batch': 8.157682609558105, 'max_batch': 8.767061042785645}
step: 45640 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 4.2461147, 'max_total_reward': 14.559999, 'min_total_reward': 7.5700006, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.855002355575562, 'actor_loss': -5.858500862121582, 'hyper_actor_loss': 0.00701279235072434, 'behavior_loss': 0.257485593855381, 'mean_batch': 8.540469646453857, 'min_batch': 8.201782274246217, 'max_batch': 8.834897136688232}
step: 45650 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 4.152885, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.315854406356811, 'actor_loss': -5.87910647392273, 'hyper_actor_loss': 0.007401820551604032, 'behavior_loss': 0.2635690256953239, 'mean_batch': 8.644357204437256, 'min_batch': 8.271496200561524, 'max_batch': 8.922072792053223}
step: 45660 @ episode report: {'average_total_reward': 10.076, 'reward_variance': 4.1456237, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.327024137973785, 'actor_loss': -5.902217721939087, 'hyper_actor_loss': 0.007397554162889719, 'behavior_loss': 0.2572521477937698, 'mean_batch': 8.715113162994385, 'min_batch': 8.395891284942627, 'max_batch': 9.008992195129395}
step: 45670 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 3.252541, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.99777455329895, 'actor_loss': -5.878040027618408, 'hyper_actor_loss': 0.00742939356714487, 'behavior_loss': 0.2817618131637573, 'mean_batch': 8.615362358093261, 'min_batch': 8.290531444549561, 'max_batch': 8.88574571609497}
step: 45680 @ episode report: {'average_total_reward': 11.231, 'reward_variance': 1.4527695, 'max_total_reward': 13.45, 'min_total_reward': 9.9, 'average_n_step': 12.1, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 6.606933832168579, 'actor_loss': -5.804105424880982, 'hyper_actor_loss': 0.007324483105912804, 'behavior_loss': 0.2864468038082123, 'mean_batch': 8.312994289398194, 'min_batch': 7.979959154129029, 'max_batch': 8.612265682220459}
step: 45690 @ episode report: {'average_total_reward': 9.443001, 'reward_variance': 1.2458212, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.577390432357788, 'actor_loss': -5.835029602050781, 'hyper_actor_loss': 0.007519545219838619, 'behavior_loss': 0.27826387733221053, 'mean_batch': 8.476350593566895, 'min_batch': 8.072271871566773, 'max_batch': 8.818610954284669}
step: 45700 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 3.519141, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.512631583213806, 'actor_loss': -5.876884937286377, 'hyper_actor_loss': 0.007287180982530117, 'behavior_loss': 0.26695368736982344, 'mean_batch': 8.638777160644532, 'min_batch': 8.258349418640137, 'max_batch': 8.996410369873047}
step: 45710 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 1.5181218, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.080502223968506, 'actor_loss': -5.875447797775268, 'hyper_actor_loss': 0.007520068949088454, 'behavior_loss': 0.2775917425751686, 'mean_batch': 8.644023895263672, 'min_batch': 8.241501808166504, 'max_batch': 8.976502323150635}
step: 45720 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 1.848849, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.239862322807312, 'actor_loss': -5.876614189147949, 'hyper_actor_loss': 0.007093769917264581, 'behavior_loss': 0.2729818344116211, 'mean_batch': 8.642550659179687, 'min_batch': 8.252559852600097, 'max_batch': 8.986077213287354}
step: 45730 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.8673642, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.662833404541016, 'actor_loss': -5.8415491580963135, 'hyper_actor_loss': 0.007312592817470431, 'behavior_loss': 0.268645715713501, 'mean_batch': 8.496045780181884, 'min_batch': 8.10590476989746, 'max_batch': 8.808688354492187}
step: 45740 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 4.345301, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.236972832679749, 'actor_loss': -5.8378589153289795, 'hyper_actor_loss': 0.007518858648836613, 'behavior_loss': 0.2449283480644226, 'mean_batch': 8.47496337890625, 'min_batch': 8.096687507629394, 'max_batch': 8.806540203094482}
step: 45750 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 5.2395844, 'max_total_reward': 14.450001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.317040348052979, 'actor_loss': -5.859740209579468, 'hyper_actor_loss': 0.007278762711212039, 'behavior_loss': 0.27361693829298017, 'mean_batch': 8.573933410644532, 'min_batch': 8.179636335372924, 'max_batch': 8.941650390625}
step: 45760 @ episode report: {'average_total_reward': 8.433001, 'reward_variance': 3.3521614, 'max_total_reward': 11.2300005, 'min_total_reward': 4.6800003, 'average_n_step': 9.5, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5470400094985965, 'actor_loss': -5.834791612625122, 'hyper_actor_loss': 0.007362552359700203, 'behavior_loss': 0.27998486906290054, 'mean_batch': 8.466369533538819, 'min_batch': 8.079581212997436, 'max_batch': 8.749337196350098}
step: 45770 @ episode report: {'average_total_reward': 10.043001, 'reward_variance': 2.6935804, 'max_total_reward': 12.340001, 'min_total_reward': 6.680001, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.671695625782013, 'actor_loss': -5.842491817474365, 'hyper_actor_loss': 0.007549601560458541, 'behavior_loss': 0.28709461390972135, 'mean_batch': 8.482940006256104, 'min_batch': 8.125892925262452, 'max_batch': 8.796089553833008}
step: 45780 @ episode report: {'average_total_reward': 10.219999, 'reward_variance': 5.982081, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.5859891176223755, 'actor_loss': -5.8591468334198, 'hyper_actor_loss': 0.007297055795788765, 'behavior_loss': 0.25691100060939787, 'mean_batch': 8.545527744293214, 'min_batch': 8.201467800140382, 'max_batch': 8.890902423858643}
step: 45790 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.70956, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.421974396705627, 'actor_loss': -5.856239604949951, 'hyper_actor_loss': 0.007342514302581549, 'behavior_loss': 0.2632469668984413, 'mean_batch': 8.572891330718994, 'min_batch': 8.151716327667236, 'max_batch': 8.913337230682373}
step: 45800 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 3.1288197, 'max_total_reward': 12.34, 'min_total_reward': 6.68, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.063915979862213, 'actor_loss': -5.866666221618653, 'hyper_actor_loss': 0.007553404895588756, 'behavior_loss': 0.257845576107502, 'mean_batch': 8.612120723724365, 'min_batch': 8.199709606170654, 'max_batch': 8.933659076690674}
step: 45810 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 5.6360803, 'max_total_reward': 13.450001, 'min_total_reward': 5.6800003, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.731868433952331, 'actor_loss': -5.870341825485229, 'hyper_actor_loss': 0.007492111437022686, 'behavior_loss': 0.28221904784440993, 'mean_batch': 8.626889324188232, 'min_batch': 8.216031646728515, 'max_batch': 8.946558094024658}
step: 45820 @ episode report: {'average_total_reward': 10.110001, 'reward_variance': 3.405461, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.578055381774902, 'actor_loss': -5.809877252578735, 'hyper_actor_loss': 0.007597172586247325, 'behavior_loss': 0.2762629210948944, 'mean_batch': 8.350030136108398, 'min_batch': 7.990284585952759, 'max_batch': 8.671260452270507}
step: 45830 @ episode report: {'average_total_reward': 10.553001, 'reward_variance': 4.0052814, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.521119093894958, 'actor_loss': -5.841754817962647, 'hyper_actor_loss': 0.007846293784677983, 'behavior_loss': 0.29370936155319216, 'mean_batch': 8.505266094207764, 'min_batch': 8.099968719482423, 'max_batch': 8.862726497650147}
step: 45840 @ episode report: {'average_total_reward': 11.031, 'reward_variance': 1.0618097, 'max_total_reward': 12.340001, 'min_total_reward': 9.899999, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.018277812004089, 'actor_loss': -5.889054918289185, 'hyper_actor_loss': 0.008087018504738808, 'behavior_loss': 0.29685942381620406, 'mean_batch': 8.710506629943847, 'min_batch': 8.290750694274902, 'max_batch': 9.040414524078368}
step: 45850 @ episode report: {'average_total_reward': 10.321001, 'reward_variance': 3.0053098, 'max_total_reward': 12.01, 'min_total_reward': 5.4599996, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.249957704544068, 'actor_loss': -5.831501817703247, 'hyper_actor_loss': 0.008066414576023816, 'behavior_loss': 0.26743628829717636, 'mean_batch': 8.44045877456665, 'min_batch': 8.077727699279786, 'max_batch': 8.74075632095337}
step: 45860 @ episode report: {'average_total_reward': 10.719999, 'reward_variance': 5.0465, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.99407126903534, 'actor_loss': -5.803011751174926, 'hyper_actor_loss': 0.00812857081182301, 'behavior_loss': 0.26839187294244765, 'mean_batch': 8.335719966888428, 'min_batch': 7.949004077911377, 'max_batch': 8.631456851959229}
step: 45870 @ episode report: {'average_total_reward': 8.722001, 'reward_variance': 6.565137, 'max_total_reward': 12.2300005, 'min_total_reward': 4.4600005, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1482568264007567, 'actor_loss': -5.849652814865112, 'hyper_actor_loss': 0.007847096771001816, 'behavior_loss': 0.2653926178812981, 'mean_batch': 8.527774810791016, 'min_batch': 8.141897630691528, 'max_batch': 8.861466121673583}
step: 45880 @ episode report: {'average_total_reward': 10.077, 'reward_variance': 2.9926012, 'max_total_reward': 13.23, 'min_total_reward': 6.68, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.725594782829285, 'actor_loss': -5.833806037902832, 'hyper_actor_loss': 0.007380061829462647, 'behavior_loss': 0.27254758328199385, 'mean_batch': 8.47958288192749, 'min_batch': 8.059251546859741, 'max_batch': 8.77831974029541}
step: 45890 @ episode report: {'average_total_reward': 8.799001, 'reward_variance': 3.3113093, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.269011497497559, 'actor_loss': -5.805403709411621, 'hyper_actor_loss': 0.007573194336146116, 'behavior_loss': 0.26399741917848585, 'mean_batch': 8.33493776321411, 'min_batch': 7.968771457672119, 'max_batch': 8.612098789215088}
step: 45900 @ episode report: {'average_total_reward': 10.986001, 'reward_variance': 1.4214045, 'max_total_reward': 13.450001, 'min_total_reward': 10.01, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.653005766868591, 'actor_loss': -5.818864870071411, 'hyper_actor_loss': 0.007573418458923698, 'behavior_loss': 0.28675133287906646, 'mean_batch': 8.40275411605835, 'min_batch': 8.011758184432983, 'max_batch': 8.717223930358887}
step: 45910 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 13.238501, 'max_total_reward': 13.450001, 'min_total_reward': 3.5700002, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8348970651626586, 'actor_loss': -5.849900817871093, 'hyper_actor_loss': 0.007687703473493457, 'behavior_loss': 0.26205979436635973, 'mean_batch': 8.522677898406982, 'min_batch': 8.14790449142456, 'max_batch': 8.83234748840332}
step: 45920 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 5.084161, 'max_total_reward': 12.12, 'min_total_reward': 3.5700002, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.416064047813416, 'actor_loss': -5.85310001373291, 'hyper_actor_loss': 0.007693885127082467, 'behavior_loss': 0.2742519199848175, 'mean_batch': 8.545467758178711, 'min_batch': 8.152369499206543, 'max_batch': 8.846396255493165}
step: 45930 @ episode report: {'average_total_reward': 9.122, 'reward_variance': 3.6954358, 'max_total_reward': 12.119999, 'min_total_reward': 5.79, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.587483024597168, 'actor_loss': -5.8228460311889645, 'hyper_actor_loss': 0.008100622752681374, 'behavior_loss': 0.2798156663775444, 'mean_batch': 8.399052810668945, 'min_batch': 8.047515678405762, 'max_batch': 8.667992496490479}
step: 45940 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 3.9506555, 'max_total_reward': 14.559999, 'min_total_reward': 6.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.624948740005493, 'actor_loss': -5.823248434066772, 'hyper_actor_loss': 0.007861341862007976, 'behavior_loss': 0.25490558594465257, 'mean_batch': 8.400370788574218, 'min_batch': 8.049131298065186, 'max_batch': 8.659220123291016}
step: 45950 @ episode report: {'average_total_reward': 11.575, 'reward_variance': 2.982905, 'max_total_reward': 14.559999, 'min_total_reward': 8.900001, 'average_n_step': 12.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.556982898712159, 'actor_loss': -5.8457252979278564, 'hyper_actor_loss': 0.007756014447659254, 'behavior_loss': 0.2576036512851715, 'mean_batch': 8.493821334838866, 'min_batch': 8.142605257034301, 'max_batch': 8.74047269821167}
step: 45960 @ episode report: {'average_total_reward': 10.431, 'reward_variance': 6.5869875, 'max_total_reward': 15.669999, 'min_total_reward': 5.79, 'average_n_step': 11.3, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.300501108169556, 'actor_loss': -5.839453268051147, 'hyper_actor_loss': 0.00788953430019319, 'behavior_loss': 0.2779055193066597, 'mean_batch': 8.4734037399292, 'min_batch': 8.110472297668457, 'max_batch': 8.730353450775146}
step: 45970 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 6.8564363, 'max_total_reward': 14.56, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8979266732931137, 'actor_loss': -5.846918964385987, 'hyper_actor_loss': 0.007843367522582412, 'behavior_loss': 0.26394894570112226, 'mean_batch': 8.501812076568603, 'min_batch': 8.14351167678833, 'max_batch': 8.7725341796875}
step: 45980 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 2.167049, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.535067367553711, 'actor_loss': -5.858051300048828, 'hyper_actor_loss': 0.007861126121133566, 'behavior_loss': 0.27549285888671876, 'mean_batch': 8.554016494750977, 'min_batch': 8.184673500061034, 'max_batch': 8.817147159576416}
step: 45990 @ episode report: {'average_total_reward': 8.911, 'reward_variance': 2.7185495, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.34427239894867, 'actor_loss': -5.848924684524536, 'hyper_actor_loss': 0.007960370555520058, 'behavior_loss': 0.27859504222869874, 'mean_batch': 8.500360584259033, 'min_batch': 8.161498069763184, 'max_batch': 8.739113330841064}
step: 46000 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 3.897388, 'max_total_reward': 13.45, 'min_total_reward': 5.7900004, 'average_n_step': 10.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.142034578323364, 'actor_loss': -5.808092498779297, 'hyper_actor_loss': 0.008105160482227803, 'behavior_loss': 0.26149083077907564, 'mean_batch': 8.336562633514404, 'min_batch': 7.989818286895752, 'max_batch': 8.588362789154052}
step: 46010 @ episode report: {'average_total_reward': 10.110001, 'reward_variance': 1.8294605, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.85495092868805, 'actor_loss': -5.800928974151612, 'hyper_actor_loss': 0.008020034618675708, 'behavior_loss': 0.24953414648771285, 'mean_batch': 8.28224515914917, 'min_batch': 7.9840020656585695, 'max_batch': 8.52088098526001}
step: 46020 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.299376, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.085645961761474, 'actor_loss': -5.801734542846679, 'hyper_actor_loss': 0.007934782234951854, 'behavior_loss': 0.263120499253273, 'mean_batch': 8.323371124267577, 'min_batch': 7.951383352279663, 'max_batch': 8.582063674926758}
step: 46030 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 3.6530159, 'max_total_reward': 14.450001, 'min_total_reward': 7.7900004, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.401133012771607, 'actor_loss': -5.812965011596679, 'hyper_actor_loss': 0.008147309999912977, 'behavior_loss': 0.2686689794063568, 'mean_batch': 8.365504932403564, 'min_batch': 8.000376510620118, 'max_batch': 8.625668144226074}
step: 46040 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 4.079816, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.748148846626282, 'actor_loss': -5.8349086284637455, 'hyper_actor_loss': 0.008522856328636409, 'behavior_loss': 0.28210039585828783, 'mean_batch': 8.439900302886963, 'min_batch': 8.105506563186646, 'max_batch': 8.705767631530762}
step: 46050 @ episode report: {'average_total_reward': 11.186, 'reward_variance': 5.548465, 'max_total_reward': 16.67, 'min_total_reward': 7.9, 'average_n_step': 12.0, 'max_n_step': 17.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.273393058776856, 'actor_loss': -5.810794734954834, 'hyper_actor_loss': 0.00857538552954793, 'behavior_loss': 0.2668916627764702, 'mean_batch': 8.350658702850343, 'min_batch': 7.997273206710815, 'max_batch': 8.606221294403076}
step: 46060 @ episode report: {'average_total_reward': 10.698001, 'reward_variance': 3.9278965, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.647835850715637, 'actor_loss': -5.804382753372193, 'hyper_actor_loss': 0.00823565712198615, 'behavior_loss': 0.2691949665546417, 'mean_batch': 8.316042518615722, 'min_batch': 7.978973865509033, 'max_batch': 8.59742784500122}
step: 46070 @ episode report: {'average_total_reward': 8.733, 'reward_variance': 3.3666813, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 9.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.337134337425232, 'actor_loss': -5.77973690032959, 'hyper_actor_loss': 0.008435601275414229, 'behavior_loss': 0.2734698697924614, 'mean_batch': 8.22511911392212, 'min_batch': 7.870517587661743, 'max_batch': 8.515879344940185}
step: 46080 @ episode report: {'average_total_reward': 9.255, 'reward_variance': 5.9744263, 'max_total_reward': 12.230001, 'min_total_reward': 3.46, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.348798704147339, 'actor_loss': -5.778468990325928, 'hyper_actor_loss': 0.008128203451633453, 'behavior_loss': 0.26541552394628526, 'mean_batch': 8.22446641921997, 'min_batch': 7.862096214294434, 'max_batch': 8.52895622253418}
step: 46090 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 5.3420053, 'max_total_reward': 12.339999, 'min_total_reward': 3.46, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.64835422039032, 'actor_loss': -5.8100487232208256, 'hyper_actor_loss': 0.0085282975807786, 'behavior_loss': 0.2718075722455978, 'mean_batch': 8.340364837646485, 'min_batch': 8.000800895690919, 'max_batch': 8.669580173492431}
step: 46100 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 1.992589, 'max_total_reward': 11.01, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.316612410545349, 'actor_loss': -5.789277219772339, 'hyper_actor_loss': 0.008380612963810563, 'behavior_loss': 0.2699621319770813, 'mean_batch': 8.264929866790771, 'min_batch': 7.907970237731933, 'max_batch': 8.556644535064697}
step: 46110 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 4.1521654, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.091490316390991, 'actor_loss': -5.791716527938843, 'hyper_actor_loss': 0.008193806139752268, 'behavior_loss': 0.2777330234646797, 'mean_batch': 8.282454299926759, 'min_batch': 7.9104491710662845, 'max_batch': 8.61448564529419}
step: 46120 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 2.5176766, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.645546317100525, 'actor_loss': -5.8019805431365965, 'hyper_actor_loss': 0.008489789674058557, 'behavior_loss': 0.2698410838842392, 'mean_batch': 8.35478630065918, 'min_batch': 7.923174428939819, 'max_batch': 8.695223426818847}
step: 46130 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.6338804, 'max_total_reward': 13.340001, 'min_total_reward': 6.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.331022644042969, 'actor_loss': -5.789977884292602, 'hyper_actor_loss': 0.008661855012178421, 'behavior_loss': 0.2690293207764626, 'mean_batch': 8.292677879333496, 'min_batch': 7.8870861530303955, 'max_batch': 8.58271141052246}
step: 46140 @ episode report: {'average_total_reward': 8.221999, 'reward_variance': 5.302716, 'max_total_reward': 12.339999, 'min_total_reward': 4.5699997, 'average_n_step': 9.3, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.125016546249389, 'actor_loss': -5.754114818572998, 'hyper_actor_loss': 0.008722861297428608, 'behavior_loss': 0.2647180840373039, 'mean_batch': 8.175868034362793, 'min_batch': 7.720132541656494, 'max_batch': 8.435926914215088}
step: 46150 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 2.826257, 'max_total_reward': 12.340001, 'min_total_reward': 7.68, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9200438499450683, 'actor_loss': -5.778436613082886, 'hyper_actor_loss': 0.008839976135641336, 'behavior_loss': 0.27989292442798613, 'mean_batch': 8.25329294204712, 'min_batch': 7.834542369842529, 'max_batch': 8.518084526062012}
step: 46160 @ episode report: {'average_total_reward': 8.910001, 'reward_variance': 4.5326204, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 9.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.658301424980164, 'actor_loss': -5.801605939865112, 'hyper_actor_loss': 0.008912425208836793, 'behavior_loss': 0.2824337527155876, 'mean_batch': 8.305321979522706, 'min_batch': 7.966968011856079, 'max_batch': 8.545766830444336}
step: 46170 @ episode report: {'average_total_reward': 10.098001, 'reward_variance': 4.8350763, 'max_total_reward': 14.56, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.129517149925232, 'actor_loss': -5.770957612991333, 'hyper_actor_loss': 0.009165068157017231, 'behavior_loss': 0.2769301772117615, 'mean_batch': 8.203765964508056, 'min_batch': 7.822751235961914, 'max_batch': 8.489758396148682}
step: 46180 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 2.1742642, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.268072199821472, 'actor_loss': -5.7804993152618405, 'hyper_actor_loss': 0.009226537030190229, 'behavior_loss': 0.2763819873332977, 'mean_batch': 8.261318588256836, 'min_batch': 7.843095493316651, 'max_batch': 8.545591926574707}
step: 46190 @ episode report: {'average_total_reward': 9.943001, 'reward_variance': 2.916921, 'max_total_reward': 13.34, 'min_total_reward': 6.9000006, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.312218284606933, 'actor_loss': -5.779950571060181, 'hyper_actor_loss': 0.009137492999434471, 'behavior_loss': 0.2636538580060005, 'mean_batch': 8.245829677581787, 'min_batch': 7.852919435501098, 'max_batch': 8.501818084716797}
step: 46200 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 3.297749, 'max_total_reward': 13.12, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0728624105453495, 'actor_loss': -5.761377143859863, 'hyper_actor_loss': 0.009204271715134382, 'behavior_loss': 0.2877333402633667, 'mean_batch': 8.192062282562256, 'min_batch': 7.759809923171997, 'max_batch': 8.463766765594482}
step: 46210 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 1.366705, 'max_total_reward': 10.12, 'min_total_reward': 6.79, 'average_n_step': 10.0, 'max_n_step': 11.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.844726300239563, 'actor_loss': -5.73417706489563, 'hyper_actor_loss': 0.009410096518695354, 'behavior_loss': 0.28311669677495954, 'mean_batch': 8.042419147491454, 'min_batch': 7.691785478591919, 'max_batch': 8.297528743743896}
step: 46220 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 2.9239647, 'max_total_reward': 13.340001, 'min_total_reward': 6.6800003, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.3770602464675905, 'actor_loss': -5.706736755371094, 'hyper_actor_loss': 0.009186352044343949, 'behavior_loss': 0.2752718612551689, 'mean_batch': 7.957988834381103, 'min_batch': 7.563439655303955, 'max_batch': 8.232721519470214}
step: 46230 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 2.2300014, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.05125777721405, 'actor_loss': -5.753597831726074, 'hyper_actor_loss': 0.009100192598998547, 'behavior_loss': 0.27560651004314424, 'mean_batch': 8.140145683288575, 'min_batch': 7.748225164413452, 'max_batch': 8.457705116271972}
step: 46240 @ episode report: {'average_total_reward': 9.299, 'reward_variance': 4.167669, 'max_total_reward': 11.2300005, 'min_total_reward': 4.68, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.065129041671753, 'actor_loss': -5.770909214019776, 'hyper_actor_loss': 0.008499235194176436, 'behavior_loss': 0.2757160171866417, 'mean_batch': 8.199419689178466, 'min_batch': 7.826245260238648, 'max_batch': 8.516656112670898}
step: 46250 @ episode report: {'average_total_reward': 10.22, 'reward_variance': 4.72556, 'max_total_reward': 14.56, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.82012448310852, 'actor_loss': -5.768637561798096, 'hyper_actor_loss': 0.008955642580986023, 'behavior_loss': 0.257896414399147, 'mean_batch': 8.165377235412597, 'min_batch': 7.841113328933716, 'max_batch': 8.470869255065917}
step: 46260 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 6.623745, 'max_total_reward': 14.56, 'min_total_reward': 6.7900004, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.284136021137238, 'actor_loss': -5.787068653106689, 'hyper_actor_loss': 0.009199298825114966, 'behavior_loss': 0.2717635303735733, 'mean_batch': 8.257058429718018, 'min_batch': 7.897985982894897, 'max_batch': 8.549724960327149}
step: 46270 @ episode report: {'average_total_reward': 9.887001, 'reward_variance': 1.5766008, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.370608925819397, 'actor_loss': -5.830756902694702, 'hyper_actor_loss': 0.009023692272603513, 'behavior_loss': 0.279491725564003, 'mean_batch': 8.430215549468993, 'min_batch': 8.081560230255127, 'max_batch': 8.684002494812011}
step: 46280 @ episode report: {'average_total_reward': 9.266001, 'reward_variance': 3.1987653, 'max_total_reward': 12.230001, 'min_total_reward': 6.68, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.020121932029724, 'actor_loss': -5.772453308105469, 'hyper_actor_loss': 0.00912327691912651, 'behavior_loss': 0.27639761865139006, 'mean_batch': 8.233192729949952, 'min_batch': 7.809198522567749, 'max_batch': 8.44517707824707}
step: 46290 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 2.2692018, 'max_total_reward': 14.560001, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.747298502922058, 'actor_loss': -5.759319686889649, 'hyper_actor_loss': 0.009415092691779137, 'behavior_loss': 0.26982604116201403, 'mean_batch': 8.182407760620118, 'min_batch': 7.754672813415527, 'max_batch': 8.391367340087891}
step: 46300 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 4.1970096, 'max_total_reward': 12.34, 'min_total_reward': 4.57, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.158442378044128, 'actor_loss': -5.820170927047729, 'hyper_actor_loss': 0.009694082010537387, 'behavior_loss': 0.2878144606947899, 'mean_batch': 8.416176033020019, 'min_batch': 8.010300397872925, 'max_batch': 8.633874225616456}
step: 46310 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 2.8429165, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.164142179489136, 'actor_loss': -5.775074243545532, 'hyper_actor_loss': 0.009500176087021828, 'behavior_loss': 0.2678007364273071, 'mean_batch': 8.184212684631348, 'min_batch': 7.873992252349853, 'max_batch': 8.365686225891114}
step: 46320 @ episode report: {'average_total_reward': 9.866, 'reward_variance': 2.284925, 'max_total_reward': 12.340002, 'min_total_reward': 7.6800003, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.263085412979126, 'actor_loss': -5.751579093933105, 'hyper_actor_loss': 0.009320863336324692, 'behavior_loss': 0.28856914639472964, 'mean_batch': 8.081036567687988, 'min_batch': 7.788839721679688, 'max_batch': 8.288273239135743}
step: 46330 @ episode report: {'average_total_reward': 10.532001, 'reward_variance': 1.5597165, 'max_total_reward': 12.12, 'min_total_reward': 7.7899995, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.416824579238892, 'actor_loss': -5.7402966022491455, 'hyper_actor_loss': 0.009571895562112331, 'behavior_loss': 0.26180365979671477, 'mean_batch': 8.080093955993652, 'min_batch': 7.7028703689575195, 'max_batch': 8.297585773468018}
step: 46340 @ episode report: {'average_total_reward': 8.811, 'reward_variance': 6.0658884, 'max_total_reward': 12.119999, 'min_total_reward': 3.46, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.885855555534363, 'actor_loss': -5.759759521484375, 'hyper_actor_loss': 0.009400126431137324, 'behavior_loss': 0.28306175470352174, 'mean_batch': 8.185307884216309, 'min_batch': 7.754589700698853, 'max_batch': 8.459758949279784}
step: 46350 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 7.1051993, 'max_total_reward': 15.67, 'min_total_reward': 5.680001, 'average_n_step': 11.2, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.9992560863494875, 'actor_loss': -5.76445574760437, 'hyper_actor_loss': 0.009725397359579802, 'behavior_loss': 0.27532744854688646, 'mean_batch': 8.165362739562989, 'min_batch': 7.808343315124512, 'max_batch': 8.415733242034912}
step: 46360 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 2.9624858, 'max_total_reward': 12.340001, 'min_total_reward': 6.7899995, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.096262466907501, 'actor_loss': -5.769970989227295, 'hyper_actor_loss': 0.009704394452273845, 'behavior_loss': 0.26306450068950654, 'mean_batch': 8.199030780792237, 'min_batch': 7.819704818725586, 'max_batch': 8.470188236236572}
step: 46370 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 2.215881, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.362584495544434, 'actor_loss': -5.794700336456299, 'hyper_actor_loss': 0.009516088571399451, 'behavior_loss': 0.2838978409767151, 'mean_batch': 8.294607257843017, 'min_batch': 7.923876190185547, 'max_batch': 8.572886753082276}
step: 46380 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 5.7835846, 'max_total_reward': 13.34, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.070476055145264, 'actor_loss': -5.725361394882202, 'hyper_actor_loss': 0.00946483900770545, 'behavior_loss': 0.27970780432224274, 'mean_batch': 8.011961269378663, 'min_batch': 7.653876829147339, 'max_batch': 8.24236764907837}
step: 46390 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 4.1249447, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.679306221008301, 'actor_loss': -5.72959532737732, 'hyper_actor_loss': 0.009310194570571185, 'behavior_loss': 0.2688189819455147, 'mean_batch': 8.037749624252319, 'min_batch': 7.662431478500366, 'max_batch': 8.280941390991211}
step: 46400 @ episode report: {'average_total_reward': 8.9, 'reward_variance': 3.8131409, 'max_total_reward': 12.2300005, 'min_total_reward': 5.46, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.152349376678467, 'actor_loss': -5.79616379737854, 'hyper_actor_loss': 0.009295063465833664, 'behavior_loss': 0.2675977647304535, 'mean_batch': 8.271724510192872, 'min_batch': 7.955914258956909, 'max_batch': 8.550954055786132}
step: 46410 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 3.5099056, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.5252443075180055, 'actor_loss': -5.731893825531006, 'hyper_actor_loss': 0.009521246701478959, 'behavior_loss': 0.27233292162418365, 'mean_batch': 8.044575452804565, 'min_batch': 7.6740625381469725, 'max_batch': 8.32440881729126}
step: 46420 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 0.92218417, 'max_total_reward': 12.2300005, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.589717054367066, 'actor_loss': -5.693303918838501, 'hyper_actor_loss': 0.009458054415881633, 'behavior_loss': 0.2605543941259384, 'mean_batch': 7.867771291732788, 'min_batch': 7.547853469848633, 'max_batch': 8.11605749130249}
step: 46430 @ episode report: {'average_total_reward': 10.321001, 'reward_variance': 3.5784695, 'max_total_reward': 14.450001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.855865955352783, 'actor_loss': -5.749393033981323, 'hyper_actor_loss': 0.009329298511147499, 'behavior_loss': 0.2847991675138474, 'mean_batch': 8.082693099975586, 'min_batch': 7.769936513900757, 'max_batch': 8.319475555419922}
step: 46440 @ episode report: {'average_total_reward': 8.6, 'reward_variance': 2.257041, 'max_total_reward': 11.120001, 'min_total_reward': 5.57, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.485771012306214, 'actor_loss': -5.72318320274353, 'hyper_actor_loss': 0.00883941212669015, 'behavior_loss': 0.28792260587215424, 'mean_batch': 8.021849346160888, 'min_batch': 7.627312469482422, 'max_batch': 8.286736679077148}
step: 46450 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 4.3839636, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.987252569198608, 'actor_loss': -5.721627521514892, 'hyper_actor_loss': 0.008983836323022843, 'behavior_loss': 0.2672200217843056, 'mean_batch': 7.982186698913575, 'min_batch': 7.652826356887817, 'max_batch': 8.253985023498535}
step: 46460 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 4.0293417, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.139152908325196, 'actor_loss': -5.719756555557251, 'hyper_actor_loss': 0.008988614566624165, 'behavior_loss': 0.2756757974624634, 'mean_batch': 8.013808917999267, 'min_batch': 7.607939338684082, 'max_batch': 8.338368320465088}
step: 46470 @ episode report: {'average_total_reward': 10.620001, 'reward_variance': 2.1333601, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6193013310432436, 'actor_loss': -5.776186323165893, 'hyper_actor_loss': 0.008807951211929321, 'behavior_loss': 0.27802679389715196, 'mean_batch': 8.222663879394531, 'min_batch': 7.845273017883301, 'max_batch': 8.56135139465332}
step: 46480 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 1.669225, 'max_total_reward': 11.23, 'min_total_reward': 6.7899995, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.943651247024536, 'actor_loss': -5.7288836479187015, 'hyper_actor_loss': 0.0089337351731956, 'behavior_loss': 0.26220578253269194, 'mean_batch': 8.022696113586425, 'min_batch': 7.6705078125, 'max_batch': 8.299561691284179}
step: 46490 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 1.7345812, 'max_total_reward': 11.120001, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.399144434928894, 'actor_loss': -5.72824068069458, 'hyper_actor_loss': 0.00903055127710104, 'behavior_loss': 0.29696943908929824, 'mean_batch': 8.036917877197265, 'min_batch': 7.652460289001465, 'max_batch': 8.294138336181641}
step: 46500 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 4.789855, 'max_total_reward': 14.34, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.040067529678344, 'actor_loss': -5.743154573440552, 'hyper_actor_loss': 0.009756627958267927, 'behavior_loss': 0.2793012037873268, 'mean_batch': 8.104619312286378, 'min_batch': 7.702460432052613, 'max_batch': 8.335832691192627}
step: 46510 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 2.0351691, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.1419525146484375, 'actor_loss': -5.708528137207031, 'hyper_actor_loss': 0.009446608740836382, 'behavior_loss': 0.2764048859477043, 'mean_batch': 7.933985471725464, 'min_batch': 7.599333381652832, 'max_batch': 8.153124523162841}
step: 46520 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 3.3572018, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.575942635536194, 'actor_loss': -5.69965090751648, 'hyper_actor_loss': 0.009097019396722316, 'behavior_loss': 0.27897709608078003, 'mean_batch': 7.899319648742676, 'min_batch': 7.5654364109039305, 'max_batch': 8.113351249694825}
step: 46530 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.8595461, 'max_total_reward': 12.120001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5324732422828675, 'actor_loss': -5.754662036895752, 'hyper_actor_loss': 0.009264139458537102, 'behavior_loss': 0.2774495393037796, 'mean_batch': 8.148592948913574, 'min_batch': 7.7485510349273685, 'max_batch': 8.376733779907227}
step: 46540 @ episode report: {'average_total_reward': 10.121, 'reward_variance': 1.0525692, 'max_total_reward': 12.12, 'min_total_reward': 8.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.0389101028442385, 'actor_loss': -5.7635931968688965, 'hyper_actor_loss': 0.0092535768635571, 'behavior_loss': 0.2747433319687843, 'mean_batch': 8.140506029129028, 'min_batch': 7.826355981826782, 'max_batch': 8.368420886993409}
step: 46550 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 2.515456, 'max_total_reward': 12.34, 'min_total_reward': 7.68, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.8148620367050174, 'actor_loss': -5.698303651809693, 'hyper_actor_loss': 0.008898214437067509, 'behavior_loss': 0.26789530664682387, 'mean_batch': 7.860833835601807, 'min_batch': 7.591430282592773, 'max_batch': 8.090957069396973}
step: 46560 @ episode report: {'average_total_reward': 9.232, 'reward_variance': 1.9220765, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.593955183029175, 'actor_loss': -5.6989751815795895, 'hyper_actor_loss': 0.00899044582620263, 'behavior_loss': 0.26822785288095474, 'mean_batch': 7.890318155288696, 'min_batch': 7.5687727451324465, 'max_batch': 8.110614824295045}
step: 46570 @ episode report: {'average_total_reward': 10.5199995, 'reward_variance': 5.51956, 'max_total_reward': 14.45, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.389749968051911, 'actor_loss': -5.738545656204224, 'hyper_actor_loss': 0.008877359330654144, 'behavior_loss': 0.2786892935633659, 'mean_batch': 8.035201692581177, 'min_batch': 7.731754922866822, 'max_batch': 8.284446716308594}
step: 46580 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.004545, 'max_total_reward': 12.12, 'min_total_reward': 7.7900004, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3830374479293823, 'actor_loss': -5.744562005996704, 'hyper_actor_loss': 0.008904843498021365, 'behavior_loss': 0.2645712152123451, 'mean_batch': 8.083896827697753, 'min_batch': 7.732372045516968, 'max_batch': 8.32567024230957}
step: 46590 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 2.0440087, 'max_total_reward': 11.23, 'min_total_reward': 6.79, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.919003534317016, 'actor_loss': -5.724831628799438, 'hyper_actor_loss': 0.008897883258759976, 'behavior_loss': 0.27668043226003647, 'mean_batch': 8.005474138259888, 'min_batch': 7.6552863121032715, 'max_batch': 8.229041957855225}
step: 46600 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.6472018, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.593955326080322, 'actor_loss': -5.687486410140991, 'hyper_actor_loss': 0.008969216886907817, 'behavior_loss': 0.2771969705820084, 'mean_batch': 7.856255006790161, 'min_batch': 7.514151668548584, 'max_batch': 8.057902622222901}
step: 46610 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.7102845, 'max_total_reward': 13.450001, 'min_total_reward': 8.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.715141463279724, 'actor_loss': -5.711756324768066, 'hyper_actor_loss': 0.009375410340726375, 'behavior_loss': 0.2565410897135735, 'mean_batch': 7.93159441947937, 'min_batch': 7.6258533000946045, 'max_batch': 8.144779396057128}
step: 46620 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.2998059, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.699409914016724, 'actor_loss': -5.7372658252716064, 'hyper_actor_loss': 0.009241206850856543, 'behavior_loss': 0.2692848205566406, 'mean_batch': 8.019310426712035, 'min_batch': 7.737633609771729, 'max_batch': 8.26973361968994}
step: 46630 @ episode report: {'average_total_reward': 11.286, 'reward_variance': 5.2056847, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.926579165458679, 'actor_loss': -5.665655851364136, 'hyper_actor_loss': 0.009632011316716671, 'behavior_loss': 0.25692777037620546, 'mean_batch': 7.7655538558959964, 'min_batch': 7.4388237476348875, 'max_batch': 8.008851099014283}
step: 46640 @ episode report: {'average_total_reward': 10.742, 'reward_variance': 3.0678356, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6187114238739015, 'actor_loss': -5.671814441680908, 'hyper_actor_loss': 0.00957915922626853, 'behavior_loss': 0.26866323202848436, 'mean_batch': 7.784924602508545, 'min_batch': 7.465724182128906, 'max_batch': 8.034809875488282}
step: 46650 @ episode report: {'average_total_reward': 11.097001, 'reward_variance': 4.470242, 'max_total_reward': 14.56, 'min_total_reward': 7.9000006, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.981686949729919, 'actor_loss': -5.704977655410767, 'hyper_actor_loss': 0.009661487489938735, 'behavior_loss': 0.27972019761800765, 'mean_batch': 7.949391508102417, 'min_batch': 7.557892751693726, 'max_batch': 8.239049530029297}
step: 46660 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 3.2548404, 'max_total_reward': 14.559999, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.394841694831848, 'actor_loss': -5.71115779876709, 'hyper_actor_loss': 0.009338937792927026, 'behavior_loss': 0.2778660416603088, 'mean_batch': 7.956184053421021, 'min_batch': 7.59855809211731, 'max_batch': 8.258806037902833}
step: 46670 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 2.674556, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6735878467559813, 'actor_loss': -5.724212503433227, 'hyper_actor_loss': 0.00912999864667654, 'behavior_loss': 0.2751797378063202, 'mean_batch': 8.005971479415894, 'min_batch': 7.650376844406128, 'max_batch': 8.290965270996093}
step: 46680 @ episode report: {'average_total_reward': 9.3880005, 'reward_variance': 5.7564573, 'max_total_reward': 12.2300005, 'min_total_reward': 4.46, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.580049848556518, 'actor_loss': -5.715304660797119, 'hyper_actor_loss': 0.008954435680061578, 'behavior_loss': 0.27963739186525344, 'mean_batch': 7.944899797439575, 'min_batch': 7.640163612365723, 'max_batch': 8.249923133850098}
step: 46690 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 3.7217968, 'max_total_reward': 12.340001, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.048435306549072, 'actor_loss': -5.664803218841553, 'hyper_actor_loss': 0.009087369218468666, 'behavior_loss': 0.2642921254038811, 'mean_batch': 7.747182893753052, 'min_batch': 7.449310255050659, 'max_batch': 7.9868134498596195}
step: 46700 @ episode report: {'average_total_reward': 9.088, 'reward_variance': 2.0041163, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7900004, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.308705043792725, 'actor_loss': -5.667160940170288, 'hyper_actor_loss': 0.009192024357616901, 'behavior_loss': 0.27012485414743426, 'mean_batch': 7.796817302703857, 'min_batch': 7.41992883682251, 'max_batch': 8.045334672927856}
step: 46710 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 2.9112256, 'max_total_reward': 13.34, 'min_total_reward': 6.7900004, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1446022391319275, 'actor_loss': -5.6801330089569095, 'hyper_actor_loss': 0.009077659621834756, 'behavior_loss': 0.2738331377506256, 'mean_batch': 7.836541748046875, 'min_batch': 7.478926420211792, 'max_batch': 8.107787609100342}
step: 46720 @ episode report: {'average_total_reward': 10.787001, 'reward_variance': 3.4206212, 'max_total_reward': 13.34, 'min_total_reward': 7.7899995, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8516153216362, 'actor_loss': -5.69122724533081, 'hyper_actor_loss': 0.009067304991185665, 'behavior_loss': 0.2684092655777931, 'mean_batch': 7.863434839248657, 'min_batch': 7.535419130325318, 'max_batch': 8.129621124267578}
step: 46730 @ episode report: {'average_total_reward': 9.998, 'reward_variance': 7.6847754, 'max_total_reward': 14.56, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.471561813354492, 'actor_loss': -5.709343481063843, 'hyper_actor_loss': 0.008822888322174548, 'behavior_loss': 0.26256063431501386, 'mean_batch': 7.946346569061279, 'min_batch': 7.593231582641602, 'max_batch': 8.204497623443604}
step: 46740 @ episode report: {'average_total_reward': 10.465001, 'reward_variance': 2.5288057, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.552758598327637, 'actor_loss': -5.688318395614624, 'hyper_actor_loss': 0.008637682255357503, 'behavior_loss': 0.27357851415872575, 'mean_batch': 7.860634088516235, 'min_batch': 7.518202114105224, 'max_batch': 8.105652999877929}
step: 46750 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 2.3007245, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.236096429824829, 'actor_loss': -5.66153883934021, 'hyper_actor_loss': 0.008546330500394106, 'behavior_loss': 0.2860669896006584, 'mean_batch': 7.732459163665771, 'min_batch': 7.438674688339233, 'max_batch': 7.976473140716553}
step: 46760 @ episode report: {'average_total_reward': 10.598001, 'reward_variance': 1.3377159, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.814302158355713, 'actor_loss': -5.658540725708008, 'hyper_actor_loss': 0.00876739015802741, 'behavior_loss': 0.2673833817243576, 'mean_batch': 7.742663812637329, 'min_batch': 7.406900358200073, 'max_batch': 8.045832681655884}
step: 46770 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 7.130526, 'max_total_reward': 14.450001, 'min_total_reward': 5.57, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.702255845069885, 'actor_loss': -5.673814535140991, 'hyper_actor_loss': 0.008716901950538158, 'behavior_loss': 0.28736798018217086, 'mean_batch': 7.802500581741333, 'min_batch': 7.463129997253418, 'max_batch': 8.077003002166748}
step: 46780 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 3.0197158, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6458985090255736, 'actor_loss': -5.624298715591431, 'hyper_actor_loss': 0.008792085107415915, 'behavior_loss': 0.2985533684492111, 'mean_batch': 7.6093415260314945, 'min_batch': 7.283313322067261, 'max_batch': 7.905268621444702}
step: 46790 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 0.94718075, 'max_total_reward': 11.23, 'min_total_reward': 7.9000006, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.154774153232575, 'actor_loss': -5.639624309539795, 'hyper_actor_loss': 0.008473776187747717, 'behavior_loss': 0.26423797607421873, 'mean_batch': 7.678436946868897, 'min_batch': 7.3296088695526125, 'max_batch': 8.004520893096924}
step: 46800 @ episode report: {'average_total_reward': 11.042001, 'reward_variance': 0.84527576, 'max_total_reward': 12.34, 'min_total_reward': 9.9, 'average_n_step': 11.9, 'max_n_step': 13.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.526292753219605, 'actor_loss': -5.658829545974731, 'hyper_actor_loss': 0.008193180616945028, 'behavior_loss': 0.2673003599047661, 'mean_batch': 7.751183366775512, 'min_batch': 7.400652885437012, 'max_batch': 8.089358234405518}
step: 46810 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 1.5052764, 'max_total_reward': 11.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3050038576126095, 'actor_loss': -5.63893313407898, 'hyper_actor_loss': 0.008399087470024824, 'behavior_loss': 0.27175183147192, 'mean_batch': 7.678383302688599, 'min_batch': 7.324107503890991, 'max_batch': 7.976764249801636}
step: 46820 @ episode report: {'average_total_reward': 9.011, 'reward_variance': 5.60073, 'max_total_reward': 11.23, 'min_total_reward': 2.91, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3989245533943175, 'actor_loss': -5.6706955909729, 'hyper_actor_loss': 0.008202566485852002, 'behavior_loss': 0.2726020947098732, 'mean_batch': 7.786314916610718, 'min_batch': 7.4557578563690186, 'max_batch': 8.07265272140503}
step: 46830 @ episode report: {'average_total_reward': 11.397, 'reward_variance': 4.867202, 'max_total_reward': 15.340001, 'min_total_reward': 6.79, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6949783325195313, 'actor_loss': -5.720132350921631, 'hyper_actor_loss': 0.008214461710304021, 'behavior_loss': 0.25176959186792375, 'mean_batch': 8.006980037689209, 'min_batch': 7.618152761459351, 'max_batch': 8.286005878448487}
step: 46840 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 5.598889, 'max_total_reward': 13.34, 'min_total_reward': 4.57, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.001411685347557, 'actor_loss': -5.7072837352752686, 'hyper_actor_loss': 0.008472479041665792, 'behavior_loss': 0.2738887116312981, 'mean_batch': 7.944055080413818, 'min_batch': 7.579784727096557, 'max_batch': 8.277113723754884}
step: 46850 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.025201, 'max_total_reward': 12.34, 'min_total_reward': 7.6800003, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.704641509056091, 'actor_loss': -5.688640069961548, 'hyper_actor_loss': 0.00848974408581853, 'behavior_loss': 0.268197762966156, 'mean_batch': 7.8648725032806395, 'min_batch': 7.515054607391358, 'max_batch': 8.138911247253418}
step: 46860 @ episode report: {'average_total_reward': 9.964999, 'reward_variance': 2.4753852, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.205673003196716, 'actor_loss': -5.669678497314453, 'hyper_actor_loss': 0.008738418389111758, 'behavior_loss': 0.2708593517541885, 'mean_batch': 7.795172595977784, 'min_batch': 7.439587736129761, 'max_batch': 8.135931968688965}
step: 46870 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 5.039735, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2113865375518795, 'actor_loss': -5.705071640014649, 'hyper_actor_loss': 0.008890615683048964, 'behavior_loss': 0.26927403062582017, 'mean_batch': 7.9267199516296385, 'min_batch': 7.579844284057617, 'max_batch': 8.248552799224854}
step: 46880 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 4.7860565, 'max_total_reward': 12.340001, 'min_total_reward': 6.7899995, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.43895320892334, 'actor_loss': -5.651063442230225, 'hyper_actor_loss': 0.008847248647361994, 'behavior_loss': 0.26671498268842697, 'mean_batch': 7.736682319641114, 'min_batch': 7.357895803451538, 'max_batch': 8.027570962905884}
step: 46890 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 3.3792014, 'max_total_reward': 13.340001, 'min_total_reward': 7.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.192086935043335, 'actor_loss': -5.648112010955811, 'hyper_actor_loss': 0.00916488841176033, 'behavior_loss': 0.26964748799800875, 'mean_batch': 7.724108743667602, 'min_batch': 7.3477942943573, 'max_batch': 8.011678838729859}
step: 46900 @ episode report: {'average_total_reward': 9.655001, 'reward_variance': 3.5467255, 'max_total_reward': 13.450001, 'min_total_reward': 6.7900004, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.067805695533752, 'actor_loss': -5.6646934986114506, 'hyper_actor_loss': 0.009205531049519777, 'behavior_loss': 0.26196433901786803, 'mean_batch': 7.787694978713989, 'min_batch': 7.410010194778442, 'max_batch': 8.08009738922119}
step: 46910 @ episode report: {'average_total_reward': 10.953001, 'reward_variance': 5.6482415, 'max_total_reward': 15.670001, 'min_total_reward': 6.7900004, 'average_n_step': 11.8, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.919557785987854, 'actor_loss': -5.655204820632934, 'hyper_actor_loss': 0.009456801787018776, 'behavior_loss': 0.2832580640912056, 'mean_batch': 7.751387262344361, 'min_batch': 7.373841571807861, 'max_batch': 8.07016887664795}
step: 46920 @ episode report: {'average_total_reward': 11.1970005, 'reward_variance': 2.2203221, 'max_total_reward': 14.56, 'min_total_reward': 9.009999, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.659863805770874, 'actor_loss': -5.64583191871643, 'hyper_actor_loss': 0.009441147278994321, 'behavior_loss': 0.28909401744604113, 'mean_batch': 7.739486598968506, 'min_batch': 7.316595888137817, 'max_batch': 8.103214931488036}
step: 46930 @ episode report: {'average_total_reward': 8.644, 'reward_variance': 2.4665642, 'max_total_reward': 11.12, 'min_total_reward': 6.7899995, 'average_n_step': 9.7, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.704299736022949, 'actor_loss': -5.697092866897583, 'hyper_actor_loss': 0.009320708457380533, 'behavior_loss': 0.27282277643680575, 'mean_batch': 7.9308513641357425, 'min_batch': 7.515196084976196, 'max_batch': 8.318478870391846}
step: 46940 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 1.1398653, 'max_total_reward': 13.2300005, 'min_total_reward': 10.01, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.392819988727569, 'actor_loss': -5.673746919631958, 'hyper_actor_loss': 0.00933224381878972, 'behavior_loss': 0.2735289990901947, 'mean_batch': 7.800360774993896, 'min_batch': 7.465268898010254, 'max_batch': 8.142377948760986}
step: 46950 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 6.555005, 'max_total_reward': 16.67, 'min_total_reward': 6.9, 'average_n_step': 11.2, 'max_n_step': 17.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.133169770240784, 'actor_loss': -5.628974056243896, 'hyper_actor_loss': 0.009028798528015613, 'behavior_loss': 0.27136432826519014, 'mean_batch': 7.648680305480957, 'min_batch': 7.279740905761718, 'max_batch': 7.982840347290039}
step: 46960 @ episode report: {'average_total_reward': 10.920001, 'reward_variance': 2.1826203, 'max_total_reward': 13.34, 'min_total_reward': 8.900001, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.410766339302063, 'actor_loss': -5.6562152862548825, 'hyper_actor_loss': 0.009028351958841085, 'behavior_loss': 0.27250495702028277, 'mean_batch': 7.775314140319824, 'min_batch': 7.359721899032593, 'max_batch': 8.09498109817505}
step: 46970 @ episode report: {'average_total_reward': 9.876, 'reward_variance': 2.8999245, 'max_total_reward': 13.45, 'min_total_reward': 7.9, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.935830974578858, 'actor_loss': -5.6416950702667235, 'hyper_actor_loss': 0.008790000341832638, 'behavior_loss': 0.2814481854438782, 'mean_batch': 7.695993852615357, 'min_batch': 7.327888059616089, 'max_batch': 8.027725076675415}
step: 46980 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 4.9669905, 'max_total_reward': 15.670001, 'min_total_reward': 7.79, 'average_n_step': 11.7, 'max_n_step': 16.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.247647428512574, 'actor_loss': -5.6042564868927, 'hyper_actor_loss': 0.00895399833098054, 'behavior_loss': 0.28036287128925325, 'mean_batch': 7.522370433807373, 'min_batch': 7.220837831497192, 'max_batch': 7.818433380126953}
step: 46990 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 2.8546638, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.602921736240387, 'actor_loss': -5.661148738861084, 'hyper_actor_loss': 0.008655366580933332, 'behavior_loss': 0.2771716326475143, 'mean_batch': 7.733152437210083, 'min_batch': 7.436119413375854, 'max_batch': 8.04963321685791}
step: 47000 @ episode report: {'average_total_reward': 10.221, 'reward_variance': 3.0061488, 'max_total_reward': 13.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.496713924407959, 'actor_loss': -5.67672872543335, 'hyper_actor_loss': 0.008693910203874111, 'behavior_loss': 0.27356288135051726, 'mean_batch': 7.828695297241211, 'min_batch': 7.459903717041016, 'max_batch': 8.120207023620605}
step: 47010 @ episode report: {'average_total_reward': 10.731, 'reward_variance': 3.702189, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.45918025970459, 'actor_loss': -5.656018829345703, 'hyper_actor_loss': 0.008763100951910019, 'behavior_loss': 0.26278611570596694, 'mean_batch': 7.745010328292847, 'min_batch': 7.386762905120849, 'max_batch': 8.052101039886475}
step: 47020 @ episode report: {'average_total_reward': 10.209002, 'reward_variance': 2.7819092, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.832391047477722, 'actor_loss': -5.6203938007354735, 'hyper_actor_loss': 0.008944983407855035, 'behavior_loss': 0.27487102150917053, 'mean_batch': 7.619662237167359, 'min_batch': 7.2448302745819095, 'max_batch': 7.925675535202027}
step: 47030 @ episode report: {'average_total_reward': 10.221001, 'reward_variance': 2.8525698, 'max_total_reward': 13.450001, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6887389063835143, 'actor_loss': -5.652088403701782, 'hyper_actor_loss': 0.009046532865613698, 'behavior_loss': 0.2839907810091972, 'mean_batch': 7.741270589828491, 'min_batch': 7.361363124847412, 'max_batch': 8.07191243171692}
step: 47040 @ episode report: {'average_total_reward': 9.698999, 'reward_variance': 2.873529, 'max_total_reward': 12.23, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.879564094543457, 'actor_loss': -5.6359227180480955, 'hyper_actor_loss': 0.008700073044747115, 'behavior_loss': 0.2903718501329422, 'mean_batch': 7.6989223003387455, 'min_batch': 7.284161901473999, 'max_batch': 8.008137464523315}
step: 47050 @ episode report: {'average_total_reward': 10.831001, 'reward_variance': 3.3795688, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.087617760896682, 'actor_loss': -5.627695989608765, 'hyper_actor_loss': 0.009152744710445405, 'behavior_loss': 0.2702556043863297, 'mean_batch': 7.6485655307769775, 'min_batch': 7.270556545257568, 'max_batch': 7.980077743530273}
step: 47060 @ episode report: {'average_total_reward': 10.143001, 'reward_variance': 4.648242, 'max_total_reward': 13.34, 'min_total_reward': 5.5699997, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6448992609977724, 'actor_loss': -5.636768007278443, 'hyper_actor_loss': 0.008906141202896834, 'behavior_loss': 0.285545252263546, 'mean_batch': 7.67993688583374, 'min_batch': 7.306796836853027, 'max_batch': 8.083904790878297}
step: 47070 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 2.7891214, 'max_total_reward': 13.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.12407078742981, 'actor_loss': -5.62449083328247, 'hyper_actor_loss': 0.009036150388419628, 'behavior_loss': 0.2769206494092941, 'mean_batch': 7.625319242477417, 'min_batch': 7.2688806533813475, 'max_batch': 7.9647321701049805}
step: 47080 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 1.9519413, 'max_total_reward': 12.340001, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.825955939292908, 'actor_loss': -5.620328950881958, 'hyper_actor_loss': 0.008851499296724796, 'behavior_loss': 0.2666771650314331, 'mean_batch': 7.607762336730957, 'min_batch': 7.255596399307251, 'max_batch': 7.899733352661133}
step: 47090 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 3.9261613, 'max_total_reward': 14.56, 'min_total_reward': 7.8999996, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.133157348632812, 'actor_loss': -5.617131090164184, 'hyper_actor_loss': 0.00853588655591011, 'behavior_loss': 0.2724501147866249, 'mean_batch': 7.584944057464599, 'min_batch': 7.25395016670227, 'max_batch': 7.86910982131958}
step: 47100 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 3.093225, 'max_total_reward': 13.34, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.850427031517029, 'actor_loss': -5.616580057144165, 'hyper_actor_loss': 0.008427119627594949, 'behavior_loss': 0.2843837529420853, 'mean_batch': 7.595389127731323, 'min_batch': 7.240162420272827, 'max_batch': 7.945002603530884}
step: 47110 @ episode report: {'average_total_reward': 10.631001, 'reward_variance': 1.8407093, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6267806768417357, 'actor_loss': -5.629966878890992, 'hyper_actor_loss': 0.008376998268067837, 'behavior_loss': 0.2654505863785744, 'mean_batch': 7.6314027309417725, 'min_batch': 7.302917718887329, 'max_batch': 7.954453754425049}
step: 47120 @ episode report: {'average_total_reward': 10.498, 'reward_variance': 2.526157, 'max_total_reward': 14.450001, 'min_total_reward': 8.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7123388290405273, 'actor_loss': -5.626415586471557, 'hyper_actor_loss': 0.008276829961687326, 'behavior_loss': 0.2599697053432465, 'mean_batch': 7.631535959243775, 'min_batch': 7.277121639251709, 'max_batch': 8.00324468612671}
step: 47130 @ episode report: {'average_total_reward': 8.9660015, 'reward_variance': 6.4413056, 'max_total_reward': 12.2300005, 'min_total_reward': 2.46, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8205532670021056, 'actor_loss': -5.647139167785644, 'hyper_actor_loss': 0.008209388796240091, 'behavior_loss': 0.26136589646339414, 'mean_batch': 7.70644998550415, 'min_batch': 7.357188177108765, 'max_batch': 8.045781373977661}
step: 47140 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 1.9267435, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.116544187068939, 'actor_loss': -5.6063957691192625, 'hyper_actor_loss': 0.008218045998364686, 'behavior_loss': 0.2919888600707054, 'mean_batch': 7.536181402206421, 'min_batch': 7.223169994354248, 'max_batch': 7.816774988174439}
step: 47150 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 4.1064653, 'max_total_reward': 14.450001, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.392604088783264, 'actor_loss': -5.62169828414917, 'hyper_actor_loss': 0.008266861829906703, 'behavior_loss': 0.2638311877846718, 'mean_batch': 7.603563690185547, 'min_batch': 7.269824838638305, 'max_batch': 7.8632196426391605}
step: 47160 @ episode report: {'average_total_reward': 10.554001, 'reward_variance': 2.4632041, 'max_total_reward': 13.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8709656953811646, 'actor_loss': -5.624162101745606, 'hyper_actor_loss': 0.008469699043780565, 'behavior_loss': 0.2705684915184975, 'mean_batch': 7.629906272888183, 'min_batch': 7.263003540039063, 'max_batch': 7.963594055175781}
step: 47170 @ episode report: {'average_total_reward': 10.232, 'reward_variance': 2.158596, 'max_total_reward': 13.2300005, 'min_total_reward': 8.68, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.833878290653229, 'actor_loss': -5.648637294769287, 'hyper_actor_loss': 0.008434980362653732, 'behavior_loss': 0.26036312580108645, 'mean_batch': 7.691306686401367, 'min_batch': 7.382668495178223, 'max_batch': 7.980333662033081}
step: 47180 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 3.3405406, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.607714033126831, 'actor_loss': -5.657928943634033, 'hyper_actor_loss': 0.008428900223225354, 'behavior_loss': 0.28483685851097107, 'mean_batch': 7.720404815673828, 'min_batch': 7.4236664295196535, 'max_batch': 8.007185554504394}
step: 47190 @ episode report: {'average_total_reward': 10.731001, 'reward_variance': 3.6337693, 'max_total_reward': 13.12, 'min_total_reward': 6.7899995, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8811944365501403, 'actor_loss': -5.662608432769775, 'hyper_actor_loss': 0.008710163924843074, 'behavior_loss': 0.28628348410129545, 'mean_batch': 7.817858028411865, 'min_batch': 7.367820596694946, 'max_batch': 8.15400676727295}
step: 47200 @ episode report: {'average_total_reward': 10.309, 'reward_variance': 3.3957894, 'max_total_reward': 13.340001, 'min_total_reward': 7.9, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.016444873809815, 'actor_loss': -5.670441150665283, 'hyper_actor_loss': 0.008316222857683898, 'behavior_loss': 0.2567002445459366, 'mean_batch': 7.783481216430664, 'min_batch': 7.456533193588257, 'max_batch': 8.082525253295898}
step: 47210 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.8700898, 'max_total_reward': 12.230001, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.190771210193634, 'actor_loss': -5.64251823425293, 'hyper_actor_loss': 0.008381970226764679, 'behavior_loss': 0.2659103959798813, 'mean_batch': 7.673248195648194, 'min_batch': 7.3550012588500975, 'max_batch': 8.014824533462525}
step: 47220 @ episode report: {'average_total_reward': 9.976001, 'reward_variance': 3.580405, 'max_total_reward': 13.340001, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.544756031036377, 'actor_loss': -5.609873962402344, 'hyper_actor_loss': 0.008763104490935803, 'behavior_loss': 0.2742188051342964, 'mean_batch': 7.599059581756592, 'min_batch': 7.190435791015625, 'max_batch': 7.924435758590699}
step: 47230 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.9124246, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.266490530967713, 'actor_loss': -5.627504014968872, 'hyper_actor_loss': 0.008471662923693658, 'behavior_loss': 0.2667278334498405, 'mean_batch': 7.637417984008789, 'min_batch': 7.2803362846374515, 'max_batch': 7.976761770248413}
step: 47240 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 1.6819893, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.02449402809143, 'actor_loss': -5.6370611667633055, 'hyper_actor_loss': 0.008237331081181765, 'behavior_loss': 0.2719915881752968, 'mean_batch': 7.6671301364898685, 'min_batch': 7.320827054977417, 'max_batch': 8.0349045753479}
step: 47250 @ episode report: {'average_total_reward': 10.920001, 'reward_variance': 1.6409401, 'max_total_reward': 13.34, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3735971689224242, 'actor_loss': -5.642016744613647, 'hyper_actor_loss': 0.008772173710167409, 'behavior_loss': 0.25803745687007906, 'mean_batch': 7.68478946685791, 'min_batch': 7.340854978561401, 'max_batch': 7.990991687774658}
step: 47260 @ episode report: {'average_total_reward': 11.275001, 'reward_variance': 2.8951643, 'max_total_reward': 14.56, 'min_total_reward': 8.790001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.190231156349182, 'actor_loss': -5.633123111724854, 'hyper_actor_loss': 0.008607441745698451, 'behavior_loss': 0.2701855808496475, 'mean_batch': 7.632121849060058, 'min_batch': 7.325309991836548, 'max_batch': 7.9869695663452145}
step: 47270 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 2.746529, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6309877395629884, 'actor_loss': -5.6270373344421385, 'hyper_actor_loss': 0.008730209153145551, 'behavior_loss': 0.254284094274044, 'mean_batch': 7.620431709289551, 'min_batch': 7.292856073379516, 'max_batch': 7.905636978149414}
step: 47280 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 5.5219803, 'max_total_reward': 12.34, 'min_total_reward': 5.6800003, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.647690987586975, 'actor_loss': -5.65519642829895, 'hyper_actor_loss': 0.008472375106066465, 'behavior_loss': 0.2716063931584358, 'mean_batch': 7.730761003494263, 'min_batch': 7.393224096298217, 'max_batch': 8.053319644927978}
step: 47290 @ episode report: {'average_total_reward': 9.099001, 'reward_variance': 4.655588, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.1, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.225091171264649, 'actor_loss': -5.631160402297974, 'hyper_actor_loss': 0.00876737292855978, 'behavior_loss': 0.2793433636426926, 'mean_batch': 7.619918584823608, 'min_batch': 7.32392430305481, 'max_batch': 7.920404243469238}
step: 47300 @ episode report: {'average_total_reward': 11.264001, 'reward_variance': 3.2899842, 'max_total_reward': 14.559999, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.629352593421936, 'actor_loss': -5.576050186157227, 'hyper_actor_loss': 0.008783157635480165, 'behavior_loss': 0.27478586584329606, 'mean_batch': 7.423024749755859, 'min_batch': 7.1145953178405765, 'max_batch': 7.679825115203857}
step: 47310 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 6.6657243, 'max_total_reward': 14.559999, 'min_total_reward': 4.68, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.537632966041565, 'actor_loss': -5.636033773422241, 'hyper_actor_loss': 0.009122281428426504, 'behavior_loss': 0.2824966922402382, 'mean_batch': 7.644752120971679, 'min_batch': 7.334789705276489, 'max_batch': 7.940744113922119}
step: 47320 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 1.8590237, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.229499077796936, 'actor_loss': -5.615808010101318, 'hyper_actor_loss': 0.009338836837559938, 'behavior_loss': 0.28277624398469925, 'mean_batch': 7.584080553054809, 'min_batch': 7.245596504211425, 'max_batch': 7.886598205566406}
step: 47330 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 1.5127044, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5839691162109375, 'actor_loss': -5.634722328186035, 'hyper_actor_loss': 0.009324608277529478, 'behavior_loss': 0.2758775264024734, 'mean_batch': 7.689700412750244, 'min_batch': 7.286159324645996, 'max_batch': 8.011919260025024}
step: 47340 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 1.8421606, 'max_total_reward': 11.23, 'min_total_reward': 6.57, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.172309124469757, 'actor_loss': -5.685466718673706, 'hyper_actor_loss': 0.009375114552676677, 'behavior_loss': 0.25676642805337907, 'mean_batch': 7.871208906173706, 'min_batch': 7.484926748275757, 'max_batch': 8.239591884613038}
step: 47350 @ episode report: {'average_total_reward': 10.764001, 'reward_variance': 1.8298842, 'max_total_reward': 12.340001, 'min_total_reward': 8.900001, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.69781408905983, 'actor_loss': -5.669273424148559, 'hyper_actor_loss': 0.009485541936010122, 'behavior_loss': 0.2792030707001686, 'mean_batch': 7.777434968948365, 'min_batch': 7.453958797454834, 'max_batch': 8.072472476959229}
step: 47360 @ episode report: {'average_total_reward': 8.977, 'reward_variance': 2.759161, 'max_total_reward': 12.34, 'min_total_reward': 6.7900004, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4799304246902465, 'actor_loss': -5.641571569442749, 'hyper_actor_loss': 0.009068547375500202, 'behavior_loss': 0.27016538828611375, 'mean_batch': 7.659370183944702, 'min_batch': 7.361326026916504, 'max_batch': 7.992822360992432}
step: 47370 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 6.070409, 'max_total_reward': 13.340001, 'min_total_reward': 4.6800003, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9828438997268676, 'actor_loss': -5.6292811870574955, 'hyper_actor_loss': 0.009405389055609703, 'behavior_loss': 0.26955017596483233, 'mean_batch': 7.632303905487061, 'min_batch': 7.297069072723389, 'max_batch': 7.922237730026245}
step: 47380 @ episode report: {'average_total_reward': 8.3, 'reward_variance': 2.9578795, 'max_total_reward': 10.12, 'min_total_reward': 4.6800003, 'average_n_step': 9.4, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.206684255599976, 'actor_loss': -5.633088302612305, 'hyper_actor_loss': 0.009532427508383989, 'behavior_loss': 0.2754596948623657, 'mean_batch': 7.669036817550659, 'min_batch': 7.290675783157349, 'max_batch': 7.955014324188232}
step: 47390 @ episode report: {'average_total_reward': 10.831, 'reward_variance': 2.5254698, 'max_total_reward': 14.450001, 'min_total_reward': 9.009999, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.230655264854431, 'actor_loss': -5.61691370010376, 'hyper_actor_loss': 0.009308252017945051, 'behavior_loss': 0.282273069024086, 'mean_batch': 7.611930894851684, 'min_batch': 7.227164888381958, 'max_batch': 7.959735298156739}
step: 47400 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 7.853256, 'max_total_reward': 14.2300005, 'min_total_reward': 4.46, 'average_n_step': 10.6, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.131849360466004, 'actor_loss': -5.62358021736145, 'hyper_actor_loss': 0.009612293634563684, 'behavior_loss': 0.2703566953539848, 'mean_batch': 7.6446929454803465, 'min_batch': 7.244357299804688, 'max_batch': 8.024305438995361}
step: 47410 @ episode report: {'average_total_reward': 11.231001, 'reward_variance': 4.433609, 'max_total_reward': 14.45, 'min_total_reward': 6.9, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.522777032852173, 'actor_loss': -5.627566003799439, 'hyper_actor_loss': 0.00964814806357026, 'behavior_loss': 0.2786695629358292, 'mean_batch': 7.666665172576904, 'min_batch': 7.252975177764893, 'max_batch': 8.026722955703736}
step: 47420 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 5.862721, 'max_total_reward': 13.340001, 'min_total_reward': 5.7899995, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.202564835548401, 'actor_loss': -5.646135473251343, 'hyper_actor_loss': 0.009618364553898574, 'behavior_loss': 0.286350217461586, 'mean_batch': 7.722220849990845, 'min_batch': 7.335487413406372, 'max_batch': 8.099634408950806}
step: 47430 @ episode report: {'average_total_reward': 9.177, 'reward_variance': 2.1715217, 'max_total_reward': 11.2300005, 'min_total_reward': 6.68, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.502514910697937, 'actor_loss': -5.596007204055786, 'hyper_actor_loss': 0.009664527978748083, 'behavior_loss': 0.29075427204370496, 'mean_batch': 7.534360933303833, 'min_batch': 7.151335954666138, 'max_batch': 7.823773193359375}
step: 47440 @ episode report: {'average_total_reward': 10.375999, 'reward_variance': 4.457705, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.269708180427552, 'actor_loss': -5.633151006698609, 'hyper_actor_loss': 0.009744108375161886, 'behavior_loss': 0.2741801723837852, 'mean_batch': 7.639791965484619, 'min_batch': 7.318637704849243, 'max_batch': 7.989062261581421}
step: 47450 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 5.9705, 'max_total_reward': 14.559999, 'min_total_reward': 6.9, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.120206022262574, 'actor_loss': -5.651009035110474, 'hyper_actor_loss': 0.009883716143667698, 'behavior_loss': 0.26541778445243835, 'mean_batch': 7.711490774154663, 'min_batch': 7.380761003494262, 'max_batch': 8.019816732406616}
step: 47460 @ episode report: {'average_total_reward': 9.31, 'reward_variance': 5.0992403, 'max_total_reward': 12.34, 'min_total_reward': 5.46, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.324412775039673, 'actor_loss': -5.661681985855102, 'hyper_actor_loss': 0.009691971074789762, 'behavior_loss': 0.2779106006026268, 'mean_batch': 7.748033428192139, 'min_batch': 7.424791479110718, 'max_batch': 8.103159761428833}
step: 47470 @ episode report: {'average_total_reward': 9.943, 'reward_variance': 3.2634406, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.259462499618531, 'actor_loss': -5.645769500732422, 'hyper_actor_loss': 0.010109538957476617, 'behavior_loss': 0.2732971653342247, 'mean_batch': 7.676008224487305, 'min_batch': 7.376478242874145, 'max_batch': 7.942226696014404}
step: 47480 @ episode report: {'average_total_reward': 9.077001, 'reward_variance': 4.439441, 'max_total_reward': 12.12, 'min_total_reward': 4.57, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6957677006721497, 'actor_loss': -5.624179315567017, 'hyper_actor_loss': 0.010179308149963618, 'behavior_loss': 0.2719533875584602, 'mean_batch': 7.5792848587036135, 'min_batch': 7.3107075691223145, 'max_batch': 7.863026237487793}
step: 47490 @ episode report: {'average_total_reward': 9.865001, 'reward_variance': 5.2890043, 'max_total_reward': 13.45, 'min_total_reward': 5.680001, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5782149195671082, 'actor_loss': -5.649422931671142, 'hyper_actor_loss': 0.009980806056410075, 'behavior_loss': 0.26706731915473936, 'mean_batch': 7.67249755859375, 'min_batch': 7.406696033477783, 'max_batch': 7.947973728179932}
step: 47500 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.4123235, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.431326484680175, 'actor_loss': -5.631399822235108, 'hyper_actor_loss': 0.009669375140219927, 'behavior_loss': 0.2725032389163971, 'mean_batch': 7.6281774044036865, 'min_batch': 7.316845083236695, 'max_batch': 7.88625545501709}
step: 47510 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 0.5470042, 'max_total_reward': 11.2300005, 'min_total_reward': 8.789999, 'average_n_step': 11.0, 'max_n_step': 12.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9845779657363893, 'actor_loss': -5.611586332321167, 'hyper_actor_loss': 0.009340014588087798, 'behavior_loss': 0.2696470350027084, 'mean_batch': 7.559743976593017, 'min_batch': 7.2387947082519535, 'max_batch': 7.854555368423462}
step: 47520 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 1.1858412, 'max_total_reward': 11.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.013644194602966, 'actor_loss': -5.633860540390015, 'hyper_actor_loss': 0.009074852708727122, 'behavior_loss': 0.2671967640519142, 'mean_batch': 7.6370221138000485, 'min_batch': 7.326135873794556, 'max_batch': 7.9599861145019535}
step: 47530 @ episode report: {'average_total_reward': 10.476001, 'reward_variance': 2.700725, 'max_total_reward': 13.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9078402876853944, 'actor_loss': -5.651764440536499, 'hyper_actor_loss': 0.009210186079144478, 'behavior_loss': 0.2690716996788979, 'mean_batch': 7.700125503540039, 'min_batch': 7.397373676300049, 'max_batch': 7.987483835220337}
step: 47540 @ episode report: {'average_total_reward': 9.710001, 'reward_variance': 9.754181, 'max_total_reward': 13.34, 'min_total_reward': 4.5699997, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6810622215270996, 'actor_loss': -5.653485631942749, 'hyper_actor_loss': 0.009245915338397026, 'behavior_loss': 0.2753765985369682, 'mean_batch': 7.714423131942749, 'min_batch': 7.3963721752166744, 'max_batch': 7.976866054534912}
step: 47550 @ episode report: {'average_total_reward': 10.898001, 'reward_variance': 3.6223762, 'max_total_reward': 13.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8506088733673094, 'actor_loss': -5.614607286453247, 'hyper_actor_loss': 0.009252337366342544, 'behavior_loss': 0.2622934550046921, 'mean_batch': 7.5535595417022705, 'min_batch': 7.266462802886963, 'max_batch': 7.810086870193482}
step: 47560 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 4.287549, 'max_total_reward': 13.45, 'min_total_reward': 6.7899995, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2661352872848513, 'actor_loss': -5.614142990112304, 'hyper_actor_loss': 0.009468130208551884, 'behavior_loss': 0.2571505755186081, 'mean_batch': 7.564371585845947, 'min_batch': 7.252699518203736, 'max_batch': 7.800410413742066}
step: 47570 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 3.2266839, 'max_total_reward': 13.23, 'min_total_reward': 5.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4836592793464662, 'actor_loss': -5.641683101654053, 'hyper_actor_loss': 0.009452766180038452, 'behavior_loss': 0.27440633326768876, 'mean_batch': 7.675873279571533, 'min_batch': 7.346592044830322, 'max_batch': 7.92562460899353}
step: 47580 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 1.0794557, 'max_total_reward': 12.23, 'min_total_reward': 8.46, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.987371826171875, 'actor_loss': -5.628181743621826, 'hyper_actor_loss': 0.009165969025343657, 'behavior_loss': 0.2731853350996971, 'mean_batch': 7.621028327941895, 'min_batch': 7.300182676315307, 'max_batch': 7.920388984680176}
step: 47590 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 5.7314253, 'max_total_reward': 12.2300005, 'min_total_reward': 3.5699997, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.990538311004639, 'actor_loss': -5.609690809249878, 'hyper_actor_loss': 0.009161108918488026, 'behavior_loss': 0.2761054515838623, 'mean_batch': 7.564540195465088, 'min_batch': 7.220177412033081, 'max_batch': 7.863815641403198}
step: 47600 @ episode report: {'average_total_reward': 10.564001, 'reward_variance': 5.5484233, 'max_total_reward': 14.45, 'min_total_reward': 6.9000006, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8006736516952513, 'actor_loss': -5.602565765380859, 'hyper_actor_loss': 0.009363534208387137, 'behavior_loss': 0.2744647696614265, 'mean_batch': 7.575449514389038, 'min_batch': 7.160362768173218, 'max_batch': 7.8775536060333256}
step: 47610 @ episode report: {'average_total_reward': 8.8220005, 'reward_variance': 1.8481156, 'max_total_reward': 11.12, 'min_total_reward': 6.6800003, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3044005393981934, 'actor_loss': -5.6578099727630615, 'hyper_actor_loss': 0.009453167300671339, 'behavior_loss': 0.2681663617491722, 'mean_batch': 7.757382583618164, 'min_batch': 7.3883867263793945, 'max_batch': 8.112750053405762}
step: 47620 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 1.9332497, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9315908551216125, 'actor_loss': -5.662480020523072, 'hyper_actor_loss': 0.009401437081396579, 'behavior_loss': 0.2798628881573677, 'mean_batch': 7.787841701507569, 'min_batch': 7.393735599517822, 'max_batch': 8.107510328292847}
step: 47630 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 1.843404, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6678356289863587, 'actor_loss': -5.638356256484985, 'hyper_actor_loss': 0.008996037393808365, 'behavior_loss': 0.25813785046339033, 'mean_batch': 7.658240556716919, 'min_batch': 7.338713073730469, 'max_batch': 7.943028926849365}
step: 47640 @ episode report: {'average_total_reward': 9.232, 'reward_variance': 2.6708162, 'max_total_reward': 12.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7582123279571533, 'actor_loss': -5.649124002456665, 'hyper_actor_loss': 0.009427900984883308, 'behavior_loss': 0.29087731391191485, 'mean_batch': 7.71863751411438, 'min_batch': 7.361081552505493, 'max_batch': 7.995320987701416}
step: 47650 @ episode report: {'average_total_reward': 10.054001, 'reward_variance': 6.348464, 'max_total_reward': 14.339999, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.869840383529663, 'actor_loss': -5.64759316444397, 'hyper_actor_loss': 0.009446517936885357, 'behavior_loss': 0.281996513903141, 'mean_batch': 7.702911901473999, 'min_batch': 7.3638472080230715, 'max_batch': 7.98453950881958}
step: 47660 @ episode report: {'average_total_reward': 10.487, 'reward_variance': 11.950983, 'max_total_reward': 15.670001, 'min_total_reward': 4.35, 'average_n_step': 11.4, 'max_n_step': 16.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.090632224082947, 'actor_loss': -5.623677349090576, 'hyper_actor_loss': 0.009585210680961609, 'behavior_loss': 0.27250843346118925, 'mean_batch': 7.622161436080932, 'min_batch': 7.267244052886963, 'max_batch': 7.999047565460205}
step: 47670 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 4.4947405, 'max_total_reward': 13.45, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1009675025939942, 'actor_loss': -5.641536903381348, 'hyper_actor_loss': 0.009604281652718783, 'behavior_loss': 0.28704611510038375, 'mean_batch': 7.65307388305664, 'min_batch': 7.367101097106934, 'max_batch': 7.942592763900757}
step: 47680 @ episode report: {'average_total_reward': 8.733, 'reward_variance': 4.8601413, 'max_total_reward': 13.450001, 'min_total_reward': 5.57, 'average_n_step': 9.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6824264287948605, 'actor_loss': -5.620844507217408, 'hyper_actor_loss': 0.009551119245588779, 'behavior_loss': 0.2799899995326996, 'mean_batch': 7.572507905960083, 'min_batch': 7.294154453277588, 'max_batch': 7.845045757293701}
step: 47690 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 3.499925, 'max_total_reward': 13.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.065499258041382, 'actor_loss': -5.597280406951905, 'hyper_actor_loss': 0.009314223099499941, 'behavior_loss': 0.2646516799926758, 'mean_batch': 7.4621429443359375, 'min_batch': 7.22860198020935, 'max_batch': 7.7056396961212155}
step: 47700 @ episode report: {'average_total_reward': 10.665, 'reward_variance': 2.6949058, 'max_total_reward': 13.010001, 'min_total_reward': 7.7900004, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9060114860534667, 'actor_loss': -5.618837356567383, 'hyper_actor_loss': 0.009437606297433376, 'behavior_loss': 0.2766469731926918, 'mean_batch': 7.557746887207031, 'min_batch': 7.292769718170166, 'max_batch': 7.776698875427246}
step: 47710 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 7.2246866, 'max_total_reward': 14.450002, 'min_total_reward': 3.46, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6905162572860717, 'actor_loss': -5.6342826843261715, 'hyper_actor_loss': 0.009830057714134454, 'behavior_loss': 0.2617224469780922, 'mean_batch': 7.610642147064209, 'min_batch': 7.3545835494995115, 'max_batch': 7.835028171539307}
step: 47720 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 1.6910636, 'max_total_reward': 13.339999, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5443257331848144, 'actor_loss': -5.626630163192749, 'hyper_actor_loss': 0.009697920735925436, 'behavior_loss': 0.2690796941518784, 'mean_batch': 7.582618999481201, 'min_batch': 7.325623512268066, 'max_batch': 7.81105604171753}
step: 47730 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 5.387809, 'max_total_reward': 14.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.571388459205627, 'actor_loss': -5.584220123291016, 'hyper_actor_loss': 0.00985794709995389, 'behavior_loss': 0.28123905062675475, 'mean_batch': 7.4380505084991455, 'min_batch': 7.158611822128296, 'max_batch': 7.696372127532959}
step: 47740 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 4.81461, 'max_total_reward': 14.34, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5398751854896546, 'actor_loss': -5.577860021591187, 'hyper_actor_loss': 0.010173410549759865, 'behavior_loss': 0.27870903313159945, 'mean_batch': 7.461622428894043, 'min_batch': 7.091150617599487, 'max_batch': 7.711242151260376}
step: 47750 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 1.685065, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3036107540130617, 'actor_loss': -5.6358363151550295, 'hyper_actor_loss': 0.009936155378818512, 'behavior_loss': 0.2800705835223198, 'mean_batch': 7.635646820068359, 'min_batch': 7.342496919631958, 'max_batch': 7.919509792327881}
step: 47760 @ episode report: {'average_total_reward': 8.489, 'reward_variance': 3.3406882, 'max_total_reward': 11.23, 'min_total_reward': 4.57, 'average_n_step': 9.6, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8557960987091064, 'actor_loss': -5.628443241119385, 'hyper_actor_loss': 0.009863381739705801, 'behavior_loss': 0.27635986506938937, 'mean_batch': 7.616516971588135, 'min_batch': 7.306193161010742, 'max_batch': 7.879585075378418}
step: 47770 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 5.0703163, 'max_total_reward': 13.450001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6393925666809084, 'actor_loss': -5.604132843017578, 'hyper_actor_loss': 0.009592602588236332, 'behavior_loss': 0.2825680270791054, 'mean_batch': 7.521567964553833, 'min_batch': 7.22074785232544, 'max_batch': 7.822351264953613}
step: 47780 @ episode report: {'average_total_reward': 10.632001, 'reward_variance': 2.386896, 'max_total_reward': 14.339999, 'min_total_reward': 8.9, 'average_n_step': 11.6, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4650013208389283, 'actor_loss': -5.617944288253784, 'hyper_actor_loss': 0.009558910690248012, 'behavior_loss': 0.2812009170651436, 'mean_batch': 7.565474033355713, 'min_batch': 7.278591537475586, 'max_batch': 7.829112243652344}
step: 47790 @ episode report: {'average_total_reward': 8.8220005, 'reward_variance': 3.087276, 'max_total_reward': 11.12, 'min_total_reward': 4.68, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.091721057891846, 'actor_loss': -5.608251094818115, 'hyper_actor_loss': 0.009596139285713434, 'behavior_loss': 0.259975902736187, 'mean_batch': 7.5229048252105715, 'min_batch': 7.249432706832886, 'max_batch': 7.822766256332398}
step: 47800 @ episode report: {'average_total_reward': 9.632001, 'reward_variance': 4.007097, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.126231074333191, 'actor_loss': -5.584285593032837, 'hyper_actor_loss': 0.009532042872160673, 'behavior_loss': 0.27234071046113967, 'mean_batch': 7.441822624206543, 'min_batch': 7.154740238189698, 'max_batch': 7.698097658157349}
step: 47810 @ episode report: {'average_total_reward': 9.776001, 'reward_variance': 4.4975452, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.049392414093018, 'actor_loss': -5.589678430557251, 'hyper_actor_loss': 0.009605348855257035, 'behavior_loss': 0.2720020890235901, 'mean_batch': 7.445536041259766, 'min_batch': 7.189651346206665, 'max_batch': 7.6820361614227295}
step: 47820 @ episode report: {'average_total_reward': 9.566, 'reward_variance': 3.1768441, 'max_total_reward': 12.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.67405960559845, 'actor_loss': -5.598162364959717, 'hyper_actor_loss': 0.009297365229576826, 'behavior_loss': 0.26423393934965134, 'mean_batch': 7.480698871612549, 'min_batch': 7.216948318481445, 'max_batch': 7.715187644958496}
step: 47830 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 6.692276, 'max_total_reward': 15.67, 'min_total_reward': 5.7900004, 'average_n_step': 10.8, 'max_n_step': 16.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.14291867017746, 'actor_loss': -5.620469236373902, 'hyper_actor_loss': 0.009722642041742802, 'behavior_loss': 0.2930287167429924, 'mean_batch': 7.573930740356445, 'min_batch': 7.289607381820678, 'max_batch': 7.813719463348389}
step: 47840 @ episode report: {'average_total_reward': 10.132001, 'reward_variance': 3.6643562, 'max_total_reward': 14.559999, 'min_total_reward': 7.79, 'average_n_step': 11.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.292872142791748, 'actor_loss': -5.578000879287719, 'hyper_actor_loss': 0.00988006079569459, 'behavior_loss': 0.2605233803391457, 'mean_batch': 7.403985929489136, 'min_batch': 7.1463991641998295, 'max_batch': 7.684578132629395}
step: 47850 @ episode report: {'average_total_reward': 11.364, 'reward_variance': 3.8145447, 'max_total_reward': 14.450001, 'min_total_reward': 7.9000006, 'average_n_step': 12.2, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.663259410858154, 'actor_loss': -5.566719627380371, 'hyper_actor_loss': 0.0099452611990273, 'behavior_loss': 0.28130280375480654, 'mean_batch': 7.375714206695557, 'min_batch': 7.093194961547852, 'max_batch': 7.648819398880005}
step: 47860 @ episode report: {'average_total_reward': 11.386, 'reward_variance': 2.6202831, 'max_total_reward': 13.45, 'min_total_reward': 8.900001, 'average_n_step': 12.2, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3456951498985292, 'actor_loss': -5.610077047348023, 'hyper_actor_loss': 0.010065447725355624, 'behavior_loss': 0.26739414781332016, 'mean_batch': 7.538662576675415, 'min_batch': 7.247569513320923, 'max_batch': 7.802006530761719}
step: 47870 @ episode report: {'average_total_reward': 10.531, 'reward_variance': 4.5970087, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.060066950321198, 'actor_loss': -5.593763208389282, 'hyper_actor_loss': 0.010147265251725912, 'behavior_loss': 0.275313064455986, 'mean_batch': 7.501071453094482, 'min_batch': 7.1665114402771, 'max_batch': 7.805975294113159}
step: 47880 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 2.272065, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 12.0, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6901599287986757, 'actor_loss': -5.559831190109253, 'hyper_actor_loss': 0.01004101550206542, 'behavior_loss': 0.2897869527339935, 'mean_batch': 7.35026364326477, 'min_batch': 7.068747615814209, 'max_batch': 7.608922243118286}
step: 47890 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 2.182284, 'max_total_reward': 12.34, 'min_total_reward': 7.79, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2303781032562258, 'actor_loss': -5.606195163726807, 'hyper_actor_loss': 0.009967339970171452, 'behavior_loss': 0.2749613612890244, 'mean_batch': 7.538464641571045, 'min_batch': 7.220226383209228, 'max_batch': 7.836686038970948}
step: 47900 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 1.1755888, 'max_total_reward': 11.12, 'min_total_reward': 7.79, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.466352581977844, 'actor_loss': -5.604180717468262, 'hyper_actor_loss': 0.009994312562048436, 'behavior_loss': 0.27094665765762327, 'mean_batch': 7.4967138290405275, 'min_batch': 7.2468297481536865, 'max_batch': 7.75505747795105}
step: 47910 @ episode report: {'average_total_reward': 9.233, 'reward_variance': 3.8668208, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.425388312339783, 'actor_loss': -5.533250856399536, 'hyper_actor_loss': 0.010005391575396061, 'behavior_loss': 0.27031820118427274, 'mean_batch': 7.262163257598877, 'min_batch': 6.9672776222229, 'max_batch': 7.535419368743897}
step: 47920 @ episode report: {'average_total_reward': 10.087, 'reward_variance': 5.2042007, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.274988999962807, 'actor_loss': -5.60173282623291, 'hyper_actor_loss': 0.010219123028218747, 'behavior_loss': 0.2850723206996918, 'mean_batch': 7.483130025863647, 'min_batch': 7.24127607345581, 'max_batch': 7.747165870666504}
step: 47930 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 1.6830094, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.209324312210083, 'actor_loss': -5.629608869552612, 'hyper_actor_loss': 0.010137935820966958, 'behavior_loss': 0.28123626857995987, 'mean_batch': 7.596552848815918, 'min_batch': 7.334158134460449, 'max_batch': 7.901266384124756}
step: 47940 @ episode report: {'average_total_reward': 11.319, 'reward_variance': 3.2723286, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.420431303977966, 'actor_loss': -5.553808259963989, 'hyper_actor_loss': 0.01008506678044796, 'behavior_loss': 0.26736961901187895, 'mean_batch': 7.3258161544799805, 'min_batch': 7.051584196090698, 'max_batch': 7.573404121398926}
step: 47950 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 1.3691206, 'max_total_reward': 12.2300005, 'min_total_reward': 8.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3354295969009398, 'actor_loss': -5.551554346084595, 'hyper_actor_loss': 0.010216941218823194, 'behavior_loss': 0.27875906229019165, 'mean_batch': 7.322550821304321, 'min_batch': 7.038117742538452, 'max_batch': 7.564780044555664}
step: 47960 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 2.776284, 'max_total_reward': 13.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9600996494293215, 'actor_loss': -5.601194858551025, 'hyper_actor_loss': 0.010242025554180145, 'behavior_loss': 0.27065015733242037, 'mean_batch': 7.542857122421265, 'min_batch': 7.1803559303283695, 'max_batch': 7.846347188949585}
step: 47970 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 4.3094606, 'max_total_reward': 13.450001, 'min_total_reward': 6.79, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.4736098885536193, 'actor_loss': -5.605567789077758, 'hyper_actor_loss': 0.01016231793910265, 'behavior_loss': 0.2687198773026466, 'mean_batch': 7.536651945114135, 'min_batch': 7.216909646987915, 'max_batch': 7.823484420776367}
step: 47980 @ episode report: {'average_total_reward': 10.498001, 'reward_variance': 2.948156, 'max_total_reward': 13.2300005, 'min_total_reward': 6.68, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.4305640935897825, 'actor_loss': -5.596226787567138, 'hyper_actor_loss': 0.009953595977276564, 'behavior_loss': 0.2762077495455742, 'mean_batch': 7.492632484436035, 'min_batch': 7.192215538024902, 'max_batch': 7.722032785415649}
step: 47990 @ episode report: {'average_total_reward': 10.198001, 'reward_variance': 1.352856, 'max_total_reward': 11.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.647066116333008, 'actor_loss': -5.560451936721802, 'hyper_actor_loss': 0.010123233310878277, 'behavior_loss': 0.26122881919145585, 'mean_batch': 7.3505946636199955, 'min_batch': 7.072908210754394, 'max_batch': 7.605078935623169}
step: 48000 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 1.7332499, 'max_total_reward': 12.340001, 'min_total_reward': 7.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7538997888565064, 'actor_loss': -5.578656959533691, 'hyper_actor_loss': 0.009985416755080223, 'behavior_loss': 0.27469037622213366, 'mean_batch': 7.424305868148804, 'min_batch': 7.131352710723877, 'max_batch': 7.671599960327148}
step: 48010 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 1.5907234, 'max_total_reward': 12.2300005, 'min_total_reward': 7.680001, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.023236680030823, 'actor_loss': -5.583782577514649, 'hyper_actor_loss': 0.010294449981302023, 'behavior_loss': 0.2670326441526413, 'mean_batch': 7.437145328521728, 'min_batch': 7.1556250095367435, 'max_batch': 7.69102201461792}
step: 48020 @ episode report: {'average_total_reward': 9.832001, 'reward_variance': 3.3277771, 'max_total_reward': 13.450001, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0919002532958983, 'actor_loss': -5.6025941371917725, 'hyper_actor_loss': 0.010051660425961017, 'behavior_loss': 0.2639612466096878, 'mean_batch': 7.517851257324219, 'min_batch': 7.213674783706665, 'max_batch': 7.7851073265075685}
step: 48030 @ episode report: {'average_total_reward': 10.276001, 'reward_variance': 3.3399632, 'max_total_reward': 13.45, 'min_total_reward': 7.7900004, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 5.03919198513031, 'actor_loss': -5.589791107177734, 'hyper_actor_loss': 0.010256045591086149, 'behavior_loss': 0.2903130084276199, 'mean_batch': 7.490089416503906, 'min_batch': 7.149397087097168, 'max_batch': 7.731507062911987}
step: 48040 @ episode report: {'average_total_reward': 10.409001, 'reward_variance': 1.4522096, 'max_total_reward': 12.340001, 'min_total_reward': 9.009999, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.383994662761688, 'actor_loss': -5.553859901428223, 'hyper_actor_loss': 0.010266842506825923, 'behavior_loss': 0.27209300398826597, 'mean_batch': 7.404071426391601, 'min_batch': 6.978958415985107, 'max_batch': 7.668292140960693}
step: 48050 @ episode report: {'average_total_reward': 10.387, 'reward_variance': 5.094741, 'max_total_reward': 14.56, 'min_total_reward': 5.7900004, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7880919218063354, 'actor_loss': -5.611450862884522, 'hyper_actor_loss': 0.01070005213841796, 'behavior_loss': 0.26832827031612394, 'mean_batch': 7.570559501647949, 'min_batch': 7.226779651641846, 'max_batch': 7.847521448135376}
step: 48060 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 9.127951, 'max_total_reward': 14.450001, 'min_total_reward': 3.1299999, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6671244859695435, 'actor_loss': -5.609775066375732, 'hyper_actor_loss': 0.010629185289144517, 'behavior_loss': 0.2709561511874199, 'mean_batch': 7.582996416091919, 'min_batch': 7.203031253814697, 'max_batch': 7.843590307235718}
step: 48070 @ episode report: {'average_total_reward': 10.297999, 'reward_variance': 5.869876, 'max_total_reward': 13.450001, 'min_total_reward': 4.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7625548601150514, 'actor_loss': -5.626640701293946, 'hyper_actor_loss': 0.010571359097957611, 'behavior_loss': 0.274052819609642, 'mean_batch': 7.604508972167968, 'min_batch': 7.304766368865967, 'max_batch': 7.884277582168579}
step: 48080 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 6.244604, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7093559980392454, 'actor_loss': -5.623893356323242, 'hyper_actor_loss': 0.010671429336071014, 'behavior_loss': 0.2683297261595726, 'mean_batch': 7.632709598541259, 'min_batch': 7.258702278137207, 'max_batch': 7.912671995162964}
step: 48090 @ episode report: {'average_total_reward': 10.198, 'reward_variance': 2.4188554, 'max_total_reward': 12.23, 'min_total_reward': 6.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5789005517959596, 'actor_loss': -5.607882118225097, 'hyper_actor_loss': 0.010526141896843911, 'behavior_loss': 0.2764086380600929, 'mean_batch': 7.550507307052612, 'min_batch': 7.220016431808472, 'max_batch': 7.838473558425903}
step: 48100 @ episode report: {'average_total_reward': 9.377001, 'reward_variance': 3.501662, 'max_total_reward': 11.2300005, 'min_total_reward': 6.57, 'average_n_step': 10.4, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.3008461713790895, 'actor_loss': -5.59801721572876, 'hyper_actor_loss': 0.010421152785420417, 'behavior_loss': 0.27510014176368713, 'mean_batch': 7.526919889450073, 'min_batch': 7.172052335739136, 'max_batch': 7.817578983306885}
step: 48110 @ episode report: {'average_total_reward': 9.654001, 'reward_variance': 2.8690448, 'max_total_reward': 12.34, 'min_total_reward': 5.7899995, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.045982551574707, 'actor_loss': -5.6008964538574215, 'hyper_actor_loss': 0.010493911150842906, 'behavior_loss': 0.2810992494225502, 'mean_batch': 7.508304786682129, 'min_batch': 7.2102597713470455, 'max_batch': 7.77637825012207}
step: 48120 @ episode report: {'average_total_reward': 9.987, 'reward_variance': 6.204661, 'max_total_reward': 12.34, 'min_total_reward': 4.68, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.686174789071083, 'actor_loss': -5.627697420120239, 'hyper_actor_loss': 0.01047500567510724, 'behavior_loss': 0.2759785160422325, 'mean_batch': 7.6086506843566895, 'min_batch': 7.308470678329468, 'max_batch': 7.8683634281158445}
step: 48130 @ episode report: {'average_total_reward': 10.109001, 'reward_variance': 4.0217094, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1426126718521115, 'actor_loss': -5.630795240402222, 'hyper_actor_loss': 0.01059061847627163, 'behavior_loss': 0.2742402419447899, 'mean_batch': 7.634263563156128, 'min_batch': 7.3065025806427, 'max_batch': 7.924541997909546}
step: 48140 @ episode report: {'average_total_reward': 10.22, 'reward_variance': 3.6910396, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4535297393798827, 'actor_loss': -5.607009506225586, 'hyper_actor_loss': 0.010758911911398172, 'behavior_loss': 0.2553411826491356, 'mean_batch': 7.540420579910278, 'min_batch': 7.223740577697754, 'max_batch': 7.822239542007447}
step: 48150 @ episode report: {'average_total_reward': 11.519, 'reward_variance': 3.0528283, 'max_total_reward': 14.559999, 'min_total_reward': 8.79, 'average_n_step': 12.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.187285029888153, 'actor_loss': -5.644180250167847, 'hyper_actor_loss': 0.010657279659062624, 'behavior_loss': 0.26397912204265594, 'mean_batch': 7.679403305053711, 'min_batch': 7.3613958835601805, 'max_batch': 7.951039886474609}
step: 48160 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 3.3206801, 'max_total_reward': 13.34, 'min_total_reward': 7.680001, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5596609115600586, 'actor_loss': -5.649385786056518, 'hyper_actor_loss': 0.01040531974285841, 'behavior_loss': 0.27639694809913634, 'mean_batch': 7.677866792678833, 'min_batch': 7.401273488998413, 'max_batch': 7.932257986068725}
step: 48170 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 5.7873254, 'max_total_reward': 14.45, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.345637202262878, 'actor_loss': -5.612137222290039, 'hyper_actor_loss': 0.010675459075719118, 'behavior_loss': 0.26043405681848525, 'mean_batch': 7.553107357025146, 'min_batch': 7.248648357391358, 'max_batch': 7.8120006084442135}
step: 48180 @ episode report: {'average_total_reward': 10.532001, 'reward_variance': 3.528656, 'max_total_reward': 14.45, 'min_total_reward': 7.79, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7745030164718627, 'actor_loss': -5.600412082672119, 'hyper_actor_loss': 0.010581191163510084, 'behavior_loss': 0.28957033306360247, 'mean_batch': 7.495071029663086, 'min_batch': 7.219326305389404, 'max_batch': 7.762040328979492}
step: 48190 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 2.5695844, 'max_total_reward': 13.34, 'min_total_reward': 8.79, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2344971895217896, 'actor_loss': -5.613159608840943, 'hyper_actor_loss': 0.010601337160915136, 'behavior_loss': 0.284206360578537, 'mean_batch': 7.560186290740967, 'min_batch': 7.2494395732879635, 'max_batch': 7.821549272537231}
step: 48200 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.2942044, 'max_total_reward': 12.2300005, 'min_total_reward': 7.9, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9326552391052245, 'actor_loss': -5.636311721801758, 'hyper_actor_loss': 0.011014287639409304, 'behavior_loss': 0.2778258979320526, 'mean_batch': 7.638841056823731, 'min_batch': 7.342424058914185, 'max_batch': 7.891828775405884}
step: 48210 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.2738416, 'max_total_reward': 12.12, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.288673597574234, 'actor_loss': -5.611163330078125, 'hyper_actor_loss': 0.011249538976699114, 'behavior_loss': 0.2630091071128845, 'mean_batch': 7.531571102142334, 'min_batch': 7.262163257598877, 'max_batch': 7.782294607162475}
step: 48220 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 2.1557057, 'max_total_reward': 13.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.216860127449036, 'actor_loss': -5.643273401260376, 'hyper_actor_loss': 0.010794753674417734, 'behavior_loss': 0.2608767732977867, 'mean_batch': 7.66055588722229, 'min_batch': 7.372964763641358, 'max_batch': 7.919990682601929}
step: 48230 @ episode report: {'average_total_reward': 10.61, 'reward_variance': 1.4036596, 'max_total_reward': 13.34, 'min_total_reward': 8.68, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8339759588241575, 'actor_loss': -5.637141466140747, 'hyper_actor_loss': 0.01084096571430564, 'behavior_loss': 0.26139764338731764, 'mean_batch': 7.628427314758301, 'min_batch': 7.358599901199341, 'max_batch': 7.857087421417236}
step: 48240 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 1.5062001, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6555126428604128, 'actor_loss': -5.598963117599487, 'hyper_actor_loss': 0.010730420146137476, 'behavior_loss': 0.2671500936150551, 'mean_batch': 7.51593713760376, 'min_batch': 7.189102458953857, 'max_batch': 7.791382932662964}
step: 48250 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 1.0948491, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8215988159179686, 'actor_loss': -5.6154581069946286, 'hyper_actor_loss': 0.011445391178131103, 'behavior_loss': 0.27610632181167605, 'mean_batch': 7.567322540283203, 'min_batch': 7.258732843399048, 'max_batch': 7.828450107574463}
step: 48260 @ episode report: {'average_total_reward': 9.344, 'reward_variance': 9.157525, 'max_total_reward': 12.339999, 'min_total_reward': 2.02, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.481058216094971, 'actor_loss': -5.61405234336853, 'hyper_actor_loss': 0.011921310052275657, 'behavior_loss': 0.26298257112503054, 'mean_batch': 7.568332624435425, 'min_batch': 7.248401498794555, 'max_batch': 7.833303833007813}
step: 48270 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 4.3082843, 'max_total_reward': 13.12, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.176850688457489, 'actor_loss': -5.591016483306885, 'hyper_actor_loss': 0.012119168508797884, 'behavior_loss': 0.2695669949054718, 'mean_batch': 7.475009202957153, 'min_batch': 7.172241687774658, 'max_batch': 7.696533346176148}
step: 48280 @ episode report: {'average_total_reward': 9.087999, 'reward_variance': 4.265895, 'max_total_reward': 12.339999, 'min_total_reward': 4.6800003, 'average_n_step': 10.1, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2520251512527465, 'actor_loss': -5.613015031814575, 'hyper_actor_loss': 0.011956501379609108, 'behavior_loss': 0.2722999840974808, 'mean_batch': 7.562663316726685, 'min_batch': 7.246292495727539, 'max_batch': 7.836677742004395}
step: 48290 @ episode report: {'average_total_reward': 10.076001, 'reward_variance': 3.935524, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7509917974472047, 'actor_loss': -5.638036155700684, 'hyper_actor_loss': 0.011441945750266313, 'behavior_loss': 0.27175341695547106, 'mean_batch': 7.64980845451355, 'min_batch': 7.344921875, 'max_batch': 7.927111959457397}
step: 48300 @ episode report: {'average_total_reward': 11.186001, 'reward_variance': 4.5361443, 'max_total_reward': 14.560001, 'min_total_reward': 7.7900004, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8891223192214968, 'actor_loss': -5.583912420272827, 'hyper_actor_loss': 0.011159034725278617, 'behavior_loss': 0.2687816649675369, 'mean_batch': 7.426594543457031, 'min_batch': 7.166923093795776, 'max_batch': 7.657761526107788}
step: 48310 @ episode report: {'average_total_reward': 9.3220005, 'reward_variance': 5.5141554, 'max_total_reward': 12.34, 'min_total_reward': 3.8000002, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6703858017921447, 'actor_loss': -5.584037780761719, 'hyper_actor_loss': 0.011123555153608322, 'behavior_loss': 0.2670776605606079, 'mean_batch': 7.417567348480224, 'min_batch': 7.176639032363892, 'max_batch': 7.679315376281738}
step: 48320 @ episode report: {'average_total_reward': 9.454, 'reward_variance': 3.4039035, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6545360922813415, 'actor_loss': -5.618858861923218, 'hyper_actor_loss': 0.011141699180006981, 'behavior_loss': 0.28165173381567, 'mean_batch': 7.569544935226441, 'min_batch': 7.281372594833374, 'max_batch': 7.8253453254699705}
step: 48330 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 3.2118802, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.067846512794494, 'actor_loss': -5.618845081329345, 'hyper_actor_loss': 0.011336386483162642, 'behavior_loss': 0.27719020694494245, 'mean_batch': 7.561308526992798, 'min_batch': 7.289336919784546, 'max_batch': 7.871225595474243}
step: 48340 @ episode report: {'average_total_reward': 10.365001, 'reward_variance': 2.395386, 'max_total_reward': 14.340001, 'min_total_reward': 8.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.531607413291931, 'actor_loss': -5.594044780731201, 'hyper_actor_loss': 0.011113804578781129, 'behavior_loss': 0.27002919316291807, 'mean_batch': 7.496665000915527, 'min_batch': 7.172291707992554, 'max_batch': 7.792159128189087}
step: 48350 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 5.654789, 'max_total_reward': 13.34, 'min_total_reward': 4.68, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4190070152282717, 'actor_loss': -5.6141884326934814, 'hyper_actor_loss': 0.011197454296052456, 'behavior_loss': 0.2852808564901352, 'mean_batch': 7.572553968429565, 'min_batch': 7.244581794738769, 'max_batch': 7.816819667816162}
step: 48360 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 1.9472841, 'max_total_reward': 12.34, 'min_total_reward': 7.5699997, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.643567967414856, 'actor_loss': -5.578747797012329, 'hyper_actor_loss': 0.01085674213245511, 'behavior_loss': 0.2924989402294159, 'mean_batch': 7.4150022029876705, 'min_batch': 7.141703033447266, 'max_batch': 7.649710369110108}
step: 48370 @ episode report: {'average_total_reward': 9.588, 'reward_variance': 2.098216, 'max_total_reward': 12.23, 'min_total_reward': 7.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.103306770324707, 'actor_loss': -5.544936227798462, 'hyper_actor_loss': 0.010938225872814655, 'behavior_loss': 0.27769011855125425, 'mean_batch': 7.294707918167115, 'min_batch': 7.017355251312256, 'max_batch': 7.529599189758301}
step: 48380 @ episode report: {'average_total_reward': 9.899, 'reward_variance': 3.3972886, 'max_total_reward': 12.34, 'min_total_reward': 5.57, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5861881256103514, 'actor_loss': -5.5957098484039305, 'hyper_actor_loss': 0.01062340522184968, 'behavior_loss': 0.271830877661705, 'mean_batch': 7.49019079208374, 'min_batch': 7.192617177963257, 'max_batch': 7.742842817306519}
step: 48390 @ episode report: {'average_total_reward': 10.598, 'reward_variance': 2.0109754, 'max_total_reward': 13.23, 'min_total_reward': 8.679999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.177634859085083, 'actor_loss': -5.582521581649781, 'hyper_actor_loss': 0.011042990814894437, 'behavior_loss': 0.282959121465683, 'mean_batch': 7.424364757537842, 'min_batch': 7.159556245803833, 'max_batch': 7.658967685699463}
step: 48400 @ episode report: {'average_total_reward': 10.265001, 'reward_variance': 0.95112514, 'max_total_reward': 12.34, 'min_total_reward': 8.900001, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2883452415466308, 'actor_loss': -5.563447141647339, 'hyper_actor_loss': 0.010836175922304393, 'behavior_loss': 0.2748586356639862, 'mean_batch': 7.3748680591583256, 'min_batch': 7.071495819091797, 'max_batch': 7.568515825271606}
step: 48410 @ episode report: {'average_total_reward': 9.155001, 'reward_variance': 9.041204, 'max_total_reward': 13.340001, 'min_total_reward': 3.3500001, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.195397090911865, 'actor_loss': -5.593009567260742, 'hyper_actor_loss': 0.010316905193030834, 'behavior_loss': 0.2639015480875969, 'mean_batch': 7.511057758331299, 'min_batch': 7.153479671478271, 'max_batch': 7.722426176071167}
step: 48420 @ episode report: {'average_total_reward': 10.809, 'reward_variance': 2.1564682, 'max_total_reward': 12.34, 'min_total_reward': 7.5700006, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5106943130493162, 'actor_loss': -5.574692296981811, 'hyper_actor_loss': 0.010185677465051413, 'behavior_loss': 0.2803916856646538, 'mean_batch': 7.425371408462524, 'min_batch': 7.104517459869385, 'max_batch': 7.640701246261597}
step: 48430 @ episode report: {'average_total_reward': 10.842001, 'reward_variance': 1.1155564, 'max_total_reward': 12.2300005, 'min_total_reward': 9.01, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3591212391853333, 'actor_loss': -5.5896909713745115, 'hyper_actor_loss': 0.010048521868884563, 'behavior_loss': 0.2734820768237114, 'mean_batch': 7.447367525100708, 'min_batch': 7.188021850585938, 'max_batch': 7.684236335754394}
step: 48440 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 3.8285568, 'max_total_reward': 12.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.121093451976776, 'actor_loss': -5.614762783050537, 'hyper_actor_loss': 0.010173118766397237, 'behavior_loss': 0.27159263342618944, 'mean_batch': 7.538676786422729, 'min_batch': 7.2812535762786865, 'max_batch': 7.746926736831665}
step: 48450 @ episode report: {'average_total_reward': 10.11, 'reward_variance': 5.498721, 'max_total_reward': 16.45, 'min_total_reward': 7.6800003, 'average_n_step': 11.1, 'max_n_step': 17.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6493058264255525, 'actor_loss': -5.605754327774048, 'hyper_actor_loss': 0.010353331454098225, 'behavior_loss': 0.282400082051754, 'mean_batch': 7.5763157367706295, 'min_batch': 7.1823983669281, 'max_batch': 7.813619756698609}
step: 48460 @ episode report: {'average_total_reward': 9.976, 'reward_variance': 2.9144032, 'max_total_reward': 11.2300005, 'min_total_reward': 5.5700006, 'average_n_step': 10.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.218318021297455, 'actor_loss': -5.593854331970215, 'hyper_actor_loss': 0.009965058136731385, 'behavior_loss': 0.2687406450510025, 'mean_batch': 7.492762899398803, 'min_batch': 7.1751610279083256, 'max_batch': 7.727621126174927}
step: 48470 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 2.0066643, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6457574367523193, 'actor_loss': -5.595890808105469, 'hyper_actor_loss': 0.009801583364605904, 'behavior_loss': 0.2634099245071411, 'mean_batch': 7.470410251617432, 'min_batch': 7.21046199798584, 'max_batch': 7.716545486450196}
step: 48480 @ episode report: {'average_total_reward': 9.432001, 'reward_variance': 3.974116, 'max_total_reward': 12.23, 'min_total_reward': 5.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.437349700927735, 'actor_loss': -5.574960517883301, 'hyper_actor_loss': 0.00978612881153822, 'behavior_loss': 0.264365029335022, 'mean_batch': 7.396282768249511, 'min_batch': 7.1324623107910154, 'max_batch': 7.610624313354492}
step: 48490 @ episode report: {'average_total_reward': 10.109, 'reward_variance': 4.494969, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5020032644271852, 'actor_loss': -5.557123422622681, 'hyper_actor_loss': 0.00968269482254982, 'behavior_loss': 0.2674840733408928, 'mean_batch': 7.324795293807983, 'min_batch': 7.074551200866699, 'max_batch': 7.540302991867065}
step: 48500 @ episode report: {'average_total_reward': 11.142001, 'reward_variance': 1.1900358, 'max_total_reward': 12.339999, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8503222703933715, 'actor_loss': -5.611474561691284, 'hyper_actor_loss': 0.010074355825781822, 'behavior_loss': 0.2687002122402191, 'mean_batch': 7.540438079833985, 'min_batch': 7.2556822299957275, 'max_batch': 7.77997579574585}
step: 48510 @ episode report: {'average_total_reward': 10.154, 'reward_variance': 1.5991442, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.968428111076355, 'actor_loss': -5.594972753524781, 'hyper_actor_loss': 0.010373023059219121, 'behavior_loss': 0.2662726104259491, 'mean_batch': 7.471692705154419, 'min_batch': 7.202791500091553, 'max_batch': 7.72599983215332}
step: 48520 @ episode report: {'average_total_reward': 10.443001, 'reward_variance': 1.5703411, 'max_total_reward': 12.2300005, 'min_total_reward': 8.68, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.392227625846862, 'actor_loss': -5.584730100631714, 'hyper_actor_loss': 0.010270753502845764, 'behavior_loss': 0.2698147386312485, 'mean_batch': 7.435875701904297, 'min_batch': 7.1635595798492435, 'max_batch': 7.666603660583496}
step: 48530 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 3.3385367, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.649816107749939, 'actor_loss': -5.584144020080567, 'hyper_actor_loss': 0.009956397395581008, 'behavior_loss': 0.2726245403289795, 'mean_batch': 7.412335634231567, 'min_batch': 7.182094383239746, 'max_batch': 7.653867387771607}
step: 48540 @ episode report: {'average_total_reward': 11.175001, 'reward_variance': 2.9380658, 'max_total_reward': 14.450001, 'min_total_reward': 9.01, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7914332151412964, 'actor_loss': -5.590061521530151, 'hyper_actor_loss': 0.009831189084798098, 'behavior_loss': 0.27584527134895326, 'mean_batch': 7.4698264598846436, 'min_batch': 7.170370817184448, 'max_batch': 7.732570171356201}
step: 48550 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 1.1061997, 'max_total_reward': 11.2300005, 'min_total_reward': 7.6800003, 'average_n_step': 10.6, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5902227640151976, 'actor_loss': -5.6111198425292965, 'hyper_actor_loss': 0.010154335480183362, 'behavior_loss': 0.2775816425681114, 'mean_batch': 7.551298904418945, 'min_batch': 7.242705535888672, 'max_batch': 7.7993511199951175}
step: 48560 @ episode report: {'average_total_reward': 9.754001, 'reward_variance': 1.4225639, 'max_total_reward': 11.230001, 'min_total_reward': 7.9000006, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.957741904258728, 'actor_loss': -5.579959106445313, 'hyper_actor_loss': 0.010342208668589592, 'behavior_loss': 0.26910126507282256, 'mean_batch': 7.428817701339722, 'min_batch': 7.136381578445435, 'max_batch': 7.669803762435913}
step: 48570 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 2.8272696, 'max_total_reward': 14.450001, 'min_total_reward': 8.9, 'average_n_step': 11.8, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8489440798759462, 'actor_loss': -5.610899019241333, 'hyper_actor_loss': 0.010548796691000461, 'behavior_loss': 0.2708879947662354, 'mean_batch': 7.541394662857056, 'min_batch': 7.25148024559021, 'max_batch': 7.77005090713501}
step: 48580 @ episode report: {'average_total_reward': 10.032001, 'reward_variance': 2.5244565, 'max_total_reward': 12.2300005, 'min_total_reward': 7.79, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9060954332351683, 'actor_loss': -5.622374677658081, 'hyper_actor_loss': 0.010520343016833068, 'behavior_loss': 0.2638730421662331, 'mean_batch': 7.577926540374756, 'min_batch': 7.29931526184082, 'max_batch': 7.79165415763855}
step: 48590 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.6749296, 'max_total_reward': 12.2300005, 'min_total_reward': 5.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.689206123352051, 'actor_loss': -5.55999722480774, 'hyper_actor_loss': 0.010602130275219678, 'behavior_loss': 0.26896631717681885, 'mean_batch': 7.326625061035156, 'min_batch': 7.092902517318725, 'max_batch': 7.5236612319946286}
step: 48600 @ episode report: {'average_total_reward': 10.953, 'reward_variance': 3.305941, 'max_total_reward': 13.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9636935234069823, 'actor_loss': -5.565770387649536, 'hyper_actor_loss': 0.010816367715597153, 'behavior_loss': 0.27701534926891325, 'mean_batch': 7.370054864883423, 'min_batch': 7.092052984237671, 'max_batch': 7.554197883605957}
step: 48610 @ episode report: {'average_total_reward': 9.932, 'reward_variance': 3.5754771, 'max_total_reward': 12.340001, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2473426342010496, 'actor_loss': -5.603720426559448, 'hyper_actor_loss': 0.011039729043841363, 'behavior_loss': 0.27236599177122117, 'mean_batch': 7.498331356048584, 'min_batch': 7.240363883972168, 'max_batch': 7.696499490737915}
step: 48620 @ episode report: {'average_total_reward': 10.476, 'reward_variance': 2.5154443, 'max_total_reward': 13.45, 'min_total_reward': 8.570001, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.263655829429626, 'actor_loss': -5.608714389801025, 'hyper_actor_loss': 0.011422911379486322, 'behavior_loss': 0.28198867440223696, 'mean_batch': 7.521429538726807, 'min_batch': 7.254177474975586, 'max_batch': 7.722705745697022}
step: 48630 @ episode report: {'average_total_reward': 10.043, 'reward_variance': 2.0885205, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.121965050697327, 'actor_loss': -5.539172172546387, 'hyper_actor_loss': 0.011598944850265979, 'behavior_loss': 0.27652483731508254, 'mean_batch': 7.261097431182861, 'min_batch': 7.0096276760101315, 'max_batch': 7.473823690414429}
step: 48640 @ episode report: {'average_total_reward': 9.765001, 'reward_variance': 2.3929658, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6495553493499755, 'actor_loss': -5.573009920120239, 'hyper_actor_loss': 0.011264922004193068, 'behavior_loss': 0.27515012174844744, 'mean_batch': 7.382272052764892, 'min_batch': 7.132016038894653, 'max_batch': 7.5735537052154545}
step: 48650 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 3.5840409, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4427992343902587, 'actor_loss': -5.605250310897827, 'hyper_actor_loss': 0.011691591609269381, 'behavior_loss': 0.26440104097127914, 'mean_batch': 7.507556009292602, 'min_batch': 7.242550468444824, 'max_batch': 7.715937852859497}
step: 48660 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 1.8212763, 'max_total_reward': 12.2300005, 'min_total_reward': 7.7900004, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.92083158493042, 'actor_loss': -5.5816397190094, 'hyper_actor_loss': 0.011608029250055552, 'behavior_loss': 0.28633217960596086, 'mean_batch': 7.433366966247559, 'min_batch': 7.144108247756958, 'max_batch': 7.644916200637818}
step: 48670 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 4.32125, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.972963237762451, 'actor_loss': -5.546618843078614, 'hyper_actor_loss': 0.01153246033936739, 'behavior_loss': 0.2652792796492577, 'mean_batch': 7.294152545928955, 'min_batch': 7.029778242111206, 'max_batch': 7.496673154830932}
step: 48680 @ episode report: {'average_total_reward': 10.830999, 'reward_variance': 1.4302087, 'max_total_reward': 13.23, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.607482922077179, 'actor_loss': -5.580743408203125, 'hyper_actor_loss': 0.011424823012202979, 'behavior_loss': 0.28378341495990755, 'mean_batch': 7.431617546081543, 'min_batch': 7.13922152519226, 'max_batch': 7.628961086273193}
step: 48690 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 1.3038694, 'max_total_reward': 11.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.329742455482483, 'actor_loss': -5.585047960281372, 'hyper_actor_loss': 0.011170805152505636, 'behavior_loss': 0.27690295726060865, 'mean_batch': 7.431854295730591, 'min_batch': 7.170313215255737, 'max_batch': 7.658250999450684}
step: 48700 @ episode report: {'average_total_reward': 10.520001, 'reward_variance': 5.3684, 'max_total_reward': 14.339999, 'min_total_reward': 6.68, 'average_n_step': 11.4, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.11247501373291, 'actor_loss': -5.561649656295776, 'hyper_actor_loss': 0.011003041546791792, 'behavior_loss': 0.2770228788256645, 'mean_batch': 7.371468210220337, 'min_batch': 7.061440658569336, 'max_batch': 7.573552417755127}
step: 48710 @ episode report: {'average_total_reward': 10.398001, 'reward_variance': 6.129117, 'max_total_reward': 15.560001, 'min_total_reward': 6.9, 'average_n_step': 11.3, 'max_n_step': 16.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.240201091766357, 'actor_loss': -5.558021593093872, 'hyper_actor_loss': 0.011114552337676286, 'behavior_loss': 0.2664996564388275, 'mean_batch': 7.347617197036743, 'min_batch': 7.058729934692383, 'max_batch': 7.563827133178711}
step: 48720 @ episode report: {'average_total_reward': 10.787001, 'reward_variance': 3.3279815, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.35707141160965, 'actor_loss': -5.524803638458252, 'hyper_actor_loss': 0.010954427905380726, 'behavior_loss': 0.2699537679553032, 'mean_batch': 7.2345006465911865, 'min_batch': 6.934845399856568, 'max_batch': 7.4438470840454105}
step: 48730 @ episode report: {'average_total_reward': 10.842, 'reward_variance': 2.8649158, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9745260953903196, 'actor_loss': -5.5299975872039795, 'hyper_actor_loss': 0.010871329810470343, 'behavior_loss': 0.26724415421485903, 'mean_batch': 7.2591233253479, 'min_batch': 6.948303174972534, 'max_batch': 7.487150239944458}
step: 48740 @ episode report: {'average_total_reward': 8.8550005, 'reward_variance': 5.685906, 'max_total_reward': 12.2300005, 'min_total_reward': 5.6799994, 'average_n_step': 9.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8977868437767027, 'actor_loss': -5.546992683410645, 'hyper_actor_loss': 0.011246295925229789, 'behavior_loss': 0.2623031407594681, 'mean_batch': 7.31783652305603, 'min_batch': 7.009610319137574, 'max_batch': 7.509603595733642}
step: 48750 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 2.3832688, 'max_total_reward': 11.2300005, 'min_total_reward': 5.6800003, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.057448816299439, 'actor_loss': -5.542397546768188, 'hyper_actor_loss': 0.011446491163223983, 'behavior_loss': 0.26331427991390227, 'mean_batch': 7.301767301559448, 'min_batch': 6.992771100997925, 'max_batch': 7.484551239013672}
step: 48760 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 5.4396844, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.95401132106781, 'actor_loss': -5.539242839813232, 'hyper_actor_loss': 0.010936311352998019, 'behavior_loss': 0.2731814280152321, 'mean_batch': 7.2807543754577635, 'min_batch': 6.990949440002441, 'max_batch': 7.485425043106079}
step: 48770 @ episode report: {'average_total_reward': 11.209002, 'reward_variance': 2.5354881, 'max_total_reward': 14.339999, 'min_total_reward': 8.900001, 'average_n_step': 12.1, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9422021389007567, 'actor_loss': -5.546151733398437, 'hyper_actor_loss': 0.011465712450444698, 'behavior_loss': 0.27010314017534254, 'mean_batch': 7.302932500839233, 'min_batch': 7.017996835708618, 'max_batch': 7.518500471115113}
step: 48780 @ episode report: {'average_total_reward': 9.044001, 'reward_variance': 2.104304, 'max_total_reward': 11.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.356431245803833, 'actor_loss': -5.543864059448242, 'hyper_actor_loss': 0.011555674113333225, 'behavior_loss': 0.26565994024276735, 'mean_batch': 7.298790454864502, 'min_batch': 7.00608377456665, 'max_batch': 7.494093179702759}
step: 48790 @ episode report: {'average_total_reward': 10.021001, 'reward_variance': 3.17023, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9978517174720762, 'actor_loss': -5.577388334274292, 'hyper_actor_loss': 0.011459504347294569, 'behavior_loss': 0.27136872708797455, 'mean_batch': 7.415269756317139, 'min_batch': 7.130886459350586, 'max_batch': 7.612453365325928}
step: 48800 @ episode report: {'average_total_reward': 9.455, 'reward_variance': 2.0717053, 'max_total_reward': 12.120001, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5818694591522218, 'actor_loss': -5.586957597732544, 'hyper_actor_loss': 0.011288659181445837, 'behavior_loss': 0.26713194251060485, 'mean_batch': 7.472594261169434, 'min_batch': 7.144580459594726, 'max_batch': 7.7029942035675045}
step: 48810 @ episode report: {'average_total_reward': 10.243, 'reward_variance': 3.347541, 'max_total_reward': 11.900001, 'min_total_reward': 5.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.723863959312439, 'actor_loss': -5.5580497741699215, 'hyper_actor_loss': 0.0115843559615314, 'behavior_loss': 0.2754669412970543, 'mean_batch': 7.350592422485351, 'min_batch': 7.056195020675659, 'max_batch': 7.562554550170899}
step: 48820 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 2.053884, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.630915880203247, 'actor_loss': -5.546912670135498, 'hyper_actor_loss': 0.01140691116452217, 'behavior_loss': 0.27707373797893525, 'mean_batch': 7.3190491676330565, 'min_batch': 7.007924175262451, 'max_batch': 7.54989104270935}
step: 48830 @ episode report: {'average_total_reward': 9.51, 'reward_variance': 5.2098804, 'max_total_reward': 14.34, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.356517338752747, 'actor_loss': -5.549531364440918, 'hyper_actor_loss': 0.011459777038544417, 'behavior_loss': 0.2632751852273941, 'mean_batch': 7.323044347763061, 'min_batch': 7.0225138664245605, 'max_batch': 7.541620779037475}
step: 48840 @ episode report: {'average_total_reward': 9.876001, 'reward_variance': 1.9142444, 'max_total_reward': 11.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6839242696762087, 'actor_loss': -5.5394655704498295, 'hyper_actor_loss': 0.011383836716413498, 'behavior_loss': 0.267994287610054, 'mean_batch': 7.305663299560547, 'min_batch': 6.968538570404053, 'max_batch': 7.515021324157715}
step: 48850 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 2.0022247, 'max_total_reward': 12.2300005, 'min_total_reward': 6.7899995, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.823764073848724, 'actor_loss': -5.549064350128174, 'hyper_actor_loss': 0.010778023488819599, 'behavior_loss': 0.2626353487372398, 'mean_batch': 7.343363523483276, 'min_batch': 6.999634599685669, 'max_batch': 7.567907857894897}
step: 48860 @ episode report: {'average_total_reward': 8.744, 'reward_variance': 3.4083848, 'max_total_reward': 11.120001, 'min_total_reward': 5.5699997, 'average_n_step': 9.8, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.176407593488693, 'actor_loss': -5.564181756973267, 'hyper_actor_loss': 0.010793783329427242, 'behavior_loss': 0.28640695810317995, 'mean_batch': 7.39534068107605, 'min_batch': 7.057118511199951, 'max_batch': 7.6121344566345215}
step: 48870 @ episode report: {'average_total_reward': 9.3550005, 'reward_variance': 6.0426645, 'max_total_reward': 12.34, 'min_total_reward': 3.13, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.04541699886322, 'actor_loss': -5.560992860794068, 'hyper_actor_loss': 0.010907807480543852, 'behavior_loss': 0.28523260056972505, 'mean_batch': 7.385750484466553, 'min_batch': 7.043202638626099, 'max_batch': 7.6284706592559814}
step: 48880 @ episode report: {'average_total_reward': 9.366, 'reward_variance': 7.875744, 'max_total_reward': 13.34, 'min_total_reward': 3.13, 'average_n_step': 10.4, 'max_n_step': 14.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3284297704696657, 'actor_loss': -5.54758996963501, 'hyper_actor_loss': 0.011310961470007897, 'behavior_loss': 0.2729748710989952, 'mean_batch': 7.340916585922241, 'min_batch': 6.991854858398438, 'max_batch': 7.5559157371521}
step: 48890 @ episode report: {'average_total_reward': 9.532001, 'reward_variance': 2.9649758, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7856844663619995, 'actor_loss': -5.578553342819214, 'hyper_actor_loss': 0.011522144917398692, 'behavior_loss': 0.2832723051309586, 'mean_batch': 7.425451993942261, 'min_batch': 7.129757404327393, 'max_batch': 7.668710947036743}
step: 48900 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 3.0184958, 'max_total_reward': 12.009999, 'min_total_reward': 5.68, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.939027041196823, 'actor_loss': -5.581179809570313, 'hyper_actor_loss': 0.011262959334999323, 'behavior_loss': 0.2750663548707962, 'mean_batch': 7.46811318397522, 'min_batch': 7.10753812789917, 'max_batch': 7.706475687026978}
step: 48910 @ episode report: {'average_total_reward': 8.999001, 'reward_variance': 5.8049684, 'max_total_reward': 13.23, 'min_total_reward': 5.7900004, 'average_n_step': 10.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1686105132102966, 'actor_loss': -5.565474510192871, 'hyper_actor_loss': 0.011419761274009944, 'behavior_loss': 0.27665177583694456, 'mean_batch': 7.398664903640747, 'min_batch': 7.062359809875488, 'max_batch': 7.613049936294556}
step: 48920 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 5.470024, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.454296815395355, 'actor_loss': -5.560032749176026, 'hyper_actor_loss': 0.011103713233023883, 'behavior_loss': 0.2731669157743454, 'mean_batch': 7.342501831054688, 'min_batch': 7.077685403823852, 'max_batch': 7.529382228851318}
step: 48930 @ episode report: {'average_total_reward': 10.853001, 'reward_variance': 1.6888609, 'max_total_reward': 13.23, 'min_total_reward': 8.900001, 'average_n_step': 11.7, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.048695278167725, 'actor_loss': -5.544771432876587, 'hyper_actor_loss': 0.01079480117186904, 'behavior_loss': 0.2764013037085533, 'mean_batch': 7.299020195007325, 'min_batch': 7.012250375747681, 'max_batch': 7.505239963531494}
step: 48940 @ episode report: {'average_total_reward': 10.209001, 'reward_variance': 2.1134894, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9489288091659547, 'actor_loss': -5.53765344619751, 'hyper_actor_loss': 0.01079328302294016, 'behavior_loss': 0.26953465193510057, 'mean_batch': 7.27290940284729, 'min_batch': 6.987431192398072, 'max_batch': 7.483601713180542}
step: 48950 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 4.5063615, 'max_total_reward': 14.56, 'min_total_reward': 7.9, 'average_n_step': 11.5, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.299778401851654, 'actor_loss': -5.565583372116089, 'hyper_actor_loss': 0.010579272359609603, 'behavior_loss': 0.27658107280731203, 'mean_batch': 7.380275058746338, 'min_batch': 7.08150429725647, 'max_batch': 7.577604913711548}
step: 48960 @ episode report: {'average_total_reward': 10.864, 'reward_variance': 1.9886639, 'max_total_reward': 12.34, 'min_total_reward': 7.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.376239800453186, 'actor_loss': -5.565278816223144, 'hyper_actor_loss': 0.010628753900527954, 'behavior_loss': 0.28237685561180115, 'mean_batch': 7.364233875274659, 'min_batch': 7.093898153305053, 'max_batch': 7.565487337112427}
step: 48970 @ episode report: {'average_total_reward': 9.843, 'reward_variance': 2.8667815, 'max_total_reward': 12.2300005, 'min_total_reward': 6.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9851728439331056, 'actor_loss': -5.52423882484436, 'hyper_actor_loss': 0.009969606436789036, 'behavior_loss': 0.2720587536692619, 'mean_batch': 7.238574647903443, 'min_batch': 6.927425384521484, 'max_batch': 7.458048391342163}
step: 48980 @ episode report: {'average_total_reward': 11.076, 'reward_variance': 1.9617455, 'max_total_reward': 14.120001, 'min_total_reward': 8.9, 'average_n_step': 12.0, 'max_n_step': 15.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5081947803497315, 'actor_loss': -5.527376651763916, 'hyper_actor_loss': 0.01012112433090806, 'behavior_loss': 0.27012809813022615, 'mean_batch': 7.253444194793701, 'min_batch': 6.935169124603272, 'max_batch': 7.457711219787598}
step: 48990 @ episode report: {'average_total_reward': 8.3220005, 'reward_variance': 10.9447155, 'max_total_reward': 12.34, 'min_total_reward': 2.3500001, 'average_n_step': 9.4, 'max_n_step': 13.0, 'min_n_step': 4.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0304768204689028, 'actor_loss': -5.576270580291748, 'hyper_actor_loss': 0.010015523806214333, 'behavior_loss': 0.2741930663585663, 'mean_batch': 7.418845319747925, 'min_batch': 7.119961261749268, 'max_batch': 7.634908723831177}
step: 49000 @ episode report: {'average_total_reward': 9.199, 'reward_variance': 2.019589, 'max_total_reward': 11.23, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5067158460617067, 'actor_loss': -5.579172277450562, 'hyper_actor_loss': 0.010348273254930974, 'behavior_loss': 0.2787570357322693, 'mean_batch': 7.4306886196136475, 'min_batch': 7.12910680770874, 'max_batch': 7.648150634765625}
step: 49010 @ episode report: {'average_total_reward': 9.321001, 'reward_variance': 1.4121692, 'max_total_reward': 11.23, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.056993532180786, 'actor_loss': -5.561585235595703, 'hyper_actor_loss': 0.0105444747954607, 'behavior_loss': 0.2666676178574562, 'mean_batch': 7.349106359481811, 'min_batch': 7.082632732391358, 'max_batch': 7.546828079223633}
step: 49020 @ episode report: {'average_total_reward': 9.932001, 'reward_variance': 2.1627364, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6542165607213972, 'actor_loss': -5.5685203075408936, 'hyper_actor_loss': 0.01039153067395091, 'behavior_loss': 0.26499767154455184, 'mean_batch': 7.379773950576782, 'min_batch': 7.10224289894104, 'max_batch': 7.582978630065918}
step: 49030 @ episode report: {'average_total_reward': 10.1310005, 'reward_variance': 1.6527693, 'max_total_reward': 12.34, 'min_total_reward': 6.8999996, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7744908809661863, 'actor_loss': -5.569254636764526, 'hyper_actor_loss': 0.01047146124765277, 'behavior_loss': 0.28007072806358335, 'mean_batch': 7.406078767776489, 'min_batch': 7.081954669952393, 'max_batch': 7.6137168407440186}
step: 49040 @ episode report: {'average_total_reward': 9.166, 'reward_variance': 5.0162654, 'max_total_reward': 13.450001, 'min_total_reward': 4.35, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.890768599510193, 'actor_loss': -5.53395357131958, 'hyper_actor_loss': 0.010622997302561998, 'behavior_loss': 0.29899033308029177, 'mean_batch': 7.277531290054322, 'min_batch': 6.957685899734497, 'max_batch': 7.47650146484375}
step: 49050 @ episode report: {'average_total_reward': 8.034, 'reward_variance': 2.3679242, 'max_total_reward': 10.12, 'min_total_reward': 4.46, 'average_n_step': 9.2, 'max_n_step': 11.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7082030534744264, 'actor_loss': -5.537399625778198, 'hyper_actor_loss': 0.010568576026707887, 'behavior_loss': 0.2657113492488861, 'mean_batch': 7.304406642913818, 'min_batch': 6.9556700706481935, 'max_batch': 7.505869340896607}
step: 49060 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 7.6793647, 'max_total_reward': 14.56, 'min_total_reward': 4.6800003, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.202426826953888, 'actor_loss': -5.546382284164428, 'hyper_actor_loss': 0.010734977666288614, 'behavior_loss': 0.2818578094244003, 'mean_batch': 7.354482221603393, 'min_batch': 6.971247911453247, 'max_batch': 7.565134572982788}
step: 49070 @ episode report: {'average_total_reward': 10.254, 'reward_variance': 3.2167637, 'max_total_reward': 13.23, 'min_total_reward': 7.6800003, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1819376587867736, 'actor_loss': -5.556132888793945, 'hyper_actor_loss': 0.010796127934008836, 'behavior_loss': 0.27596504986286163, 'mean_batch': 7.355418014526367, 'min_batch': 7.03784327507019, 'max_batch': 7.553873777389526}
step: 49080 @ episode report: {'average_total_reward': 10.021, 'reward_variance': 5.0681295, 'max_total_reward': 14.2300005, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8750757455825804, 'actor_loss': -5.520543956756592, 'hyper_actor_loss': 0.010694951005280017, 'behavior_loss': 0.2774209275841713, 'mean_batch': 7.201078033447265, 'min_batch': 6.938201999664306, 'max_batch': 7.374570894241333}
step: 49090 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 1.3642842, 'max_total_reward': 11.009998, 'min_total_reward': 6.9, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.773758053779602, 'actor_loss': -5.503038692474365, 'hyper_actor_loss': 0.010810456704348326, 'behavior_loss': 0.27235320806503294, 'mean_batch': 7.163279485702515, 'min_batch': 6.854121685028076, 'max_batch': 7.325563240051269}
step: 49100 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 2.8302612, 'max_total_reward': 11.2300005, 'min_total_reward': 5.4599996, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.773728084564209, 'actor_loss': -5.557755661010742, 'hyper_actor_loss': 0.011020982544869185, 'behavior_loss': 0.2572847753763199, 'mean_batch': 7.373484373092651, 'min_batch': 7.032806491851806, 'max_batch': 7.56937689781189}
step: 49110 @ episode report: {'average_total_reward': 11.453001, 'reward_variance': 1.0809411, 'max_total_reward': 13.45, 'min_total_reward': 10.01, 'average_n_step': 12.3, 'max_n_step': 14.0, 'min_n_step': 11.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5857239723205567, 'actor_loss': -5.580011224746704, 'hyper_actor_loss': 0.011124461516737938, 'behavior_loss': 0.2727464079856873, 'mean_batch': 7.425295066833496, 'min_batch': 7.140031051635742, 'max_batch': 7.610298728942871}
step: 49120 @ episode report: {'average_total_reward': 10.931001, 'reward_variance': 4.210729, 'max_total_reward': 13.450001, 'min_total_reward': 7.79, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.527777624130249, 'actor_loss': -5.539465999603271, 'hyper_actor_loss': 0.011454734858125449, 'behavior_loss': 0.2686837688088417, 'mean_batch': 7.273856067657471, 'min_batch': 6.999717712402344, 'max_batch': 7.468459415435791}
step: 49130 @ episode report: {'average_total_reward': 9.854001, 'reward_variance': 1.1173441, 'max_total_reward': 12.2300005, 'min_total_reward': 8.9, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.392893612384796, 'actor_loss': -5.533704233169556, 'hyper_actor_loss': 0.01155565045773983, 'behavior_loss': 0.2803257375955582, 'mean_batch': 7.255922269821167, 'min_batch': 6.976451730728149, 'max_batch': 7.448355388641358}
step: 49140 @ episode report: {'average_total_reward': 9.721001, 'reward_variance': 2.127889, 'max_total_reward': 11.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9973057985305784, 'actor_loss': -5.543437576293945, 'hyper_actor_loss': 0.011907421238720416, 'behavior_loss': 0.2654915049672127, 'mean_batch': 7.277783203125, 'min_batch': 7.023239183425903, 'max_batch': 7.45430817604065}
step: 49150 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 3.3554254, 'max_total_reward': 13.45, 'min_total_reward': 7.68, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1433827638626095, 'actor_loss': -5.5372796058654785, 'hyper_actor_loss': 0.011580315418541431, 'behavior_loss': 0.28331142067909243, 'mean_batch': 7.260174131393432, 'min_batch': 6.997022867202759, 'max_batch': 7.44907956123352}
step: 49160 @ episode report: {'average_total_reward': 9.643, 'reward_variance': 3.3771415, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5233606100082397, 'actor_loss': -5.527178525924683, 'hyper_actor_loss': 0.011376025434583426, 'behavior_loss': 0.273845936357975, 'mean_batch': 7.219887828826904, 'min_batch': 6.965313863754273, 'max_batch': 7.400005102157593}
step: 49170 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 2.018021, 'max_total_reward': 11.2300005, 'min_total_reward': 6.9000006, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.638290214538574, 'actor_loss': -5.548956298828125, 'hyper_actor_loss': 0.011675964668393135, 'behavior_loss': 0.27859196215868, 'mean_batch': 7.340903425216675, 'min_batch': 7.0013960838317875, 'max_batch': 7.590341281890869}
step: 49180 @ episode report: {'average_total_reward': 10.698001, 'reward_variance': 5.172517, 'max_total_reward': 13.450001, 'min_total_reward': 6.6800003, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9206398606300352, 'actor_loss': -5.554852151870728, 'hyper_actor_loss': 0.01186651885509491, 'behavior_loss': 0.2842736229300499, 'mean_batch': 7.364496469497681, 'min_batch': 7.020553874969482, 'max_batch': 7.568765544891358}
step: 49190 @ episode report: {'average_total_reward': 9.277, 'reward_variance': 1.9841213, 'max_total_reward': 12.34, 'min_total_reward': 7.7899995, 'average_n_step': 10.3, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.259382820129394, 'actor_loss': -5.534483480453491, 'hyper_actor_loss': 0.011493591405451298, 'behavior_loss': 0.28569443374872205, 'mean_batch': 7.2998439311981205, 'min_batch': 6.940699720382691, 'max_batch': 7.503516578674317}
step: 49200 @ episode report: {'average_total_reward': 10.209002, 'reward_variance': 5.670331, 'max_total_reward': 13.340001, 'min_total_reward': 5.79, 'average_n_step': 11.1, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.925820159912109, 'actor_loss': -5.510128784179687, 'hyper_actor_loss': 0.01140592833980918, 'behavior_loss': 0.284770642220974, 'mean_batch': 7.200596570968628, 'min_batch': 6.866338062286377, 'max_batch': 7.413238191604615}
step: 49210 @ episode report: {'average_total_reward': 9.244, 'reward_variance': 3.3776448, 'max_total_reward': 13.340001, 'min_total_reward': 6.9, 'average_n_step': 10.3, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.633593440055847, 'actor_loss': -5.544007349014282, 'hyper_actor_loss': 0.011161989532411098, 'behavior_loss': 0.274114628136158, 'mean_batch': 7.321157693862915, 'min_batch': 6.9858685493469235, 'max_batch': 7.573924016952515}
step: 49220 @ episode report: {'average_total_reward': 9.81, 'reward_variance': 2.1089401, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.689482593536377, 'actor_loss': -5.549105930328369, 'hyper_actor_loss': 0.010939477197825908, 'behavior_loss': 0.26914230585098264, 'mean_batch': 7.343382358551025, 'min_batch': 7.000101137161255, 'max_batch': 7.551421976089477}
step: 49230 @ episode report: {'average_total_reward': 9.887, 'reward_variance': 5.4704804, 'max_total_reward': 13.45, 'min_total_reward': 4.68, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.189872694015503, 'actor_loss': -5.568181085586548, 'hyper_actor_loss': 0.011302733235061169, 'behavior_loss': 0.28900436013937, 'mean_batch': 7.40963568687439, 'min_batch': 7.071450519561767, 'max_batch': 7.655747270584106}
step: 49240 @ episode report: {'average_total_reward': 9.732, 'reward_variance': 3.313757, 'max_total_reward': 13.45, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.820251989364624, 'actor_loss': -5.583935260772705, 'hyper_actor_loss': 0.011449433397501707, 'behavior_loss': 0.263946621119976, 'mean_batch': 7.476589107513428, 'min_batch': 7.119068241119384, 'max_batch': 7.716763687133789}
step: 49250 @ episode report: {'average_total_reward': 9.932, 'reward_variance': 6.686297, 'max_total_reward': 12.340001, 'min_total_reward': 5.79, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3546167612075806, 'actor_loss': -5.565591049194336, 'hyper_actor_loss': 0.011220145877450705, 'behavior_loss': 0.26592386066913604, 'mean_batch': 7.410939455032349, 'min_batch': 7.052961587905884, 'max_batch': 7.651767301559448}
step: 49260 @ episode report: {'average_total_reward': 10.0980015, 'reward_variance': 4.169075, 'max_total_reward': 13.45, 'min_total_reward': 6.9, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5259841442108155, 'actor_loss': -5.583320760726929, 'hyper_actor_loss': 0.011054011899977923, 'behavior_loss': 0.2853082776069641, 'mean_batch': 7.453090476989746, 'min_batch': 7.137324810028076, 'max_batch': 7.713767957687378}
step: 49270 @ episode report: {'average_total_reward': 10.176001, 'reward_variance': 2.4488442, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.1148529052734375, 'actor_loss': -5.559927463531494, 'hyper_actor_loss': 0.011121668573468923, 'behavior_loss': 0.2786630839109421, 'mean_batch': 7.356262874603272, 'min_batch': 7.064049577713012, 'max_batch': 7.60283055305481}
step: 49280 @ episode report: {'average_total_reward': 9.721, 'reward_variance': 6.12167, 'max_total_reward': 13.45, 'min_total_reward': 5.79, 'average_n_step': 10.7, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5304731965065, 'actor_loss': -5.553673267364502, 'hyper_actor_loss': 0.011267313919961452, 'behavior_loss': 0.2788333386182785, 'mean_batch': 7.364250802993775, 'min_batch': 7.013801383972168, 'max_batch': 7.594273233413697}
step: 49290 @ episode report: {'average_total_reward': 9.821001, 'reward_variance': 3.4541092, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8051831841468813, 'actor_loss': -5.5740172386169435, 'hyper_actor_loss': 0.011880600266158581, 'behavior_loss': 0.266928993165493, 'mean_batch': 7.407890796661377, 'min_batch': 7.113962888717651, 'max_batch': 7.649218034744263}
step: 49300 @ episode report: {'average_total_reward': 10.754, 'reward_variance': 2.071384, 'max_total_reward': 12.34, 'min_total_reward': 8.570001, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.302763569355011, 'actor_loss': -5.571025419235229, 'hyper_actor_loss': 0.011524513363838196, 'behavior_loss': 0.28832319378852844, 'mean_batch': 7.41322431564331, 'min_batch': 7.087991237640381, 'max_batch': 7.633008241653442}
step: 49310 @ episode report: {'average_total_reward': 10.5980015, 'reward_variance': 1.9768763, 'max_total_reward': 13.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.102378034591675, 'actor_loss': -5.570016145706177, 'hyper_actor_loss': 0.011455748043954373, 'behavior_loss': 0.2753889784216881, 'mean_batch': 7.42142391204834, 'min_batch': 7.073181962966919, 'max_batch': 7.677954769134521}
step: 49320 @ episode report: {'average_total_reward': 9.210001, 'reward_variance': 7.4692397, 'max_total_reward': 12.01, 'min_total_reward': 3.46, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 5.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5133896589279177, 'actor_loss': -5.546156167984009, 'hyper_actor_loss': 0.011419420596212149, 'behavior_loss': 0.28931436836719515, 'mean_batch': 7.342917537689209, 'min_batch': 6.981424045562744, 'max_batch': 7.586046171188355}
step: 49330 @ episode report: {'average_total_reward': 10.975, 'reward_variance': 2.3563852, 'max_total_reward': 13.45, 'min_total_reward': 9.009999, 'average_n_step': 11.8, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8107689142227175, 'actor_loss': -5.557902860641479, 'hyper_actor_loss': 0.011221098341047763, 'behavior_loss': 0.2565285935997963, 'mean_batch': 7.3493725776672365, 'min_batch': 7.056157636642456, 'max_batch': 7.581315565109253}
step: 49340 @ episode report: {'average_total_reward': 9.477, 'reward_variance': 2.7105803, 'max_total_reward': 12.12, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.570556843280792, 'actor_loss': -5.554815816879272, 'hyper_actor_loss': 0.011190463416278362, 'behavior_loss': 0.28436139822006223, 'mean_batch': 7.32374758720398, 'min_batch': 7.058947896957397, 'max_batch': 7.560280895233154}
step: 49350 @ episode report: {'average_total_reward': 10.676001, 'reward_variance': 2.6010637, 'max_total_reward': 12.23, 'min_total_reward': 6.79, 'average_n_step': 11.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7167410850524902, 'actor_loss': -5.570847415924073, 'hyper_actor_loss': 0.011116626858711242, 'behavior_loss': 0.2737797379493713, 'mean_batch': 7.3909307479858395, 'min_batch': 7.1079730033874515, 'max_batch': 7.605422925949097}
step: 49360 @ episode report: {'average_total_reward': 9.466001, 'reward_variance': 2.253524, 'max_total_reward': 11.23, 'min_total_reward': 6.7899995, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6685386180877684, 'actor_loss': -5.564285039901733, 'hyper_actor_loss': 0.010978174302726984, 'behavior_loss': 0.28018504083156587, 'mean_batch': 7.375956964492798, 'min_batch': 7.075725078582764, 'max_batch': 7.616658735275268}
step: 49370 @ episode report: {'average_total_reward': 9.865, 'reward_variance': 2.8980653, 'max_total_reward': 12.34, 'min_total_reward': 6.7899995, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6735973000526427, 'actor_loss': -5.5664746284484865, 'hyper_actor_loss': 0.010882369987666608, 'behavior_loss': 0.25782545655965805, 'mean_batch': 7.38496356010437, 'min_batch': 7.082443141937256, 'max_batch': 7.624327516555786}
step: 49380 @ episode report: {'average_total_reward': 11.020001, 'reward_variance': 3.0080807, 'max_total_reward': 13.450001, 'min_total_reward': 7.5699997, 'average_n_step': 11.9, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.437547755241394, 'actor_loss': -5.592012977600097, 'hyper_actor_loss': 0.011216955352574587, 'behavior_loss': 0.28354686200618745, 'mean_batch': 7.490232849121094, 'min_batch': 7.163839673995971, 'max_batch': 7.747378158569336}
step: 49390 @ episode report: {'average_total_reward': 10.354001, 'reward_variance': 8.847324, 'max_total_reward': 14.34, 'min_total_reward': 5.6800003, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7817083835601806, 'actor_loss': -5.575754451751709, 'hyper_actor_loss': 0.011889989115297794, 'behavior_loss': 0.28780181258916854, 'mean_batch': 7.43332872390747, 'min_batch': 7.102877235412597, 'max_batch': 7.682727432250976}
step: 49400 @ episode report: {'average_total_reward': 9.777, 'reward_variance': 3.0183809, 'max_total_reward': 13.23, 'min_total_reward': 6.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.363763380050659, 'actor_loss': -5.5584447383880615, 'hyper_actor_loss': 0.011852210201323033, 'behavior_loss': 0.2897083878517151, 'mean_batch': 7.358364534378052, 'min_batch': 7.051204538345337, 'max_batch': 7.621300840377808}
step: 49410 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 4.4536495, 'max_total_reward': 12.34, 'min_total_reward': 5.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5501087307929993, 'actor_loss': -5.58092851638794, 'hyper_actor_loss': 0.012380593456327915, 'behavior_loss': 0.27918650954961777, 'mean_batch': 7.446416282653809, 'min_batch': 7.126644515991211, 'max_batch': 7.762304449081421}
step: 49420 @ episode report: {'average_total_reward': 9.055, 'reward_variance': 5.8883257, 'max_total_reward': 11.2300005, 'min_total_reward': 4.5699997, 'average_n_step': 10.1, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0820810317993166, 'actor_loss': -5.594654560089111, 'hyper_actor_loss': 0.01254341695457697, 'behavior_loss': 0.2767157882452011, 'mean_batch': 7.507938718795776, 'min_batch': 7.165770864486694, 'max_batch': 7.787431240081787}
step: 49430 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 1.4644418, 'max_total_reward': 11.2300005, 'min_total_reward': 7.79, 'average_n_step': 10.7, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.009149074554443, 'actor_loss': -5.561495780944824, 'hyper_actor_loss': 0.011776847206056118, 'behavior_loss': 0.27392019927501676, 'mean_batch': 7.382891511917114, 'min_batch': 7.05036358833313, 'max_batch': 7.653853034973144}
step: 49440 @ episode report: {'average_total_reward': 8.955, 'reward_variance': 4.889646, 'max_total_reward': 12.230001, 'min_total_reward': 4.6800003, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8439494609832763, 'actor_loss': -5.565808486938477, 'hyper_actor_loss': 0.011541173607110978, 'behavior_loss': 0.2849427595734596, 'mean_batch': 7.395232391357422, 'min_batch': 7.068520498275757, 'max_batch': 7.665197134017944}
step: 49450 @ episode report: {'average_total_reward': 9.488001, 'reward_variance': 2.250136, 'max_total_reward': 12.2300005, 'min_total_reward': 6.9, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9112290382385253, 'actor_loss': -5.599743366241455, 'hyper_actor_loss': 0.011592846643179656, 'behavior_loss': 0.2734953373670578, 'mean_batch': 7.512173509597778, 'min_batch': 7.198339891433716, 'max_batch': 7.8073619365692135}
step: 49460 @ episode report: {'average_total_reward': 9.133, 'reward_variance': 4.248261, 'max_total_reward': 13.45, 'min_total_reward': 6.68, 'average_n_step': 10.2, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.0336467027664185, 'actor_loss': -5.547272348403931, 'hyper_actor_loss': 0.011668124981224538, 'behavior_loss': 0.26890844404697417, 'mean_batch': 7.332349538803101, 'min_batch': 6.998755311965942, 'max_batch': 7.61596417427063}
step: 49470 @ episode report: {'average_total_reward': 10.243001, 'reward_variance': 1.7768005, 'max_total_reward': 12.339999, 'min_total_reward': 8.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.414293825626373, 'actor_loss': -5.535649347305298, 'hyper_actor_loss': 0.011490423511713744, 'behavior_loss': 0.28467670530080796, 'mean_batch': 7.300689220428467, 'min_batch': 6.947136402130127, 'max_batch': 7.580425071716308}
step: 49480 @ episode report: {'average_total_reward': 10.166, 'reward_variance': 6.4796247, 'max_total_reward': 14.34, 'min_total_reward': 6.7899995, 'average_n_step': 11.2, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9269798040390014, 'actor_loss': -5.537761688232422, 'hyper_actor_loss': 0.011693775746971368, 'behavior_loss': 0.2917369693517685, 'mean_batch': 7.29722580909729, 'min_batch': 6.96572093963623, 'max_batch': 7.596692991256714}
step: 49490 @ episode report: {'average_total_reward': 10.210001, 'reward_variance': 1.3384004, 'max_total_reward': 12.34, 'min_total_reward': 8.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3881851196289063, 'actor_loss': -5.5733214855194095, 'hyper_actor_loss': 0.011566106509417296, 'behavior_loss': 0.27931748479604723, 'mean_batch': 7.408756113052368, 'min_batch': 7.108881616592408, 'max_batch': 7.67378306388855}
step: 49500 @ episode report: {'average_total_reward': 10.587001, 'reward_variance': 2.3350005, 'max_total_reward': 13.45, 'min_total_reward': 8.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.693119502067566, 'actor_loss': -5.597207498550415, 'hyper_actor_loss': 0.011237639840692282, 'behavior_loss': 0.26456280052661896, 'mean_batch': 7.512886571884155, 'min_batch': 7.179525995254517, 'max_batch': 7.807151651382446}
step: 49510 @ episode report: {'average_total_reward': 9.9210005, 'reward_variance': 3.18937, 'max_total_reward': 13.450001, 'min_total_reward': 6.68, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9293524503707884, 'actor_loss': -5.579206466674805, 'hyper_actor_loss': 0.010949573293328286, 'behavior_loss': 0.2697782203555107, 'mean_batch': 7.460441207885742, 'min_batch': 7.1007853031158445, 'max_batch': 7.7522958278656}
step: 49520 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 2.7115495, 'max_total_reward': 13.2300005, 'min_total_reward': 6.68, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.573340582847595, 'actor_loss': -5.557669258117675, 'hyper_actor_loss': 0.01114950655028224, 'behavior_loss': 0.2887033879756927, 'mean_batch': 7.382269954681396, 'min_batch': 7.023951005935669, 'max_batch': 7.675945663452149}
step: 49530 @ episode report: {'average_total_reward': 10.065001, 'reward_variance': 1.7816454, 'max_total_reward': 12.34, 'min_total_reward': 7.9000006, 'average_n_step': 11.0, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9194437146186827, 'actor_loss': -5.571918535232544, 'hyper_actor_loss': 0.011126662231981754, 'behavior_loss': 0.26853002458810804, 'mean_batch': 7.446633338928223, 'min_batch': 7.063861751556397, 'max_batch': 7.729987335205078}
step: 49540 @ episode report: {'average_total_reward': 11.786, 'reward_variance': 1.9130634, 'max_total_reward': 13.45, 'min_total_reward': 9.01, 'average_n_step': 12.6, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.463217782974243, 'actor_loss': -5.602012586593628, 'hyper_actor_loss': 0.011648747604340315, 'behavior_loss': 0.27764950692653656, 'mean_batch': 7.521309566497803, 'min_batch': 7.205885219573974, 'max_batch': 7.797069454193116}
step: 49550 @ episode report: {'average_total_reward': 10.553, 'reward_variance': 2.455922, 'max_total_reward': 12.340001, 'min_total_reward': 6.8999996, 'average_n_step': 11.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.149526852369308, 'actor_loss': -5.574797201156616, 'hyper_actor_loss': 0.01147443037480116, 'behavior_loss': 0.2727908819913864, 'mean_batch': 7.4149473190307615, 'min_batch': 7.113551330566406, 'max_batch': 7.720528030395508}
step: 49560 @ episode report: {'average_total_reward': 11.364001, 'reward_variance': 3.5661244, 'max_total_reward': 15.67, 'min_total_reward': 8.79, 'average_n_step': 12.2, 'max_n_step': 16.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.998617696762085, 'actor_loss': -5.545971059799195, 'hyper_actor_loss': 0.01194733688607812, 'behavior_loss': 0.2737398833036423, 'mean_batch': 7.316326141357422, 'min_batch': 7.004565048217773, 'max_batch': 7.578832721710205}
step: 49570 @ episode report: {'average_total_reward': 10.642, 'reward_variance': 4.021497, 'max_total_reward': 13.45, 'min_total_reward': 6.79, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9049192667007446, 'actor_loss': -5.567830610275268, 'hyper_actor_loss': 0.011675538867712021, 'behavior_loss': 0.27137941122055054, 'mean_batch': 7.413268327713013, 'min_batch': 7.065635442733765, 'max_batch': 7.772799015045166}
step: 49580 @ episode report: {'average_total_reward': 9.909, 'reward_variance': 5.6534095, 'max_total_reward': 13.450001, 'min_total_reward': 5.79, 'average_n_step': 10.8, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.0533993244171143, 'actor_loss': -5.57333517074585, 'hyper_actor_loss': 0.011246184166520835, 'behavior_loss': 0.27261286675930024, 'mean_batch': 7.480336999893188, 'min_batch': 7.041966581344605, 'max_batch': 7.87405686378479}
step: 49590 @ episode report: {'average_total_reward': 10.387001, 'reward_variance': 2.5013819, 'max_total_reward': 13.450001, 'min_total_reward': 7.9, 'average_n_step': 11.3, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.675249457359314, 'actor_loss': -5.559085083007813, 'hyper_actor_loss': 0.010880072508007288, 'behavior_loss': 0.28494070619344714, 'mean_batch': 7.351573038101196, 'min_batch': 7.062566328048706, 'max_batch': 7.645595359802246}
step: 49600 @ episode report: {'average_total_reward': 9.942999, 'reward_variance': 6.0346007, 'max_total_reward': 13.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9332125186920166, 'actor_loss': -5.56716480255127, 'hyper_actor_loss': 0.0110274869017303, 'behavior_loss': 0.2873736724257469, 'mean_batch': 7.379770183563233, 'min_batch': 7.092206811904907, 'max_batch': 7.689625978469849}
step: 49610 @ episode report: {'average_total_reward': 10.376001, 'reward_variance': 1.4249836, 'max_total_reward': 12.34, 'min_total_reward': 8.9, 'average_n_step': 11.3, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.1851038932800293, 'actor_loss': -5.542451667785644, 'hyper_actor_loss': 0.010930380038917064, 'behavior_loss': 0.2659877121448517, 'mean_batch': 7.312116241455078, 'min_batch': 6.983456707000732, 'max_batch': 7.614746809005737}
step: 49620 @ episode report: {'average_total_reward': 10.165001, 'reward_variance': 0.8481253, 'max_total_reward': 12.340001, 'min_total_reward': 9.01, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2379873394966125, 'actor_loss': -5.567065811157226, 'hyper_actor_loss': 0.01114923832938075, 'behavior_loss': 0.26531519591808317, 'mean_batch': 7.4214598655700685, 'min_batch': 7.051851749420166, 'max_batch': 7.746226787567139}
step: 49630 @ episode report: {'average_total_reward': 10.254001, 'reward_variance': 3.9707646, 'max_total_reward': 13.34, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.6108602523803714, 'actor_loss': -5.544022178649902, 'hyper_actor_loss': 0.011397423781454563, 'behavior_loss': 0.2770059809088707, 'mean_batch': 7.336707639694214, 'min_batch': 6.972535181045532, 'max_batch': 7.648045206069947}
step: 49640 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 3.4859154, 'max_total_reward': 13.45, 'min_total_reward': 6.6800003, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8508436918258666, 'actor_loss': -5.488933658599853, 'hyper_actor_loss': 0.011210541520267726, 'behavior_loss': 0.27203699946403503, 'mean_batch': 7.159577369689941, 'min_batch': 6.762551736831665, 'max_batch': 7.466087532043457}
step: 49650 @ episode report: {'average_total_reward': 10.576001, 'reward_variance': 1.5945834, 'max_total_reward': 13.01, 'min_total_reward': 8.900001, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8032862901687623, 'actor_loss': -5.533531904220581, 'hyper_actor_loss': 0.01155197536572814, 'behavior_loss': 0.2783990278840065, 'mean_batch': 7.320200490951538, 'min_batch': 6.915967512130737, 'max_batch': 7.649449110031128}
step: 49660 @ episode report: {'average_total_reward': 9.299001, 'reward_variance': 1.432629, 'max_total_reward': 11.12, 'min_total_reward': 6.8999996, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6046910524368285, 'actor_loss': -5.554073619842529, 'hyper_actor_loss': 0.0115067926235497, 'behavior_loss': 0.26781186908483506, 'mean_batch': 7.398340559005737, 'min_batch': 6.984973382949829, 'max_batch': 7.706151056289673}
step: 49670 @ episode report: {'average_total_reward': 10.42, 'reward_variance': 8.366279, 'max_total_reward': 14.559999, 'min_total_reward': 6.79, 'average_n_step': 11.3, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.2640433549880985, 'actor_loss': -5.540611410140992, 'hyper_actor_loss': 0.01121248323470354, 'behavior_loss': 0.2700998976826668, 'mean_batch': 7.37005763053894, 'min_batch': 6.917088460922241, 'max_batch': 7.728150224685669}
step: 49680 @ episode report: {'average_total_reward': 9.621, 'reward_variance': 2.936289, 'max_total_reward': 12.34, 'min_total_reward': 6.5699997, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.718223714828491, 'actor_loss': -5.523523426055908, 'hyper_actor_loss': 0.011058624740689993, 'behavior_loss': 0.277810038626194, 'mean_batch': 7.263066148757934, 'min_batch': 6.899114990234375, 'max_batch': 7.6263751029968265}
step: 49690 @ episode report: {'average_total_reward': 9.954, 'reward_variance': 3.2807446, 'max_total_reward': 12.34, 'min_total_reward': 7.8999996, 'average_n_step': 10.9, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.045564675331116, 'actor_loss': -5.55685133934021, 'hyper_actor_loss': 0.011211587022989989, 'behavior_loss': 0.28322445005178454, 'mean_batch': 7.4275373935699465, 'min_batch': 6.9763665199279785, 'max_batch': 7.871215963363648}
step: 49700 @ episode report: {'average_total_reward': 8.977, 'reward_variance': 5.3820014, 'max_total_reward': 14.34, 'min_total_reward': 6.79, 'average_n_step': 10.0, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6789659023284913, 'actor_loss': -5.483847904205322, 'hyper_actor_loss': 0.011492797452956439, 'behavior_loss': 0.2757125720381737, 'mean_batch': 7.187491512298584, 'min_batch': 6.7031444072723385, 'max_batch': 7.547152280807495}
step: 49710 @ episode report: {'average_total_reward': 9.677, 'reward_variance': 3.403461, 'max_total_reward': 12.2300005, 'min_total_reward': 6.57, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.317744994163513, 'actor_loss': -5.519293737411499, 'hyper_actor_loss': 0.011564749199897051, 'behavior_loss': 0.26435118317604067, 'mean_batch': 7.338766193389892, 'min_batch': 6.8043742179870605, 'max_batch': 7.718822956085205}
step: 49720 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 4.5175858, 'max_total_reward': 14.56, 'min_total_reward': 6.6800003, 'average_n_step': 10.9, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9081016540527345, 'actor_loss': -5.5357810974121096, 'hyper_actor_loss': 0.011344504170119762, 'behavior_loss': 0.28505606651306153, 'mean_batch': 7.330985975265503, 'min_batch': 6.92083511352539, 'max_batch': 7.674080085754395}
step: 49730 @ episode report: {'average_total_reward': 9.521001, 'reward_variance': 2.3091292, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.5, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.9672929763793947, 'actor_loss': -5.496024322509766, 'hyper_actor_loss': 0.011689526494592428, 'behavior_loss': 0.2746968105435371, 'mean_batch': 7.146157550811767, 'min_batch': 6.821951389312744, 'max_batch': 7.434347248077392}
step: 49740 @ episode report: {'average_total_reward': 9.610001, 'reward_variance': 3.5138793, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7527104139328005, 'actor_loss': -5.514475965499878, 'hyper_actor_loss': 0.012123545166105032, 'behavior_loss': 0.26888606399297715, 'mean_batch': 7.267654514312744, 'min_batch': 6.835480880737305, 'max_batch': 7.559207963943481}
step: 49750 @ episode report: {'average_total_reward': 11.0529995, 'reward_variance': 3.1585007, 'max_total_reward': 14.45, 'min_total_reward': 7.9, 'average_n_step': 11.9, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.539835524559021, 'actor_loss': -5.538263845443725, 'hyper_actor_loss': 0.011755161825567484, 'behavior_loss': 0.2668809205293655, 'mean_batch': 7.393223762512207, 'min_batch': 6.8815820693969725, 'max_batch': 7.667157363891602}
step: 49760 @ episode report: {'average_total_reward': 10.154001, 'reward_variance': 1.9602045, 'max_total_reward': 12.2300005, 'min_total_reward': 7.8999996, 'average_n_step': 11.1, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.201555943489075, 'actor_loss': -5.563598489761352, 'hyper_actor_loss': 0.011625620629638433, 'behavior_loss': 0.2610434338450432, 'mean_batch': 7.420729160308838, 'min_batch': 7.029014301300049, 'max_batch': 7.733421516418457}
step: 49770 @ episode report: {'average_total_reward': 9.688001, 'reward_variance': 2.943456, 'max_total_reward': 12.34, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.791307818889618, 'actor_loss': -5.541934251785278, 'hyper_actor_loss': 0.012128041684627533, 'behavior_loss': 0.2811223641037941, 'mean_batch': 7.344679737091065, 'min_batch': 6.951500368118286, 'max_batch': 7.7161292552948}
step: 49780 @ episode report: {'average_total_reward': 10.731, 'reward_variance': 4.5635486, 'max_total_reward': 13.45, 'min_total_reward': 5.57, 'average_n_step': 11.6, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7466543197631834, 'actor_loss': -5.530531978607177, 'hyper_actor_loss': 0.012231092713773251, 'behavior_loss': 0.26104279309511186, 'mean_batch': 7.2595987796783445, 'min_batch': 6.950518226623535, 'max_batch': 7.532290506362915}
step: 49790 @ episode report: {'average_total_reward': 10.509001, 'reward_variance': 2.467669, 'max_total_reward': 13.34, 'min_total_reward': 7.9, 'average_n_step': 11.4, 'max_n_step': 14.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5784908533096313, 'actor_loss': -5.543171310424805, 'hyper_actor_loss': 0.01207240903750062, 'behavior_loss': 0.27495153695344926, 'mean_batch': 7.318975353240967, 'min_batch': 6.981716728210449, 'max_batch': 7.590885877609253}
step: 49800 @ episode report: {'average_total_reward': 9.554001, 'reward_variance': 4.3419437, 'max_total_reward': 11.2300005, 'min_total_reward': 4.68, 'average_n_step': 10.5, 'max_n_step': 12.0, 'min_n_step': 6.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5184870958328247, 'actor_loss': -5.529671382904053, 'hyper_actor_loss': 0.01225212449207902, 'behavior_loss': 0.2755965799093246, 'mean_batch': 7.330305910110473, 'min_batch': 6.879371595382691, 'max_batch': 7.642037630081177}
step: 49810 @ episode report: {'average_total_reward': 8.844, 'reward_variance': 2.866004, 'max_total_reward': 11.12, 'min_total_reward': 5.4599996, 'average_n_step': 9.9, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.5615933656692507, 'actor_loss': -5.560106992721558, 'hyper_actor_loss': 0.012066621333360672, 'behavior_loss': 0.28046970814466476, 'mean_batch': 7.401455211639404, 'min_batch': 7.022729063034058, 'max_batch': 7.725883817672729}
step: 49820 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 6.4267416, 'max_total_reward': 14.56, 'min_total_reward': 6.79, 'average_n_step': 10.7, 'max_n_step': 15.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.303420662879944, 'actor_loss': -5.556580972671509, 'hyper_actor_loss': 0.012189110647886992, 'behavior_loss': 0.26824816316366196, 'mean_batch': 7.341079664230347, 'min_batch': 7.054568672180176, 'max_batch': 7.582609224319458}
step: 49830 @ episode report: {'average_total_reward': 9.966001, 'reward_variance': 4.8947635, 'max_total_reward': 13.45, 'min_total_reward': 5.46, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7861409425735473, 'actor_loss': -5.547600984573364, 'hyper_actor_loss': 0.012471272330731153, 'behavior_loss': 0.27596399635076524, 'mean_batch': 7.360314989089966, 'min_batch': 6.973780536651612, 'max_batch': 7.70121750831604}
step: 49840 @ episode report: {'average_total_reward': 9.809999, 'reward_variance': 2.4558806, 'max_total_reward': 12.23, 'min_total_reward': 6.6799994, 'average_n_step': 10.8, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.161671996116638, 'actor_loss': -5.567527627944946, 'hyper_actor_loss': 0.012096883915364742, 'behavior_loss': 0.27724475264549253, 'mean_batch': 7.38383116722107, 'min_batch': 7.091214275360107, 'max_batch': 7.709824275970459}
step: 49850 @ episode report: {'average_total_reward': 10.874999, 'reward_variance': 3.673905, 'max_total_reward': 12.340001, 'min_total_reward': 6.9, 'average_n_step': 11.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.2654003739356994, 'actor_loss': -5.577735376358032, 'hyper_actor_loss': 0.012072379514575005, 'behavior_loss': 0.24749853312969208, 'mean_batch': 7.450244808197022, 'min_batch': 7.100043058395386, 'max_batch': 7.815935325622559}
step: 49860 @ episode report: {'average_total_reward': 10.287001, 'reward_variance': 2.1471016, 'max_total_reward': 12.340001, 'min_total_reward': 7.79, 'average_n_step': 11.2, 'max_n_step': 13.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.708931088447571, 'actor_loss': -5.5765509605407715, 'hyper_actor_loss': 0.011891653481870889, 'behavior_loss': 0.2744938015937805, 'mean_batch': 7.467936563491821, 'min_batch': 7.074886846542358, 'max_batch': 7.8245237350463865}
step: 49870 @ episode report: {'average_total_reward': 9.599001, 'reward_variance': 2.4329097, 'max_total_reward': 12.2300005, 'min_total_reward': 6.79, 'average_n_step': 10.6, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 4.098352003097534, 'actor_loss': -5.555156183242798, 'hyper_actor_loss': 0.011883667856454849, 'behavior_loss': 0.28659123331308367, 'mean_batch': 7.385759687423706, 'min_batch': 7.002438068389893, 'max_batch': 7.722205686569214}
step: 49880 @ episode report: {'average_total_reward': 9.4210005, 'reward_variance': 3.60669, 'max_total_reward': 14.56, 'min_total_reward': 7.68, 'average_n_step': 10.4, 'max_n_step': 15.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.7987322330474855, 'actor_loss': -5.553388929367065, 'hyper_actor_loss': 0.012152696866542101, 'behavior_loss': 0.26425431966781615, 'mean_batch': 7.405805873870849, 'min_batch': 6.972100687026978, 'max_batch': 7.791991710662842}
step: 49890 @ episode report: {'average_total_reward': 8.933001, 'reward_variance': 4.140001, 'max_total_reward': 11.2300005, 'min_total_reward': 5.57, 'average_n_step': 10.0, 'max_n_step': 12.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8710107088088987, 'actor_loss': -5.54624924659729, 'hyper_actor_loss': 0.012414465844631194, 'behavior_loss': 0.28488310128450395, 'mean_batch': 7.389260149002075, 'min_batch': 6.938381671905518, 'max_batch': 7.716514301300049}
step: 49900 @ episode report: {'average_total_reward': 9.699, 'reward_variance': 2.6026888, 'max_total_reward': 12.2300005, 'min_total_reward': 5.7900004, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.4072295904159544, 'actor_loss': -5.5732934951782225, 'hyper_actor_loss': 0.012736092600971461, 'behavior_loss': 0.27780747711658477, 'mean_batch': 7.472795391082764, 'min_batch': 7.049727582931519, 'max_batch': 7.801095294952392}
step: 49910 @ episode report: {'average_total_reward': 10.609, 'reward_variance': 1.6281894, 'max_total_reward': 13.120001, 'min_total_reward': 9.009999, 'average_n_step': 11.5, 'max_n_step': 14.0, 'min_n_step': 10.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.861645781993866, 'actor_loss': -5.615880870819092, 'hyper_actor_loss': 0.012679815199226141, 'behavior_loss': 0.26702144742012024, 'mean_batch': 7.64135217666626, 'min_batch': 7.193317985534668, 'max_batch': 7.982236003875732}
step: 49920 @ episode report: {'average_total_reward': 9.211, 'reward_variance': 1.0827893, 'max_total_reward': 11.2300005, 'min_total_reward': 7.5699997, 'average_n_step': 10.3, 'max_n_step': 12.0, 'min_n_step': 9.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8348299741744993, 'actor_loss': -5.624603366851806, 'hyper_actor_loss': 0.012936337385326624, 'behavior_loss': 0.23705983757972718, 'mean_batch': 7.61822247505188, 'min_batch': 7.276818895339966, 'max_batch': 7.959420919418335}
step: 49930 @ episode report: {'average_total_reward': 9.965, 'reward_variance': 2.8925447, 'max_total_reward': 13.23, 'min_total_reward': 6.7900004, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.9753854751586912, 'actor_loss': -5.599642610549926, 'hyper_actor_loss': 0.012848655693233013, 'behavior_loss': 0.2708605334162712, 'mean_batch': 7.523117923736573, 'min_batch': 7.18706955909729, 'max_batch': 7.798085021972656}
step: 49940 @ episode report: {'average_total_reward': 9.965001, 'reward_variance': 3.3145442, 'max_total_reward': 13.23, 'min_total_reward': 6.9, 'average_n_step': 10.9, 'max_n_step': 14.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.234121060371399, 'actor_loss': -5.586045408248902, 'hyper_actor_loss': 0.013295853044837713, 'behavior_loss': 0.28267085999250413, 'mean_batch': 7.454621934890747, 'min_batch': 7.155002593994141, 'max_batch': 7.724755811691284}
step: 49950 @ episode report: {'average_total_reward': 8.988, 'reward_variance': 4.000556, 'max_total_reward': 12.34, 'min_total_reward': 5.7900004, 'average_n_step': 10.0, 'max_n_step': 13.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.6328389167785646, 'actor_loss': -5.569933605194092, 'hyper_actor_loss': 0.013429310731589794, 'behavior_loss': 0.27633834481239317, 'mean_batch': 7.3946021556854244, 'min_batch': 7.098197412490845, 'max_batch': 7.668386793136596}
step: 49960 @ episode report: {'average_total_reward': 10.032, 'reward_variance': 4.9714966, 'max_total_reward': 13.450001, 'min_total_reward': 5.7900004, 'average_n_step': 11.0, 'max_n_step': 14.0, 'min_n_step': 7.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.8749104499816895, 'actor_loss': -5.548469924926758, 'hyper_actor_loss': 0.013593461271375418, 'behavior_loss': 0.26965655833482743, 'mean_batch': 7.314202547073364, 'min_batch': 7.023434114456177, 'max_batch': 7.626275110244751}
step: 49970 @ episode report: {'average_total_reward': 9.399, 'reward_variance': 2.0285094, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.4, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.3872178316116335, 'actor_loss': -5.5687073230743405, 'hyper_actor_loss': 0.013874606043100358, 'behavior_loss': 0.27165035605430604, 'mean_batch': 7.4084827423095705, 'min_batch': 7.076362228393554, 'max_batch': 7.719831705093384}
step: 49980 @ episode report: {'average_total_reward': 9.188001, 'reward_variance': 2.522516, 'max_total_reward': 12.34, 'min_total_reward': 6.9, 'average_n_step': 10.2, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 2.8872698068618776, 'actor_loss': -5.586870431900024, 'hyper_actor_loss': 0.013718174304813147, 'behavior_loss': 0.27904058545827864, 'mean_batch': 7.464946365356445, 'min_batch': 7.1516705513000485, 'max_batch': 7.820415401458741}
step: 49990 @ episode report: {'average_total_reward': 9.743001, 'reward_variance': 3.3964412, 'max_total_reward': 12.230001, 'min_total_reward': 6.9, 'average_n_step': 10.7, 'max_n_step': 13.0, 'min_n_step': 8.0, 'buffer_size': 100000} @ step loss: {'critic_loss': 3.59924898147583, 'actor_loss': -5.5714503765106205, 'hyper_actor_loss': 0.014006466045975685, 'behavior_loss': 0.2744840383529663, 'mean_batch': 7.411296224594116, 'min_batch': 7.093553590774536, 'max_batch': 7.72130651473999}
